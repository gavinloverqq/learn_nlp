{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fine-Tune a Generative AI Model for Dialogue Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will fine-tune an existing LLM from Hugging Face for enhanced dialogue summarization. You will use the [FLAN-T5](https://huggingface.co/docs/transformers/model_doc/flan-t5) model, which provides a high quality instruction tuned model and can summarize text out of the box. To improve the inferences, you will explore a full fine-tuning approach and evaluate the results with ROUGE metrics. Then you will perform Parameter Efficient Fine-Tuning (PEFT), evaluate the resulting model and see that the benefits of PEFT outweigh the slightly-lower performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- [ 1 - Set up Kernel, Load Required Dependencies, Dataset and LLM](#1)\n",
    "  - [ 1.1 - Set up Kernel and Required Dependencies](#1.1)\n",
    "  - [ 1.2 - Load Dataset and LLM](#1.2)\n",
    "  - [ 1.3 - Test the Model with Zero Shot Inferencing](#1.3)\n",
    "- [ 2 - Perform Full Fine-Tuning](#2)\n",
    "  - [ 2.1 - Preprocess the Dialog-Summary Dataset](#2.1)\n",
    "  - [ 2.2 - Fine-Tune the Model with the Preprocessed Dataset](#2.2)\n",
    "  - [ 2.3 - Evaluate the Model Qualitatively (Human Evaluation)](#2.3)\n",
    "  - [ 2.4 - Evaluate the Model Quantitatively (with ROUGE Metric)](#2.4)\n",
    "- [ 3 - Perform Parameter Efficient Fine-Tuning (PEFT)](#3)\n",
    "  - [ 3.1 - Setup the PEFT/LoRA model for Fine-Tuning](#3.1)\n",
    "  - [ 3.2 - Train PEFT Adapter](#3.2)\n",
    "  - [ 3.3 - Evaluate the Model Qualitatively (Human Evaluation)](#3.3)\n",
    "  - [ 3.4 - Evaluate the Model Quantitatively (with ROUGE Metric)](#3.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Set up Kernel, Load Required Dependencies, Dataset and LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1.1'></a>\n",
    "### 1.1 - Set up Kernel and Required Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "To begin with, check that the kernel is selected correctly.\n",
    "\n",
    "<img src=\"images/kernel_set_up.png\" width=\"300\"/>\n",
    "\n",
    "If you click on that (top right of the screen), you'll be able to see and check the details of the image, kernel, and instance type.\n",
    "\n",
    "<img src=\"images/w2_kernel_and_instance_type.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now install the required packages for the LLM and datasets.\n",
    "\n",
    "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSIxMjUiIHZpZXdCb3g9IjAgMCA4MDAgMTI1IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogICAgPGRlZnM+CiAgICAgICAgPGxpbmVhckdyYWRpZW50IGlkPSJmYWRlR3JhZGllbnQiIHgxPSIwIiB4Mj0iMSI+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMCUiIHN0b3AtY29sb3I9IiNGMEYwRjAiLz4KICAgICAgICAgICAgPHN0b3Agb2Zmc2V0PSIxMDAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIiBzdG9wLW9wYWNpdHk9IjAiLz4KICAgICAgICA8L2xpbmVhckdyYWRpZW50PgogICAgICAgIDxtYXNrIGlkPSJmYWRlTWFzayI+CiAgICAgICAgICAgIDxyZWN0IHg9IjAiIHk9IjAiIHdpZHRoPSI3NTAiIGhlaWdodD0iMTI1IiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSIxMjUiIGZpbGw9InVybCgjZmFkZUdyYWRpZW50KSIvPgogICAgICAgIDwvbWFzaz4KICAgIDwvZGVmcz4KICAgIDxwYXRoIGQ9Ik0zLDUwIEE1MCw1MCAwIDAgMSA1MywzIEw3OTcsMyBMNzk3LDk3IEw5Nyw5NyBMNTAsMTE1IEwzLDk3IFoiIGZpbGw9IiNGMEYwRjAiIHN0cm9rZT0iI0UwRTBFMCIgc3Ryb2tlLXdpZHRoPSIxIiBtYXNrPSJ1cmwoI2ZhZGVNYXNrKSIvPgogICAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgcj0iMzAiIGZpbGw9IiM1N2M0ZjgiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIxIi8+CiAgICA8Y2lyY2xlIGN4PSI1MCIgY3k9IjUwIiByPSIyNSIgZmlsbD0iI0YwRjBGMCIvPgogICAgPGxpbmUgeDE9IjUwIiB5MT0iNTAiIHgyPSI1MCIgeTI9IjMwIiBzdHJva2U9IiM1N2M0ZjgiIHN0cm9rZS13aWR0aD0iMyIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIi8+CiAgICA8bGluZSB4MT0iNTAiIHkxPSI1MCIgeDI9IjY1IiB5Mj0iNTAiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIzIiBzdHJva2UtbGluZWNhcD0icm91bmQiLz4KICAgIDx0ZXh0IHg9IjEwMCIgeT0iMzQiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIxNCIgZmlsbD0iIzMzMzMzMyI+VGhlIG5leHQgY2VsbCBtYXkgdGFrZSBhIGZldyBtaW51dGVzIHRvIHJ1bi4gUGxlYXNlIGJlIHBhdGllbnQuPC90ZXh0PgogICAgPHRleHQgeD0iMTAwIiB5PSI1NiIgZm9udC1mYW1pbHk9IkFyaWFsLCBzYW5zLXNlcmlmIiBmb250LXNpemU9IjE0IiBmaWxsPSIjMzMzMzMzIj5JZ25vcmUgdGhlIHdhcm5pbmdzIGFuZCBlcnJvcnMsIGFsb25nIHdpdGggdGhlIG5vdGUgYWJvdXQgcmVzdGFydGluZyB0aGUga2VybmVsIGF0IHRoZSBlbmQuPC90ZXh0Pgo8L3N2Zz4K\" alt=\"Time alert open medium\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['all_proxy'] = \"socks5://127.0.0.1:10808\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /home/frog/anaconda3/envs/learning_dl/lib/python3.11/site-packages/huggingface_hub-0.17.2-py3.8.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pip in /home/frog/anaconda3/envs/learning_dl/lib/python3.11/site-packages (23.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mDEPRECATION: Loading egg at /home/frog/anaconda3/envs/learning_dl/lib/python3.11/site-packages/huggingface_hub-0.17.2-py3.8.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchdata==0.5.1 (from versions: 0.3.0a0, 0.3.0a1, 0.3.0, 0.6.0, 0.6.1)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torchdata==0.5.1\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mDEPRECATION: Loading egg at /home/frog/anaconda3/envs/learning_dl/lib/python3.11/site-packages/huggingface_hub-0.17.2-py3.8.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install --disable-pip-version-check \\\n",
    "    torch==1.13.1 \\\n",
    "    torchdata==0.5.1 --quiet\n",
    "\n",
    "%pip install \\\n",
    "    transformers==4.27.2 \\\n",
    "    datasets==2.11.0 \\\n",
    "    evaluate==0.4.0 \\\n",
    "    rouge_score==0.1.2 \\\n",
    "    loralib==0.1.1 \\\n",
    "    peft==0.3.0 --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSI1MCIgdmlld0JveD0iMCAwIDgwMCA1MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxkZWZzPgogICAgICAgIDxsaW5lYXJHcmFkaWVudCBpZD0iZmFkZUdyYWRpZW50IiB4MT0iMCIgeDI9IjEiPgogICAgICAgICAgICA8c3RvcCBvZmZzZXQ9IjAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIi8+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMTAwJSIgc3RvcC1jb2xvcj0iI0YwRjBGMCIgc3RvcC1vcGFjaXR5PSIwIi8+CiAgICAgICAgPC9saW5lYXJHcmFkaWVudD4KICAgICAgICA8bWFzayBpZD0iZmFkZU1hc2siPgogICAgICAgICAgICA8cmVjdCB4PSIwIiB5PSIwIiB3aWR0aD0iNzUwIiBoZWlnaHQ9IjUwIiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSI1MCIgZmlsbD0idXJsKCNmYWRlR3JhZGllbnQpIi8+CiAgICAgICAgPC9tYXNrPgogICAgPC9kZWZzPgogICAgPHBhdGggZD0iTTI1LDUwIFEwLDUwIDAsMjUgTDUwLDMgTDk3LDI1IEw3OTcsMjUgTDc5Nyw1MCBMMjUsNTAgWiIgZmlsbD0iI0YwRjBGMCIgc3Ryb2tlPSIjRTBFMEUwIiBzdHJva2Utd2lkdGg9IjEiIG1hc2s9InVybCgjZmFkZU1hc2spIi8+Cjwvc3ZnPgo=\" alt=\"Time alert close\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Import the necessary components. Some of them are new for this week, they will be discussed later in the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\n",
    "import torch\n",
    "import time\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name='1.2'></a>\n",
    "### 1.2 - Load Dataset and LLM\n",
    "\n",
    "You are going to continue experimenting with the [DialogSum](https://huggingface.co/datasets/knkarthick/dialogsum) Hugging Face dataset. It contains 10,000+ dialogues with the corresponding manually labeled summaries and topics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/frog/.cache/huggingface/datasets/knkarthick___csv/knkarthick--dialogsum-931380d0e19583fc/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ddb435a4dc434dafc5e1d50d6b6d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 12460\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
    "\n",
    "dataset = load_dataset(huggingface_dataset_name)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Load the pre-trained [FLAN-T5 model](https://huggingface.co/docs/transformers/model_doc/flan-t5) and its tokenizer directly from HuggingFace. Notice that you will be using the [small version](https://huggingface.co/google/flan-t5-base) of FLAN-T5. Setting `torch_dtype=torch.bfloat16` specifies the memory type to be used by this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name='google/flan-t5-base'\n",
    "\n",
    "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "It is possible to pull out the number of model parameters and find out how many of them are trainable. The following function can be used to do that, at this stage, you do not need to go into details of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 247577856\n",
      "all model parameters: 247577856\n",
      "percentage of trainable model parameters: 100.00%\n"
     ]
    }
   ],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(original_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name='1.3'></a>\n",
    "### 1.3 - Test the Model with Zero Shot Inferencing\n",
    "\n",
    "Test the model with the zero shot inferencing. You can see that the model struggles to summarize the dialogue compared to the baseline summary, but it does pull out some important information from the text which indicates the model can be fine-tuned to the task at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "\n",
      "Summarize the following conversation.\n",
      "\n",
      "#Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks.\n",
      "\n",
      "Summary:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - ZERO SHOT:\n",
      "#Person1#: I'm thinking of upgrading my computer.\n"
     ]
    }
   ],
   "source": [
    "index = 200\n",
    "\n",
    "dialogue = dataset['test'][index]['dialogue']\n",
    "summary = dataset['test'][index]['summary']\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "output = tokenizer.decode(\n",
    "    original_model.generate(\n",
    "        inputs[\"input_ids\"], \n",
    "        max_new_tokens=200,\n",
    "    )[0], \n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Perform Full Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name='2.1'></a>\n",
    "### 2.1 - Preprocess the Dialog-Summary Dataset\n",
    "\n",
    "You need to convert the dialog-summary (prompt-response) pairs into explicit instructions for the LLM. Prepend an instruction to the start of the dialog with `Summarize the following conversation` and to the start of the summary with `Summary` as follows:\n",
    "\n",
    "Training prompt (dialogue):\n",
    "```\n",
    "Summarize the following conversation.\n",
    "\n",
    "    Chris: This is his part of the conversation.\n",
    "    Antje: This is her part of the conversation.\n",
    "    \n",
    "Summary: \n",
    "```\n",
    "\n",
    "Training response (summary):\n",
    "```\n",
    "Both Chris and Antje participated in the conversation.\n",
    "```\n",
    "\n",
    "Then preprocess the prompt-response dataset into tokens and pull out their `input_ids` (1 per token)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/frog/.cache/huggingface/datasets/knkarthick___csv/knkarthick--dialogsum-931380d0e19583fc/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-3579c015ced2fa53.arrow\n",
      "Loading cached processed dataset at /home/frog/.cache/huggingface/datasets/knkarthick___csv/knkarthick--dialogsum-931380d0e19583fc/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-657b7992ea4cc6bb.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb69b67831043f4a598c0610892aa28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    start_prompt = 'Summarize the following conversation.\\n\\n'\n",
    "    end_prompt = '\\n\\nSummary: '\n",
    "    prompt = [start_prompt + dialogue + end_prompt for dialogue in example[\"dialogue\"]]\n",
    "    example['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    example['labels'] = tokenizer(example[\"summary\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    return example\n",
    "\n",
    "# The dataset actually contains 3 diff splits: train, validation, test.\n",
    "# The tokenize_function code is handling all data across all splits in batches.\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['id', 'topic', 'dialogue', 'summary',])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "To save some time in the lab, you will subsample the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenized_datasets = tokenized_datasets.filter(lambda example, index: index % 100 == 0, with_indices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Check the shapes of all three parts of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of the datasets:\n",
      "Training: (12460, 2)\n",
      "Validation: (500, 2)\n",
      "Test: (1500, 2)\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 12460\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 1500\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shapes of the datasets:\")\n",
    "print(f\"Training: {tokenized_datasets['train'].shape}\")\n",
    "print(f\"Validation: {tokenized_datasets['validation'].shape}\")\n",
    "print(f\"Test: {tokenized_datasets['test'].shape}\")\n",
    "\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output dataset is ready for fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2.2'></a>\n",
    "### 2.2 - Fine-Tune the Model with the Preprocessed Dataset\n",
    "\n",
    "Now utilize the built-in Hugging Face `Trainer` class (see the documentation [here](https://huggingface.co/docs/transformers/main_classes/trainer)). Pass the preprocessed dataset with reference to the original model. Other training parameters are found experimentally and there is no need to go into details about those at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = f'./dialogue-summary-training-{str(int(time.time()))}'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=1,\n",
    "    max_steps=5000\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=original_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Start training process...\n",
    "\n",
    "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSIxMjUiIHZpZXdCb3g9IjAgMCA4MDAgMTI1IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogICAgPGRlZnM+CiAgICAgICAgPGxpbmVhckdyYWRpZW50IGlkPSJmYWRlR3JhZGllbnQiIHgxPSIwIiB4Mj0iMSI+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMCUiIHN0b3AtY29sb3I9IiNGMEYwRjAiLz4KICAgICAgICAgICAgPHN0b3Agb2Zmc2V0PSIxMDAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIiBzdG9wLW9wYWNpdHk9IjAiLz4KICAgICAgICA8L2xpbmVhckdyYWRpZW50PgogICAgICAgIDxtYXNrIGlkPSJmYWRlTWFzayI+CiAgICAgICAgICAgIDxyZWN0IHg9IjAiIHk9IjAiIHdpZHRoPSI3NTAiIGhlaWdodD0iMTI1IiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSIxMjUiIGZpbGw9InVybCgjZmFkZUdyYWRpZW50KSIvPgogICAgICAgIDwvbWFzaz4KICAgIDwvZGVmcz4KICAgIDxwYXRoIGQ9Ik0zLDUwIEE1MCw1MCAwIDAgMSA1MywzIEw3OTcsMyBMNzk3LDk3IEw5Nyw5NyBMNTAsMTE1IEwzLDk3IFoiIGZpbGw9IiNGMEYwRjAiIHN0cm9rZT0iI0UwRTBFMCIgc3Ryb2tlLXdpZHRoPSIxIiBtYXNrPSJ1cmwoI2ZhZGVNYXNrKSIvPgogICAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgcj0iMzAiIGZpbGw9IiM1N2M0ZjgiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIxIi8+CiAgICA8Y2lyY2xlIGN4PSI1MCIgY3k9IjUwIiByPSIyNSIgZmlsbD0iI0YwRjBGMCIvPgogICAgPGxpbmUgeDE9IjUwIiB5MT0iNTAiIHgyPSI1MCIgeTI9IjMwIiBzdHJva2U9IiM1N2M0ZjgiIHN0cm9rZS13aWR0aD0iMyIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIi8+CiAgICA8bGluZSB4MT0iNTAiIHkxPSI1MCIgeDI9IjY1IiB5Mj0iNTAiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIzIiBzdHJva2UtbGluZWNhcD0icm91bmQiLz4KICAgIDx0ZXh0IHg9IjEwMCIgeT0iMzQiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIxNCIgZmlsbD0iIzMzMzMzMyI+VGhlIG5leHQgY2VsbCBtYXkgdGFrZSBhIGZldyBtaW51dGVzIHRvIHJ1bi4gUGxlYXNlIGJlIHBhdGllbnQuPC90ZXh0PgogICAgPHRleHQgeD0iMTAwIiB5PSI1NiIgZm9udC1mYW1pbHk9IkFyaWFsLCBzYW5zLXNlcmlmIiBmb250LXNpemU9IjE0IiBmaWxsPSIjMzMzMzMzIj5Zb3UgY2FuIHNhZmVseSBpZ25vcmUgdGhlIHdhcm5pbmcgbWVzc2FnZXMuPC90ZXh0Pgo8L3N2Zz4K\" alt=\"Time alert open medium\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb. init(mode=\"disabled\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d30c1f260ab499aba23720603309924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 49.5, 'learning_rate': 9.999e-06, 'epoch': 0.0}\n",
      "{'loss': 50.0, 'learning_rate': 9.998000000000002e-06, 'epoch': 0.0}\n",
      "{'loss': 49.5, 'learning_rate': 9.997000000000001e-06, 'epoch': 0.0}\n",
      "{'loss': 49.25, 'learning_rate': 9.996e-06, 'epoch': 0.0}\n",
      "{'loss': 48.0, 'learning_rate': 9.995000000000002e-06, 'epoch': 0.0}\n",
      "{'loss': 50.25, 'learning_rate': 9.994000000000001e-06, 'epoch': 0.0}\n",
      "{'loss': 48.25, 'learning_rate': 9.993e-06, 'epoch': 0.0}\n",
      "{'loss': 49.25, 'learning_rate': 9.992e-06, 'epoch': 0.01}\n",
      "{'loss': 47.25, 'learning_rate': 9.991000000000001e-06, 'epoch': 0.01}\n",
      "{'loss': 48.0, 'learning_rate': 9.990000000000001e-06, 'epoch': 0.01}\n",
      "{'loss': 49.0, 'learning_rate': 9.989e-06, 'epoch': 0.01}\n",
      "{'loss': 49.0, 'learning_rate': 9.988000000000002e-06, 'epoch': 0.01}\n",
      "{'loss': 49.5, 'learning_rate': 9.987000000000001e-06, 'epoch': 0.01}\n",
      "{'loss': 49.5, 'learning_rate': 9.986e-06, 'epoch': 0.01}\n",
      "{'loss': 47.75, 'learning_rate': 9.985000000000002e-06, 'epoch': 0.01}\n",
      "{'loss': 47.75, 'learning_rate': 9.984e-06, 'epoch': 0.01}\n",
      "{'loss': 45.5, 'learning_rate': 9.983e-06, 'epoch': 0.01}\n",
      "{'loss': 46.5, 'learning_rate': 9.982e-06, 'epoch': 0.01}\n",
      "{'loss': 48.0, 'learning_rate': 9.981000000000002e-06, 'epoch': 0.01}\n",
      "{'loss': 48.5, 'learning_rate': 9.980000000000001e-06, 'epoch': 0.01}\n",
      "{'loss': 48.75, 'learning_rate': 9.979e-06, 'epoch': 0.01}\n",
      "{'loss': 48.5, 'learning_rate': 9.978000000000002e-06, 'epoch': 0.01}\n",
      "{'loss': 47.75, 'learning_rate': 9.977000000000001e-06, 'epoch': 0.01}\n",
      "{'loss': 50.0, 'learning_rate': 9.976e-06, 'epoch': 0.02}\n",
      "{'loss': 48.25, 'learning_rate': 9.975000000000002e-06, 'epoch': 0.02}\n",
      "{'loss': 49.0, 'learning_rate': 9.974e-06, 'epoch': 0.02}\n",
      "{'loss': 45.5, 'learning_rate': 9.973000000000001e-06, 'epoch': 0.02}\n",
      "{'loss': 48.0, 'learning_rate': 9.972e-06, 'epoch': 0.02}\n",
      "{'loss': 46.25, 'learning_rate': 9.971e-06, 'epoch': 0.02}\n",
      "{'loss': 48.25, 'learning_rate': 9.970000000000001e-06, 'epoch': 0.02}\n",
      "{'loss': 48.5, 'learning_rate': 9.969e-06, 'epoch': 0.02}\n",
      "{'loss': 49.25, 'learning_rate': 9.968000000000002e-06, 'epoch': 0.02}\n",
      "{'loss': 47.25, 'learning_rate': 9.967000000000001e-06, 'epoch': 0.02}\n",
      "{'loss': 46.5, 'learning_rate': 9.966e-06, 'epoch': 0.02}\n",
      "{'loss': 47.5, 'learning_rate': 9.965000000000002e-06, 'epoch': 0.02}\n",
      "{'loss': 46.0, 'learning_rate': 9.964e-06, 'epoch': 0.02}\n",
      "{'loss': 46.75, 'learning_rate': 9.963000000000001e-06, 'epoch': 0.02}\n",
      "{'loss': 47.0, 'learning_rate': 9.962e-06, 'epoch': 0.02}\n",
      "{'loss': 45.75, 'learning_rate': 9.961e-06, 'epoch': 0.03}\n",
      "{'loss': 47.0, 'learning_rate': 9.960000000000001e-06, 'epoch': 0.03}\n",
      "{'loss': 48.5, 'learning_rate': 9.959e-06, 'epoch': 0.03}\n",
      "{'loss': 46.0, 'learning_rate': 9.958e-06, 'epoch': 0.03}\n",
      "{'loss': 47.25, 'learning_rate': 9.957000000000001e-06, 'epoch': 0.03}\n",
      "{'loss': 47.0, 'learning_rate': 9.956000000000001e-06, 'epoch': 0.03}\n",
      "{'loss': 47.25, 'learning_rate': 9.955000000000002e-06, 'epoch': 0.03}\n",
      "{'loss': 47.25, 'learning_rate': 9.954e-06, 'epoch': 0.03}\n",
      "{'loss': 47.5, 'learning_rate': 9.953000000000001e-06, 'epoch': 0.03}\n",
      "{'loss': 46.0, 'learning_rate': 9.952e-06, 'epoch': 0.03}\n",
      "{'loss': 45.75, 'learning_rate': 9.951e-06, 'epoch': 0.03}\n",
      "{'loss': 44.5, 'learning_rate': 9.950000000000001e-06, 'epoch': 0.03}\n",
      "{'loss': 48.25, 'learning_rate': 9.949e-06, 'epoch': 0.03}\n",
      "{'loss': 46.0, 'learning_rate': 9.948e-06, 'epoch': 0.03}\n",
      "{'loss': 45.75, 'learning_rate': 9.947000000000001e-06, 'epoch': 0.03}\n",
      "{'loss': 45.75, 'learning_rate': 9.946000000000001e-06, 'epoch': 0.03}\n",
      "{'loss': 47.5, 'learning_rate': 9.945e-06, 'epoch': 0.04}\n",
      "{'loss': 46.0, 'learning_rate': 9.944e-06, 'epoch': 0.04}\n",
      "{'loss': 45.5, 'learning_rate': 9.943000000000001e-06, 'epoch': 0.04}\n",
      "{'loss': 46.25, 'learning_rate': 9.942e-06, 'epoch': 0.04}\n",
      "{'loss': 45.25, 'learning_rate': 9.941e-06, 'epoch': 0.04}\n",
      "{'loss': 45.25, 'learning_rate': 9.940000000000001e-06, 'epoch': 0.04}\n",
      "{'loss': 45.0, 'learning_rate': 9.939000000000001e-06, 'epoch': 0.04}\n",
      "{'loss': 44.75, 'learning_rate': 9.938e-06, 'epoch': 0.04}\n",
      "{'loss': 46.5, 'learning_rate': 9.937000000000002e-06, 'epoch': 0.04}\n",
      "{'loss': 45.5, 'learning_rate': 9.936000000000001e-06, 'epoch': 0.04}\n",
      "{'loss': 45.25, 'learning_rate': 9.935e-06, 'epoch': 0.04}\n",
      "{'loss': 46.75, 'learning_rate': 9.934e-06, 'epoch': 0.04}\n",
      "{'loss': 45.75, 'learning_rate': 9.933e-06, 'epoch': 0.04}\n",
      "{'loss': 45.25, 'learning_rate': 9.932e-06, 'epoch': 0.04}\n",
      "{'loss': 44.25, 'learning_rate': 9.931e-06, 'epoch': 0.04}\n",
      "{'loss': 46.5, 'learning_rate': 9.930000000000001e-06, 'epoch': 0.04}\n",
      "{'loss': 44.75, 'learning_rate': 9.929000000000001e-06, 'epoch': 0.05}\n",
      "{'loss': 45.75, 'learning_rate': 9.928e-06, 'epoch': 0.05}\n",
      "{'loss': 44.5, 'learning_rate': 9.927000000000002e-06, 'epoch': 0.05}\n",
      "{'loss': 45.75, 'learning_rate': 9.926000000000001e-06, 'epoch': 0.05}\n",
      "{'loss': 45.0, 'learning_rate': 9.925e-06, 'epoch': 0.05}\n",
      "{'loss': 45.5, 'learning_rate': 9.924e-06, 'epoch': 0.05}\n",
      "{'loss': 45.25, 'learning_rate': 9.923e-06, 'epoch': 0.05}\n",
      "{'loss': 45.25, 'learning_rate': 9.922000000000001e-06, 'epoch': 0.05}\n",
      "{'loss': 43.0, 'learning_rate': 9.921e-06, 'epoch': 0.05}\n",
      "{'loss': 42.5, 'learning_rate': 9.920000000000002e-06, 'epoch': 0.05}\n",
      "{'loss': 44.5, 'learning_rate': 9.919000000000001e-06, 'epoch': 0.05}\n",
      "{'loss': 45.25, 'learning_rate': 9.918e-06, 'epoch': 0.05}\n",
      "{'loss': 43.5, 'learning_rate': 9.917000000000002e-06, 'epoch': 0.05}\n",
      "{'loss': 44.0, 'learning_rate': 9.916000000000001e-06, 'epoch': 0.05}\n",
      "{'loss': 43.75, 'learning_rate': 9.915e-06, 'epoch': 0.05}\n",
      "{'loss': 44.25, 'learning_rate': 9.914e-06, 'epoch': 0.06}\n",
      "{'loss': 43.75, 'learning_rate': 9.913e-06, 'epoch': 0.06}\n",
      "{'loss': 44.0, 'learning_rate': 9.912000000000001e-06, 'epoch': 0.06}\n",
      "{'loss': 44.25, 'learning_rate': 9.911e-06, 'epoch': 0.06}\n",
      "{'loss': 43.25, 'learning_rate': 9.91e-06, 'epoch': 0.06}\n",
      "{'loss': 42.0, 'learning_rate': 9.909000000000001e-06, 'epoch': 0.06}\n",
      "{'loss': 45.75, 'learning_rate': 9.908e-06, 'epoch': 0.06}\n",
      "{'loss': 43.75, 'learning_rate': 9.907000000000002e-06, 'epoch': 0.06}\n",
      "{'loss': 44.75, 'learning_rate': 9.906000000000001e-06, 'epoch': 0.06}\n",
      "{'loss': 43.75, 'learning_rate': 9.905000000000001e-06, 'epoch': 0.06}\n",
      "{'loss': 42.0, 'learning_rate': 9.904e-06, 'epoch': 0.06}\n",
      "{'loss': 43.5, 'learning_rate': 9.903e-06, 'epoch': 0.06}\n",
      "{'loss': 41.5, 'learning_rate': 9.902000000000001e-06, 'epoch': 0.06}\n",
      "{'loss': 44.25, 'learning_rate': 9.901e-06, 'epoch': 0.06}\n",
      "{'loss': 43.75, 'learning_rate': 9.9e-06, 'epoch': 0.06}\n",
      "{'loss': 44.25, 'learning_rate': 9.899000000000001e-06, 'epoch': 0.06}\n",
      "{'loss': 42.75, 'learning_rate': 9.898e-06, 'epoch': 0.07}\n",
      "{'loss': 43.5, 'learning_rate': 9.897e-06, 'epoch': 0.07}\n",
      "{'loss': 44.0, 'learning_rate': 9.896000000000001e-06, 'epoch': 0.07}\n",
      "{'loss': 42.5, 'learning_rate': 9.895000000000001e-06, 'epoch': 0.07}\n",
      "{'loss': 40.75, 'learning_rate': 9.894e-06, 'epoch': 0.07}\n",
      "{'loss': 41.5, 'learning_rate': 9.893e-06, 'epoch': 0.07}\n",
      "{'loss': 44.5, 'learning_rate': 9.892000000000001e-06, 'epoch': 0.07}\n",
      "{'loss': 42.25, 'learning_rate': 9.891e-06, 'epoch': 0.07}\n",
      "{'loss': 42.75, 'learning_rate': 9.89e-06, 'epoch': 0.07}\n",
      "{'loss': 42.0, 'learning_rate': 9.889000000000001e-06, 'epoch': 0.07}\n",
      "{'loss': 42.25, 'learning_rate': 9.888000000000001e-06, 'epoch': 0.07}\n",
      "{'loss': 43.0, 'learning_rate': 9.887e-06, 'epoch': 0.07}\n",
      "{'loss': 40.25, 'learning_rate': 9.886000000000002e-06, 'epoch': 0.07}\n",
      "{'loss': 42.25, 'learning_rate': 9.885000000000001e-06, 'epoch': 0.07}\n",
      "{'loss': 42.0, 'learning_rate': 9.884e-06, 'epoch': 0.07}\n",
      "{'loss': 43.75, 'learning_rate': 9.883e-06, 'epoch': 0.08}\n",
      "{'loss': 41.75, 'learning_rate': 9.882000000000001e-06, 'epoch': 0.08}\n",
      "{'loss': 42.75, 'learning_rate': 9.881e-06, 'epoch': 0.08}\n",
      "{'loss': 45.25, 'learning_rate': 9.88e-06, 'epoch': 0.08}\n",
      "{'loss': 41.75, 'learning_rate': 9.879000000000001e-06, 'epoch': 0.08}\n",
      "{'loss': 41.75, 'learning_rate': 9.878000000000001e-06, 'epoch': 0.08}\n",
      "{'loss': 41.25, 'learning_rate': 9.877e-06, 'epoch': 0.08}\n",
      "{'loss': 42.75, 'learning_rate': 9.876000000000002e-06, 'epoch': 0.08}\n",
      "{'loss': 43.25, 'learning_rate': 9.875000000000001e-06, 'epoch': 0.08}\n",
      "{'loss': 42.75, 'learning_rate': 9.874e-06, 'epoch': 0.08}\n",
      "{'loss': 41.5, 'learning_rate': 9.873e-06, 'epoch': 0.08}\n",
      "{'loss': 43.0, 'learning_rate': 9.872e-06, 'epoch': 0.08}\n",
      "{'loss': 43.25, 'learning_rate': 9.871000000000001e-06, 'epoch': 0.08}\n",
      "{'loss': 40.5, 'learning_rate': 9.87e-06, 'epoch': 0.08}\n",
      "{'loss': 44.25, 'learning_rate': 9.869000000000002e-06, 'epoch': 0.08}\n",
      "{'loss': 43.0, 'learning_rate': 9.868000000000001e-06, 'epoch': 0.08}\n",
      "{'loss': 42.5, 'learning_rate': 9.867e-06, 'epoch': 0.09}\n",
      "{'loss': 40.75, 'learning_rate': 9.866000000000002e-06, 'epoch': 0.09}\n",
      "{'loss': 43.75, 'learning_rate': 9.865000000000001e-06, 'epoch': 0.09}\n",
      "{'loss': 41.25, 'learning_rate': 9.864e-06, 'epoch': 0.09}\n",
      "{'loss': 42.0, 'learning_rate': 9.863e-06, 'epoch': 0.09}\n",
      "{'loss': 44.0, 'learning_rate': 9.862e-06, 'epoch': 0.09}\n",
      "{'loss': 41.75, 'learning_rate': 9.861000000000001e-06, 'epoch': 0.09}\n",
      "{'loss': 42.5, 'learning_rate': 9.86e-06, 'epoch': 0.09}\n",
      "{'loss': 41.25, 'learning_rate': 9.859e-06, 'epoch': 0.09}\n",
      "{'loss': 42.5, 'learning_rate': 9.858000000000001e-06, 'epoch': 0.09}\n",
      "{'loss': 42.25, 'learning_rate': 9.857e-06, 'epoch': 0.09}\n",
      "{'loss': 42.75, 'learning_rate': 9.856000000000002e-06, 'epoch': 0.09}\n",
      "{'loss': 40.75, 'learning_rate': 9.855000000000001e-06, 'epoch': 0.09}\n",
      "{'loss': 41.25, 'learning_rate': 9.854000000000001e-06, 'epoch': 0.09}\n",
      "{'loss': 40.5, 'learning_rate': 9.853e-06, 'epoch': 0.09}\n",
      "{'loss': 42.0, 'learning_rate': 9.852e-06, 'epoch': 0.09}\n",
      "{'loss': 41.5, 'learning_rate': 9.851000000000001e-06, 'epoch': 0.1}\n",
      "{'loss': 41.75, 'learning_rate': 9.85e-06, 'epoch': 0.1}\n",
      "{'loss': 41.0, 'learning_rate': 9.849e-06, 'epoch': 0.1}\n",
      "{'loss': 41.5, 'learning_rate': 9.848000000000001e-06, 'epoch': 0.1}\n",
      "{'loss': 41.5, 'learning_rate': 9.847e-06, 'epoch': 0.1}\n",
      "{'loss': 41.5, 'learning_rate': 9.846000000000002e-06, 'epoch': 0.1}\n",
      "{'loss': 40.75, 'learning_rate': 9.845000000000001e-06, 'epoch': 0.1}\n",
      "{'loss': 41.25, 'learning_rate': 9.844000000000001e-06, 'epoch': 0.1}\n",
      "{'loss': 43.0, 'learning_rate': 9.843e-06, 'epoch': 0.1}\n",
      "{'loss': 41.0, 'learning_rate': 9.842e-06, 'epoch': 0.1}\n",
      "{'loss': 41.25, 'learning_rate': 9.841000000000001e-06, 'epoch': 0.1}\n",
      "{'loss': 41.0, 'learning_rate': 9.84e-06, 'epoch': 0.1}\n",
      "{'loss': 41.0, 'learning_rate': 9.839e-06, 'epoch': 0.1}\n",
      "{'loss': 41.25, 'learning_rate': 9.838000000000001e-06, 'epoch': 0.1}\n",
      "{'loss': 39.75, 'learning_rate': 9.837000000000001e-06, 'epoch': 0.1}\n",
      "{'loss': 41.5, 'learning_rate': 9.836e-06, 'epoch': 0.11}\n",
      "{'loss': 39.5, 'learning_rate': 9.835000000000002e-06, 'epoch': 0.11}\n",
      "{'loss': 41.25, 'learning_rate': 9.834000000000001e-06, 'epoch': 0.11}\n",
      "{'loss': 40.25, 'learning_rate': 9.833e-06, 'epoch': 0.11}\n",
      "{'loss': 41.0, 'learning_rate': 9.832e-06, 'epoch': 0.11}\n",
      "{'loss': 41.0, 'learning_rate': 9.831000000000001e-06, 'epoch': 0.11}\n",
      "{'loss': 41.25, 'learning_rate': 9.83e-06, 'epoch': 0.11}\n",
      "{'loss': 40.5, 'learning_rate': 9.829e-06, 'epoch': 0.11}\n",
      "{'loss': 40.25, 'learning_rate': 9.828000000000001e-06, 'epoch': 0.11}\n",
      "{'loss': 41.75, 'learning_rate': 9.827000000000001e-06, 'epoch': 0.11}\n",
      "{'loss': 43.25, 'learning_rate': 9.826e-06, 'epoch': 0.11}\n",
      "{'loss': 39.75, 'learning_rate': 9.825000000000002e-06, 'epoch': 0.11}\n",
      "{'loss': 40.75, 'learning_rate': 9.824000000000001e-06, 'epoch': 0.11}\n",
      "{'loss': 41.25, 'learning_rate': 9.823e-06, 'epoch': 0.11}\n",
      "{'loss': 42.0, 'learning_rate': 9.822e-06, 'epoch': 0.11}\n",
      "{'loss': 41.5, 'learning_rate': 9.821000000000001e-06, 'epoch': 0.11}\n",
      "{'loss': 42.75, 'learning_rate': 9.820000000000001e-06, 'epoch': 0.12}\n",
      "{'loss': 42.0, 'learning_rate': 9.819e-06, 'epoch': 0.12}\n",
      "{'loss': 39.5, 'learning_rate': 9.818000000000002e-06, 'epoch': 0.12}\n",
      "{'loss': 40.25, 'learning_rate': 9.817000000000001e-06, 'epoch': 0.12}\n",
      "{'loss': 39.75, 'learning_rate': 9.816e-06, 'epoch': 0.12}\n",
      "{'loss': 38.75, 'learning_rate': 9.815000000000002e-06, 'epoch': 0.12}\n",
      "{'loss': 40.5, 'learning_rate': 9.814000000000001e-06, 'epoch': 0.12}\n",
      "{'loss': 40.5, 'learning_rate': 9.813e-06, 'epoch': 0.12}\n",
      "{'loss': 40.25, 'learning_rate': 9.812e-06, 'epoch': 0.12}\n",
      "{'loss': 40.75, 'learning_rate': 9.811e-06, 'epoch': 0.12}\n",
      "{'loss': 40.0, 'learning_rate': 9.810000000000001e-06, 'epoch': 0.12}\n",
      "{'loss': 41.25, 'learning_rate': 9.809e-06, 'epoch': 0.12}\n",
      "{'loss': 39.25, 'learning_rate': 9.808000000000002e-06, 'epoch': 0.12}\n",
      "{'loss': 41.5, 'learning_rate': 9.807000000000001e-06, 'epoch': 0.12}\n",
      "{'loss': 40.25, 'learning_rate': 9.806e-06, 'epoch': 0.12}\n",
      "{'loss': 38.75, 'learning_rate': 9.805000000000002e-06, 'epoch': 0.13}\n",
      "{'loss': 40.25, 'learning_rate': 9.804000000000001e-06, 'epoch': 0.13}\n",
      "{'loss': 40.25, 'learning_rate': 9.803e-06, 'epoch': 0.13}\n",
      "{'loss': 39.5, 'learning_rate': 9.802e-06, 'epoch': 0.13}\n",
      "{'loss': 40.25, 'learning_rate': 9.801e-06, 'epoch': 0.13}\n",
      "{'loss': 39.5, 'learning_rate': 9.800000000000001e-06, 'epoch': 0.13}\n",
      "{'loss': 40.0, 'learning_rate': 9.799e-06, 'epoch': 0.13}\n",
      "{'loss': 39.25, 'learning_rate': 9.798e-06, 'epoch': 0.13}\n",
      "{'loss': 41.0, 'learning_rate': 9.797000000000001e-06, 'epoch': 0.13}\n",
      "{'loss': 39.0, 'learning_rate': 9.796e-06, 'epoch': 0.13}\n",
      "{'loss': 39.75, 'learning_rate': 9.795000000000002e-06, 'epoch': 0.13}\n",
      "{'loss': 38.25, 'learning_rate': 9.794000000000001e-06, 'epoch': 0.13}\n",
      "{'loss': 38.0, 'learning_rate': 9.793000000000001e-06, 'epoch': 0.13}\n",
      "{'loss': 40.75, 'learning_rate': 9.792e-06, 'epoch': 0.13}\n",
      "{'loss': 38.0, 'learning_rate': 9.791e-06, 'epoch': 0.13}\n",
      "{'loss': 40.0, 'learning_rate': 9.790000000000001e-06, 'epoch': 0.13}\n",
      "{'loss': 39.0, 'learning_rate': 9.789e-06, 'epoch': 0.14}\n",
      "{'loss': 39.0, 'learning_rate': 9.788e-06, 'epoch': 0.14}\n",
      "{'loss': 38.75, 'learning_rate': 9.787000000000001e-06, 'epoch': 0.14}\n",
      "{'loss': 38.5, 'learning_rate': 9.786e-06, 'epoch': 0.14}\n",
      "{'loss': 37.75, 'learning_rate': 9.785e-06, 'epoch': 0.14}\n",
      "{'loss': 38.25, 'learning_rate': 9.784000000000002e-06, 'epoch': 0.14}\n",
      "{'loss': 40.25, 'learning_rate': 9.783000000000001e-06, 'epoch': 0.14}\n",
      "{'loss': 39.75, 'learning_rate': 9.782e-06, 'epoch': 0.14}\n",
      "{'loss': 39.0, 'learning_rate': 9.781e-06, 'epoch': 0.14}\n",
      "{'loss': 39.0, 'learning_rate': 9.780000000000001e-06, 'epoch': 0.14}\n",
      "{'loss': 39.0, 'learning_rate': 9.779e-06, 'epoch': 0.14}\n",
      "{'loss': 39.25, 'learning_rate': 9.778e-06, 'epoch': 0.14}\n",
      "{'loss': 39.5, 'learning_rate': 9.777000000000001e-06, 'epoch': 0.14}\n",
      "{'loss': 38.75, 'learning_rate': 9.776000000000001e-06, 'epoch': 0.14}\n",
      "{'loss': 38.5, 'learning_rate': 9.775e-06, 'epoch': 0.14}\n",
      "{'loss': 39.25, 'learning_rate': 9.774000000000002e-06, 'epoch': 0.15}\n",
      "{'loss': 39.0, 'learning_rate': 9.773e-06, 'epoch': 0.15}\n",
      "{'loss': 39.5, 'learning_rate': 9.772e-06, 'epoch': 0.15}\n",
      "{'loss': 39.5, 'learning_rate': 9.771e-06, 'epoch': 0.15}\n",
      "{'loss': 39.0, 'learning_rate': 9.770000000000001e-06, 'epoch': 0.15}\n",
      "{'loss': 38.5, 'learning_rate': 9.769e-06, 'epoch': 0.15}\n",
      "{'loss': 37.0, 'learning_rate': 9.768e-06, 'epoch': 0.15}\n",
      "{'loss': 39.0, 'learning_rate': 9.767000000000002e-06, 'epoch': 0.15}\n",
      "{'loss': 38.5, 'learning_rate': 9.766000000000001e-06, 'epoch': 0.15}\n",
      "{'loss': 39.0, 'learning_rate': 9.765e-06, 'epoch': 0.15}\n",
      "{'loss': 39.25, 'learning_rate': 9.764000000000002e-06, 'epoch': 0.15}\n",
      "{'loss': 38.5, 'learning_rate': 9.763e-06, 'epoch': 0.15}\n",
      "{'loss': 39.25, 'learning_rate': 9.762e-06, 'epoch': 0.15}\n",
      "{'loss': 38.75, 'learning_rate': 9.761e-06, 'epoch': 0.15}\n",
      "{'loss': 39.0, 'learning_rate': 9.760000000000001e-06, 'epoch': 0.15}\n",
      "{'loss': 37.75, 'learning_rate': 9.759000000000001e-06, 'epoch': 0.15}\n",
      "{'loss': 39.75, 'learning_rate': 9.758e-06, 'epoch': 0.16}\n",
      "{'loss': 38.0, 'learning_rate': 9.757000000000002e-06, 'epoch': 0.16}\n",
      "{'loss': 36.75, 'learning_rate': 9.756000000000001e-06, 'epoch': 0.16}\n",
      "{'loss': 38.5, 'learning_rate': 9.755e-06, 'epoch': 0.16}\n",
      "{'loss': 39.5, 'learning_rate': 9.754000000000002e-06, 'epoch': 0.16}\n",
      "{'loss': 38.0, 'learning_rate': 9.753e-06, 'epoch': 0.16}\n",
      "{'loss': 37.75, 'learning_rate': 9.752e-06, 'epoch': 0.16}\n",
      "{'loss': 37.0, 'learning_rate': 9.751e-06, 'epoch': 0.16}\n",
      "{'loss': 37.5, 'learning_rate': 9.75e-06, 'epoch': 0.16}\n",
      "{'loss': 38.5, 'learning_rate': 9.749000000000001e-06, 'epoch': 0.16}\n",
      "{'loss': 38.25, 'learning_rate': 9.748e-06, 'epoch': 0.16}\n",
      "{'loss': 38.75, 'learning_rate': 9.747000000000002e-06, 'epoch': 0.16}\n",
      "{'loss': 38.75, 'learning_rate': 9.746000000000001e-06, 'epoch': 0.16}\n",
      "{'loss': 38.25, 'learning_rate': 9.745e-06, 'epoch': 0.16}\n",
      "{'loss': 38.75, 'learning_rate': 9.744000000000002e-06, 'epoch': 0.16}\n",
      "{'loss': 38.5, 'learning_rate': 9.743000000000001e-06, 'epoch': 0.16}\n",
      "{'loss': 38.0, 'learning_rate': 9.742000000000001e-06, 'epoch': 0.17}\n",
      "{'loss': 39.5, 'learning_rate': 9.741e-06, 'epoch': 0.17}\n",
      "{'loss': 37.25, 'learning_rate': 9.74e-06, 'epoch': 0.17}\n",
      "{'loss': 38.0, 'learning_rate': 9.739000000000001e-06, 'epoch': 0.17}\n",
      "{'loss': 37.5, 'learning_rate': 9.738e-06, 'epoch': 0.17}\n",
      "{'loss': 38.5, 'learning_rate': 9.737e-06, 'epoch': 0.17}\n",
      "{'loss': 38.0, 'learning_rate': 9.736000000000001e-06, 'epoch': 0.17}\n",
      "{'loss': 36.5, 'learning_rate': 9.735e-06, 'epoch': 0.17}\n",
      "{'loss': 38.25, 'learning_rate': 9.734000000000002e-06, 'epoch': 0.17}\n",
      "{'loss': 38.25, 'learning_rate': 9.733000000000002e-06, 'epoch': 0.17}\n",
      "{'loss': 36.5, 'learning_rate': 9.732000000000001e-06, 'epoch': 0.17}\n",
      "{'loss': 38.25, 'learning_rate': 9.731e-06, 'epoch': 0.17}\n",
      "{'loss': 40.0, 'learning_rate': 9.73e-06, 'epoch': 0.17}\n",
      "{'loss': 38.75, 'learning_rate': 9.729000000000001e-06, 'epoch': 0.17}\n",
      "{'loss': 37.75, 'learning_rate': 9.728e-06, 'epoch': 0.17}\n",
      "{'loss': 38.25, 'learning_rate': 9.727e-06, 'epoch': 0.18}\n",
      "{'loss': 38.25, 'learning_rate': 9.726000000000001e-06, 'epoch': 0.18}\n",
      "{'loss': 37.5, 'learning_rate': 9.725000000000001e-06, 'epoch': 0.18}\n",
      "{'loss': 40.0, 'learning_rate': 9.724e-06, 'epoch': 0.18}\n",
      "{'loss': 36.75, 'learning_rate': 9.723000000000002e-06, 'epoch': 0.18}\n",
      "{'loss': 36.0, 'learning_rate': 9.722000000000001e-06, 'epoch': 0.18}\n",
      "{'loss': 37.5, 'learning_rate': 9.721e-06, 'epoch': 0.18}\n",
      "{'loss': 37.5, 'learning_rate': 9.72e-06, 'epoch': 0.18}\n",
      "{'loss': 38.0, 'learning_rate': 9.719000000000001e-06, 'epoch': 0.18}\n",
      "{'loss': 38.75, 'learning_rate': 9.718e-06, 'epoch': 0.18}\n",
      "{'loss': 38.0, 'learning_rate': 9.717e-06, 'epoch': 0.18}\n",
      "{'loss': 39.25, 'learning_rate': 9.716000000000002e-06, 'epoch': 0.18}\n",
      "{'loss': 34.75, 'learning_rate': 9.715000000000001e-06, 'epoch': 0.18}\n",
      "{'loss': 38.0, 'learning_rate': 9.714e-06, 'epoch': 0.18}\n",
      "{'loss': 38.0, 'learning_rate': 9.713000000000002e-06, 'epoch': 0.18}\n",
      "{'loss': 38.25, 'learning_rate': 9.712e-06, 'epoch': 0.18}\n",
      "{'loss': 36.75, 'learning_rate': 9.711e-06, 'epoch': 0.19}\n",
      "{'loss': 37.5, 'learning_rate': 9.71e-06, 'epoch': 0.19}\n",
      "{'loss': 37.0, 'learning_rate': 9.709000000000001e-06, 'epoch': 0.19}\n",
      "{'loss': 38.0, 'learning_rate': 9.708000000000001e-06, 'epoch': 0.19}\n",
      "{'loss': 36.5, 'learning_rate': 9.707e-06, 'epoch': 0.19}\n",
      "{'loss': 36.25, 'learning_rate': 9.706000000000002e-06, 'epoch': 0.19}\n",
      "{'loss': 36.75, 'learning_rate': 9.705000000000001e-06, 'epoch': 0.19}\n",
      "{'loss': 35.5, 'learning_rate': 9.704e-06, 'epoch': 0.19}\n",
      "{'loss': 37.25, 'learning_rate': 9.703000000000002e-06, 'epoch': 0.19}\n",
      "{'loss': 38.0, 'learning_rate': 9.702e-06, 'epoch': 0.19}\n",
      "{'loss': 37.75, 'learning_rate': 9.701e-06, 'epoch': 0.19}\n",
      "{'loss': 37.75, 'learning_rate': 9.7e-06, 'epoch': 0.19}\n",
      "{'loss': 38.0, 'learning_rate': 9.699e-06, 'epoch': 0.19}\n",
      "{'loss': 36.75, 'learning_rate': 9.698000000000001e-06, 'epoch': 0.19}\n",
      "{'loss': 35.75, 'learning_rate': 9.697e-06, 'epoch': 0.19}\n",
      "{'loss': 37.0, 'learning_rate': 9.696000000000002e-06, 'epoch': 0.2}\n",
      "{'loss': 37.0, 'learning_rate': 9.695000000000001e-06, 'epoch': 0.2}\n",
      "{'loss': 37.5, 'learning_rate': 9.694e-06, 'epoch': 0.2}\n",
      "{'loss': 36.75, 'learning_rate': 9.693000000000002e-06, 'epoch': 0.2}\n",
      "{'loss': 39.25, 'learning_rate': 9.692e-06, 'epoch': 0.2}\n",
      "{'loss': 36.0, 'learning_rate': 9.691000000000001e-06, 'epoch': 0.2}\n",
      "{'loss': 35.75, 'learning_rate': 9.69e-06, 'epoch': 0.2}\n",
      "{'loss': 37.5, 'learning_rate': 9.689e-06, 'epoch': 0.2}\n",
      "{'loss': 35.25, 'learning_rate': 9.688000000000001e-06, 'epoch': 0.2}\n",
      "{'loss': 36.0, 'learning_rate': 9.687e-06, 'epoch': 0.2}\n",
      "{'loss': 37.25, 'learning_rate': 9.686000000000002e-06, 'epoch': 0.2}\n",
      "{'loss': 37.25, 'learning_rate': 9.685000000000001e-06, 'epoch': 0.2}\n",
      "{'loss': 36.5, 'learning_rate': 9.684e-06, 'epoch': 0.2}\n",
      "{'loss': 36.5, 'learning_rate': 9.683000000000002e-06, 'epoch': 0.2}\n",
      "{'loss': 36.0, 'learning_rate': 9.682e-06, 'epoch': 0.2}\n",
      "{'loss': 37.0, 'learning_rate': 9.681000000000001e-06, 'epoch': 0.2}\n",
      "{'loss': 36.5, 'learning_rate': 9.68e-06, 'epoch': 0.21}\n",
      "{'loss': 37.25, 'learning_rate': 9.679e-06, 'epoch': 0.21}\n",
      "{'loss': 34.75, 'learning_rate': 9.678000000000001e-06, 'epoch': 0.21}\n",
      "{'loss': 36.0, 'learning_rate': 9.677e-06, 'epoch': 0.21}\n",
      "{'loss': 36.75, 'learning_rate': 9.676e-06, 'epoch': 0.21}\n",
      "{'loss': 35.5, 'learning_rate': 9.675000000000001e-06, 'epoch': 0.21}\n",
      "{'loss': 36.75, 'learning_rate': 9.674000000000001e-06, 'epoch': 0.21}\n",
      "{'loss': 36.25, 'learning_rate': 9.673000000000002e-06, 'epoch': 0.21}\n",
      "{'loss': 36.0, 'learning_rate': 9.672e-06, 'epoch': 0.21}\n",
      "{'loss': 36.5, 'learning_rate': 9.671000000000001e-06, 'epoch': 0.21}\n",
      "{'loss': 37.5, 'learning_rate': 9.67e-06, 'epoch': 0.21}\n",
      "{'loss': 37.0, 'learning_rate': 9.669e-06, 'epoch': 0.21}\n",
      "{'loss': 35.0, 'learning_rate': 9.668000000000001e-06, 'epoch': 0.21}\n",
      "{'loss': 35.25, 'learning_rate': 9.667e-06, 'epoch': 0.21}\n",
      "{'loss': 36.5, 'learning_rate': 9.666e-06, 'epoch': 0.21}\n",
      "{'loss': 35.5, 'learning_rate': 9.665000000000001e-06, 'epoch': 0.22}\n",
      "{'loss': 35.5, 'learning_rate': 9.664000000000001e-06, 'epoch': 0.22}\n",
      "{'loss': 36.25, 'learning_rate': 9.663e-06, 'epoch': 0.22}\n",
      "{'loss': 35.25, 'learning_rate': 9.662e-06, 'epoch': 0.22}\n",
      "{'loss': 35.25, 'learning_rate': 9.661000000000001e-06, 'epoch': 0.22}\n",
      "{'loss': 34.5, 'learning_rate': 9.66e-06, 'epoch': 0.22}\n",
      "{'loss': 37.0, 'learning_rate': 9.659e-06, 'epoch': 0.22}\n",
      "{'loss': 35.25, 'learning_rate': 9.658000000000001e-06, 'epoch': 0.22}\n",
      "{'loss': 36.25, 'learning_rate': 9.657000000000001e-06, 'epoch': 0.22}\n",
      "{'loss': 36.25, 'learning_rate': 9.656e-06, 'epoch': 0.22}\n",
      "{'loss': 35.0, 'learning_rate': 9.655000000000002e-06, 'epoch': 0.22}\n",
      "{'loss': 35.25, 'learning_rate': 9.654000000000001e-06, 'epoch': 0.22}\n",
      "{'loss': 35.5, 'learning_rate': 9.653e-06, 'epoch': 0.22}\n",
      "{'loss': 37.25, 'learning_rate': 9.652e-06, 'epoch': 0.22}\n",
      "{'loss': 37.0, 'learning_rate': 9.651e-06, 'epoch': 0.22}\n",
      "{'loss': 36.75, 'learning_rate': 9.65e-06, 'epoch': 0.22}\n",
      "{'loss': 36.0, 'learning_rate': 9.649e-06, 'epoch': 0.23}\n",
      "{'loss': 35.5, 'learning_rate': 9.648000000000001e-06, 'epoch': 0.23}\n",
      "{'loss': 35.0, 'learning_rate': 9.647000000000001e-06, 'epoch': 0.23}\n",
      "{'loss': 36.75, 'learning_rate': 9.646e-06, 'epoch': 0.23}\n",
      "{'loss': 35.75, 'learning_rate': 9.645000000000002e-06, 'epoch': 0.23}\n",
      "{'loss': 37.75, 'learning_rate': 9.644000000000001e-06, 'epoch': 0.23}\n",
      "{'loss': 36.0, 'learning_rate': 9.643e-06, 'epoch': 0.23}\n",
      "{'loss': 34.5, 'learning_rate': 9.642e-06, 'epoch': 0.23}\n",
      "{'loss': 34.0, 'learning_rate': 9.641e-06, 'epoch': 0.23}\n",
      "{'loss': 35.75, 'learning_rate': 9.640000000000001e-06, 'epoch': 0.23}\n",
      "{'loss': 36.5, 'learning_rate': 9.639e-06, 'epoch': 0.23}\n",
      "{'loss': 36.5, 'learning_rate': 9.638e-06, 'epoch': 0.23}\n",
      "{'loss': 36.75, 'learning_rate': 9.637000000000001e-06, 'epoch': 0.23}\n",
      "{'loss': 35.5, 'learning_rate': 9.636e-06, 'epoch': 0.23}\n",
      "{'loss': 36.0, 'learning_rate': 9.635000000000002e-06, 'epoch': 0.23}\n",
      "{'loss': 35.25, 'learning_rate': 9.634000000000001e-06, 'epoch': 0.23}\n",
      "{'loss': 35.0, 'learning_rate': 9.633e-06, 'epoch': 0.24}\n",
      "{'loss': 34.5, 'learning_rate': 9.632e-06, 'epoch': 0.24}\n",
      "{'loss': 34.5, 'learning_rate': 9.631e-06, 'epoch': 0.24}\n",
      "{'loss': 35.75, 'learning_rate': 9.630000000000001e-06, 'epoch': 0.24}\n",
      "{'loss': 35.5, 'learning_rate': 9.629e-06, 'epoch': 0.24}\n",
      "{'loss': 34.75, 'learning_rate': 9.628e-06, 'epoch': 0.24}\n",
      "{'loss': 36.5, 'learning_rate': 9.627000000000001e-06, 'epoch': 0.24}\n",
      "{'loss': 36.5, 'learning_rate': 9.626e-06, 'epoch': 0.24}\n",
      "{'loss': 34.75, 'learning_rate': 9.625e-06, 'epoch': 0.24}\n",
      "{'loss': 34.5, 'learning_rate': 9.624000000000001e-06, 'epoch': 0.24}\n",
      "{'loss': 35.75, 'learning_rate': 9.623000000000001e-06, 'epoch': 0.24}\n",
      "{'loss': 33.0, 'learning_rate': 9.622000000000002e-06, 'epoch': 0.24}\n",
      "{'loss': 36.0, 'learning_rate': 9.621e-06, 'epoch': 0.24}\n",
      "{'loss': 34.5, 'learning_rate': 9.620000000000001e-06, 'epoch': 0.24}\n",
      "{'loss': 34.5, 'learning_rate': 9.619e-06, 'epoch': 0.24}\n",
      "{'loss': 33.25, 'learning_rate': 9.618e-06, 'epoch': 0.25}\n",
      "{'loss': 36.0, 'learning_rate': 9.617000000000001e-06, 'epoch': 0.25}\n",
      "{'loss': 33.25, 'learning_rate': 9.616e-06, 'epoch': 0.25}\n",
      "{'loss': 34.25, 'learning_rate': 9.615e-06, 'epoch': 0.25}\n",
      "{'loss': 34.75, 'learning_rate': 9.614000000000001e-06, 'epoch': 0.25}\n",
      "{'loss': 35.0, 'learning_rate': 9.613000000000001e-06, 'epoch': 0.25}\n",
      "{'loss': 35.25, 'learning_rate': 9.612000000000002e-06, 'epoch': 0.25}\n",
      "{'loss': 34.5, 'learning_rate': 9.611e-06, 'epoch': 0.25}\n",
      "{'loss': 34.75, 'learning_rate': 9.610000000000001e-06, 'epoch': 0.25}\n",
      "{'loss': 34.75, 'learning_rate': 9.609e-06, 'epoch': 0.25}\n",
      "{'loss': 33.5, 'learning_rate': 9.608e-06, 'epoch': 0.25}\n",
      "{'loss': 34.75, 'learning_rate': 9.607000000000001e-06, 'epoch': 0.25}\n",
      "{'loss': 33.5, 'learning_rate': 9.606000000000001e-06, 'epoch': 0.25}\n",
      "{'loss': 34.25, 'learning_rate': 9.605e-06, 'epoch': 0.25}\n",
      "{'loss': 33.75, 'learning_rate': 9.604000000000002e-06, 'epoch': 0.25}\n",
      "{'loss': 34.75, 'learning_rate': 9.603000000000001e-06, 'epoch': 0.25}\n",
      "{'loss': 33.75, 'learning_rate': 9.602e-06, 'epoch': 0.26}\n",
      "{'loss': 36.25, 'learning_rate': 9.601e-06, 'epoch': 0.26}\n",
      "{'loss': 34.25, 'learning_rate': 9.600000000000001e-06, 'epoch': 0.26}\n",
      "{'loss': 33.75, 'learning_rate': 9.599e-06, 'epoch': 0.26}\n",
      "{'loss': 34.0, 'learning_rate': 9.598e-06, 'epoch': 0.26}\n",
      "{'loss': 32.5, 'learning_rate': 9.597000000000001e-06, 'epoch': 0.26}\n",
      "{'loss': 34.5, 'learning_rate': 9.596000000000001e-06, 'epoch': 0.26}\n",
      "{'loss': 35.0, 'learning_rate': 9.595e-06, 'epoch': 0.26}\n",
      "{'loss': 34.75, 'learning_rate': 9.594000000000002e-06, 'epoch': 0.26}\n",
      "{'loss': 34.25, 'learning_rate': 9.593000000000001e-06, 'epoch': 0.26}\n",
      "{'loss': 33.0, 'learning_rate': 9.592e-06, 'epoch': 0.26}\n",
      "{'loss': 35.25, 'learning_rate': 9.591e-06, 'epoch': 0.26}\n",
      "{'loss': 33.0, 'learning_rate': 9.59e-06, 'epoch': 0.26}\n",
      "{'loss': 33.75, 'learning_rate': 9.589000000000001e-06, 'epoch': 0.26}\n",
      "{'loss': 34.25, 'learning_rate': 9.588e-06, 'epoch': 0.26}\n",
      "{'loss': 35.5, 'learning_rate': 9.587000000000002e-06, 'epoch': 0.27}\n",
      "{'loss': 34.75, 'learning_rate': 9.586000000000001e-06, 'epoch': 0.27}\n",
      "{'loss': 33.5, 'learning_rate': 9.585e-06, 'epoch': 0.27}\n",
      "{'loss': 33.75, 'learning_rate': 9.584000000000002e-06, 'epoch': 0.27}\n",
      "{'loss': 33.75, 'learning_rate': 9.583000000000001e-06, 'epoch': 0.27}\n",
      "{'loss': 35.25, 'learning_rate': 9.582e-06, 'epoch': 0.27}\n",
      "{'loss': 35.0, 'learning_rate': 9.581e-06, 'epoch': 0.27}\n",
      "{'loss': 33.0, 'learning_rate': 9.58e-06, 'epoch': 0.27}\n",
      "{'loss': 33.25, 'learning_rate': 9.579000000000001e-06, 'epoch': 0.27}\n",
      "{'loss': 34.75, 'learning_rate': 9.578e-06, 'epoch': 0.27}\n",
      "{'loss': 33.75, 'learning_rate': 9.577e-06, 'epoch': 0.27}\n",
      "{'loss': 33.75, 'learning_rate': 9.576000000000001e-06, 'epoch': 0.27}\n",
      "{'loss': 35.25, 'learning_rate': 9.575e-06, 'epoch': 0.27}\n",
      "{'loss': 34.0, 'learning_rate': 9.574000000000002e-06, 'epoch': 0.27}\n",
      "{'loss': 34.5, 'learning_rate': 9.573000000000001e-06, 'epoch': 0.27}\n",
      "{'loss': 34.25, 'learning_rate': 9.572000000000001e-06, 'epoch': 0.27}\n",
      "{'loss': 34.25, 'learning_rate': 9.571e-06, 'epoch': 0.28}\n",
      "{'loss': 34.0, 'learning_rate': 9.57e-06, 'epoch': 0.28}\n",
      "{'loss': 34.5, 'learning_rate': 9.569000000000001e-06, 'epoch': 0.28}\n",
      "{'loss': 34.75, 'learning_rate': 9.568e-06, 'epoch': 0.28}\n",
      "{'loss': 34.5, 'learning_rate': 9.567e-06, 'epoch': 0.28}\n",
      "{'loss': 33.25, 'learning_rate': 9.566000000000001e-06, 'epoch': 0.28}\n",
      "{'loss': 34.75, 'learning_rate': 9.565e-06, 'epoch': 0.28}\n",
      "{'loss': 33.5, 'learning_rate': 9.564e-06, 'epoch': 0.28}\n",
      "{'loss': 34.25, 'learning_rate': 9.563000000000001e-06, 'epoch': 0.28}\n",
      "{'loss': 33.25, 'learning_rate': 9.562000000000001e-06, 'epoch': 0.28}\n",
      "{'loss': 33.5, 'learning_rate': 9.561e-06, 'epoch': 0.28}\n",
      "{'loss': 35.25, 'learning_rate': 9.56e-06, 'epoch': 0.28}\n",
      "{'loss': 33.75, 'learning_rate': 9.559000000000001e-06, 'epoch': 0.28}\n",
      "{'loss': 32.5, 'learning_rate': 9.558e-06, 'epoch': 0.28}\n",
      "{'loss': 33.5, 'learning_rate': 9.557e-06, 'epoch': 0.28}\n",
      "{'loss': 33.25, 'learning_rate': 9.556000000000001e-06, 'epoch': 0.28}\n",
      "{'loss': 33.0, 'learning_rate': 9.555e-06, 'epoch': 0.29}\n",
      "{'loss': 33.0, 'learning_rate': 9.554e-06, 'epoch': 0.29}\n",
      "{'loss': 36.0, 'learning_rate': 9.553000000000002e-06, 'epoch': 0.29}\n",
      "{'loss': 35.0, 'learning_rate': 9.552000000000001e-06, 'epoch': 0.29}\n",
      "{'loss': 33.5, 'learning_rate': 9.551e-06, 'epoch': 0.29}\n",
      "{'loss': 35.25, 'learning_rate': 9.55e-06, 'epoch': 0.29}\n",
      "{'loss': 33.25, 'learning_rate': 9.549000000000001e-06, 'epoch': 0.29}\n",
      "{'loss': 33.25, 'learning_rate': 9.548e-06, 'epoch': 0.29}\n",
      "{'loss': 35.0, 'learning_rate': 9.547e-06, 'epoch': 0.29}\n",
      "{'loss': 34.5, 'learning_rate': 9.546000000000001e-06, 'epoch': 0.29}\n",
      "{'loss': 33.25, 'learning_rate': 9.545000000000001e-06, 'epoch': 0.29}\n",
      "{'loss': 34.0, 'learning_rate': 9.544e-06, 'epoch': 0.29}\n",
      "{'loss': 33.25, 'learning_rate': 9.543000000000002e-06, 'epoch': 0.29}\n",
      "{'loss': 33.5, 'learning_rate': 9.542000000000001e-06, 'epoch': 0.29}\n",
      "{'loss': 33.0, 'learning_rate': 9.541e-06, 'epoch': 0.29}\n",
      "{'loss': 34.25, 'learning_rate': 9.54e-06, 'epoch': 0.3}\n",
      "{'loss': 33.75, 'learning_rate': 9.539e-06, 'epoch': 0.3}\n",
      "{'loss': 33.0, 'learning_rate': 9.538e-06, 'epoch': 0.3}\n",
      "{'loss': 32.25, 'learning_rate': 9.537e-06, 'epoch': 0.3}\n",
      "{'loss': 35.0, 'learning_rate': 9.536000000000002e-06, 'epoch': 0.3}\n",
      "{'loss': 32.25, 'learning_rate': 9.535000000000001e-06, 'epoch': 0.3}\n",
      "{'loss': 32.75, 'learning_rate': 9.534e-06, 'epoch': 0.3}\n",
      "{'loss': 34.0, 'learning_rate': 9.533000000000002e-06, 'epoch': 0.3}\n",
      "{'loss': 32.75, 'learning_rate': 9.532000000000001e-06, 'epoch': 0.3}\n",
      "{'loss': 32.75, 'learning_rate': 9.531e-06, 'epoch': 0.3}\n",
      "{'loss': 33.5, 'learning_rate': 9.53e-06, 'epoch': 0.3}\n",
      "{'loss': 32.5, 'learning_rate': 9.529e-06, 'epoch': 0.3}\n",
      "{'loss': 33.5, 'learning_rate': 9.528000000000001e-06, 'epoch': 0.3}\n",
      "{'loss': 32.5, 'learning_rate': 9.527e-06, 'epoch': 0.3}\n",
      "{'loss': 32.75, 'learning_rate': 9.526000000000002e-06, 'epoch': 0.3}\n",
      "{'loss': 33.0, 'learning_rate': 9.525000000000001e-06, 'epoch': 0.3}\n",
      "{'loss': 33.25, 'learning_rate': 9.524e-06, 'epoch': 0.31}\n",
      "{'loss': 32.25, 'learning_rate': 9.523000000000002e-06, 'epoch': 0.31}\n",
      "{'loss': 32.75, 'learning_rate': 9.522000000000001e-06, 'epoch': 0.31}\n",
      "{'loss': 32.75, 'learning_rate': 9.521e-06, 'epoch': 0.31}\n",
      "{'loss': 32.5, 'learning_rate': 9.52e-06, 'epoch': 0.31}\n",
      "{'loss': 32.5, 'learning_rate': 9.519e-06, 'epoch': 0.31}\n",
      "{'loss': 33.25, 'learning_rate': 9.518000000000001e-06, 'epoch': 0.31}\n",
      "{'loss': 32.25, 'learning_rate': 9.517e-06, 'epoch': 0.31}\n",
      "{'loss': 33.75, 'learning_rate': 9.516e-06, 'epoch': 0.31}\n",
      "{'loss': 32.5, 'learning_rate': 9.515000000000001e-06, 'epoch': 0.31}\n",
      "{'loss': 34.5, 'learning_rate': 9.514e-06, 'epoch': 0.31}\n",
      "{'loss': 32.25, 'learning_rate': 9.513000000000002e-06, 'epoch': 0.31}\n",
      "{'loss': 33.5, 'learning_rate': 9.512000000000001e-06, 'epoch': 0.31}\n",
      "{'loss': 35.5, 'learning_rate': 9.511000000000001e-06, 'epoch': 0.31}\n",
      "{'loss': 33.0, 'learning_rate': 9.51e-06, 'epoch': 0.31}\n",
      "{'loss': 31.25, 'learning_rate': 9.509e-06, 'epoch': 0.32}\n",
      "{'loss': 32.75, 'learning_rate': 9.508000000000001e-06, 'epoch': 0.32}\n",
      "{'loss': 33.25, 'learning_rate': 9.507e-06, 'epoch': 0.32}\n",
      "{'loss': 32.5, 'learning_rate': 9.506e-06, 'epoch': 0.32}\n",
      "{'loss': 32.75, 'learning_rate': 9.505000000000001e-06, 'epoch': 0.32}\n",
      "{'loss': 32.25, 'learning_rate': 9.504e-06, 'epoch': 0.32}\n",
      "{'loss': 32.5, 'learning_rate': 9.503e-06, 'epoch': 0.32}\n",
      "{'loss': 32.25, 'learning_rate': 9.502000000000002e-06, 'epoch': 0.32}\n",
      "{'loss': 32.75, 'learning_rate': 9.501000000000001e-06, 'epoch': 0.32}\n",
      "{'loss': 33.25, 'learning_rate': 9.5e-06, 'epoch': 0.32}\n",
      "{'loss': 33.25, 'learning_rate': 9.499e-06, 'epoch': 0.32}\n",
      "{'loss': 33.0, 'learning_rate': 9.498000000000001e-06, 'epoch': 0.32}\n",
      "{'loss': 32.25, 'learning_rate': 9.497e-06, 'epoch': 0.32}\n",
      "{'loss': 32.25, 'learning_rate': 9.496e-06, 'epoch': 0.32}\n",
      "{'loss': 32.75, 'learning_rate': 9.495000000000001e-06, 'epoch': 0.32}\n",
      "{'loss': 31.375, 'learning_rate': 9.494000000000001e-06, 'epoch': 0.32}\n",
      "{'loss': 32.25, 'learning_rate': 9.493e-06, 'epoch': 0.33}\n",
      "{'loss': 32.75, 'learning_rate': 9.492000000000002e-06, 'epoch': 0.33}\n",
      "{'loss': 32.25, 'learning_rate': 9.491000000000001e-06, 'epoch': 0.33}\n",
      "{'loss': 32.25, 'learning_rate': 9.49e-06, 'epoch': 0.33}\n",
      "{'loss': 32.5, 'learning_rate': 9.489e-06, 'epoch': 0.33}\n",
      "{'loss': 32.0, 'learning_rate': 9.488000000000001e-06, 'epoch': 0.33}\n",
      "{'loss': 32.25, 'learning_rate': 9.487e-06, 'epoch': 0.33}\n",
      "{'loss': 31.5, 'learning_rate': 9.486e-06, 'epoch': 0.33}\n",
      "{'loss': 31.75, 'learning_rate': 9.485000000000002e-06, 'epoch': 0.33}\n",
      "{'loss': 31.375, 'learning_rate': 9.484000000000001e-06, 'epoch': 0.33}\n",
      "{'loss': 32.25, 'learning_rate': 9.483e-06, 'epoch': 0.33}\n",
      "{'loss': 33.5, 'learning_rate': 9.482000000000002e-06, 'epoch': 0.33}\n",
      "{'loss': 32.75, 'learning_rate': 9.481000000000001e-06, 'epoch': 0.33}\n",
      "{'loss': 31.375, 'learning_rate': 9.48e-06, 'epoch': 0.33}\n",
      "{'loss': 32.5, 'learning_rate': 9.479e-06, 'epoch': 0.33}\n",
      "{'loss': 32.5, 'learning_rate': 9.478e-06, 'epoch': 0.34}\n",
      "{'loss': 31.75, 'learning_rate': 9.477000000000001e-06, 'epoch': 0.34}\n",
      "{'loss': 32.5, 'learning_rate': 9.476e-06, 'epoch': 0.34}\n",
      "{'loss': 33.25, 'learning_rate': 9.475000000000002e-06, 'epoch': 0.34}\n",
      "{'loss': 34.5, 'learning_rate': 9.474000000000001e-06, 'epoch': 0.34}\n",
      "{'loss': 31.625, 'learning_rate': 9.473e-06, 'epoch': 0.34}\n",
      "{'loss': 33.0, 'learning_rate': 9.472000000000002e-06, 'epoch': 0.34}\n",
      "{'loss': 31.625, 'learning_rate': 9.471000000000001e-06, 'epoch': 0.34}\n",
      "{'loss': 31.125, 'learning_rate': 9.47e-06, 'epoch': 0.34}\n",
      "{'loss': 31.5, 'learning_rate': 9.469e-06, 'epoch': 0.34}\n",
      "{'loss': 32.25, 'learning_rate': 9.468e-06, 'epoch': 0.34}\n",
      "{'loss': 31.5, 'learning_rate': 9.467000000000001e-06, 'epoch': 0.34}\n",
      "{'loss': 31.875, 'learning_rate': 9.466e-06, 'epoch': 0.34}\n",
      "{'loss': 31.75, 'learning_rate': 9.465e-06, 'epoch': 0.34}\n",
      "{'loss': 31.25, 'learning_rate': 9.464000000000001e-06, 'epoch': 0.34}\n",
      "{'loss': 31.625, 'learning_rate': 9.463e-06, 'epoch': 0.34}\n",
      "{'loss': 32.25, 'learning_rate': 9.462000000000002e-06, 'epoch': 0.35}\n",
      "{'loss': 30.875, 'learning_rate': 9.461000000000001e-06, 'epoch': 0.35}\n",
      "{'loss': 33.0, 'learning_rate': 9.460000000000001e-06, 'epoch': 0.35}\n",
      "{'loss': 33.25, 'learning_rate': 9.459e-06, 'epoch': 0.35}\n",
      "{'loss': 30.625, 'learning_rate': 9.458e-06, 'epoch': 0.35}\n",
      "{'loss': 31.5, 'learning_rate': 9.457000000000001e-06, 'epoch': 0.35}\n",
      "{'loss': 32.0, 'learning_rate': 9.456e-06, 'epoch': 0.35}\n",
      "{'loss': 31.375, 'learning_rate': 9.455e-06, 'epoch': 0.35}\n",
      "{'loss': 31.875, 'learning_rate': 9.454000000000001e-06, 'epoch': 0.35}\n",
      "{'loss': 31.625, 'learning_rate': 9.453e-06, 'epoch': 0.35}\n",
      "{'loss': 33.75, 'learning_rate': 9.452000000000002e-06, 'epoch': 0.35}\n",
      "{'loss': 31.375, 'learning_rate': 9.451000000000002e-06, 'epoch': 0.35}\n",
      "{'loss': 31.25, 'learning_rate': 9.450000000000001e-06, 'epoch': 0.35}\n",
      "{'loss': 32.25, 'learning_rate': 9.449e-06, 'epoch': 0.35}\n",
      "{'loss': 31.625, 'learning_rate': 9.448e-06, 'epoch': 0.35}\n",
      "{'loss': 30.875, 'learning_rate': 9.447000000000001e-06, 'epoch': 0.35}\n",
      "{'loss': 30.0, 'learning_rate': 9.446e-06, 'epoch': 0.36}\n",
      "{'loss': 32.5, 'learning_rate': 9.445e-06, 'epoch': 0.36}\n",
      "{'loss': 31.25, 'learning_rate': 9.444000000000001e-06, 'epoch': 0.36}\n",
      "{'loss': 32.5, 'learning_rate': 9.443000000000001e-06, 'epoch': 0.36}\n",
      "{'loss': 31.875, 'learning_rate': 9.442e-06, 'epoch': 0.36}\n",
      "{'loss': 32.75, 'learning_rate': 9.441000000000002e-06, 'epoch': 0.36}\n",
      "{'loss': 33.0, 'learning_rate': 9.440000000000001e-06, 'epoch': 0.36}\n",
      "{'loss': 32.75, 'learning_rate': 9.439e-06, 'epoch': 0.36}\n",
      "{'loss': 31.875, 'learning_rate': 9.438e-06, 'epoch': 0.36}\n",
      "{'loss': 34.25, 'learning_rate': 9.437000000000001e-06, 'epoch': 0.36}\n",
      "{'loss': 31.625, 'learning_rate': 9.436e-06, 'epoch': 0.36}\n",
      "{'loss': 32.0, 'learning_rate': 9.435e-06, 'epoch': 0.36}\n",
      "{'loss': 31.625, 'learning_rate': 9.434000000000001e-06, 'epoch': 0.36}\n",
      "{'loss': 31.625, 'learning_rate': 9.433000000000001e-06, 'epoch': 0.36}\n",
      "{'loss': 33.25, 'learning_rate': 9.432e-06, 'epoch': 0.36}\n",
      "{'loss': 32.25, 'learning_rate': 9.431000000000002e-06, 'epoch': 0.37}\n",
      "{'loss': 33.25, 'learning_rate': 9.43e-06, 'epoch': 0.37}\n",
      "{'loss': 31.5, 'learning_rate': 9.429e-06, 'epoch': 0.37}\n",
      "{'loss': 30.875, 'learning_rate': 9.428e-06, 'epoch': 0.37}\n",
      "{'loss': 31.125, 'learning_rate': 9.427000000000001e-06, 'epoch': 0.37}\n",
      "{'loss': 30.875, 'learning_rate': 9.426000000000001e-06, 'epoch': 0.37}\n",
      "{'loss': 32.0, 'learning_rate': 9.425e-06, 'epoch': 0.37}\n",
      "{'loss': 31.875, 'learning_rate': 9.424000000000002e-06, 'epoch': 0.37}\n",
      "{'loss': 31.625, 'learning_rate': 9.423000000000001e-06, 'epoch': 0.37}\n",
      "{'loss': 31.375, 'learning_rate': 9.422e-06, 'epoch': 0.37}\n",
      "{'loss': 31.0, 'learning_rate': 9.421000000000002e-06, 'epoch': 0.37}\n",
      "{'loss': 30.5, 'learning_rate': 9.42e-06, 'epoch': 0.37}\n",
      "{'loss': 31.375, 'learning_rate': 9.419e-06, 'epoch': 0.37}\n",
      "{'loss': 31.25, 'learning_rate': 9.418e-06, 'epoch': 0.37}\n",
      "{'loss': 32.0, 'learning_rate': 9.417e-06, 'epoch': 0.37}\n",
      "{'loss': 31.0, 'learning_rate': 9.416000000000001e-06, 'epoch': 0.37}\n",
      "{'loss': 32.0, 'learning_rate': 9.415e-06, 'epoch': 0.38}\n",
      "{'loss': 31.625, 'learning_rate': 9.414000000000002e-06, 'epoch': 0.38}\n",
      "{'loss': 31.875, 'learning_rate': 9.413000000000001e-06, 'epoch': 0.38}\n",
      "{'loss': 31.75, 'learning_rate': 9.412e-06, 'epoch': 0.38}\n",
      "{'loss': 31.75, 'learning_rate': 9.411000000000002e-06, 'epoch': 0.38}\n",
      "{'loss': 31.75, 'learning_rate': 9.41e-06, 'epoch': 0.38}\n",
      "{'loss': 30.5, 'learning_rate': 9.409000000000001e-06, 'epoch': 0.38}\n",
      "{'loss': 30.5, 'learning_rate': 9.408e-06, 'epoch': 0.38}\n",
      "{'loss': 31.125, 'learning_rate': 9.407e-06, 'epoch': 0.38}\n",
      "{'loss': 30.75, 'learning_rate': 9.406000000000001e-06, 'epoch': 0.38}\n",
      "{'loss': 30.125, 'learning_rate': 9.405e-06, 'epoch': 0.38}\n",
      "{'loss': 30.5, 'learning_rate': 9.404e-06, 'epoch': 0.38}\n",
      "{'loss': 32.25, 'learning_rate': 9.403000000000001e-06, 'epoch': 0.38}\n",
      "{'loss': 30.5, 'learning_rate': 9.402e-06, 'epoch': 0.38}\n",
      "{'loss': 30.625, 'learning_rate': 9.401000000000002e-06, 'epoch': 0.38}\n",
      "{'loss': 30.25, 'learning_rate': 9.4e-06, 'epoch': 0.39}\n",
      "{'loss': 31.375, 'learning_rate': 9.399000000000001e-06, 'epoch': 0.39}\n",
      "{'loss': 31.625, 'learning_rate': 9.398e-06, 'epoch': 0.39}\n",
      "{'loss': 31.25, 'learning_rate': 9.397e-06, 'epoch': 0.39}\n",
      "{'loss': 32.25, 'learning_rate': 9.396000000000001e-06, 'epoch': 0.39}\n",
      "{'loss': 31.625, 'learning_rate': 9.395e-06, 'epoch': 0.39}\n",
      "{'loss': 30.75, 'learning_rate': 9.394e-06, 'epoch': 0.39}\n",
      "{'loss': 30.0, 'learning_rate': 9.393000000000001e-06, 'epoch': 0.39}\n",
      "{'loss': 30.375, 'learning_rate': 9.392000000000001e-06, 'epoch': 0.39}\n",
      "{'loss': 30.25, 'learning_rate': 9.391e-06, 'epoch': 0.39}\n",
      "{'loss': 31.375, 'learning_rate': 9.39e-06, 'epoch': 0.39}\n",
      "{'loss': 30.25, 'learning_rate': 9.389000000000001e-06, 'epoch': 0.39}\n",
      "{'loss': 32.25, 'learning_rate': 9.388e-06, 'epoch': 0.39}\n",
      "{'loss': 31.375, 'learning_rate': 9.387e-06, 'epoch': 0.39}\n",
      "{'loss': 30.5, 'learning_rate': 9.386000000000001e-06, 'epoch': 0.39}\n",
      "{'loss': 30.875, 'learning_rate': 9.385e-06, 'epoch': 0.39}\n",
      "{'loss': 30.625, 'learning_rate': 9.384e-06, 'epoch': 0.4}\n",
      "{'loss': 31.375, 'learning_rate': 9.383000000000001e-06, 'epoch': 0.4}\n",
      "{'loss': 34.5, 'learning_rate': 9.382000000000001e-06, 'epoch': 0.4}\n",
      "{'loss': 31.625, 'learning_rate': 9.381e-06, 'epoch': 0.4}\n",
      "{'loss': 30.75, 'learning_rate': 9.38e-06, 'epoch': 0.4}\n",
      "{'loss': 30.625, 'learning_rate': 9.379000000000001e-06, 'epoch': 0.4}\n",
      "{'loss': 32.25, 'learning_rate': 9.378e-06, 'epoch': 0.4}\n",
      "{'loss': 30.5, 'learning_rate': 9.377e-06, 'epoch': 0.4}\n",
      "{'loss': 30.75, 'learning_rate': 9.376000000000001e-06, 'epoch': 0.4}\n",
      "{'loss': 30.625, 'learning_rate': 9.375000000000001e-06, 'epoch': 0.4}\n",
      "{'loss': 31.875, 'learning_rate': 9.374e-06, 'epoch': 0.4}\n",
      "{'loss': 32.0, 'learning_rate': 9.373000000000002e-06, 'epoch': 0.4}\n",
      "{'loss': 31.125, 'learning_rate': 9.372000000000001e-06, 'epoch': 0.4}\n",
      "{'loss': 30.25, 'learning_rate': 9.371e-06, 'epoch': 0.4}\n",
      "{'loss': 29.625, 'learning_rate': 9.370000000000002e-06, 'epoch': 0.4}\n",
      "{'loss': 30.875, 'learning_rate': 9.369e-06, 'epoch': 0.41}\n",
      "{'loss': 31.75, 'learning_rate': 9.368e-06, 'epoch': 0.41}\n",
      "{'loss': 31.875, 'learning_rate': 9.367e-06, 'epoch': 0.41}\n",
      "{'loss': 29.875, 'learning_rate': 9.366000000000001e-06, 'epoch': 0.41}\n",
      "{'loss': 30.375, 'learning_rate': 9.365000000000001e-06, 'epoch': 0.41}\n",
      "{'loss': 30.875, 'learning_rate': 9.364e-06, 'epoch': 0.41}\n",
      "{'loss': 30.5, 'learning_rate': 9.363000000000002e-06, 'epoch': 0.41}\n",
      "{'loss': 31.375, 'learning_rate': 9.362000000000001e-06, 'epoch': 0.41}\n",
      "{'loss': 30.75, 'learning_rate': 9.361e-06, 'epoch': 0.41}\n",
      "{'loss': 31.625, 'learning_rate': 9.360000000000002e-06, 'epoch': 0.41}\n",
      "{'loss': 30.25, 'learning_rate': 9.359e-06, 'epoch': 0.41}\n",
      "{'loss': 30.875, 'learning_rate': 9.358000000000001e-06, 'epoch': 0.41}\n",
      "{'loss': 30.75, 'learning_rate': 9.357e-06, 'epoch': 0.41}\n",
      "{'loss': 31.5, 'learning_rate': 9.356e-06, 'epoch': 0.41}\n",
      "{'loss': 30.375, 'learning_rate': 9.355000000000001e-06, 'epoch': 0.41}\n",
      "{'loss': 30.375, 'learning_rate': 9.354e-06, 'epoch': 0.41}\n",
      "{'loss': 30.875, 'learning_rate': 9.353000000000002e-06, 'epoch': 0.42}\n",
      "{'loss': 30.25, 'learning_rate': 9.352000000000001e-06, 'epoch': 0.42}\n",
      "{'loss': 30.875, 'learning_rate': 9.351e-06, 'epoch': 0.42}\n",
      "{'loss': 30.5, 'learning_rate': 9.350000000000002e-06, 'epoch': 0.42}\n",
      "{'loss': 30.0, 'learning_rate': 9.349e-06, 'epoch': 0.42}\n",
      "{'loss': 30.125, 'learning_rate': 9.348000000000001e-06, 'epoch': 0.42}\n",
      "{'loss': 29.625, 'learning_rate': 9.347e-06, 'epoch': 0.42}\n",
      "{'loss': 30.875, 'learning_rate': 9.346e-06, 'epoch': 0.42}\n",
      "{'loss': 30.875, 'learning_rate': 9.345000000000001e-06, 'epoch': 0.42}\n",
      "{'loss': 30.75, 'learning_rate': 9.344e-06, 'epoch': 0.42}\n",
      "{'loss': 30.75, 'learning_rate': 9.343e-06, 'epoch': 0.42}\n",
      "{'loss': 29.75, 'learning_rate': 9.342000000000001e-06, 'epoch': 0.42}\n",
      "{'loss': 30.875, 'learning_rate': 9.341000000000001e-06, 'epoch': 0.42}\n",
      "{'loss': 31.75, 'learning_rate': 9.340000000000002e-06, 'epoch': 0.42}\n",
      "{'loss': 32.25, 'learning_rate': 9.339e-06, 'epoch': 0.42}\n",
      "{'loss': 30.125, 'learning_rate': 9.338000000000001e-06, 'epoch': 0.42}\n",
      "{'loss': 30.875, 'learning_rate': 9.337e-06, 'epoch': 0.43}\n",
      "{'loss': 31.125, 'learning_rate': 9.336e-06, 'epoch': 0.43}\n",
      "{'loss': 30.375, 'learning_rate': 9.335000000000001e-06, 'epoch': 0.43}\n",
      "{'loss': 30.625, 'learning_rate': 9.334e-06, 'epoch': 0.43}\n",
      "{'loss': 29.375, 'learning_rate': 9.333e-06, 'epoch': 0.43}\n",
      "{'loss': 30.375, 'learning_rate': 9.332000000000001e-06, 'epoch': 0.43}\n",
      "{'loss': 31.0, 'learning_rate': 9.331000000000001e-06, 'epoch': 0.43}\n",
      "{'loss': 29.5, 'learning_rate': 9.33e-06, 'epoch': 0.43}\n",
      "{'loss': 29.875, 'learning_rate': 9.329e-06, 'epoch': 0.43}\n",
      "{'loss': 31.25, 'learning_rate': 9.328000000000001e-06, 'epoch': 0.43}\n",
      "{'loss': 32.0, 'learning_rate': 9.327e-06, 'epoch': 0.43}\n",
      "{'loss': 30.125, 'learning_rate': 9.326e-06, 'epoch': 0.43}\n",
      "{'loss': 29.0, 'learning_rate': 9.325000000000001e-06, 'epoch': 0.43}\n",
      "{'loss': 30.875, 'learning_rate': 9.324000000000001e-06, 'epoch': 0.43}\n",
      "{'loss': 29.75, 'learning_rate': 9.323e-06, 'epoch': 0.43}\n",
      "{'loss': 33.25, 'learning_rate': 9.322000000000002e-06, 'epoch': 0.44}\n",
      "{'loss': 30.125, 'learning_rate': 9.321000000000001e-06, 'epoch': 0.44}\n",
      "{'loss': 29.875, 'learning_rate': 9.32e-06, 'epoch': 0.44}\n",
      "{'loss': 29.75, 'learning_rate': 9.319e-06, 'epoch': 0.44}\n",
      "{'loss': 29.125, 'learning_rate': 9.318e-06, 'epoch': 0.44}\n",
      "{'loss': 30.375, 'learning_rate': 9.317e-06, 'epoch': 0.44}\n",
      "{'loss': 29.375, 'learning_rate': 9.316e-06, 'epoch': 0.44}\n",
      "{'loss': 29.25, 'learning_rate': 9.315000000000001e-06, 'epoch': 0.44}\n",
      "{'loss': 29.875, 'learning_rate': 9.314000000000001e-06, 'epoch': 0.44}\n",
      "{'loss': 29.625, 'learning_rate': 9.313e-06, 'epoch': 0.44}\n",
      "{'loss': 30.75, 'learning_rate': 9.312000000000002e-06, 'epoch': 0.44}\n",
      "{'loss': 30.125, 'learning_rate': 9.311000000000001e-06, 'epoch': 0.44}\n",
      "{'loss': 31.25, 'learning_rate': 9.31e-06, 'epoch': 0.44}\n",
      "{'loss': 29.5, 'learning_rate': 9.309e-06, 'epoch': 0.44}\n",
      "{'loss': 30.375, 'learning_rate': 9.308e-06, 'epoch': 0.44}\n",
      "{'loss': 30.0, 'learning_rate': 9.307e-06, 'epoch': 0.44}\n",
      "{'loss': 28.625, 'learning_rate': 9.306e-06, 'epoch': 0.45}\n",
      "{'loss': 29.875, 'learning_rate': 9.305000000000002e-06, 'epoch': 0.45}\n",
      "{'loss': 30.25, 'learning_rate': 9.304000000000001e-06, 'epoch': 0.45}\n",
      "{'loss': 29.5, 'learning_rate': 9.303e-06, 'epoch': 0.45}\n",
      "{'loss': 30.125, 'learning_rate': 9.302000000000002e-06, 'epoch': 0.45}\n",
      "{'loss': 29.75, 'learning_rate': 9.301000000000001e-06, 'epoch': 0.45}\n",
      "{'loss': 29.625, 'learning_rate': 9.3e-06, 'epoch': 0.45}\n",
      "{'loss': 30.375, 'learning_rate': 9.299e-06, 'epoch': 0.45}\n",
      "{'loss': 30.125, 'learning_rate': 9.298e-06, 'epoch': 0.45}\n",
      "{'loss': 30.25, 'learning_rate': 9.297000000000001e-06, 'epoch': 0.45}\n",
      "{'loss': 29.375, 'learning_rate': 9.296e-06, 'epoch': 0.45}\n",
      "{'loss': 30.125, 'learning_rate': 9.295e-06, 'epoch': 0.45}\n",
      "{'loss': 32.25, 'learning_rate': 9.294000000000001e-06, 'epoch': 0.45}\n",
      "{'loss': 31.375, 'learning_rate': 9.293e-06, 'epoch': 0.45}\n",
      "{'loss': 29.875, 'learning_rate': 9.292000000000002e-06, 'epoch': 0.45}\n",
      "{'loss': 29.25, 'learning_rate': 9.291000000000001e-06, 'epoch': 0.46}\n",
      "{'loss': 30.875, 'learning_rate': 9.29e-06, 'epoch': 0.46}\n",
      "{'loss': 29.75, 'learning_rate': 9.289e-06, 'epoch': 0.46}\n",
      "{'loss': 31.625, 'learning_rate': 9.288e-06, 'epoch': 0.46}\n",
      "{'loss': 29.25, 'learning_rate': 9.287000000000001e-06, 'epoch': 0.46}\n",
      "{'loss': 28.625, 'learning_rate': 9.286e-06, 'epoch': 0.46}\n",
      "{'loss': 29.75, 'learning_rate': 9.285e-06, 'epoch': 0.46}\n",
      "{'loss': 30.125, 'learning_rate': 9.284000000000001e-06, 'epoch': 0.46}\n",
      "{'loss': 30.625, 'learning_rate': 9.283e-06, 'epoch': 0.46}\n",
      "{'loss': 29.625, 'learning_rate': 9.282e-06, 'epoch': 0.46}\n",
      "{'loss': 29.875, 'learning_rate': 9.281000000000001e-06, 'epoch': 0.46}\n",
      "{'loss': 29.75, 'learning_rate': 9.280000000000001e-06, 'epoch': 0.46}\n",
      "{'loss': 30.375, 'learning_rate': 9.279e-06, 'epoch': 0.46}\n",
      "{'loss': 30.125, 'learning_rate': 9.278e-06, 'epoch': 0.46}\n",
      "{'loss': 29.375, 'learning_rate': 9.277000000000001e-06, 'epoch': 0.46}\n",
      "{'loss': 32.0, 'learning_rate': 9.276e-06, 'epoch': 0.46}\n",
      "{'loss': 30.25, 'learning_rate': 9.275e-06, 'epoch': 0.47}\n",
      "{'loss': 29.75, 'learning_rate': 9.274000000000001e-06, 'epoch': 0.47}\n",
      "{'loss': 29.625, 'learning_rate': 9.273e-06, 'epoch': 0.47}\n",
      "{'loss': 30.0, 'learning_rate': 9.272e-06, 'epoch': 0.47}\n",
      "{'loss': 30.125, 'learning_rate': 9.271000000000002e-06, 'epoch': 0.47}\n",
      "{'loss': 31.0, 'learning_rate': 9.270000000000001e-06, 'epoch': 0.47}\n",
      "{'loss': 30.375, 'learning_rate': 9.269e-06, 'epoch': 0.47}\n",
      "{'loss': 29.625, 'learning_rate': 9.268e-06, 'epoch': 0.47}\n",
      "{'loss': 29.875, 'learning_rate': 9.267000000000001e-06, 'epoch': 0.47}\n",
      "{'loss': 29.75, 'learning_rate': 9.266e-06, 'epoch': 0.47}\n",
      "{'loss': 30.125, 'learning_rate': 9.265e-06, 'epoch': 0.47}\n",
      "{'loss': 29.75, 'learning_rate': 9.264000000000001e-06, 'epoch': 0.47}\n",
      "{'loss': 29.875, 'learning_rate': 9.263000000000001e-06, 'epoch': 0.47}\n",
      "{'loss': 29.5, 'learning_rate': 9.262e-06, 'epoch': 0.47}\n",
      "{'loss': 30.375, 'learning_rate': 9.261000000000002e-06, 'epoch': 0.47}\n",
      "{'loss': 30.125, 'learning_rate': 9.260000000000001e-06, 'epoch': 0.47}\n",
      "{'loss': 29.875, 'learning_rate': 9.259e-06, 'epoch': 0.48}\n",
      "{'loss': 30.875, 'learning_rate': 9.258e-06, 'epoch': 0.48}\n",
      "{'loss': 29.875, 'learning_rate': 9.257e-06, 'epoch': 0.48}\n",
      "{'loss': 31.25, 'learning_rate': 9.256e-06, 'epoch': 0.48}\n",
      "{'loss': 28.75, 'learning_rate': 9.255e-06, 'epoch': 0.48}\n",
      "{'loss': 30.125, 'learning_rate': 9.254000000000002e-06, 'epoch': 0.48}\n",
      "{'loss': 30.5, 'learning_rate': 9.253000000000001e-06, 'epoch': 0.48}\n",
      "{'loss': 29.5, 'learning_rate': 9.252e-06, 'epoch': 0.48}\n",
      "{'loss': 31.375, 'learning_rate': 9.251000000000002e-06, 'epoch': 0.48}\n",
      "{'loss': 28.75, 'learning_rate': 9.250000000000001e-06, 'epoch': 0.48}\n",
      "{'loss': 29.25, 'learning_rate': 9.249e-06, 'epoch': 0.48}\n",
      "{'loss': 31.875, 'learning_rate': 9.248e-06, 'epoch': 0.48}\n",
      "{'loss': 30.875, 'learning_rate': 9.247e-06, 'epoch': 0.48}\n",
      "{'loss': 30.0, 'learning_rate': 9.246000000000001e-06, 'epoch': 0.48}\n",
      "{'loss': 30.625, 'learning_rate': 9.245e-06, 'epoch': 0.48}\n",
      "{'loss': 29.75, 'learning_rate': 9.244e-06, 'epoch': 0.49}\n",
      "{'loss': 30.5, 'learning_rate': 9.243000000000001e-06, 'epoch': 0.49}\n",
      "{'loss': 30.25, 'learning_rate': 9.242e-06, 'epoch': 0.49}\n",
      "{'loss': 29.625, 'learning_rate': 9.241000000000002e-06, 'epoch': 0.49}\n",
      "{'loss': 29.875, 'learning_rate': 9.240000000000001e-06, 'epoch': 0.49}\n",
      "{'loss': 28.375, 'learning_rate': 9.239e-06, 'epoch': 0.49}\n",
      "{'loss': 30.625, 'learning_rate': 9.238e-06, 'epoch': 0.49}\n",
      "{'loss': 30.25, 'learning_rate': 9.237e-06, 'epoch': 0.49}\n",
      "{'loss': 29.25, 'learning_rate': 9.236000000000001e-06, 'epoch': 0.49}\n",
      "{'loss': 29.0, 'learning_rate': 9.235e-06, 'epoch': 0.49}\n",
      "{'loss': 29.0, 'learning_rate': 9.234e-06, 'epoch': 0.49}\n",
      "{'loss': 29.75, 'learning_rate': 9.233000000000001e-06, 'epoch': 0.49}\n",
      "{'loss': 29.375, 'learning_rate': 9.232e-06, 'epoch': 0.49}\n",
      "{'loss': 31.5, 'learning_rate': 9.231000000000002e-06, 'epoch': 0.49}\n",
      "{'loss': 30.25, 'learning_rate': 9.230000000000001e-06, 'epoch': 0.49}\n",
      "{'loss': 30.0, 'learning_rate': 9.229000000000001e-06, 'epoch': 0.49}\n",
      "{'loss': 28.375, 'learning_rate': 9.228e-06, 'epoch': 0.5}\n",
      "{'loss': 29.625, 'learning_rate': 9.227e-06, 'epoch': 0.5}\n",
      "{'loss': 28.625, 'learning_rate': 9.226000000000001e-06, 'epoch': 0.5}\n",
      "{'loss': 31.0, 'learning_rate': 9.225e-06, 'epoch': 0.5}\n",
      "{'loss': 28.875, 'learning_rate': 9.224e-06, 'epoch': 0.5}\n",
      "{'loss': 30.625, 'learning_rate': 9.223000000000001e-06, 'epoch': 0.5}\n",
      "{'loss': 30.25, 'learning_rate': 9.222e-06, 'epoch': 0.5}\n",
      "{'loss': 29.375, 'learning_rate': 9.221e-06, 'epoch': 0.5}\n",
      "{'loss': 29.25, 'learning_rate': 9.220000000000002e-06, 'epoch': 0.5}\n",
      "{'loss': 29.5, 'learning_rate': 9.219000000000001e-06, 'epoch': 0.5}\n",
      "{'loss': 31.5, 'learning_rate': 9.218e-06, 'epoch': 0.5}\n",
      "{'loss': 29.375, 'learning_rate': 9.217e-06, 'epoch': 0.5}\n",
      "{'loss': 30.25, 'learning_rate': 9.216000000000001e-06, 'epoch': 0.5}\n",
      "{'loss': 29.625, 'learning_rate': 9.215e-06, 'epoch': 0.5}\n",
      "{'loss': 29.125, 'learning_rate': 9.214e-06, 'epoch': 0.5}\n",
      "{'loss': 28.625, 'learning_rate': 9.213000000000001e-06, 'epoch': 0.51}\n",
      "{'loss': 29.375, 'learning_rate': 9.212000000000001e-06, 'epoch': 0.51}\n",
      "{'loss': 28.625, 'learning_rate': 9.211e-06, 'epoch': 0.51}\n",
      "{'loss': 29.625, 'learning_rate': 9.210000000000002e-06, 'epoch': 0.51}\n",
      "{'loss': 30.0, 'learning_rate': 9.209000000000001e-06, 'epoch': 0.51}\n",
      "{'loss': 28.625, 'learning_rate': 9.208e-06, 'epoch': 0.51}\n",
      "{'loss': 29.0, 'learning_rate': 9.207e-06, 'epoch': 0.51}\n",
      "{'loss': 29.75, 'learning_rate': 9.206000000000001e-06, 'epoch': 0.51}\n",
      "{'loss': 30.875, 'learning_rate': 9.205e-06, 'epoch': 0.51}\n",
      "{'loss': 29.75, 'learning_rate': 9.204e-06, 'epoch': 0.51}\n",
      "{'loss': 30.25, 'learning_rate': 9.203000000000002e-06, 'epoch': 0.51}\n",
      "{'loss': 31.375, 'learning_rate': 9.202000000000001e-06, 'epoch': 0.51}\n",
      "{'loss': 28.875, 'learning_rate': 9.201e-06, 'epoch': 0.51}\n",
      "{'loss': 29.0, 'learning_rate': 9.200000000000002e-06, 'epoch': 0.51}\n",
      "{'loss': 29.0, 'learning_rate': 9.199000000000001e-06, 'epoch': 0.51}\n",
      "{'loss': 28.75, 'learning_rate': 9.198e-06, 'epoch': 0.51}\n",
      "{'loss': 30.5, 'learning_rate': 9.197e-06, 'epoch': 0.52}\n",
      "{'loss': 29.5, 'learning_rate': 9.196e-06, 'epoch': 0.52}\n",
      "{'loss': 29.25, 'learning_rate': 9.195000000000001e-06, 'epoch': 0.52}\n",
      "{'loss': 29.125, 'learning_rate': 9.194e-06, 'epoch': 0.52}\n",
      "{'loss': 28.75, 'learning_rate': 9.193000000000002e-06, 'epoch': 0.52}\n",
      "{'loss': 30.75, 'learning_rate': 9.192000000000001e-06, 'epoch': 0.52}\n",
      "{'loss': 28.5, 'learning_rate': 9.191e-06, 'epoch': 0.52}\n",
      "{'loss': 28.5, 'learning_rate': 9.190000000000002e-06, 'epoch': 0.52}\n",
      "{'loss': 29.25, 'learning_rate': 9.189000000000001e-06, 'epoch': 0.52}\n",
      "{'loss': 29.375, 'learning_rate': 9.188e-06, 'epoch': 0.52}\n",
      "{'loss': 30.875, 'learning_rate': 9.187e-06, 'epoch': 0.52}\n",
      "{'loss': 29.75, 'learning_rate': 9.186e-06, 'epoch': 0.52}\n",
      "{'loss': 29.125, 'learning_rate': 9.185000000000001e-06, 'epoch': 0.52}\n",
      "{'loss': 28.875, 'learning_rate': 9.184e-06, 'epoch': 0.52}\n",
      "{'loss': 31.0, 'learning_rate': 9.183e-06, 'epoch': 0.52}\n",
      "{'loss': 29.625, 'learning_rate': 9.182000000000001e-06, 'epoch': 0.53}\n",
      "{'loss': 29.75, 'learning_rate': 9.181e-06, 'epoch': 0.53}\n",
      "{'loss': 29.125, 'learning_rate': 9.180000000000002e-06, 'epoch': 0.53}\n",
      "{'loss': 30.25, 'learning_rate': 9.179000000000001e-06, 'epoch': 0.53}\n",
      "{'loss': 28.375, 'learning_rate': 9.178000000000001e-06, 'epoch': 0.53}\n",
      "{'loss': 30.25, 'learning_rate': 9.177e-06, 'epoch': 0.53}\n",
      "{'loss': 28.25, 'learning_rate': 9.176e-06, 'epoch': 0.53}\n",
      "{'loss': 30.25, 'learning_rate': 9.175000000000001e-06, 'epoch': 0.53}\n",
      "{'loss': 30.875, 'learning_rate': 9.174e-06, 'epoch': 0.53}\n",
      "{'loss': 28.875, 'learning_rate': 9.173e-06, 'epoch': 0.53}\n",
      "{'loss': 28.875, 'learning_rate': 9.172000000000001e-06, 'epoch': 0.53}\n",
      "{'loss': 29.875, 'learning_rate': 9.171e-06, 'epoch': 0.53}\n",
      "{'loss': 28.75, 'learning_rate': 9.17e-06, 'epoch': 0.53}\n",
      "{'loss': 28.5, 'learning_rate': 9.169000000000001e-06, 'epoch': 0.53}\n",
      "{'loss': 30.0, 'learning_rate': 9.168000000000001e-06, 'epoch': 0.53}\n",
      "{'loss': 29.5, 'learning_rate': 9.167e-06, 'epoch': 0.53}\n",
      "{'loss': 28.75, 'learning_rate': 9.166e-06, 'epoch': 0.54}\n",
      "{'loss': 30.5, 'learning_rate': 9.165000000000001e-06, 'epoch': 0.54}\n",
      "{'loss': 29.375, 'learning_rate': 9.164e-06, 'epoch': 0.54}\n",
      "{'loss': 28.75, 'learning_rate': 9.163e-06, 'epoch': 0.54}\n",
      "{'loss': 29.25, 'learning_rate': 9.162000000000001e-06, 'epoch': 0.54}\n",
      "{'loss': 28.0, 'learning_rate': 9.161000000000001e-06, 'epoch': 0.54}\n",
      "{'loss': 29.125, 'learning_rate': 9.16e-06, 'epoch': 0.54}\n",
      "{'loss': 30.625, 'learning_rate': 9.159000000000002e-06, 'epoch': 0.54}\n",
      "{'loss': 28.625, 'learning_rate': 9.158e-06, 'epoch': 0.54}\n",
      "{'loss': 28.25, 'learning_rate': 9.157e-06, 'epoch': 0.54}\n",
      "{'loss': 29.75, 'learning_rate': 9.156e-06, 'epoch': 0.54}\n",
      "{'loss': 28.25, 'learning_rate': 9.155000000000001e-06, 'epoch': 0.54}\n",
      "{'loss': 28.25, 'learning_rate': 9.154e-06, 'epoch': 0.54}\n",
      "{'loss': 27.875, 'learning_rate': 9.153e-06, 'epoch': 0.54}\n",
      "{'loss': 30.0, 'learning_rate': 9.152000000000001e-06, 'epoch': 0.54}\n",
      "{'loss': 28.75, 'learning_rate': 9.151000000000001e-06, 'epoch': 0.54}\n",
      "{'loss': 29.75, 'learning_rate': 9.15e-06, 'epoch': 0.55}\n",
      "{'loss': 29.375, 'learning_rate': 9.149000000000002e-06, 'epoch': 0.55}\n",
      "{'loss': 30.5, 'learning_rate': 9.148e-06, 'epoch': 0.55}\n",
      "{'loss': 29.125, 'learning_rate': 9.147e-06, 'epoch': 0.55}\n",
      "{'loss': 28.75, 'learning_rate': 9.146e-06, 'epoch': 0.55}\n",
      "{'loss': 29.375, 'learning_rate': 9.145000000000001e-06, 'epoch': 0.55}\n",
      "{'loss': 29.75, 'learning_rate': 9.144000000000001e-06, 'epoch': 0.55}\n",
      "{'loss': 28.25, 'learning_rate': 9.143e-06, 'epoch': 0.55}\n",
      "{'loss': 29.625, 'learning_rate': 9.142000000000002e-06, 'epoch': 0.55}\n",
      "{'loss': 29.5, 'learning_rate': 9.141000000000001e-06, 'epoch': 0.55}\n",
      "{'loss': 29.75, 'learning_rate': 9.14e-06, 'epoch': 0.55}\n",
      "{'loss': 29.125, 'learning_rate': 9.139000000000002e-06, 'epoch': 0.55}\n",
      "{'loss': 28.875, 'learning_rate': 9.138e-06, 'epoch': 0.55}\n",
      "{'loss': 28.875, 'learning_rate': 9.137e-06, 'epoch': 0.55}\n",
      "{'loss': 29.0, 'learning_rate': 9.136e-06, 'epoch': 0.55}\n",
      "{'loss': 29.625, 'learning_rate': 9.135e-06, 'epoch': 0.56}\n",
      "{'loss': 29.0, 'learning_rate': 9.134000000000001e-06, 'epoch': 0.56}\n",
      "{'loss': 28.875, 'learning_rate': 9.133e-06, 'epoch': 0.56}\n",
      "{'loss': 28.625, 'learning_rate': 9.132000000000002e-06, 'epoch': 0.56}\n",
      "{'loss': 29.625, 'learning_rate': 9.131000000000001e-06, 'epoch': 0.56}\n",
      "{'loss': 28.875, 'learning_rate': 9.13e-06, 'epoch': 0.56}\n",
      "{'loss': 29.125, 'learning_rate': 9.129000000000002e-06, 'epoch': 0.56}\n",
      "{'loss': 30.625, 'learning_rate': 9.128e-06, 'epoch': 0.56}\n",
      "{'loss': 30.5, 'learning_rate': 9.127000000000001e-06, 'epoch': 0.56}\n",
      "{'loss': 28.875, 'learning_rate': 9.126e-06, 'epoch': 0.56}\n",
      "{'loss': 28.875, 'learning_rate': 9.125e-06, 'epoch': 0.56}\n",
      "{'loss': 28.125, 'learning_rate': 9.124000000000001e-06, 'epoch': 0.56}\n",
      "{'loss': 28.875, 'learning_rate': 9.123e-06, 'epoch': 0.56}\n",
      "{'loss': 29.0, 'learning_rate': 9.122e-06, 'epoch': 0.56}\n",
      "{'loss': 30.25, 'learning_rate': 9.121000000000001e-06, 'epoch': 0.56}\n",
      "{'loss': 29.0, 'learning_rate': 9.12e-06, 'epoch': 0.56}\n",
      "{'loss': 28.625, 'learning_rate': 9.119000000000002e-06, 'epoch': 0.57}\n",
      "{'loss': 29.875, 'learning_rate': 9.118000000000001e-06, 'epoch': 0.57}\n",
      "{'loss': 30.125, 'learning_rate': 9.117000000000001e-06, 'epoch': 0.57}\n",
      "{'loss': 29.0, 'learning_rate': 9.116e-06, 'epoch': 0.57}\n",
      "{'loss': 30.0, 'learning_rate': 9.115e-06, 'epoch': 0.57}\n",
      "{'loss': 28.75, 'learning_rate': 9.114000000000001e-06, 'epoch': 0.57}\n",
      "{'loss': 31.125, 'learning_rate': 9.113e-06, 'epoch': 0.57}\n",
      "{'loss': 28.75, 'learning_rate': 9.112e-06, 'epoch': 0.57}\n",
      "{'loss': 28.875, 'learning_rate': 9.111000000000001e-06, 'epoch': 0.57}\n",
      "{'loss': 30.875, 'learning_rate': 9.110000000000001e-06, 'epoch': 0.57}\n",
      "{'loss': 30.0, 'learning_rate': 9.109e-06, 'epoch': 0.57}\n",
      "{'loss': 29.0, 'learning_rate': 9.108000000000002e-06, 'epoch': 0.57}\n",
      "{'loss': 28.625, 'learning_rate': 9.107000000000001e-06, 'epoch': 0.57}\n",
      "{'loss': 31.0, 'learning_rate': 9.106e-06, 'epoch': 0.57}\n",
      "{'loss': 28.75, 'learning_rate': 9.105e-06, 'epoch': 0.57}\n",
      "{'loss': 28.875, 'learning_rate': 9.104000000000001e-06, 'epoch': 0.58}\n",
      "{'loss': 28.25, 'learning_rate': 9.103e-06, 'epoch': 0.58}\n",
      "{'loss': 29.5, 'learning_rate': 9.102e-06, 'epoch': 0.58}\n",
      "{'loss': 29.125, 'learning_rate': 9.101000000000001e-06, 'epoch': 0.58}\n",
      "{'loss': 28.375, 'learning_rate': 9.100000000000001e-06, 'epoch': 0.58}\n",
      "{'loss': 29.0, 'learning_rate': 9.099e-06, 'epoch': 0.58}\n",
      "{'loss': 28.125, 'learning_rate': 9.098000000000002e-06, 'epoch': 0.58}\n",
      "{'loss': 28.25, 'learning_rate': 9.097e-06, 'epoch': 0.58}\n",
      "{'loss': 28.0, 'learning_rate': 9.096e-06, 'epoch': 0.58}\n",
      "{'loss': 29.5, 'learning_rate': 9.095e-06, 'epoch': 0.58}\n",
      "{'loss': 28.0, 'learning_rate': 9.094000000000001e-06, 'epoch': 0.58}\n",
      "{'loss': 30.75, 'learning_rate': 9.093000000000001e-06, 'epoch': 0.58}\n",
      "{'loss': 29.0, 'learning_rate': 9.092e-06, 'epoch': 0.58}\n",
      "{'loss': 28.125, 'learning_rate': 9.091000000000002e-06, 'epoch': 0.58}\n",
      "{'loss': 28.25, 'learning_rate': 9.090000000000001e-06, 'epoch': 0.58}\n",
      "{'loss': 28.75, 'learning_rate': 9.089e-06, 'epoch': 0.58}\n",
      "{'loss': 28.875, 'learning_rate': 9.088000000000002e-06, 'epoch': 0.59}\n",
      "{'loss': 28.5, 'learning_rate': 9.087e-06, 'epoch': 0.59}\n",
      "{'loss': 28.25, 'learning_rate': 9.086e-06, 'epoch': 0.59}\n",
      "{'loss': 28.75, 'learning_rate': 9.085e-06, 'epoch': 0.59}\n",
      "{'loss': 30.625, 'learning_rate': 9.084e-06, 'epoch': 0.59}\n",
      "{'loss': 28.625, 'learning_rate': 9.083000000000001e-06, 'epoch': 0.59}\n",
      "{'loss': 28.875, 'learning_rate': 9.082e-06, 'epoch': 0.59}\n",
      "{'loss': 29.75, 'learning_rate': 9.081000000000002e-06, 'epoch': 0.59}\n",
      "{'loss': 28.375, 'learning_rate': 9.080000000000001e-06, 'epoch': 0.59}\n",
      "{'loss': 28.875, 'learning_rate': 9.079e-06, 'epoch': 0.59}\n",
      "{'loss': 28.75, 'learning_rate': 9.078000000000002e-06, 'epoch': 0.59}\n",
      "{'loss': 28.625, 'learning_rate': 9.077e-06, 'epoch': 0.59}\n",
      "{'loss': 30.5, 'learning_rate': 9.076000000000001e-06, 'epoch': 0.59}\n",
      "{'loss': 29.125, 'learning_rate': 9.075e-06, 'epoch': 0.59}\n",
      "{'loss': 28.125, 'learning_rate': 9.074e-06, 'epoch': 0.59}\n",
      "{'loss': 29.0, 'learning_rate': 9.073000000000001e-06, 'epoch': 0.59}\n",
      "{'loss': 30.5, 'learning_rate': 9.072e-06, 'epoch': 0.6}\n",
      "{'loss': 29.5, 'learning_rate': 9.071000000000002e-06, 'epoch': 0.6}\n",
      "{'loss': 29.75, 'learning_rate': 9.070000000000001e-06, 'epoch': 0.6}\n",
      "{'loss': 28.75, 'learning_rate': 9.069e-06, 'epoch': 0.6}\n",
      "{'loss': 29.625, 'learning_rate': 9.068000000000002e-06, 'epoch': 0.6}\n",
      "{'loss': 28.375, 'learning_rate': 9.067e-06, 'epoch': 0.6}\n",
      "{'loss': 29.125, 'learning_rate': 9.066000000000001e-06, 'epoch': 0.6}\n",
      "{'loss': 28.25, 'learning_rate': 9.065e-06, 'epoch': 0.6}\n",
      "{'loss': 28.875, 'learning_rate': 9.064e-06, 'epoch': 0.6}\n",
      "{'loss': 29.25, 'learning_rate': 9.063000000000001e-06, 'epoch': 0.6}\n",
      "{'loss': 32.25, 'learning_rate': 9.062e-06, 'epoch': 0.6}\n",
      "{'loss': 29.25, 'learning_rate': 9.061e-06, 'epoch': 0.6}\n",
      "{'loss': 28.25, 'learning_rate': 9.060000000000001e-06, 'epoch': 0.6}\n",
      "{'loss': 27.75, 'learning_rate': 9.059000000000001e-06, 'epoch': 0.6}\n",
      "{'loss': 29.875, 'learning_rate': 9.058000000000002e-06, 'epoch': 0.6}\n",
      "{'loss': 29.375, 'learning_rate': 9.057e-06, 'epoch': 0.61}\n",
      "{'loss': 28.625, 'learning_rate': 9.056000000000001e-06, 'epoch': 0.61}\n",
      "{'loss': 31.25, 'learning_rate': 9.055e-06, 'epoch': 0.61}\n",
      "{'loss': 29.0, 'learning_rate': 9.054e-06, 'epoch': 0.61}\n",
      "{'loss': 29.125, 'learning_rate': 9.053000000000001e-06, 'epoch': 0.61}\n",
      "{'loss': 28.875, 'learning_rate': 9.052e-06, 'epoch': 0.61}\n",
      "{'loss': 28.125, 'learning_rate': 9.051e-06, 'epoch': 0.61}\n",
      "{'loss': 28.125, 'learning_rate': 9.050000000000001e-06, 'epoch': 0.61}\n",
      "{'loss': 28.5, 'learning_rate': 9.049000000000001e-06, 'epoch': 0.61}\n",
      "{'loss': 28.25, 'learning_rate': 9.048e-06, 'epoch': 0.61}\n",
      "{'loss': 28.25, 'learning_rate': 9.047e-06, 'epoch': 0.61}\n",
      "{'loss': 29.0, 'learning_rate': 9.046000000000001e-06, 'epoch': 0.61}\n",
      "{'loss': 29.25, 'learning_rate': 9.045e-06, 'epoch': 0.61}\n",
      "{'loss': 28.25, 'learning_rate': 9.044e-06, 'epoch': 0.61}\n",
      "{'loss': 28.75, 'learning_rate': 9.043000000000001e-06, 'epoch': 0.61}\n",
      "{'loss': 28.75, 'learning_rate': 9.042e-06, 'epoch': 0.61}\n",
      "{'loss': 29.5, 'learning_rate': 9.041e-06, 'epoch': 0.62}\n",
      "{'loss': 29.75, 'learning_rate': 9.040000000000002e-06, 'epoch': 0.62}\n",
      "{'loss': 29.25, 'learning_rate': 9.039000000000001e-06, 'epoch': 0.62}\n",
      "{'loss': 28.875, 'learning_rate': 9.038e-06, 'epoch': 0.62}\n",
      "{'loss': 29.75, 'learning_rate': 9.037e-06, 'epoch': 0.62}\n",
      "{'loss': 27.875, 'learning_rate': 9.036e-06, 'epoch': 0.62}\n",
      "{'loss': 28.125, 'learning_rate': 9.035e-06, 'epoch': 0.62}\n",
      "{'loss': 30.75, 'learning_rate': 9.034e-06, 'epoch': 0.62}\n",
      "{'loss': 28.25, 'learning_rate': 9.033000000000001e-06, 'epoch': 0.62}\n",
      "{'loss': 28.125, 'learning_rate': 9.032000000000001e-06, 'epoch': 0.62}\n",
      "{'loss': 29.625, 'learning_rate': 9.031e-06, 'epoch': 0.62}\n",
      "{'loss': 28.25, 'learning_rate': 9.030000000000002e-06, 'epoch': 0.62}\n",
      "{'loss': 28.125, 'learning_rate': 9.029000000000001e-06, 'epoch': 0.62}\n",
      "{'loss': 28.125, 'learning_rate': 9.028e-06, 'epoch': 0.62}\n",
      "{'loss': 29.875, 'learning_rate': 9.027e-06, 'epoch': 0.62}\n",
      "{'loss': 27.125, 'learning_rate': 9.026e-06, 'epoch': 0.63}\n",
      "{'loss': 28.875, 'learning_rate': 9.025e-06, 'epoch': 0.63}\n",
      "{'loss': 30.75, 'learning_rate': 9.024e-06, 'epoch': 0.63}\n",
      "{'loss': 28.125, 'learning_rate': 9.023e-06, 'epoch': 0.63}\n",
      "{'loss': 27.75, 'learning_rate': 9.022000000000001e-06, 'epoch': 0.63}\n",
      "{'loss': 29.875, 'learning_rate': 9.021e-06, 'epoch': 0.63}\n",
      "{'loss': 28.875, 'learning_rate': 9.020000000000002e-06, 'epoch': 0.63}\n",
      "{'loss': 28.5, 'learning_rate': 9.019000000000001e-06, 'epoch': 0.63}\n",
      "{'loss': 29.0, 'learning_rate': 9.018e-06, 'epoch': 0.63}\n",
      "{'loss': 28.625, 'learning_rate': 9.017e-06, 'epoch': 0.63}\n",
      "{'loss': 29.625, 'learning_rate': 9.016e-06, 'epoch': 0.63}\n",
      "{'loss': 28.375, 'learning_rate': 9.015000000000001e-06, 'epoch': 0.63}\n",
      "{'loss': 28.625, 'learning_rate': 9.014e-06, 'epoch': 0.63}\n",
      "{'loss': 28.25, 'learning_rate': 9.013e-06, 'epoch': 0.63}\n",
      "{'loss': 27.625, 'learning_rate': 9.012000000000001e-06, 'epoch': 0.63}\n",
      "{'loss': 28.375, 'learning_rate': 9.011e-06, 'epoch': 0.63}\n",
      "{'loss': 28.125, 'learning_rate': 9.01e-06, 'epoch': 0.64}\n",
      "{'loss': 27.875, 'learning_rate': 9.009000000000001e-06, 'epoch': 0.64}\n",
      "{'loss': 29.5, 'learning_rate': 9.008e-06, 'epoch': 0.64}\n",
      "{'loss': 28.875, 'learning_rate': 9.007e-06, 'epoch': 0.64}\n",
      "{'loss': 29.125, 'learning_rate': 9.006e-06, 'epoch': 0.64}\n",
      "{'loss': 30.0, 'learning_rate': 9.005000000000001e-06, 'epoch': 0.64}\n",
      "{'loss': 29.0, 'learning_rate': 9.004e-06, 'epoch': 0.64}\n",
      "{'loss': 30.0, 'learning_rate': 9.003e-06, 'epoch': 0.64}\n",
      "{'loss': 29.0, 'learning_rate': 9.002000000000001e-06, 'epoch': 0.64}\n",
      "{'loss': 30.25, 'learning_rate': 9.001e-06, 'epoch': 0.64}\n",
      "{'loss': 28.375, 'learning_rate': 9e-06, 'epoch': 0.64}\n",
      "{'loss': 29.5, 'learning_rate': 8.999000000000001e-06, 'epoch': 0.64}\n",
      "{'loss': 29.5, 'learning_rate': 8.998000000000001e-06, 'epoch': 0.64}\n",
      "{'loss': 28.25, 'learning_rate': 8.997000000000002e-06, 'epoch': 0.64}\n",
      "{'loss': 27.75, 'learning_rate': 8.996e-06, 'epoch': 0.64}\n",
      "{'loss': 28.25, 'learning_rate': 8.995000000000001e-06, 'epoch': 0.65}\n",
      "{'loss': 30.125, 'learning_rate': 8.994e-06, 'epoch': 0.65}\n",
      "{'loss': 29.5, 'learning_rate': 8.993e-06, 'epoch': 0.65}\n",
      "{'loss': 28.5, 'learning_rate': 8.992000000000001e-06, 'epoch': 0.65}\n",
      "{'loss': 27.75, 'learning_rate': 8.991e-06, 'epoch': 0.65}\n",
      "{'loss': 28.125, 'learning_rate': 8.99e-06, 'epoch': 0.65}\n",
      "{'loss': 29.625, 'learning_rate': 8.989000000000002e-06, 'epoch': 0.65}\n",
      "{'loss': 28.625, 'learning_rate': 8.988000000000001e-06, 'epoch': 0.65}\n",
      "{'loss': 29.125, 'learning_rate': 8.987e-06, 'epoch': 0.65}\n",
      "{'loss': 29.25, 'learning_rate': 8.986e-06, 'epoch': 0.65}\n",
      "{'loss': 28.625, 'learning_rate': 8.985000000000001e-06, 'epoch': 0.65}\n",
      "{'loss': 28.5, 'learning_rate': 8.984e-06, 'epoch': 0.65}\n",
      "{'loss': 28.0, 'learning_rate': 8.983e-06, 'epoch': 0.65}\n",
      "{'loss': 28.875, 'learning_rate': 8.982000000000001e-06, 'epoch': 0.65}\n",
      "{'loss': 29.0, 'learning_rate': 8.981000000000001e-06, 'epoch': 0.65}\n",
      "{'loss': 29.0, 'learning_rate': 8.98e-06, 'epoch': 0.65}\n",
      "{'loss': 30.25, 'learning_rate': 8.979000000000002e-06, 'epoch': 0.66}\n",
      "{'loss': 29.375, 'learning_rate': 8.978000000000001e-06, 'epoch': 0.66}\n",
      "{'loss': 30.0, 'learning_rate': 8.977e-06, 'epoch': 0.66}\n",
      "{'loss': 29.125, 'learning_rate': 8.976e-06, 'epoch': 0.66}\n",
      "{'loss': 28.0, 'learning_rate': 8.975e-06, 'epoch': 0.66}\n",
      "{'loss': 27.125, 'learning_rate': 8.974e-06, 'epoch': 0.66}\n",
      "{'loss': 28.75, 'learning_rate': 8.973e-06, 'epoch': 0.66}\n",
      "{'loss': 29.625, 'learning_rate': 8.972000000000002e-06, 'epoch': 0.66}\n",
      "{'loss': 28.625, 'learning_rate': 8.971000000000001e-06, 'epoch': 0.66}\n",
      "{'loss': 28.125, 'learning_rate': 8.97e-06, 'epoch': 0.66}\n",
      "{'loss': 30.25, 'learning_rate': 8.969000000000002e-06, 'epoch': 0.66}\n",
      "{'loss': 28.75, 'learning_rate': 8.968000000000001e-06, 'epoch': 0.66}\n",
      "{'loss': 27.5, 'learning_rate': 8.967e-06, 'epoch': 0.66}\n",
      "{'loss': 28.75, 'learning_rate': 8.966e-06, 'epoch': 0.66}\n",
      "{'loss': 28.625, 'learning_rate': 8.965e-06, 'epoch': 0.66}\n",
      "{'loss': 28.5, 'learning_rate': 8.964000000000001e-06, 'epoch': 0.66}\n",
      "{'loss': 31.0, 'learning_rate': 8.963e-06, 'epoch': 0.67}\n",
      "{'loss': 28.75, 'learning_rate': 8.962e-06, 'epoch': 0.67}\n",
      "{'loss': 29.875, 'learning_rate': 8.961000000000001e-06, 'epoch': 0.67}\n",
      "{'loss': 28.5, 'learning_rate': 8.96e-06, 'epoch': 0.67}\n",
      "{'loss': 28.5, 'learning_rate': 8.959000000000002e-06, 'epoch': 0.67}\n",
      "{'loss': 28.25, 'learning_rate': 8.958000000000001e-06, 'epoch': 0.67}\n",
      "{'loss': 29.0, 'learning_rate': 8.957e-06, 'epoch': 0.67}\n",
      "{'loss': 29.75, 'learning_rate': 8.956e-06, 'epoch': 0.67}\n",
      "{'loss': 28.875, 'learning_rate': 8.955e-06, 'epoch': 0.67}\n",
      "{'loss': 27.875, 'learning_rate': 8.954000000000001e-06, 'epoch': 0.67}\n",
      "{'loss': 27.875, 'learning_rate': 8.953e-06, 'epoch': 0.67}\n",
      "{'loss': 29.625, 'learning_rate': 8.952e-06, 'epoch': 0.67}\n",
      "{'loss': 27.625, 'learning_rate': 8.951000000000001e-06, 'epoch': 0.67}\n",
      "{'loss': 28.0, 'learning_rate': 8.95e-06, 'epoch': 0.67}\n",
      "{'loss': 28.125, 'learning_rate': 8.949e-06, 'epoch': 0.67}\n",
      "{'loss': 29.25, 'learning_rate': 8.948000000000001e-06, 'epoch': 0.68}\n",
      "{'loss': 27.5, 'learning_rate': 8.947000000000001e-06, 'epoch': 0.68}\n",
      "{'loss': 29.375, 'learning_rate': 8.946e-06, 'epoch': 0.68}\n",
      "{'loss': 29.375, 'learning_rate': 8.945e-06, 'epoch': 0.68}\n",
      "{'loss': 28.625, 'learning_rate': 8.944000000000001e-06, 'epoch': 0.68}\n",
      "{'loss': 28.75, 'learning_rate': 8.943e-06, 'epoch': 0.68}\n",
      "{'loss': 27.75, 'learning_rate': 8.942e-06, 'epoch': 0.68}\n",
      "{'loss': 28.875, 'learning_rate': 8.941000000000001e-06, 'epoch': 0.68}\n",
      "{'loss': 28.0, 'learning_rate': 8.94e-06, 'epoch': 0.68}\n",
      "{'loss': 28.625, 'learning_rate': 8.939e-06, 'epoch': 0.68}\n",
      "{'loss': 28.0, 'learning_rate': 8.938000000000001e-06, 'epoch': 0.68}\n",
      "{'loss': 28.0, 'learning_rate': 8.937000000000001e-06, 'epoch': 0.68}\n",
      "{'loss': 28.0, 'learning_rate': 8.936e-06, 'epoch': 0.68}\n",
      "{'loss': 29.125, 'learning_rate': 8.935e-06, 'epoch': 0.68}\n",
      "{'loss': 31.375, 'learning_rate': 8.934000000000001e-06, 'epoch': 0.68}\n",
      "{'loss': 28.25, 'learning_rate': 8.933e-06, 'epoch': 0.68}\n",
      "{'loss': 29.625, 'learning_rate': 8.932e-06, 'epoch': 0.69}\n",
      "{'loss': 29.625, 'learning_rate': 8.931000000000001e-06, 'epoch': 0.69}\n",
      "{'loss': 28.5, 'learning_rate': 8.930000000000001e-06, 'epoch': 0.69}\n",
      "{'loss': 28.25, 'learning_rate': 8.929e-06, 'epoch': 0.69}\n",
      "{'loss': 29.875, 'learning_rate': 8.928000000000002e-06, 'epoch': 0.69}\n",
      "{'loss': 28.25, 'learning_rate': 8.927000000000001e-06, 'epoch': 0.69}\n",
      "{'loss': 28.875, 'learning_rate': 8.926e-06, 'epoch': 0.69}\n",
      "{'loss': 29.125, 'learning_rate': 8.925e-06, 'epoch': 0.69}\n",
      "{'loss': 28.875, 'learning_rate': 8.924e-06, 'epoch': 0.69}\n",
      "{'loss': 28.0, 'learning_rate': 8.923e-06, 'epoch': 0.69}\n",
      "{'loss': 30.75, 'learning_rate': 8.922e-06, 'epoch': 0.69}\n",
      "{'loss': 28.0, 'learning_rate': 8.921000000000001e-06, 'epoch': 0.69}\n",
      "{'loss': 28.5, 'learning_rate': 8.920000000000001e-06, 'epoch': 0.69}\n",
      "{'loss': 28.75, 'learning_rate': 8.919e-06, 'epoch': 0.69}\n",
      "{'loss': 28.125, 'learning_rate': 8.918000000000002e-06, 'epoch': 0.69}\n",
      "{'loss': 28.5, 'learning_rate': 8.917000000000001e-06, 'epoch': 0.7}\n",
      "{'loss': 27.875, 'learning_rate': 8.916e-06, 'epoch': 0.7}\n",
      "{'loss': 28.25, 'learning_rate': 8.915e-06, 'epoch': 0.7}\n",
      "{'loss': 28.5, 'learning_rate': 8.914e-06, 'epoch': 0.7}\n",
      "{'loss': 27.75, 'learning_rate': 8.913000000000001e-06, 'epoch': 0.7}\n",
      "{'loss': 29.125, 'learning_rate': 8.912e-06, 'epoch': 0.7}\n",
      "{'loss': 28.75, 'learning_rate': 8.911000000000002e-06, 'epoch': 0.7}\n",
      "{'loss': 27.75, 'learning_rate': 8.910000000000001e-06, 'epoch': 0.7}\n",
      "{'loss': 28.625, 'learning_rate': 8.909e-06, 'epoch': 0.7}\n",
      "{'loss': 27.75, 'learning_rate': 8.908000000000002e-06, 'epoch': 0.7}\n",
      "{'loss': 28.375, 'learning_rate': 8.907000000000001e-06, 'epoch': 0.7}\n",
      "{'loss': 27.625, 'learning_rate': 8.906e-06, 'epoch': 0.7}\n",
      "{'loss': 28.25, 'learning_rate': 8.905e-06, 'epoch': 0.7}\n",
      "{'loss': 28.375, 'learning_rate': 8.904e-06, 'epoch': 0.7}\n",
      "{'loss': 28.25, 'learning_rate': 8.903000000000001e-06, 'epoch': 0.7}\n",
      "{'loss': 28.625, 'learning_rate': 8.902e-06, 'epoch': 0.7}\n",
      "{'loss': 28.625, 'learning_rate': 8.901e-06, 'epoch': 0.71}\n",
      "{'loss': 28.0, 'learning_rate': 8.900000000000001e-06, 'epoch': 0.71}\n",
      "{'loss': 28.125, 'learning_rate': 8.899e-06, 'epoch': 0.71}\n",
      "{'loss': 27.625, 'learning_rate': 8.898000000000002e-06, 'epoch': 0.71}\n",
      "{'loss': 28.625, 'learning_rate': 8.897000000000001e-06, 'epoch': 0.71}\n",
      "{'loss': 28.375, 'learning_rate': 8.896000000000001e-06, 'epoch': 0.71}\n",
      "{'loss': 27.875, 'learning_rate': 8.895e-06, 'epoch': 0.71}\n",
      "{'loss': 28.25, 'learning_rate': 8.894e-06, 'epoch': 0.71}\n",
      "{'loss': 28.75, 'learning_rate': 8.893000000000001e-06, 'epoch': 0.71}\n",
      "{'loss': 28.375, 'learning_rate': 8.892e-06, 'epoch': 0.71}\n",
      "{'loss': 27.5, 'learning_rate': 8.891e-06, 'epoch': 0.71}\n",
      "{'loss': 29.875, 'learning_rate': 8.890000000000001e-06, 'epoch': 0.71}\n",
      "{'loss': 29.5, 'learning_rate': 8.889e-06, 'epoch': 0.71}\n",
      "{'loss': 28.625, 'learning_rate': 8.888e-06, 'epoch': 0.71}\n",
      "{'loss': 27.75, 'learning_rate': 8.887000000000001e-06, 'epoch': 0.71}\n",
      "{'loss': 29.0, 'learning_rate': 8.886000000000001e-06, 'epoch': 0.72}\n",
      "{'loss': 28.25, 'learning_rate': 8.885e-06, 'epoch': 0.72}\n",
      "{'loss': 28.875, 'learning_rate': 8.884e-06, 'epoch': 0.72}\n",
      "{'loss': 28.5, 'learning_rate': 8.883000000000001e-06, 'epoch': 0.72}\n",
      "{'loss': 28.125, 'learning_rate': 8.882e-06, 'epoch': 0.72}\n",
      "{'loss': 28.5, 'learning_rate': 8.881e-06, 'epoch': 0.72}\n",
      "{'loss': 28.625, 'learning_rate': 8.880000000000001e-06, 'epoch': 0.72}\n",
      "{'loss': 28.25, 'learning_rate': 8.879000000000001e-06, 'epoch': 0.72}\n",
      "{'loss': 29.25, 'learning_rate': 8.878e-06, 'epoch': 0.72}\n",
      "{'loss': 27.75, 'learning_rate': 8.877000000000002e-06, 'epoch': 0.72}\n",
      "{'loss': 29.5, 'learning_rate': 8.876e-06, 'epoch': 0.72}\n",
      "{'loss': 27.875, 'learning_rate': 8.875e-06, 'epoch': 0.72}\n",
      "{'loss': 28.25, 'learning_rate': 8.874e-06, 'epoch': 0.72}\n",
      "{'loss': 29.625, 'learning_rate': 8.873000000000001e-06, 'epoch': 0.72}\n",
      "{'loss': 28.125, 'learning_rate': 8.872e-06, 'epoch': 0.72}\n",
      "{'loss': 28.5, 'learning_rate': 8.871e-06, 'epoch': 0.72}\n",
      "{'loss': 28.125, 'learning_rate': 8.870000000000001e-06, 'epoch': 0.73}\n",
      "{'loss': 28.25, 'learning_rate': 8.869000000000001e-06, 'epoch': 0.73}\n",
      "{'loss': 29.875, 'learning_rate': 8.868e-06, 'epoch': 0.73}\n",
      "{'loss': 28.125, 'learning_rate': 8.867000000000002e-06, 'epoch': 0.73}\n",
      "{'loss': 27.75, 'learning_rate': 8.866000000000001e-06, 'epoch': 0.73}\n",
      "{'loss': 27.125, 'learning_rate': 8.865e-06, 'epoch': 0.73}\n",
      "{'loss': 27.625, 'learning_rate': 8.864e-06, 'epoch': 0.73}\n",
      "{'loss': 30.0, 'learning_rate': 8.863e-06, 'epoch': 0.73}\n",
      "{'loss': 29.5, 'learning_rate': 8.862000000000001e-06, 'epoch': 0.73}\n",
      "{'loss': 28.0, 'learning_rate': 8.861e-06, 'epoch': 0.73}\n",
      "{'loss': 30.0, 'learning_rate': 8.860000000000002e-06, 'epoch': 0.73}\n",
      "{'loss': 30.75, 'learning_rate': 8.859000000000001e-06, 'epoch': 0.73}\n",
      "{'loss': 28.75, 'learning_rate': 8.858e-06, 'epoch': 0.73}\n",
      "{'loss': 26.75, 'learning_rate': 8.857000000000002e-06, 'epoch': 0.73}\n",
      "{'loss': 28.5, 'learning_rate': 8.856000000000001e-06, 'epoch': 0.73}\n",
      "{'loss': 29.125, 'learning_rate': 8.855e-06, 'epoch': 0.73}\n",
      "{'loss': 28.375, 'learning_rate': 8.854e-06, 'epoch': 0.74}\n",
      "{'loss': 27.5, 'learning_rate': 8.853e-06, 'epoch': 0.74}\n",
      "{'loss': 28.0, 'learning_rate': 8.852000000000001e-06, 'epoch': 0.74}\n",
      "{'loss': 28.125, 'learning_rate': 8.851e-06, 'epoch': 0.74}\n",
      "{'loss': 30.0, 'learning_rate': 8.85e-06, 'epoch': 0.74}\n",
      "{'loss': 27.125, 'learning_rate': 8.849000000000001e-06, 'epoch': 0.74}\n",
      "{'loss': 30.25, 'learning_rate': 8.848e-06, 'epoch': 0.74}\n",
      "{'loss': 28.125, 'learning_rate': 8.847000000000002e-06, 'epoch': 0.74}\n",
      "{'loss': 27.875, 'learning_rate': 8.846000000000001e-06, 'epoch': 0.74}\n",
      "{'loss': 28.375, 'learning_rate': 8.845000000000001e-06, 'epoch': 0.74}\n",
      "{'loss': 28.5, 'learning_rate': 8.844e-06, 'epoch': 0.74}\n",
      "{'loss': 28.625, 'learning_rate': 8.843e-06, 'epoch': 0.74}\n",
      "{'loss': 28.25, 'learning_rate': 8.842000000000001e-06, 'epoch': 0.74}\n",
      "{'loss': 28.375, 'learning_rate': 8.841e-06, 'epoch': 0.74}\n",
      "{'loss': 27.875, 'learning_rate': 8.84e-06, 'epoch': 0.74}\n",
      "{'loss': 29.0, 'learning_rate': 8.839000000000001e-06, 'epoch': 0.75}\n",
      "{'loss': 28.75, 'learning_rate': 8.838e-06, 'epoch': 0.75}\n",
      "{'loss': 29.25, 'learning_rate': 8.837000000000002e-06, 'epoch': 0.75}\n",
      "{'loss': 27.375, 'learning_rate': 8.836000000000001e-06, 'epoch': 0.75}\n",
      "{'loss': 27.5, 'learning_rate': 8.835000000000001e-06, 'epoch': 0.75}\n",
      "{'loss': 28.875, 'learning_rate': 8.834e-06, 'epoch': 0.75}\n",
      "{'loss': 28.625, 'learning_rate': 8.833e-06, 'epoch': 0.75}\n",
      "{'loss': 28.625, 'learning_rate': 8.832000000000001e-06, 'epoch': 0.75}\n",
      "{'loss': 26.875, 'learning_rate': 8.831e-06, 'epoch': 0.75}\n",
      "{'loss': 28.25, 'learning_rate': 8.83e-06, 'epoch': 0.75}\n",
      "{'loss': 28.625, 'learning_rate': 8.829000000000001e-06, 'epoch': 0.75}\n",
      "{'loss': 27.625, 'learning_rate': 8.828000000000001e-06, 'epoch': 0.75}\n",
      "{'loss': 28.375, 'learning_rate': 8.827e-06, 'epoch': 0.75}\n",
      "{'loss': 28.625, 'learning_rate': 8.826000000000002e-06, 'epoch': 0.75}\n",
      "{'loss': 28.625, 'learning_rate': 8.825000000000001e-06, 'epoch': 0.75}\n",
      "{'loss': 27.0, 'learning_rate': 8.824e-06, 'epoch': 0.75}\n",
      "{'loss': 27.625, 'learning_rate': 8.823e-06, 'epoch': 0.76}\n",
      "{'loss': 28.75, 'learning_rate': 8.822000000000001e-06, 'epoch': 0.76}\n",
      "{'loss': 28.0, 'learning_rate': 8.821e-06, 'epoch': 0.76}\n",
      "{'loss': 27.625, 'learning_rate': 8.82e-06, 'epoch': 0.76}\n",
      "{'loss': 29.0, 'learning_rate': 8.819000000000001e-06, 'epoch': 0.76}\n",
      "{'loss': 28.625, 'learning_rate': 8.818000000000001e-06, 'epoch': 0.76}\n",
      "{'loss': 27.75, 'learning_rate': 8.817e-06, 'epoch': 0.76}\n",
      "{'loss': 28.125, 'learning_rate': 8.816000000000002e-06, 'epoch': 0.76}\n",
      "{'loss': 29.375, 'learning_rate': 8.815e-06, 'epoch': 0.76}\n",
      "{'loss': 28.25, 'learning_rate': 8.814e-06, 'epoch': 0.76}\n",
      "{'loss': 28.375, 'learning_rate': 8.813e-06, 'epoch': 0.76}\n",
      "{'loss': 29.125, 'learning_rate': 8.812000000000001e-06, 'epoch': 0.76}\n",
      "{'loss': 28.625, 'learning_rate': 8.811000000000001e-06, 'epoch': 0.76}\n",
      "{'loss': 28.125, 'learning_rate': 8.81e-06, 'epoch': 0.76}\n",
      "{'loss': 29.75, 'learning_rate': 8.809000000000002e-06, 'epoch': 0.76}\n",
      "{'loss': 28.875, 'learning_rate': 8.808000000000001e-06, 'epoch': 0.77}\n",
      "{'loss': 28.5, 'learning_rate': 8.807e-06, 'epoch': 0.77}\n",
      "{'loss': 28.75, 'learning_rate': 8.806000000000002e-06, 'epoch': 0.77}\n",
      "{'loss': 28.875, 'learning_rate': 8.805e-06, 'epoch': 0.77}\n",
      "{'loss': 28.75, 'learning_rate': 8.804e-06, 'epoch': 0.77}\n",
      "{'loss': 29.75, 'learning_rate': 8.803e-06, 'epoch': 0.77}\n",
      "{'loss': 29.25, 'learning_rate': 8.802e-06, 'epoch': 0.77}\n",
      "{'loss': 28.75, 'learning_rate': 8.801000000000001e-06, 'epoch': 0.77}\n",
      "{'loss': 27.75, 'learning_rate': 8.8e-06, 'epoch': 0.77}\n",
      "{'loss': 29.375, 'learning_rate': 8.799000000000002e-06, 'epoch': 0.77}\n",
      "{'loss': 27.625, 'learning_rate': 8.798000000000001e-06, 'epoch': 0.77}\n",
      "{'loss': 27.625, 'learning_rate': 8.797e-06, 'epoch': 0.77}\n",
      "{'loss': 29.625, 'learning_rate': 8.796000000000002e-06, 'epoch': 0.77}\n",
      "{'loss': 27.375, 'learning_rate': 8.795e-06, 'epoch': 0.77}\n",
      "{'loss': 28.0, 'learning_rate': 8.794e-06, 'epoch': 0.77}\n",
      "{'loss': 27.375, 'learning_rate': 8.793e-06, 'epoch': 0.77}\n",
      "{'loss': 28.125, 'learning_rate': 8.792e-06, 'epoch': 0.78}\n",
      "{'loss': 28.75, 'learning_rate': 8.791000000000001e-06, 'epoch': 0.78}\n",
      "{'loss': 28.25, 'learning_rate': 8.79e-06, 'epoch': 0.78}\n",
      "{'loss': 28.5, 'learning_rate': 8.789e-06, 'epoch': 0.78}\n",
      "{'loss': 29.5, 'learning_rate': 8.788000000000001e-06, 'epoch': 0.78}\n",
      "{'loss': 28.75, 'learning_rate': 8.787e-06, 'epoch': 0.78}\n",
      "{'loss': 29.25, 'learning_rate': 8.786000000000002e-06, 'epoch': 0.78}\n",
      "{'loss': 28.125, 'learning_rate': 8.785e-06, 'epoch': 0.78}\n",
      "{'loss': 29.125, 'learning_rate': 8.784000000000001e-06, 'epoch': 0.78}\n",
      "{'loss': 28.75, 'learning_rate': 8.783e-06, 'epoch': 0.78}\n",
      "{'loss': 28.5, 'learning_rate': 8.782e-06, 'epoch': 0.78}\n",
      "{'loss': 28.375, 'learning_rate': 8.781000000000001e-06, 'epoch': 0.78}\n",
      "{'loss': 28.875, 'learning_rate': 8.78e-06, 'epoch': 0.78}\n",
      "{'loss': 27.875, 'learning_rate': 8.779e-06, 'epoch': 0.78}\n",
      "{'loss': 28.25, 'learning_rate': 8.778000000000001e-06, 'epoch': 0.78}\n",
      "{'loss': 27.375, 'learning_rate': 8.777e-06, 'epoch': 0.78}\n",
      "{'loss': 28.75, 'learning_rate': 8.776e-06, 'epoch': 0.79}\n",
      "{'loss': 28.0, 'learning_rate': 8.775e-06, 'epoch': 0.79}\n",
      "{'loss': 27.875, 'learning_rate': 8.774000000000001e-06, 'epoch': 0.79}\n",
      "{'loss': 28.625, 'learning_rate': 8.773e-06, 'epoch': 0.79}\n",
      "{'loss': 28.375, 'learning_rate': 8.772e-06, 'epoch': 0.79}\n",
      "{'loss': 27.25, 'learning_rate': 8.771000000000001e-06, 'epoch': 0.79}\n",
      "{'loss': 28.5, 'learning_rate': 8.77e-06, 'epoch': 0.79}\n",
      "{'loss': 28.125, 'learning_rate': 8.769e-06, 'epoch': 0.79}\n",
      "{'loss': 28.125, 'learning_rate': 8.768000000000001e-06, 'epoch': 0.79}\n",
      "{'loss': 28.0, 'learning_rate': 8.767000000000001e-06, 'epoch': 0.79}\n",
      "{'loss': 28.75, 'learning_rate': 8.766e-06, 'epoch': 0.79}\n",
      "{'loss': 28.5, 'learning_rate': 8.765e-06, 'epoch': 0.79}\n",
      "{'loss': 27.875, 'learning_rate': 8.764e-06, 'epoch': 0.79}\n",
      "{'loss': 30.75, 'learning_rate': 8.763e-06, 'epoch': 0.79}\n",
      "{'loss': 27.625, 'learning_rate': 8.762e-06, 'epoch': 0.79}\n",
      "{'loss': 27.375, 'learning_rate': 8.761000000000001e-06, 'epoch': 0.8}\n",
      "{'loss': 29.125, 'learning_rate': 8.76e-06, 'epoch': 0.8}\n",
      "{'loss': 27.25, 'learning_rate': 8.759e-06, 'epoch': 0.8}\n",
      "{'loss': 28.25, 'learning_rate': 8.758000000000002e-06, 'epoch': 0.8}\n",
      "{'loss': 29.5, 'learning_rate': 8.757000000000001e-06, 'epoch': 0.8}\n",
      "{'loss': 29.625, 'learning_rate': 8.756e-06, 'epoch': 0.8}\n",
      "{'loss': 28.5, 'learning_rate': 8.755e-06, 'epoch': 0.8}\n",
      "{'loss': 27.625, 'learning_rate': 8.754e-06, 'epoch': 0.8}\n",
      "{'loss': 27.75, 'learning_rate': 8.753e-06, 'epoch': 0.8}\n",
      "{'loss': 28.5, 'learning_rate': 8.752e-06, 'epoch': 0.8}\n",
      "{'loss': 28.625, 'learning_rate': 8.751000000000001e-06, 'epoch': 0.8}\n",
      "{'loss': 28.625, 'learning_rate': 8.750000000000001e-06, 'epoch': 0.8}\n",
      "{'loss': 28.25, 'learning_rate': 8.749e-06, 'epoch': 0.8}\n",
      "{'loss': 27.875, 'learning_rate': 8.748000000000002e-06, 'epoch': 0.8}\n",
      "{'loss': 29.25, 'learning_rate': 8.747000000000001e-06, 'epoch': 0.8}\n",
      "{'loss': 26.625, 'learning_rate': 8.746e-06, 'epoch': 0.8}\n",
      "{'loss': 28.25, 'learning_rate': 8.745000000000002e-06, 'epoch': 0.81}\n",
      "{'loss': 27.25, 'learning_rate': 8.744e-06, 'epoch': 0.81}\n",
      "{'loss': 27.375, 'learning_rate': 8.743e-06, 'epoch': 0.81}\n",
      "{'loss': 28.25, 'learning_rate': 8.742e-06, 'epoch': 0.81}\n",
      "{'loss': 28.0, 'learning_rate': 8.741e-06, 'epoch': 0.81}\n",
      "{'loss': 28.25, 'learning_rate': 8.740000000000001e-06, 'epoch': 0.81}\n",
      "{'loss': 28.875, 'learning_rate': 8.739e-06, 'epoch': 0.81}\n",
      "{'loss': 28.75, 'learning_rate': 8.738000000000002e-06, 'epoch': 0.81}\n",
      "{'loss': 28.25, 'learning_rate': 8.737000000000001e-06, 'epoch': 0.81}\n",
      "{'loss': 28.625, 'learning_rate': 8.736e-06, 'epoch': 0.81}\n",
      "{'loss': 28.75, 'learning_rate': 8.735000000000002e-06, 'epoch': 0.81}\n",
      "{'loss': 28.5, 'learning_rate': 8.734e-06, 'epoch': 0.81}\n",
      "{'loss': 28.375, 'learning_rate': 8.733000000000001e-06, 'epoch': 0.81}\n",
      "{'loss': 29.25, 'learning_rate': 8.732e-06, 'epoch': 0.81}\n",
      "{'loss': 28.125, 'learning_rate': 8.731e-06, 'epoch': 0.81}\n",
      "{'loss': 28.625, 'learning_rate': 8.730000000000001e-06, 'epoch': 0.82}\n",
      "{'loss': 27.5, 'learning_rate': 8.729e-06, 'epoch': 0.82}\n",
      "{'loss': 27.75, 'learning_rate': 8.728e-06, 'epoch': 0.82}\n",
      "{'loss': 27.5, 'learning_rate': 8.727000000000001e-06, 'epoch': 0.82}\n",
      "{'loss': 27.25, 'learning_rate': 8.726e-06, 'epoch': 0.82}\n",
      "{'loss': 28.625, 'learning_rate': 8.725000000000002e-06, 'epoch': 0.82}\n",
      "{'loss': 28.625, 'learning_rate': 8.724e-06, 'epoch': 0.82}\n",
      "{'loss': 27.5, 'learning_rate': 8.723000000000001e-06, 'epoch': 0.82}\n",
      "{'loss': 28.25, 'learning_rate': 8.722e-06, 'epoch': 0.82}\n",
      "{'loss': 28.375, 'learning_rate': 8.721e-06, 'epoch': 0.82}\n",
      "{'loss': 28.0, 'learning_rate': 8.720000000000001e-06, 'epoch': 0.82}\n",
      "{'loss': 28.875, 'learning_rate': 8.719e-06, 'epoch': 0.82}\n",
      "{'loss': 29.375, 'learning_rate': 8.718e-06, 'epoch': 0.82}\n",
      "{'loss': 27.375, 'learning_rate': 8.717000000000001e-06, 'epoch': 0.82}\n",
      "{'loss': 28.625, 'learning_rate': 8.716000000000001e-06, 'epoch': 0.82}\n",
      "{'loss': 28.0, 'learning_rate': 8.715e-06, 'epoch': 0.82}\n",
      "{'loss': 27.875, 'learning_rate': 8.714e-06, 'epoch': 0.83}\n",
      "{'loss': 28.125, 'learning_rate': 8.713000000000001e-06, 'epoch': 0.83}\n",
      "{'loss': 27.375, 'learning_rate': 8.712e-06, 'epoch': 0.83}\n",
      "{'loss': 28.25, 'learning_rate': 8.711e-06, 'epoch': 0.83}\n",
      "{'loss': 29.125, 'learning_rate': 8.710000000000001e-06, 'epoch': 0.83}\n",
      "{'loss': 28.125, 'learning_rate': 8.709e-06, 'epoch': 0.83}\n",
      "{'loss': 27.625, 'learning_rate': 8.708e-06, 'epoch': 0.83}\n",
      "{'loss': 27.625, 'learning_rate': 8.707000000000002e-06, 'epoch': 0.83}\n",
      "{'loss': 29.5, 'learning_rate': 8.706000000000001e-06, 'epoch': 0.83}\n",
      "{'loss': 27.375, 'learning_rate': 8.705e-06, 'epoch': 0.83}\n",
      "{'loss': 28.625, 'learning_rate': 8.704e-06, 'epoch': 0.83}\n",
      "{'loss': 30.0, 'learning_rate': 8.703e-06, 'epoch': 0.83}\n",
      "{'loss': 29.875, 'learning_rate': 8.702e-06, 'epoch': 0.83}\n",
      "{'loss': 29.375, 'learning_rate': 8.701e-06, 'epoch': 0.83}\n",
      "{'loss': 28.625, 'learning_rate': 8.700000000000001e-06, 'epoch': 0.83}\n",
      "{'loss': 29.25, 'learning_rate': 8.699000000000001e-06, 'epoch': 0.84}\n",
      "{'loss': 30.625, 'learning_rate': 8.698e-06, 'epoch': 0.84}\n",
      "{'loss': 29.5, 'learning_rate': 8.697000000000002e-06, 'epoch': 0.84}\n",
      "{'loss': 27.375, 'learning_rate': 8.696000000000001e-06, 'epoch': 0.84}\n",
      "{'loss': 28.0, 'learning_rate': 8.695e-06, 'epoch': 0.84}\n",
      "{'loss': 27.25, 'learning_rate': 8.694e-06, 'epoch': 0.84}\n",
      "{'loss': 28.0, 'learning_rate': 8.693e-06, 'epoch': 0.84}\n",
      "{'loss': 27.5, 'learning_rate': 8.692e-06, 'epoch': 0.84}\n",
      "{'loss': 29.5, 'learning_rate': 8.691e-06, 'epoch': 0.84}\n",
      "{'loss': 29.0, 'learning_rate': 8.690000000000002e-06, 'epoch': 0.84}\n",
      "{'loss': 28.0, 'learning_rate': 8.689000000000001e-06, 'epoch': 0.84}\n",
      "{'loss': 28.0, 'learning_rate': 8.688e-06, 'epoch': 0.84}\n",
      "{'loss': 28.0, 'learning_rate': 8.687000000000002e-06, 'epoch': 0.84}\n",
      "{'loss': 28.5, 'learning_rate': 8.686000000000001e-06, 'epoch': 0.84}\n",
      "{'loss': 29.125, 'learning_rate': 8.685e-06, 'epoch': 0.84}\n",
      "{'loss': 28.875, 'learning_rate': 8.684e-06, 'epoch': 0.84}\n",
      "{'loss': 26.5, 'learning_rate': 8.683e-06, 'epoch': 0.85}\n",
      "{'loss': 27.5, 'learning_rate': 8.682000000000001e-06, 'epoch': 0.85}\n",
      "{'loss': 28.875, 'learning_rate': 8.681e-06, 'epoch': 0.85}\n",
      "{'loss': 28.0, 'learning_rate': 8.68e-06, 'epoch': 0.85}\n",
      "{'loss': 30.0, 'learning_rate': 8.679000000000001e-06, 'epoch': 0.85}\n",
      "{'loss': 28.25, 'learning_rate': 8.678e-06, 'epoch': 0.85}\n",
      "{'loss': 27.0, 'learning_rate': 8.677000000000002e-06, 'epoch': 0.85}\n",
      "{'loss': 28.125, 'learning_rate': 8.676000000000001e-06, 'epoch': 0.85}\n",
      "{'loss': 28.0, 'learning_rate': 8.675e-06, 'epoch': 0.85}\n",
      "{'loss': 27.375, 'learning_rate': 8.674e-06, 'epoch': 0.85}\n",
      "{'loss': 27.5, 'learning_rate': 8.673e-06, 'epoch': 0.85}\n",
      "{'loss': 28.5, 'learning_rate': 8.672000000000001e-06, 'epoch': 0.85}\n",
      "{'loss': 27.375, 'learning_rate': 8.671e-06, 'epoch': 0.85}\n",
      "{'loss': 26.75, 'learning_rate': 8.67e-06, 'epoch': 0.85}\n",
      "{'loss': 28.0, 'learning_rate': 8.669000000000001e-06, 'epoch': 0.85}\n",
      "{'loss': 28.0, 'learning_rate': 8.668e-06, 'epoch': 0.85}\n",
      "{'loss': 29.0, 'learning_rate': 8.667e-06, 'epoch': 0.86}\n",
      "{'loss': 28.5, 'learning_rate': 8.666000000000001e-06, 'epoch': 0.86}\n",
      "{'loss': 28.375, 'learning_rate': 8.665000000000001e-06, 'epoch': 0.86}\n",
      "{'loss': 27.25, 'learning_rate': 8.664e-06, 'epoch': 0.86}\n",
      "{'loss': 27.5, 'learning_rate': 8.663e-06, 'epoch': 0.86}\n",
      "{'loss': 29.5, 'learning_rate': 8.662000000000001e-06, 'epoch': 0.86}\n",
      "{'loss': 29.5, 'learning_rate': 8.661e-06, 'epoch': 0.86}\n",
      "{'loss': 28.625, 'learning_rate': 8.66e-06, 'epoch': 0.86}\n",
      "{'loss': 27.75, 'learning_rate': 8.659000000000001e-06, 'epoch': 0.86}\n",
      "{'loss': 28.5, 'learning_rate': 8.658e-06, 'epoch': 0.86}\n",
      "{'loss': 28.25, 'learning_rate': 8.657e-06, 'epoch': 0.86}\n",
      "{'loss': 27.75, 'learning_rate': 8.656000000000001e-06, 'epoch': 0.86}\n",
      "{'loss': 29.125, 'learning_rate': 8.655000000000001e-06, 'epoch': 0.86}\n",
      "{'loss': 27.875, 'learning_rate': 8.654e-06, 'epoch': 0.86}\n",
      "{'loss': 27.625, 'learning_rate': 8.653e-06, 'epoch': 0.86}\n",
      "{'loss': 30.0, 'learning_rate': 8.652000000000001e-06, 'epoch': 0.87}\n",
      "{'loss': 27.5, 'learning_rate': 8.651e-06, 'epoch': 0.87}\n",
      "{'loss': 27.625, 'learning_rate': 8.65e-06, 'epoch': 0.87}\n",
      "{'loss': 28.625, 'learning_rate': 8.649000000000001e-06, 'epoch': 0.87}\n",
      "{'loss': 27.5, 'learning_rate': 8.648000000000001e-06, 'epoch': 0.87}\n",
      "{'loss': 27.25, 'learning_rate': 8.647e-06, 'epoch': 0.87}\n",
      "{'loss': 28.5, 'learning_rate': 8.646000000000002e-06, 'epoch': 0.87}\n",
      "{'loss': 27.5, 'learning_rate': 8.645000000000001e-06, 'epoch': 0.87}\n",
      "{'loss': 27.75, 'learning_rate': 8.644e-06, 'epoch': 0.87}\n",
      "{'loss': 27.875, 'learning_rate': 8.643e-06, 'epoch': 0.87}\n",
      "{'loss': 27.25, 'learning_rate': 8.642e-06, 'epoch': 0.87}\n",
      "{'loss': 28.125, 'learning_rate': 8.641e-06, 'epoch': 0.87}\n",
      "{'loss': 28.5, 'learning_rate': 8.64e-06, 'epoch': 0.87}\n",
      "{'loss': 27.75, 'learning_rate': 8.639000000000001e-06, 'epoch': 0.87}\n",
      "{'loss': 28.125, 'learning_rate': 8.638000000000001e-06, 'epoch': 0.87}\n",
      "{'loss': 27.0, 'learning_rate': 8.637e-06, 'epoch': 0.87}\n",
      "{'loss': 28.0, 'learning_rate': 8.636000000000002e-06, 'epoch': 0.88}\n",
      "{'loss': 27.125, 'learning_rate': 8.635000000000001e-06, 'epoch': 0.88}\n",
      "{'loss': 28.25, 'learning_rate': 8.634e-06, 'epoch': 0.88}\n",
      "{'loss': 28.5, 'learning_rate': 8.633e-06, 'epoch': 0.88}\n",
      "{'loss': 27.75, 'learning_rate': 8.632e-06, 'epoch': 0.88}\n",
      "{'loss': 27.75, 'learning_rate': 8.631000000000001e-06, 'epoch': 0.88}\n",
      "{'loss': 28.0, 'learning_rate': 8.63e-06, 'epoch': 0.88}\n",
      "{'loss': 28.125, 'learning_rate': 8.629e-06, 'epoch': 0.88}\n",
      "{'loss': 27.875, 'learning_rate': 8.628000000000001e-06, 'epoch': 0.88}\n",
      "{'loss': 29.125, 'learning_rate': 8.627e-06, 'epoch': 0.88}\n",
      "{'loss': 27.75, 'learning_rate': 8.626000000000002e-06, 'epoch': 0.88}\n",
      "{'loss': 28.25, 'learning_rate': 8.625000000000001e-06, 'epoch': 0.88}\n",
      "{'loss': 27.75, 'learning_rate': 8.624e-06, 'epoch': 0.88}\n",
      "{'loss': 28.5, 'learning_rate': 8.623e-06, 'epoch': 0.88}\n",
      "{'loss': 27.75, 'learning_rate': 8.622e-06, 'epoch': 0.88}\n",
      "{'loss': 29.125, 'learning_rate': 8.621000000000001e-06, 'epoch': 0.89}\n",
      "{'loss': 27.125, 'learning_rate': 8.62e-06, 'epoch': 0.89}\n",
      "{'loss': 27.625, 'learning_rate': 8.619e-06, 'epoch': 0.89}\n",
      "{'loss': 28.0, 'learning_rate': 8.618000000000001e-06, 'epoch': 0.89}\n",
      "{'loss': 28.625, 'learning_rate': 8.617e-06, 'epoch': 0.89}\n",
      "{'loss': 28.25, 'learning_rate': 8.616000000000002e-06, 'epoch': 0.89}\n",
      "{'loss': 28.5, 'learning_rate': 8.615000000000001e-06, 'epoch': 0.89}\n",
      "{'loss': 28.0, 'learning_rate': 8.614000000000001e-06, 'epoch': 0.89}\n",
      "{'loss': 27.125, 'learning_rate': 8.613e-06, 'epoch': 0.89}\n",
      "{'loss': 28.625, 'learning_rate': 8.612e-06, 'epoch': 0.89}\n",
      "{'loss': 28.0, 'learning_rate': 8.611000000000001e-06, 'epoch': 0.89}\n",
      "{'loss': 28.25, 'learning_rate': 8.61e-06, 'epoch': 0.89}\n",
      "{'loss': 28.25, 'learning_rate': 8.609e-06, 'epoch': 0.89}\n",
      "{'loss': 27.5, 'learning_rate': 8.608000000000001e-06, 'epoch': 0.89}\n",
      "{'loss': 28.25, 'learning_rate': 8.607e-06, 'epoch': 0.89}\n",
      "{'loss': 28.125, 'learning_rate': 8.606e-06, 'epoch': 0.89}\n",
      "{'loss': 27.375, 'learning_rate': 8.605000000000001e-06, 'epoch': 0.9}\n",
      "{'loss': 28.875, 'learning_rate': 8.604000000000001e-06, 'epoch': 0.9}\n",
      "{'loss': 26.75, 'learning_rate': 8.603e-06, 'epoch': 0.9}\n",
      "{'loss': 28.25, 'learning_rate': 8.602e-06, 'epoch': 0.9}\n",
      "{'loss': 27.75, 'learning_rate': 8.601000000000001e-06, 'epoch': 0.9}\n",
      "{'loss': 30.75, 'learning_rate': 8.6e-06, 'epoch': 0.9}\n",
      "{'loss': 28.375, 'learning_rate': 8.599e-06, 'epoch': 0.9}\n",
      "{'loss': 29.375, 'learning_rate': 8.598000000000001e-06, 'epoch': 0.9}\n",
      "{'loss': 27.375, 'learning_rate': 8.597000000000001e-06, 'epoch': 0.9}\n",
      "{'loss': 28.625, 'learning_rate': 8.596e-06, 'epoch': 0.9}\n",
      "{'loss': 28.875, 'learning_rate': 8.595000000000002e-06, 'epoch': 0.9}\n",
      "{'loss': 27.0, 'learning_rate': 8.594000000000001e-06, 'epoch': 0.9}\n",
      "{'loss': 29.125, 'learning_rate': 8.593e-06, 'epoch': 0.9}\n",
      "{'loss': 28.25, 'learning_rate': 8.592e-06, 'epoch': 0.9}\n",
      "{'loss': 27.375, 'learning_rate': 8.591000000000001e-06, 'epoch': 0.9}\n",
      "{'loss': 28.875, 'learning_rate': 8.59e-06, 'epoch': 0.91}\n",
      "{'loss': 28.75, 'learning_rate': 8.589e-06, 'epoch': 0.91}\n",
      "{'loss': 28.125, 'learning_rate': 8.588000000000001e-06, 'epoch': 0.91}\n",
      "{'loss': 28.375, 'learning_rate': 8.587000000000001e-06, 'epoch': 0.91}\n",
      "{'loss': 28.5, 'learning_rate': 8.586e-06, 'epoch': 0.91}\n",
      "{'loss': 27.5, 'learning_rate': 8.585000000000002e-06, 'epoch': 0.91}\n",
      "{'loss': 28.125, 'learning_rate': 8.584000000000001e-06, 'epoch': 0.91}\n",
      "{'loss': 26.875, 'learning_rate': 8.583e-06, 'epoch': 0.91}\n",
      "{'loss': 28.875, 'learning_rate': 8.582e-06, 'epoch': 0.91}\n",
      "{'loss': 27.125, 'learning_rate': 8.581e-06, 'epoch': 0.91}\n",
      "{'loss': 27.75, 'learning_rate': 8.580000000000001e-06, 'epoch': 0.91}\n",
      "{'loss': 27.375, 'learning_rate': 8.579e-06, 'epoch': 0.91}\n",
      "{'loss': 27.125, 'learning_rate': 8.578000000000002e-06, 'epoch': 0.91}\n",
      "{'loss': 27.5, 'learning_rate': 8.577000000000001e-06, 'epoch': 0.91}\n",
      "{'loss': 28.25, 'learning_rate': 8.576e-06, 'epoch': 0.91}\n",
      "{'loss': 28.0, 'learning_rate': 8.575000000000002e-06, 'epoch': 0.91}\n",
      "{'loss': 27.75, 'learning_rate': 8.574000000000001e-06, 'epoch': 0.92}\n",
      "{'loss': 28.125, 'learning_rate': 8.573e-06, 'epoch': 0.92}\n",
      "{'loss': 28.625, 'learning_rate': 8.572e-06, 'epoch': 0.92}\n",
      "{'loss': 27.375, 'learning_rate': 8.571e-06, 'epoch': 0.92}\n",
      "{'loss': 28.5, 'learning_rate': 8.570000000000001e-06, 'epoch': 0.92}\n",
      "{'loss': 28.75, 'learning_rate': 8.569e-06, 'epoch': 0.92}\n",
      "{'loss': 28.5, 'learning_rate': 8.568e-06, 'epoch': 0.92}\n",
      "{'loss': 28.25, 'learning_rate': 8.567000000000001e-06, 'epoch': 0.92}\n",
      "{'loss': 29.125, 'learning_rate': 8.566e-06, 'epoch': 0.92}\n",
      "{'loss': 27.5, 'learning_rate': 8.565000000000002e-06, 'epoch': 0.92}\n",
      "{'loss': 28.375, 'learning_rate': 8.564000000000001e-06, 'epoch': 0.92}\n",
      "{'loss': 27.625, 'learning_rate': 8.563000000000001e-06, 'epoch': 0.92}\n",
      "{'loss': 30.5, 'learning_rate': 8.562e-06, 'epoch': 0.92}\n",
      "{'loss': 27.625, 'learning_rate': 8.561e-06, 'epoch': 0.92}\n",
      "{'loss': 28.5, 'learning_rate': 8.560000000000001e-06, 'epoch': 0.92}\n",
      "{'loss': 27.375, 'learning_rate': 8.559e-06, 'epoch': 0.92}\n",
      "{'loss': 28.375, 'learning_rate': 8.558e-06, 'epoch': 0.93}\n",
      "{'loss': 29.0, 'learning_rate': 8.557000000000001e-06, 'epoch': 0.93}\n",
      "{'loss': 27.125, 'learning_rate': 8.556e-06, 'epoch': 0.93}\n",
      "{'loss': 27.625, 'learning_rate': 8.555e-06, 'epoch': 0.93}\n",
      "{'loss': 27.75, 'learning_rate': 8.554000000000001e-06, 'epoch': 0.93}\n",
      "{'loss': 27.75, 'learning_rate': 8.553000000000001e-06, 'epoch': 0.93}\n",
      "{'loss': 27.25, 'learning_rate': 8.552e-06, 'epoch': 0.93}\n",
      "{'loss': 26.875, 'learning_rate': 8.551e-06, 'epoch': 0.93}\n",
      "{'loss': 29.25, 'learning_rate': 8.550000000000001e-06, 'epoch': 0.93}\n",
      "{'loss': 27.75, 'learning_rate': 8.549e-06, 'epoch': 0.93}\n",
      "{'loss': 29.5, 'learning_rate': 8.548e-06, 'epoch': 0.93}\n",
      "{'loss': 27.375, 'learning_rate': 8.547000000000001e-06, 'epoch': 0.93}\n",
      "{'loss': 27.5, 'learning_rate': 8.546000000000001e-06, 'epoch': 0.93}\n",
      "{'loss': 28.875, 'learning_rate': 8.545e-06, 'epoch': 0.93}\n",
      "{'loss': 30.25, 'learning_rate': 8.544000000000002e-06, 'epoch': 0.93}\n",
      "{'loss': 29.25, 'learning_rate': 8.543e-06, 'epoch': 0.94}\n",
      "{'loss': 29.125, 'learning_rate': 8.542e-06, 'epoch': 0.94}\n",
      "{'loss': 28.25, 'learning_rate': 8.541e-06, 'epoch': 0.94}\n",
      "{'loss': 28.0, 'learning_rate': 8.540000000000001e-06, 'epoch': 0.94}\n",
      "{'loss': 27.125, 'learning_rate': 8.539e-06, 'epoch': 0.94}\n",
      "{'loss': 28.875, 'learning_rate': 8.538e-06, 'epoch': 0.94}\n",
      "{'loss': 29.125, 'learning_rate': 8.537000000000001e-06, 'epoch': 0.94}\n",
      "{'loss': 27.125, 'learning_rate': 8.536000000000001e-06, 'epoch': 0.94}\n",
      "{'loss': 27.625, 'learning_rate': 8.535e-06, 'epoch': 0.94}\n",
      "{'loss': 27.875, 'learning_rate': 8.534000000000002e-06, 'epoch': 0.94}\n",
      "{'loss': 27.625, 'learning_rate': 8.533e-06, 'epoch': 0.94}\n",
      "{'loss': 28.375, 'learning_rate': 8.532e-06, 'epoch': 0.94}\n",
      "{'loss': 27.75, 'learning_rate': 8.531e-06, 'epoch': 0.94}\n",
      "{'loss': 28.625, 'learning_rate': 8.530000000000001e-06, 'epoch': 0.94}\n",
      "{'loss': 29.625, 'learning_rate': 8.529e-06, 'epoch': 0.94}\n",
      "{'loss': 27.875, 'learning_rate': 8.528e-06, 'epoch': 0.94}\n",
      "{'loss': 29.0, 'learning_rate': 8.527000000000002e-06, 'epoch': 0.95}\n",
      "{'loss': 26.375, 'learning_rate': 8.526000000000001e-06, 'epoch': 0.95}\n",
      "{'loss': 28.5, 'learning_rate': 8.525e-06, 'epoch': 0.95}\n",
      "{'loss': 28.0, 'learning_rate': 8.524000000000002e-06, 'epoch': 0.95}\n",
      "{'loss': 28.375, 'learning_rate': 8.523e-06, 'epoch': 0.95}\n",
      "{'loss': 27.375, 'learning_rate': 8.522e-06, 'epoch': 0.95}\n",
      "{'loss': 31.625, 'learning_rate': 8.521e-06, 'epoch': 0.95}\n",
      "{'loss': 28.375, 'learning_rate': 8.52e-06, 'epoch': 0.95}\n",
      "{'loss': 27.625, 'learning_rate': 8.519000000000001e-06, 'epoch': 0.95}\n",
      "{'loss': 28.0, 'learning_rate': 8.518e-06, 'epoch': 0.95}\n",
      "{'loss': 28.375, 'learning_rate': 8.517000000000002e-06, 'epoch': 0.95}\n",
      "{'loss': 27.5, 'learning_rate': 8.516000000000001e-06, 'epoch': 0.95}\n",
      "{'loss': 27.625, 'learning_rate': 8.515e-06, 'epoch': 0.95}\n",
      "{'loss': 27.375, 'learning_rate': 8.514000000000002e-06, 'epoch': 0.95}\n",
      "{'loss': 27.125, 'learning_rate': 8.513e-06, 'epoch': 0.95}\n",
      "{'loss': 28.625, 'learning_rate': 8.512e-06, 'epoch': 0.96}\n",
      "{'loss': 27.5, 'learning_rate': 8.511e-06, 'epoch': 0.96}\n",
      "{'loss': 27.625, 'learning_rate': 8.51e-06, 'epoch': 0.96}\n",
      "{'loss': 28.375, 'learning_rate': 8.509000000000001e-06, 'epoch': 0.96}\n",
      "{'loss': 28.0, 'learning_rate': 8.508e-06, 'epoch': 0.96}\n",
      "{'loss': 27.625, 'learning_rate': 8.507e-06, 'epoch': 0.96}\n",
      "{'loss': 29.75, 'learning_rate': 8.506000000000001e-06, 'epoch': 0.96}\n",
      "{'loss': 29.375, 'learning_rate': 8.505e-06, 'epoch': 0.96}\n",
      "{'loss': 27.375, 'learning_rate': 8.504000000000002e-06, 'epoch': 0.96}\n",
      "{'loss': 27.625, 'learning_rate': 8.503e-06, 'epoch': 0.96}\n",
      "{'loss': 28.25, 'learning_rate': 8.502000000000001e-06, 'epoch': 0.96}\n",
      "{'loss': 27.75, 'learning_rate': 8.501e-06, 'epoch': 0.96}\n",
      "{'loss': 27.375, 'learning_rate': 8.5e-06, 'epoch': 0.96}\n",
      "{'loss': 28.25, 'learning_rate': 8.499000000000001e-06, 'epoch': 0.96}\n",
      "{'loss': 27.375, 'learning_rate': 8.498e-06, 'epoch': 0.96}\n",
      "{'loss': 27.25, 'learning_rate': 8.497e-06, 'epoch': 0.96}\n",
      "{'loss': 27.75, 'learning_rate': 8.496000000000001e-06, 'epoch': 0.97}\n",
      "{'loss': 27.25, 'learning_rate': 8.495e-06, 'epoch': 0.97}\n",
      "{'loss': 27.375, 'learning_rate': 8.494e-06, 'epoch': 0.97}\n",
      "{'loss': 29.5, 'learning_rate': 8.493000000000002e-06, 'epoch': 0.97}\n",
      "{'loss': 26.75, 'learning_rate': 8.492000000000001e-06, 'epoch': 0.97}\n",
      "{'loss': 28.0, 'learning_rate': 8.491e-06, 'epoch': 0.97}\n",
      "{'loss': 27.375, 'learning_rate': 8.49e-06, 'epoch': 0.97}\n",
      "{'loss': 27.375, 'learning_rate': 8.489000000000001e-06, 'epoch': 0.97}\n",
      "{'loss': 28.5, 'learning_rate': 8.488e-06, 'epoch': 0.97}\n",
      "{'loss': 30.125, 'learning_rate': 8.487e-06, 'epoch': 0.97}\n",
      "{'loss': 29.625, 'learning_rate': 8.486000000000001e-06, 'epoch': 0.97}\n",
      "{'loss': 28.875, 'learning_rate': 8.485000000000001e-06, 'epoch': 0.97}\n",
      "{'loss': 28.375, 'learning_rate': 8.484e-06, 'epoch': 0.97}\n",
      "{'loss': 27.875, 'learning_rate': 8.483000000000002e-06, 'epoch': 0.97}\n",
      "{'loss': 28.625, 'learning_rate': 8.482e-06, 'epoch': 0.97}\n",
      "{'loss': 27.875, 'learning_rate': 8.481e-06, 'epoch': 0.97}\n",
      "{'loss': 27.875, 'learning_rate': 8.48e-06, 'epoch': 0.98}\n",
      "{'loss': 28.0, 'learning_rate': 8.479000000000001e-06, 'epoch': 0.98}\n",
      "{'loss': 29.0, 'learning_rate': 8.478e-06, 'epoch': 0.98}\n",
      "{'loss': 27.625, 'learning_rate': 8.477e-06, 'epoch': 0.98}\n",
      "{'loss': 27.125, 'learning_rate': 8.476000000000002e-06, 'epoch': 0.98}\n",
      "{'loss': 28.75, 'learning_rate': 8.475000000000001e-06, 'epoch': 0.98}\n",
      "{'loss': 28.125, 'learning_rate': 8.474e-06, 'epoch': 0.98}\n",
      "{'loss': 28.625, 'learning_rate': 8.473000000000002e-06, 'epoch': 0.98}\n",
      "{'loss': 27.125, 'learning_rate': 8.472e-06, 'epoch': 0.98}\n",
      "{'loss': 29.875, 'learning_rate': 8.471e-06, 'epoch': 0.98}\n",
      "{'loss': 31.875, 'learning_rate': 8.47e-06, 'epoch': 0.98}\n",
      "{'loss': 28.125, 'learning_rate': 8.469e-06, 'epoch': 0.98}\n",
      "{'loss': 27.375, 'learning_rate': 8.468000000000001e-06, 'epoch': 0.98}\n",
      "{'loss': 27.125, 'learning_rate': 8.467e-06, 'epoch': 0.98}\n",
      "{'loss': 27.5, 'learning_rate': 8.466000000000002e-06, 'epoch': 0.98}\n",
      "{'loss': 28.25, 'learning_rate': 8.465000000000001e-06, 'epoch': 0.99}\n",
      "{'loss': 28.25, 'learning_rate': 8.464e-06, 'epoch': 0.99}\n",
      "{'loss': 28.5, 'learning_rate': 8.463000000000002e-06, 'epoch': 0.99}\n",
      "{'loss': 28.875, 'learning_rate': 8.462e-06, 'epoch': 0.99}\n",
      "{'loss': 27.875, 'learning_rate': 8.461e-06, 'epoch': 0.99}\n",
      "{'loss': 27.375, 'learning_rate': 8.46e-06, 'epoch': 0.99}\n",
      "{'loss': 28.375, 'learning_rate': 8.459e-06, 'epoch': 0.99}\n",
      "{'loss': 27.0, 'learning_rate': 8.458000000000001e-06, 'epoch': 0.99}\n",
      "{'loss': 27.125, 'learning_rate': 8.457e-06, 'epoch': 0.99}\n",
      "{'loss': 27.5, 'learning_rate': 8.456000000000002e-06, 'epoch': 0.99}\n",
      "{'loss': 27.75, 'learning_rate': 8.455000000000001e-06, 'epoch': 0.99}\n",
      "{'loss': 27.125, 'learning_rate': 8.454e-06, 'epoch': 0.99}\n",
      "{'loss': 28.5, 'learning_rate': 8.453000000000002e-06, 'epoch': 0.99}\n",
      "{'loss': 27.625, 'learning_rate': 8.452e-06, 'epoch': 0.99}\n",
      "{'loss': 27.125, 'learning_rate': 8.451000000000001e-06, 'epoch': 0.99}\n",
      "{'loss': 27.625, 'learning_rate': 8.45e-06, 'epoch': 0.99}\n",
      "{'loss': 29.625, 'learning_rate': 8.449e-06, 'epoch': 1.0}\n",
      "{'loss': 28.0, 'learning_rate': 8.448000000000001e-06, 'epoch': 1.0}\n",
      "{'loss': 26.75, 'learning_rate': 8.447e-06, 'epoch': 1.0}\n",
      "{'loss': 28.25, 'learning_rate': 8.446e-06, 'epoch': 1.0}\n",
      "{'loss': 29.375, 'learning_rate': 8.445000000000001e-06, 'epoch': 1.0}\n",
      "{'loss': 27.875, 'learning_rate': 8.444e-06, 'epoch': 1.0}\n",
      "{'loss': 27.75, 'learning_rate': 8.443000000000002e-06, 'epoch': 1.0}\n",
      "{'loss': 30.375, 'learning_rate': 8.442e-06, 'epoch': 1.0}\n",
      "{'loss': 28.5, 'learning_rate': 8.441000000000001e-06, 'epoch': 1.0}\n",
      "{'loss': 27.75, 'learning_rate': 8.44e-06, 'epoch': 1.0}\n",
      "{'loss': 28.625, 'learning_rate': 8.439e-06, 'epoch': 1.0}\n",
      "{'loss': 28.75, 'learning_rate': 8.438000000000001e-06, 'epoch': 1.0}\n",
      "{'loss': 28.75, 'learning_rate': 8.437e-06, 'epoch': 1.0}\n",
      "{'loss': 28.25, 'learning_rate': 8.436e-06, 'epoch': 1.0}\n",
      "{'loss': 26.75, 'learning_rate': 8.435000000000001e-06, 'epoch': 1.0}\n",
      "{'loss': 30.75, 'learning_rate': 8.434000000000001e-06, 'epoch': 1.01}\n",
      "{'loss': 28.375, 'learning_rate': 8.433e-06, 'epoch': 1.01}\n",
      "{'loss': 27.375, 'learning_rate': 8.432e-06, 'epoch': 1.01}\n",
      "{'loss': 27.125, 'learning_rate': 8.431000000000001e-06, 'epoch': 1.01}\n",
      "{'loss': 27.875, 'learning_rate': 8.43e-06, 'epoch': 1.01}\n",
      "{'loss': 27.5, 'learning_rate': 8.429e-06, 'epoch': 1.01}\n",
      "{'loss': 27.625, 'learning_rate': 8.428000000000001e-06, 'epoch': 1.01}\n",
      "{'loss': 27.25, 'learning_rate': 8.427e-06, 'epoch': 1.01}\n",
      "{'loss': 28.125, 'learning_rate': 8.426e-06, 'epoch': 1.01}\n",
      "{'loss': 27.5, 'learning_rate': 8.425000000000001e-06, 'epoch': 1.01}\n",
      "{'loss': 27.75, 'learning_rate': 8.424000000000001e-06, 'epoch': 1.01}\n",
      "{'loss': 27.5, 'learning_rate': 8.423e-06, 'epoch': 1.01}\n",
      "{'loss': 28.75, 'learning_rate': 8.422e-06, 'epoch': 1.01}\n",
      "{'loss': 27.75, 'learning_rate': 8.421e-06, 'epoch': 1.01}\n",
      "{'loss': 28.0, 'learning_rate': 8.42e-06, 'epoch': 1.01}\n",
      "{'loss': 29.25, 'learning_rate': 8.419e-06, 'epoch': 1.01}\n",
      "{'loss': 28.375, 'learning_rate': 8.418000000000001e-06, 'epoch': 1.02}\n",
      "{'loss': 27.875, 'learning_rate': 8.417000000000001e-06, 'epoch': 1.02}\n",
      "{'loss': 29.5, 'learning_rate': 8.416e-06, 'epoch': 1.02}\n",
      "{'loss': 27.25, 'learning_rate': 8.415000000000002e-06, 'epoch': 1.02}\n",
      "{'loss': 29.375, 'learning_rate': 8.414000000000001e-06, 'epoch': 1.02}\n",
      "{'loss': 28.25, 'learning_rate': 8.413e-06, 'epoch': 1.02}\n",
      "{'loss': 31.0, 'learning_rate': 8.412e-06, 'epoch': 1.02}\n",
      "{'loss': 30.0, 'learning_rate': 8.411e-06, 'epoch': 1.02}\n",
      "{'loss': 27.875, 'learning_rate': 8.41e-06, 'epoch': 1.02}\n",
      "{'loss': 28.625, 'learning_rate': 8.409e-06, 'epoch': 1.02}\n",
      "{'loss': 28.75, 'learning_rate': 8.408e-06, 'epoch': 1.02}\n",
      "{'loss': 27.625, 'learning_rate': 8.407000000000001e-06, 'epoch': 1.02}\n",
      "{'loss': 27.375, 'learning_rate': 8.406e-06, 'epoch': 1.02}\n",
      "{'loss': 27.5, 'learning_rate': 8.405000000000002e-06, 'epoch': 1.02}\n",
      "{'loss': 27.875, 'learning_rate': 8.404000000000001e-06, 'epoch': 1.02}\n",
      "{'loss': 28.75, 'learning_rate': 8.403e-06, 'epoch': 1.03}\n",
      "{'loss': 27.5, 'learning_rate': 8.402e-06, 'epoch': 1.03}\n",
      "{'loss': 29.125, 'learning_rate': 8.401e-06, 'epoch': 1.03}\n",
      "{'loss': 27.25, 'learning_rate': 8.400000000000001e-06, 'epoch': 1.03}\n",
      "{'loss': 27.375, 'learning_rate': 8.399e-06, 'epoch': 1.03}\n",
      "{'loss': 27.0, 'learning_rate': 8.398e-06, 'epoch': 1.03}\n",
      "{'loss': 28.375, 'learning_rate': 8.397000000000001e-06, 'epoch': 1.03}\n",
      "{'loss': 27.25, 'learning_rate': 8.396e-06, 'epoch': 1.03}\n",
      "{'loss': 27.875, 'learning_rate': 8.395e-06, 'epoch': 1.03}\n",
      "{'loss': 27.75, 'learning_rate': 8.394000000000001e-06, 'epoch': 1.03}\n",
      "{'loss': 27.875, 'learning_rate': 8.393e-06, 'epoch': 1.03}\n",
      "{'loss': 27.125, 'learning_rate': 8.392e-06, 'epoch': 1.03}\n",
      "{'loss': 27.25, 'learning_rate': 8.391e-06, 'epoch': 1.03}\n",
      "{'loss': 27.125, 'learning_rate': 8.390000000000001e-06, 'epoch': 1.03}\n",
      "{'loss': 27.5, 'learning_rate': 8.389e-06, 'epoch': 1.03}\n",
      "{'loss': 28.0, 'learning_rate': 8.388e-06, 'epoch': 1.03}\n",
      "{'loss': 28.75, 'learning_rate': 8.387000000000001e-06, 'epoch': 1.04}\n",
      "{'loss': 27.375, 'learning_rate': 8.386e-06, 'epoch': 1.04}\n",
      "{'loss': 27.75, 'learning_rate': 8.385e-06, 'epoch': 1.04}\n",
      "{'loss': 28.0, 'learning_rate': 8.384000000000001e-06, 'epoch': 1.04}\n",
      "{'loss': 27.25, 'learning_rate': 8.383000000000001e-06, 'epoch': 1.04}\n",
      "{'loss': 28.5, 'learning_rate': 8.382e-06, 'epoch': 1.04}\n",
      "{'loss': 27.5, 'learning_rate': 8.381e-06, 'epoch': 1.04}\n",
      "{'loss': 27.75, 'learning_rate': 8.380000000000001e-06, 'epoch': 1.04}\n",
      "{'loss': 27.375, 'learning_rate': 8.379e-06, 'epoch': 1.04}\n",
      "{'loss': 29.0, 'learning_rate': 8.378e-06, 'epoch': 1.04}\n",
      "{'loss': 26.75, 'learning_rate': 8.377000000000001e-06, 'epoch': 1.04}\n",
      "{'loss': 27.375, 'learning_rate': 8.376e-06, 'epoch': 1.04}\n",
      "{'loss': 27.125, 'learning_rate': 8.375e-06, 'epoch': 1.04}\n",
      "{'loss': 27.75, 'learning_rate': 8.374000000000001e-06, 'epoch': 1.04}\n",
      "{'loss': 27.375, 'learning_rate': 8.373000000000001e-06, 'epoch': 1.04}\n",
      "{'loss': 27.75, 'learning_rate': 8.372e-06, 'epoch': 1.04}\n",
      "{'loss': 27.75, 'learning_rate': 8.371e-06, 'epoch': 1.05}\n",
      "{'loss': 27.125, 'learning_rate': 8.370000000000001e-06, 'epoch': 1.05}\n",
      "{'loss': 26.625, 'learning_rate': 8.369e-06, 'epoch': 1.05}\n",
      "{'loss': 27.25, 'learning_rate': 8.368e-06, 'epoch': 1.05}\n",
      "{'loss': 28.0, 'learning_rate': 8.367000000000001e-06, 'epoch': 1.05}\n",
      "{'loss': 27.75, 'learning_rate': 8.366000000000001e-06, 'epoch': 1.05}\n",
      "{'loss': 27.0, 'learning_rate': 8.365e-06, 'epoch': 1.05}\n",
      "{'loss': 27.875, 'learning_rate': 8.364000000000002e-06, 'epoch': 1.05}\n",
      "{'loss': 27.875, 'learning_rate': 8.363000000000001e-06, 'epoch': 1.05}\n",
      "{'loss': 26.0, 'learning_rate': 8.362e-06, 'epoch': 1.05}\n",
      "{'loss': 29.25, 'learning_rate': 8.361e-06, 'epoch': 1.05}\n",
      "{'loss': 26.875, 'learning_rate': 8.36e-06, 'epoch': 1.05}\n",
      "{'loss': 28.375, 'learning_rate': 8.359e-06, 'epoch': 1.05}\n",
      "{'loss': 28.375, 'learning_rate': 8.358e-06, 'epoch': 1.05}\n",
      "{'loss': 27.625, 'learning_rate': 8.357000000000001e-06, 'epoch': 1.05}\n",
      "{'loss': 27.5, 'learning_rate': 8.356000000000001e-06, 'epoch': 1.06}\n",
      "{'loss': 29.875, 'learning_rate': 8.355e-06, 'epoch': 1.06}\n",
      "{'loss': 27.875, 'learning_rate': 8.354000000000002e-06, 'epoch': 1.06}\n",
      "{'loss': 28.0, 'learning_rate': 8.353000000000001e-06, 'epoch': 1.06}\n",
      "{'loss': 27.75, 'learning_rate': 8.352e-06, 'epoch': 1.06}\n",
      "{'loss': 27.125, 'learning_rate': 8.351e-06, 'epoch': 1.06}\n",
      "{'loss': 27.875, 'learning_rate': 8.35e-06, 'epoch': 1.06}\n",
      "{'loss': 28.0, 'learning_rate': 8.349000000000001e-06, 'epoch': 1.06}\n",
      "{'loss': 29.75, 'learning_rate': 8.348e-06, 'epoch': 1.06}\n",
      "{'loss': 27.125, 'learning_rate': 8.347e-06, 'epoch': 1.06}\n",
      "{'loss': 26.875, 'learning_rate': 8.346000000000001e-06, 'epoch': 1.06}\n",
      "{'loss': 28.375, 'learning_rate': 8.345e-06, 'epoch': 1.06}\n",
      "{'loss': 27.625, 'learning_rate': 8.344000000000002e-06, 'epoch': 1.06}\n",
      "{'loss': 28.0, 'learning_rate': 8.343000000000001e-06, 'epoch': 1.06}\n",
      "{'loss': 30.875, 'learning_rate': 8.342e-06, 'epoch': 1.06}\n",
      "{'loss': 27.5, 'learning_rate': 8.341e-06, 'epoch': 1.06}\n",
      "{'loss': 27.0, 'learning_rate': 8.34e-06, 'epoch': 1.07}\n",
      "{'loss': 27.875, 'learning_rate': 8.339000000000001e-06, 'epoch': 1.07}\n",
      "{'loss': 28.75, 'learning_rate': 8.338e-06, 'epoch': 1.07}\n",
      "{'loss': 30.125, 'learning_rate': 8.337e-06, 'epoch': 1.07}\n",
      "{'loss': 27.375, 'learning_rate': 8.336000000000001e-06, 'epoch': 1.07}\n",
      "{'loss': 28.125, 'learning_rate': 8.335e-06, 'epoch': 1.07}\n",
      "{'loss': 28.375, 'learning_rate': 8.334e-06, 'epoch': 1.07}\n",
      "{'loss': 26.25, 'learning_rate': 8.333000000000001e-06, 'epoch': 1.07}\n",
      "{'loss': 26.375, 'learning_rate': 8.332000000000001e-06, 'epoch': 1.07}\n",
      "{'loss': 28.0, 'learning_rate': 8.331e-06, 'epoch': 1.07}\n",
      "{'loss': 27.75, 'learning_rate': 8.33e-06, 'epoch': 1.07}\n",
      "{'loss': 28.0, 'learning_rate': 8.329000000000001e-06, 'epoch': 1.07}\n",
      "{'loss': 27.625, 'learning_rate': 8.328e-06, 'epoch': 1.07}\n",
      "{'loss': 27.75, 'learning_rate': 8.327e-06, 'epoch': 1.07}\n",
      "{'loss': 27.25, 'learning_rate': 8.326000000000001e-06, 'epoch': 1.07}\n",
      "{'loss': 27.375, 'learning_rate': 8.325e-06, 'epoch': 1.08}\n",
      "{'loss': 27.5, 'learning_rate': 8.324e-06, 'epoch': 1.08}\n",
      "{'loss': 28.5, 'learning_rate': 8.323000000000001e-06, 'epoch': 1.08}\n",
      "{'loss': 29.375, 'learning_rate': 8.322000000000001e-06, 'epoch': 1.08}\n",
      "{'loss': 27.125, 'learning_rate': 8.321e-06, 'epoch': 1.08}\n",
      "{'loss': 27.625, 'learning_rate': 8.32e-06, 'epoch': 1.08}\n",
      "{'loss': 28.25, 'learning_rate': 8.319000000000001e-06, 'epoch': 1.08}\n",
      "{'loss': 28.125, 'learning_rate': 8.318e-06, 'epoch': 1.08}\n",
      "{'loss': 27.375, 'learning_rate': 8.317e-06, 'epoch': 1.08}\n",
      "{'loss': 29.375, 'learning_rate': 8.316000000000001e-06, 'epoch': 1.08}\n",
      "{'loss': 27.0, 'learning_rate': 8.315000000000001e-06, 'epoch': 1.08}\n",
      "{'loss': 27.0, 'learning_rate': 8.314e-06, 'epoch': 1.08}\n",
      "{'loss': 28.25, 'learning_rate': 8.313000000000002e-06, 'epoch': 1.08}\n",
      "{'loss': 27.75, 'learning_rate': 8.312000000000001e-06, 'epoch': 1.08}\n",
      "{'loss': 26.625, 'learning_rate': 8.311e-06, 'epoch': 1.08}\n",
      "{'loss': 28.625, 'learning_rate': 8.31e-06, 'epoch': 1.08}\n",
      "{'loss': 28.375, 'learning_rate': 8.309e-06, 'epoch': 1.09}\n",
      "{'loss': 27.0, 'learning_rate': 8.308e-06, 'epoch': 1.09}\n",
      "{'loss': 27.25, 'learning_rate': 8.307e-06, 'epoch': 1.09}\n",
      "{'loss': 28.375, 'learning_rate': 8.306000000000001e-06, 'epoch': 1.09}\n",
      "{'loss': 27.625, 'learning_rate': 8.305000000000001e-06, 'epoch': 1.09}\n",
      "{'loss': 28.125, 'learning_rate': 8.304e-06, 'epoch': 1.09}\n",
      "{'loss': 28.0, 'learning_rate': 8.303000000000002e-06, 'epoch': 1.09}\n",
      "{'loss': 27.625, 'learning_rate': 8.302000000000001e-06, 'epoch': 1.09}\n",
      "{'loss': 27.5, 'learning_rate': 8.301e-06, 'epoch': 1.09}\n",
      "{'loss': 26.75, 'learning_rate': 8.3e-06, 'epoch': 1.09}\n",
      "{'loss': 27.625, 'learning_rate': 8.299e-06, 'epoch': 1.09}\n",
      "{'loss': 28.375, 'learning_rate': 8.298000000000001e-06, 'epoch': 1.09}\n",
      "{'loss': 27.375, 'learning_rate': 8.297e-06, 'epoch': 1.09}\n",
      "{'loss': 27.625, 'learning_rate': 8.296000000000002e-06, 'epoch': 1.09}\n",
      "{'loss': 27.125, 'learning_rate': 8.295000000000001e-06, 'epoch': 1.09}\n",
      "{'loss': 26.875, 'learning_rate': 8.294e-06, 'epoch': 1.09}\n",
      "{'loss': 27.125, 'learning_rate': 8.293000000000002e-06, 'epoch': 1.1}\n",
      "{'loss': 27.125, 'learning_rate': 8.292000000000001e-06, 'epoch': 1.1}\n",
      "{'loss': 27.0, 'learning_rate': 8.291e-06, 'epoch': 1.1}\n",
      "{'loss': 31.5, 'learning_rate': 8.29e-06, 'epoch': 1.1}\n",
      "{'loss': 27.625, 'learning_rate': 8.289e-06, 'epoch': 1.1}\n",
      "{'loss': 27.75, 'learning_rate': 8.288000000000001e-06, 'epoch': 1.1}\n",
      "{'loss': 28.375, 'learning_rate': 8.287e-06, 'epoch': 1.1}\n",
      "{'loss': 27.5, 'learning_rate': 8.286e-06, 'epoch': 1.1}\n",
      "{'loss': 30.0, 'learning_rate': 8.285000000000001e-06, 'epoch': 1.1}\n",
      "{'loss': 26.625, 'learning_rate': 8.284e-06, 'epoch': 1.1}\n",
      "{'loss': 26.375, 'learning_rate': 8.283000000000002e-06, 'epoch': 1.1}\n",
      "{'loss': 29.875, 'learning_rate': 8.282000000000001e-06, 'epoch': 1.1}\n",
      "{'loss': 27.75, 'learning_rate': 8.281e-06, 'epoch': 1.1}\n",
      "{'loss': 27.75, 'learning_rate': 8.28e-06, 'epoch': 1.1}\n",
      "{'loss': 27.875, 'learning_rate': 8.279e-06, 'epoch': 1.1}\n",
      "{'loss': 27.25, 'learning_rate': 8.278000000000001e-06, 'epoch': 1.11}\n",
      "{'loss': 27.125, 'learning_rate': 8.277e-06, 'epoch': 1.11}\n",
      "{'loss': 26.875, 'learning_rate': 8.276e-06, 'epoch': 1.11}\n",
      "{'loss': 26.75, 'learning_rate': 8.275000000000001e-06, 'epoch': 1.11}\n",
      "{'loss': 28.75, 'learning_rate': 8.274e-06, 'epoch': 1.11}\n",
      "{'loss': 27.25, 'learning_rate': 8.273e-06, 'epoch': 1.11}\n",
      "{'loss': 27.75, 'learning_rate': 8.272000000000001e-06, 'epoch': 1.11}\n",
      "{'loss': 27.75, 'learning_rate': 8.271000000000001e-06, 'epoch': 1.11}\n",
      "{'loss': 27.125, 'learning_rate': 8.27e-06, 'epoch': 1.11}\n",
      "{'loss': 27.625, 'learning_rate': 8.269e-06, 'epoch': 1.11}\n",
      "{'loss': 28.0, 'learning_rate': 8.268000000000001e-06, 'epoch': 1.11}\n",
      "{'loss': 27.125, 'learning_rate': 8.267e-06, 'epoch': 1.11}\n",
      "{'loss': 26.875, 'learning_rate': 8.266e-06, 'epoch': 1.11}\n",
      "{'loss': 28.5, 'learning_rate': 8.265000000000001e-06, 'epoch': 1.11}\n",
      "{'loss': 26.875, 'learning_rate': 8.264e-06, 'epoch': 1.11}\n",
      "{'loss': 28.5, 'learning_rate': 8.263e-06, 'epoch': 1.11}\n",
      "{'loss': 27.25, 'learning_rate': 8.262000000000002e-06, 'epoch': 1.12}\n",
      "{'loss': 26.875, 'learning_rate': 8.261e-06, 'epoch': 1.12}\n",
      "{'loss': 27.625, 'learning_rate': 8.26e-06, 'epoch': 1.12}\n",
      "{'loss': 27.0, 'learning_rate': 8.259e-06, 'epoch': 1.12}\n",
      "{'loss': 26.875, 'learning_rate': 8.258000000000001e-06, 'epoch': 1.12}\n",
      "{'loss': 27.75, 'learning_rate': 8.257e-06, 'epoch': 1.12}\n",
      "{'loss': 28.0, 'learning_rate': 8.256e-06, 'epoch': 1.12}\n",
      "{'loss': 29.25, 'learning_rate': 8.255000000000001e-06, 'epoch': 1.12}\n",
      "{'loss': 26.875, 'learning_rate': 8.254000000000001e-06, 'epoch': 1.12}\n",
      "{'loss': 26.75, 'learning_rate': 8.253e-06, 'epoch': 1.12}\n",
      "{'loss': 26.375, 'learning_rate': 8.252000000000002e-06, 'epoch': 1.12}\n",
      "{'loss': 28.5, 'learning_rate': 8.251e-06, 'epoch': 1.12}\n",
      "{'loss': 28.25, 'learning_rate': 8.25e-06, 'epoch': 1.12}\n",
      "{'loss': 27.0, 'learning_rate': 8.249e-06, 'epoch': 1.12}\n",
      "{'loss': 27.25, 'learning_rate': 8.248e-06, 'epoch': 1.12}\n",
      "{'loss': 26.75, 'learning_rate': 8.247e-06, 'epoch': 1.13}\n",
      "{'loss': 26.875, 'learning_rate': 8.246e-06, 'epoch': 1.13}\n",
      "{'loss': 27.125, 'learning_rate': 8.245000000000002e-06, 'epoch': 1.13}\n",
      "{'loss': 26.5, 'learning_rate': 8.244000000000001e-06, 'epoch': 1.13}\n",
      "{'loss': 28.875, 'learning_rate': 8.243e-06, 'epoch': 1.13}\n",
      "{'loss': 27.625, 'learning_rate': 8.242000000000002e-06, 'epoch': 1.13}\n",
      "{'loss': 29.375, 'learning_rate': 8.241000000000001e-06, 'epoch': 1.13}\n",
      "{'loss': 28.625, 'learning_rate': 8.24e-06, 'epoch': 1.13}\n",
      "{'loss': 27.5, 'learning_rate': 8.239e-06, 'epoch': 1.13}\n",
      "{'loss': 27.875, 'learning_rate': 8.238e-06, 'epoch': 1.13}\n",
      "{'loss': 27.0, 'learning_rate': 8.237000000000001e-06, 'epoch': 1.13}\n",
      "{'loss': 27.375, 'learning_rate': 8.236e-06, 'epoch': 1.13}\n",
      "{'loss': 29.0, 'learning_rate': 8.235e-06, 'epoch': 1.13}\n",
      "{'loss': 27.875, 'learning_rate': 8.234000000000001e-06, 'epoch': 1.13}\n",
      "{'loss': 27.875, 'learning_rate': 8.233e-06, 'epoch': 1.13}\n",
      "{'loss': 26.75, 'learning_rate': 8.232000000000002e-06, 'epoch': 1.13}\n",
      "{'loss': 27.375, 'learning_rate': 8.231000000000001e-06, 'epoch': 1.14}\n",
      "{'loss': 28.75, 'learning_rate': 8.23e-06, 'epoch': 1.14}\n",
      "{'loss': 26.875, 'learning_rate': 8.229e-06, 'epoch': 1.14}\n",
      "{'loss': 27.75, 'learning_rate': 8.228e-06, 'epoch': 1.14}\n",
      "{'loss': 29.125, 'learning_rate': 8.227000000000001e-06, 'epoch': 1.14}\n",
      "{'loss': 30.5, 'learning_rate': 8.226e-06, 'epoch': 1.14}\n",
      "{'loss': 27.875, 'learning_rate': 8.225e-06, 'epoch': 1.14}\n",
      "{'loss': 29.125, 'learning_rate': 8.224000000000001e-06, 'epoch': 1.14}\n",
      "{'loss': 27.0, 'learning_rate': 8.223e-06, 'epoch': 1.14}\n",
      "{'loss': 27.625, 'learning_rate': 8.222000000000002e-06, 'epoch': 1.14}\n",
      "{'loss': 29.0, 'learning_rate': 8.221000000000001e-06, 'epoch': 1.14}\n",
      "{'loss': 27.625, 'learning_rate': 8.220000000000001e-06, 'epoch': 1.14}\n",
      "{'loss': 27.125, 'learning_rate': 8.219e-06, 'epoch': 1.14}\n",
      "{'loss': 28.125, 'learning_rate': 8.218e-06, 'epoch': 1.14}\n",
      "{'loss': 28.125, 'learning_rate': 8.217000000000001e-06, 'epoch': 1.14}\n",
      "{'loss': 29.75, 'learning_rate': 8.216e-06, 'epoch': 1.15}\n",
      "{'loss': 31.5, 'learning_rate': 8.215e-06, 'epoch': 1.15}\n",
      "{'loss': 28.875, 'learning_rate': 8.214000000000001e-06, 'epoch': 1.15}\n",
      "{'loss': 27.125, 'learning_rate': 8.213e-06, 'epoch': 1.15}\n",
      "{'loss': 27.75, 'learning_rate': 8.212e-06, 'epoch': 1.15}\n",
      "{'loss': 29.375, 'learning_rate': 8.211000000000002e-06, 'epoch': 1.15}\n",
      "{'loss': 27.0, 'learning_rate': 8.210000000000001e-06, 'epoch': 1.15}\n",
      "{'loss': 28.875, 'learning_rate': 8.209e-06, 'epoch': 1.15}\n",
      "{'loss': 27.75, 'learning_rate': 8.208e-06, 'epoch': 1.15}\n",
      "{'loss': 28.75, 'learning_rate': 8.207000000000001e-06, 'epoch': 1.15}\n",
      "{'loss': 27.125, 'learning_rate': 8.206e-06, 'epoch': 1.15}\n",
      "{'loss': 27.875, 'learning_rate': 8.205e-06, 'epoch': 1.15}\n",
      "{'loss': 27.625, 'learning_rate': 8.204000000000001e-06, 'epoch': 1.15}\n",
      "{'loss': 27.25, 'learning_rate': 8.203000000000001e-06, 'epoch': 1.15}\n",
      "{'loss': 27.375, 'learning_rate': 8.202e-06, 'epoch': 1.15}\n",
      "{'loss': 28.75, 'learning_rate': 8.201000000000002e-06, 'epoch': 1.15}\n",
      "{'loss': 27.75, 'learning_rate': 8.2e-06, 'epoch': 1.16}\n",
      "{'loss': 30.5, 'learning_rate': 8.199e-06, 'epoch': 1.16}\n",
      "{'loss': 27.125, 'learning_rate': 8.198e-06, 'epoch': 1.16}\n",
      "{'loss': 27.875, 'learning_rate': 8.197000000000001e-06, 'epoch': 1.16}\n",
      "{'loss': 26.875, 'learning_rate': 8.196e-06, 'epoch': 1.16}\n",
      "{'loss': 27.0, 'learning_rate': 8.195e-06, 'epoch': 1.16}\n",
      "{'loss': 27.75, 'learning_rate': 8.194000000000002e-06, 'epoch': 1.16}\n",
      "{'loss': 27.875, 'learning_rate': 8.193000000000001e-06, 'epoch': 1.16}\n",
      "{'loss': 27.75, 'learning_rate': 8.192e-06, 'epoch': 1.16}\n",
      "{'loss': 27.75, 'learning_rate': 8.191000000000002e-06, 'epoch': 1.16}\n",
      "{'loss': 27.375, 'learning_rate': 8.19e-06, 'epoch': 1.16}\n",
      "{'loss': 26.75, 'learning_rate': 8.189e-06, 'epoch': 1.16}\n",
      "{'loss': 27.75, 'learning_rate': 8.188e-06, 'epoch': 1.16}\n",
      "{'loss': 27.0, 'learning_rate': 8.187e-06, 'epoch': 1.16}\n",
      "{'loss': 31.125, 'learning_rate': 8.186000000000001e-06, 'epoch': 1.16}\n",
      "{'loss': 27.125, 'learning_rate': 8.185e-06, 'epoch': 1.16}\n",
      "{'loss': 27.5, 'learning_rate': 8.184000000000002e-06, 'epoch': 1.17}\n",
      "{'loss': 26.5, 'learning_rate': 8.183000000000001e-06, 'epoch': 1.17}\n",
      "{'loss': 28.625, 'learning_rate': 8.182e-06, 'epoch': 1.17}\n",
      "{'loss': 28.625, 'learning_rate': 8.181000000000002e-06, 'epoch': 1.17}\n",
      "{'loss': 27.5, 'learning_rate': 8.18e-06, 'epoch': 1.17}\n",
      "{'loss': 27.5, 'learning_rate': 8.179e-06, 'epoch': 1.17}\n",
      "{'loss': 26.875, 'learning_rate': 8.178e-06, 'epoch': 1.17}\n",
      "{'loss': 27.625, 'learning_rate': 8.177e-06, 'epoch': 1.17}\n",
      "{'loss': 30.25, 'learning_rate': 8.176000000000001e-06, 'epoch': 1.17}\n",
      "{'loss': 28.625, 'learning_rate': 8.175e-06, 'epoch': 1.17}\n",
      "{'loss': 28.75, 'learning_rate': 8.174e-06, 'epoch': 1.17}\n",
      "{'loss': 29.75, 'learning_rate': 8.173000000000001e-06, 'epoch': 1.17}\n",
      "{'loss': 28.125, 'learning_rate': 8.172e-06, 'epoch': 1.17}\n",
      "{'loss': 28.0, 'learning_rate': 8.171000000000002e-06, 'epoch': 1.17}\n",
      "{'loss': 28.625, 'learning_rate': 8.17e-06, 'epoch': 1.17}\n",
      "{'loss': 27.125, 'learning_rate': 8.169000000000001e-06, 'epoch': 1.18}\n",
      "{'loss': 27.25, 'learning_rate': 8.168e-06, 'epoch': 1.18}\n",
      "{'loss': 29.0, 'learning_rate': 8.167e-06, 'epoch': 1.18}\n",
      "{'loss': 28.875, 'learning_rate': 8.166000000000001e-06, 'epoch': 1.18}\n",
      "{'loss': 26.75, 'learning_rate': 8.165e-06, 'epoch': 1.18}\n",
      "{'loss': 27.25, 'learning_rate': 8.164e-06, 'epoch': 1.18}\n",
      "{'loss': 27.625, 'learning_rate': 8.163000000000001e-06, 'epoch': 1.18}\n",
      "{'loss': 27.875, 'learning_rate': 8.162e-06, 'epoch': 1.18}\n",
      "{'loss': 28.125, 'learning_rate': 8.161e-06, 'epoch': 1.18}\n",
      "{'loss': 27.25, 'learning_rate': 8.16e-06, 'epoch': 1.18}\n",
      "{'loss': 26.5, 'learning_rate': 8.159000000000001e-06, 'epoch': 1.18}\n",
      "{'loss': 27.875, 'learning_rate': 8.158e-06, 'epoch': 1.18}\n",
      "{'loss': 29.0, 'learning_rate': 8.157e-06, 'epoch': 1.18}\n",
      "{'loss': 27.375, 'learning_rate': 8.156000000000001e-06, 'epoch': 1.18}\n",
      "{'loss': 28.625, 'learning_rate': 8.155e-06, 'epoch': 1.18}\n",
      "{'loss': 27.375, 'learning_rate': 8.154e-06, 'epoch': 1.18}\n",
      "{'loss': 28.125, 'learning_rate': 8.153000000000001e-06, 'epoch': 1.19}\n",
      "{'loss': 28.125, 'learning_rate': 8.152000000000001e-06, 'epoch': 1.19}\n",
      "{'loss': 27.875, 'learning_rate': 8.151e-06, 'epoch': 1.19}\n",
      "{'loss': 26.875, 'learning_rate': 8.15e-06, 'epoch': 1.19}\n",
      "{'loss': 28.125, 'learning_rate': 8.149e-06, 'epoch': 1.19}\n",
      "{'loss': 28.375, 'learning_rate': 8.148e-06, 'epoch': 1.19}\n",
      "{'loss': 29.125, 'learning_rate': 8.147e-06, 'epoch': 1.19}\n",
      "{'loss': 26.875, 'learning_rate': 8.146000000000001e-06, 'epoch': 1.19}\n",
      "{'loss': 28.375, 'learning_rate': 8.145e-06, 'epoch': 1.19}\n",
      "{'loss': 27.125, 'learning_rate': 8.144e-06, 'epoch': 1.19}\n",
      "{'loss': 27.75, 'learning_rate': 8.143000000000001e-06, 'epoch': 1.19}\n",
      "{'loss': 28.0, 'learning_rate': 8.142000000000001e-06, 'epoch': 1.19}\n",
      "{'loss': 27.5, 'learning_rate': 8.141e-06, 'epoch': 1.19}\n",
      "{'loss': 27.75, 'learning_rate': 8.14e-06, 'epoch': 1.19}\n",
      "{'loss': 26.5, 'learning_rate': 8.139e-06, 'epoch': 1.19}\n",
      "{'loss': 27.875, 'learning_rate': 8.138e-06, 'epoch': 1.2}\n",
      "{'loss': 28.0, 'learning_rate': 8.137e-06, 'epoch': 1.2}\n",
      "{'loss': 27.875, 'learning_rate': 8.136000000000001e-06, 'epoch': 1.2}\n",
      "{'loss': 27.625, 'learning_rate': 8.135000000000001e-06, 'epoch': 1.2}\n",
      "{'loss': 27.75, 'learning_rate': 8.134e-06, 'epoch': 1.2}\n",
      "{'loss': 27.25, 'learning_rate': 8.133000000000002e-06, 'epoch': 1.2}\n",
      "{'loss': 28.625, 'learning_rate': 8.132000000000001e-06, 'epoch': 1.2}\n",
      "{'loss': 26.5, 'learning_rate': 8.131e-06, 'epoch': 1.2}\n",
      "{'loss': 29.25, 'learning_rate': 8.13e-06, 'epoch': 1.2}\n",
      "{'loss': 28.0, 'learning_rate': 8.129e-06, 'epoch': 1.2}\n",
      "{'loss': 28.375, 'learning_rate': 8.128e-06, 'epoch': 1.2}\n",
      "{'loss': 26.875, 'learning_rate': 8.127e-06, 'epoch': 1.2}\n",
      "{'loss': 27.0, 'learning_rate': 8.126e-06, 'epoch': 1.2}\n",
      "{'loss': 26.625, 'learning_rate': 8.125000000000001e-06, 'epoch': 1.2}\n",
      "{'loss': 27.625, 'learning_rate': 8.124e-06, 'epoch': 1.2}\n",
      "{'loss': 29.25, 'learning_rate': 8.123000000000002e-06, 'epoch': 1.2}\n",
      "{'loss': 27.25, 'learning_rate': 8.122000000000001e-06, 'epoch': 1.21}\n",
      "{'loss': 27.875, 'learning_rate': 8.121e-06, 'epoch': 1.21}\n",
      "{'loss': 27.5, 'learning_rate': 8.120000000000002e-06, 'epoch': 1.21}\n",
      "{'loss': 27.0, 'learning_rate': 8.119e-06, 'epoch': 1.21}\n",
      "{'loss': 26.75, 'learning_rate': 8.118000000000001e-06, 'epoch': 1.21}\n",
      "{'loss': 26.625, 'learning_rate': 8.117e-06, 'epoch': 1.21}\n",
      "{'loss': 26.5, 'learning_rate': 8.116e-06, 'epoch': 1.21}\n",
      "{'loss': 27.875, 'learning_rate': 8.115000000000001e-06, 'epoch': 1.21}\n",
      "{'loss': 26.875, 'learning_rate': 8.114e-06, 'epoch': 1.21}\n",
      "{'loss': 28.25, 'learning_rate': 8.113e-06, 'epoch': 1.21}\n",
      "{'loss': 28.625, 'learning_rate': 8.112000000000001e-06, 'epoch': 1.21}\n",
      "{'loss': 27.0, 'learning_rate': 8.111e-06, 'epoch': 1.21}\n",
      "{'loss': 27.25, 'learning_rate': 8.110000000000002e-06, 'epoch': 1.21}\n",
      "{'loss': 27.25, 'learning_rate': 8.109e-06, 'epoch': 1.21}\n",
      "{'loss': 27.0, 'learning_rate': 8.108000000000001e-06, 'epoch': 1.21}\n",
      "{'loss': 26.375, 'learning_rate': 8.107e-06, 'epoch': 1.22}\n",
      "{'loss': 30.125, 'learning_rate': 8.106e-06, 'epoch': 1.22}\n",
      "{'loss': 28.625, 'learning_rate': 8.105000000000001e-06, 'epoch': 1.22}\n",
      "{'loss': 28.875, 'learning_rate': 8.104e-06, 'epoch': 1.22}\n",
      "{'loss': 27.875, 'learning_rate': 8.103e-06, 'epoch': 1.22}\n",
      "{'loss': 27.875, 'learning_rate': 8.102000000000001e-06, 'epoch': 1.22}\n",
      "{'loss': 31.75, 'learning_rate': 8.101000000000001e-06, 'epoch': 1.22}\n",
      "{'loss': 29.375, 'learning_rate': 8.1e-06, 'epoch': 1.22}\n",
      "{'loss': 26.75, 'learning_rate': 8.099e-06, 'epoch': 1.22}\n",
      "{'loss': 28.25, 'learning_rate': 8.098000000000001e-06, 'epoch': 1.22}\n",
      "{'loss': 28.375, 'learning_rate': 8.097e-06, 'epoch': 1.22}\n",
      "{'loss': 27.25, 'learning_rate': 8.096e-06, 'epoch': 1.22}\n",
      "{'loss': 27.25, 'learning_rate': 8.095000000000001e-06, 'epoch': 1.22}\n",
      "{'loss': 26.5, 'learning_rate': 8.094e-06, 'epoch': 1.22}\n",
      "{'loss': 27.125, 'learning_rate': 8.093e-06, 'epoch': 1.22}\n",
      "{'loss': 27.75, 'learning_rate': 8.092000000000001e-06, 'epoch': 1.22}\n",
      "{'loss': 26.75, 'learning_rate': 8.091000000000001e-06, 'epoch': 1.23}\n",
      "{'loss': 28.0, 'learning_rate': 8.09e-06, 'epoch': 1.23}\n",
      "{'loss': 28.0, 'learning_rate': 8.089e-06, 'epoch': 1.23}\n",
      "{'loss': 28.75, 'learning_rate': 8.088e-06, 'epoch': 1.23}\n",
      "{'loss': 28.75, 'learning_rate': 8.087e-06, 'epoch': 1.23}\n",
      "{'loss': 28.75, 'learning_rate': 8.086e-06, 'epoch': 1.23}\n",
      "{'loss': 27.5, 'learning_rate': 8.085000000000001e-06, 'epoch': 1.23}\n",
      "{'loss': 28.125, 'learning_rate': 8.084000000000001e-06, 'epoch': 1.23}\n",
      "{'loss': 27.875, 'learning_rate': 8.083e-06, 'epoch': 1.23}\n",
      "{'loss': 26.625, 'learning_rate': 8.082000000000002e-06, 'epoch': 1.23}\n",
      "{'loss': 28.75, 'learning_rate': 8.081000000000001e-06, 'epoch': 1.23}\n",
      "{'loss': 27.5, 'learning_rate': 8.08e-06, 'epoch': 1.23}\n",
      "{'loss': 27.875, 'learning_rate': 8.079e-06, 'epoch': 1.23}\n",
      "{'loss': 29.375, 'learning_rate': 8.078e-06, 'epoch': 1.23}\n",
      "{'loss': 27.375, 'learning_rate': 8.077e-06, 'epoch': 1.23}\n",
      "{'loss': 29.625, 'learning_rate': 8.076e-06, 'epoch': 1.23}\n",
      "{'loss': 27.5, 'learning_rate': 8.075000000000001e-06, 'epoch': 1.24}\n",
      "{'loss': 28.125, 'learning_rate': 8.074000000000001e-06, 'epoch': 1.24}\n",
      "{'loss': 26.75, 'learning_rate': 8.073e-06, 'epoch': 1.24}\n",
      "{'loss': 29.0, 'learning_rate': 8.072000000000002e-06, 'epoch': 1.24}\n",
      "{'loss': 27.25, 'learning_rate': 8.071000000000001e-06, 'epoch': 1.24}\n",
      "{'loss': 26.875, 'learning_rate': 8.07e-06, 'epoch': 1.24}\n",
      "{'loss': 30.75, 'learning_rate': 8.069e-06, 'epoch': 1.24}\n",
      "{'loss': 27.0, 'learning_rate': 8.068e-06, 'epoch': 1.24}\n",
      "{'loss': 28.25, 'learning_rate': 8.067000000000001e-06, 'epoch': 1.24}\n",
      "{'loss': 27.625, 'learning_rate': 8.066e-06, 'epoch': 1.24}\n",
      "{'loss': 27.0, 'learning_rate': 8.065e-06, 'epoch': 1.24}\n",
      "{'loss': 27.625, 'learning_rate': 8.064000000000001e-06, 'epoch': 1.24}\n",
      "{'loss': 28.75, 'learning_rate': 8.063e-06, 'epoch': 1.24}\n",
      "{'loss': 28.875, 'learning_rate': 8.062000000000002e-06, 'epoch': 1.24}\n",
      "{'loss': 27.0, 'learning_rate': 8.061000000000001e-06, 'epoch': 1.24}\n",
      "{'loss': 26.875, 'learning_rate': 8.06e-06, 'epoch': 1.25}\n",
      "{'loss': 27.25, 'learning_rate': 8.059e-06, 'epoch': 1.25}\n",
      "{'loss': 26.625, 'learning_rate': 8.058e-06, 'epoch': 1.25}\n",
      "{'loss': 27.375, 'learning_rate': 8.057000000000001e-06, 'epoch': 1.25}\n",
      "{'loss': 28.5, 'learning_rate': 8.056e-06, 'epoch': 1.25}\n",
      "{'loss': 28.0, 'learning_rate': 8.055e-06, 'epoch': 1.25}\n",
      "{'loss': 28.5, 'learning_rate': 8.054000000000001e-06, 'epoch': 1.25}\n",
      "{'loss': 29.375, 'learning_rate': 8.053e-06, 'epoch': 1.25}\n",
      "{'loss': 27.25, 'learning_rate': 8.052e-06, 'epoch': 1.25}\n",
      "{'loss': 27.125, 'learning_rate': 8.051000000000001e-06, 'epoch': 1.25}\n",
      "{'loss': 27.75, 'learning_rate': 8.050000000000001e-06, 'epoch': 1.25}\n",
      "{'loss': 27.75, 'learning_rate': 8.049e-06, 'epoch': 1.25}\n",
      "{'loss': 27.625, 'learning_rate': 8.048e-06, 'epoch': 1.25}\n",
      "{'loss': 28.125, 'learning_rate': 8.047000000000001e-06, 'epoch': 1.25}\n",
      "{'loss': 27.875, 'learning_rate': 8.046e-06, 'epoch': 1.25}\n",
      "{'loss': 26.75, 'learning_rate': 8.045e-06, 'epoch': 1.25}\n",
      "{'loss': 27.625, 'learning_rate': 8.044000000000001e-06, 'epoch': 1.26}\n",
      "{'loss': 27.625, 'learning_rate': 8.043e-06, 'epoch': 1.26}\n",
      "{'loss': 28.5, 'learning_rate': 8.042e-06, 'epoch': 1.26}\n",
      "{'loss': 27.5, 'learning_rate': 8.041000000000001e-06, 'epoch': 1.26}\n",
      "{'loss': 27.5, 'learning_rate': 8.040000000000001e-06, 'epoch': 1.26}\n",
      "{'loss': 29.625, 'learning_rate': 8.039e-06, 'epoch': 1.26}\n",
      "{'loss': 27.125, 'learning_rate': 8.038e-06, 'epoch': 1.26}\n",
      "{'loss': 27.875, 'learning_rate': 8.037000000000001e-06, 'epoch': 1.26}\n",
      "{'loss': 27.625, 'learning_rate': 8.036e-06, 'epoch': 1.26}\n",
      "{'loss': 28.0, 'learning_rate': 8.035e-06, 'epoch': 1.26}\n",
      "{'loss': 28.375, 'learning_rate': 8.034000000000001e-06, 'epoch': 1.26}\n",
      "{'loss': 28.125, 'learning_rate': 8.033e-06, 'epoch': 1.26}\n",
      "{'loss': 26.875, 'learning_rate': 8.032e-06, 'epoch': 1.26}\n",
      "{'loss': 29.125, 'learning_rate': 8.031000000000002e-06, 'epoch': 1.26}\n",
      "{'loss': 28.375, 'learning_rate': 8.030000000000001e-06, 'epoch': 1.26}\n",
      "{'loss': 28.0, 'learning_rate': 8.029e-06, 'epoch': 1.27}\n",
      "{'loss': 27.0, 'learning_rate': 8.028e-06, 'epoch': 1.27}\n",
      "{'loss': 28.25, 'learning_rate': 8.027e-06, 'epoch': 1.27}\n",
      "{'loss': 28.375, 'learning_rate': 8.026e-06, 'epoch': 1.27}\n",
      "{'loss': 28.5, 'learning_rate': 8.025e-06, 'epoch': 1.27}\n",
      "{'loss': 26.875, 'learning_rate': 8.024000000000001e-06, 'epoch': 1.27}\n",
      "{'loss': 27.625, 'learning_rate': 8.023000000000001e-06, 'epoch': 1.27}\n",
      "{'loss': 29.0, 'learning_rate': 8.022e-06, 'epoch': 1.27}\n",
      "{'loss': 31.125, 'learning_rate': 8.021000000000002e-06, 'epoch': 1.27}\n",
      "{'loss': 29.125, 'learning_rate': 8.020000000000001e-06, 'epoch': 1.27}\n",
      "{'loss': 27.25, 'learning_rate': 8.019e-06, 'epoch': 1.27}\n",
      "{'loss': 27.0, 'learning_rate': 8.018e-06, 'epoch': 1.27}\n",
      "{'loss': 26.875, 'learning_rate': 8.017e-06, 'epoch': 1.27}\n",
      "{'loss': 28.0, 'learning_rate': 8.016e-06, 'epoch': 1.27}\n",
      "{'loss': 27.75, 'learning_rate': 8.015e-06, 'epoch': 1.27}\n",
      "{'loss': 26.375, 'learning_rate': 8.014e-06, 'epoch': 1.27}\n",
      "{'loss': 27.375, 'learning_rate': 8.013000000000001e-06, 'epoch': 1.28}\n",
      "{'loss': 29.25, 'learning_rate': 8.012e-06, 'epoch': 1.28}\n",
      "{'loss': 26.625, 'learning_rate': 8.011000000000002e-06, 'epoch': 1.28}\n",
      "{'loss': 27.625, 'learning_rate': 8.010000000000001e-06, 'epoch': 1.28}\n",
      "{'loss': 28.625, 'learning_rate': 8.009e-06, 'epoch': 1.28}\n",
      "{'loss': 27.5, 'learning_rate': 8.008e-06, 'epoch': 1.28}\n",
      "{'loss': 26.875, 'learning_rate': 8.007e-06, 'epoch': 1.28}\n",
      "{'loss': 26.75, 'learning_rate': 8.006000000000001e-06, 'epoch': 1.28}\n",
      "{'loss': 27.875, 'learning_rate': 8.005e-06, 'epoch': 1.28}\n",
      "{'loss': 27.375, 'learning_rate': 8.004e-06, 'epoch': 1.28}\n",
      "{'loss': 27.625, 'learning_rate': 8.003000000000001e-06, 'epoch': 1.28}\n",
      "{'loss': 28.125, 'learning_rate': 8.002e-06, 'epoch': 1.28}\n",
      "{'loss': 27.875, 'learning_rate': 8.001000000000002e-06, 'epoch': 1.28}\n",
      "{'loss': 29.0, 'learning_rate': 8.000000000000001e-06, 'epoch': 1.28}\n",
      "{'loss': 26.875, 'learning_rate': 7.999e-06, 'epoch': 1.28}\n",
      "{'loss': 28.25, 'learning_rate': 7.998e-06, 'epoch': 1.28}\n",
      "{'loss': 28.125, 'learning_rate': 7.997e-06, 'epoch': 1.29}\n",
      "{'loss': 27.25, 'learning_rate': 7.996000000000001e-06, 'epoch': 1.29}\n",
      "{'loss': 27.125, 'learning_rate': 7.995e-06, 'epoch': 1.29}\n",
      "{'loss': 26.625, 'learning_rate': 7.994e-06, 'epoch': 1.29}\n",
      "{'loss': 27.125, 'learning_rate': 7.993000000000001e-06, 'epoch': 1.29}\n",
      "{'loss': 26.875, 'learning_rate': 7.992e-06, 'epoch': 1.29}\n",
      "{'loss': 28.25, 'learning_rate': 7.991e-06, 'epoch': 1.29}\n",
      "{'loss': 28.5, 'learning_rate': 7.990000000000001e-06, 'epoch': 1.29}\n",
      "{'loss': 28.75, 'learning_rate': 7.989000000000001e-06, 'epoch': 1.29}\n",
      "{'loss': 27.625, 'learning_rate': 7.988e-06, 'epoch': 1.29}\n",
      "{'loss': 27.25, 'learning_rate': 7.987e-06, 'epoch': 1.29}\n",
      "{'loss': 28.125, 'learning_rate': 7.986000000000001e-06, 'epoch': 1.29}\n",
      "{'loss': 29.5, 'learning_rate': 7.985e-06, 'epoch': 1.29}\n",
      "{'loss': 27.875, 'learning_rate': 7.984e-06, 'epoch': 1.29}\n",
      "{'loss': 26.5, 'learning_rate': 7.983000000000001e-06, 'epoch': 1.29}\n",
      "{'loss': 27.5, 'learning_rate': 7.982e-06, 'epoch': 1.3}\n",
      "{'loss': 28.0, 'learning_rate': 7.981e-06, 'epoch': 1.3}\n",
      "{'loss': 28.875, 'learning_rate': 7.980000000000002e-06, 'epoch': 1.3}\n",
      "{'loss': 28.125, 'learning_rate': 7.979000000000001e-06, 'epoch': 1.3}\n",
      "{'loss': 27.875, 'learning_rate': 7.978e-06, 'epoch': 1.3}\n",
      "{'loss': 27.75, 'learning_rate': 7.977e-06, 'epoch': 1.3}\n",
      "{'loss': 26.875, 'learning_rate': 7.976000000000001e-06, 'epoch': 1.3}\n",
      "{'loss': 27.125, 'learning_rate': 7.975e-06, 'epoch': 1.3}\n",
      "{'loss': 29.5, 'learning_rate': 7.974e-06, 'epoch': 1.3}\n",
      "{'loss': 26.625, 'learning_rate': 7.973000000000001e-06, 'epoch': 1.3}\n",
      "{'loss': 28.125, 'learning_rate': 7.972000000000001e-06, 'epoch': 1.3}\n",
      "{'loss': 29.25, 'learning_rate': 7.971e-06, 'epoch': 1.3}\n",
      "{'loss': 27.75, 'learning_rate': 7.970000000000002e-06, 'epoch': 1.3}\n",
      "{'loss': 27.625, 'learning_rate': 7.969000000000001e-06, 'epoch': 1.3}\n",
      "{'loss': 26.625, 'learning_rate': 7.968e-06, 'epoch': 1.3}\n",
      "{'loss': 28.125, 'learning_rate': 7.967e-06, 'epoch': 1.3}\n",
      "{'loss': 27.75, 'learning_rate': 7.966e-06, 'epoch': 1.31}\n",
      "{'loss': 27.75, 'learning_rate': 7.965e-06, 'epoch': 1.31}\n",
      "{'loss': 26.625, 'learning_rate': 7.964e-06, 'epoch': 1.31}\n",
      "{'loss': 28.125, 'learning_rate': 7.963000000000002e-06, 'epoch': 1.31}\n",
      "{'loss': 27.625, 'learning_rate': 7.962000000000001e-06, 'epoch': 1.31}\n",
      "{'loss': 26.875, 'learning_rate': 7.961e-06, 'epoch': 1.31}\n",
      "{'loss': 29.75, 'learning_rate': 7.960000000000002e-06, 'epoch': 1.31}\n",
      "{'loss': 27.5, 'learning_rate': 7.959000000000001e-06, 'epoch': 1.31}\n",
      "{'loss': 26.375, 'learning_rate': 7.958e-06, 'epoch': 1.31}\n",
      "{'loss': 27.75, 'learning_rate': 7.957e-06, 'epoch': 1.31}\n",
      "{'loss': 27.375, 'learning_rate': 7.956e-06, 'epoch': 1.31}\n",
      "{'loss': 28.875, 'learning_rate': 7.955000000000001e-06, 'epoch': 1.31}\n",
      "{'loss': 27.25, 'learning_rate': 7.954e-06, 'epoch': 1.31}\n",
      "{'loss': 28.5, 'learning_rate': 7.953e-06, 'epoch': 1.31}\n",
      "{'loss': 27.25, 'learning_rate': 7.952000000000001e-06, 'epoch': 1.31}\n",
      "{'loss': 28.25, 'learning_rate': 7.951e-06, 'epoch': 1.32}\n",
      "{'loss': 27.75, 'learning_rate': 7.950000000000002e-06, 'epoch': 1.32}\n",
      "{'loss': 31.25, 'learning_rate': 7.949000000000001e-06, 'epoch': 1.32}\n",
      "{'loss': 27.25, 'learning_rate': 7.948e-06, 'epoch': 1.32}\n",
      "{'loss': 28.875, 'learning_rate': 7.947e-06, 'epoch': 1.32}\n",
      "{'loss': 27.125, 'learning_rate': 7.946e-06, 'epoch': 1.32}\n",
      "{'loss': 27.25, 'learning_rate': 7.945000000000001e-06, 'epoch': 1.32}\n",
      "{'loss': 27.375, 'learning_rate': 7.944e-06, 'epoch': 1.32}\n",
      "{'loss': 27.375, 'learning_rate': 7.943e-06, 'epoch': 1.32}\n",
      "{'loss': 28.25, 'learning_rate': 7.942000000000001e-06, 'epoch': 1.32}\n",
      "{'loss': 27.125, 'learning_rate': 7.941e-06, 'epoch': 1.32}\n",
      "{'loss': 28.25, 'learning_rate': 7.94e-06, 'epoch': 1.32}\n",
      "{'loss': 27.625, 'learning_rate': 7.939000000000001e-06, 'epoch': 1.32}\n",
      "{'loss': 26.75, 'learning_rate': 7.938000000000001e-06, 'epoch': 1.32}\n",
      "{'loss': 28.0, 'learning_rate': 7.937e-06, 'epoch': 1.32}\n",
      "{'loss': 27.25, 'learning_rate': 7.936e-06, 'epoch': 1.32}\n",
      "{'loss': 27.0, 'learning_rate': 7.935000000000001e-06, 'epoch': 1.33}\n",
      "{'loss': 27.875, 'learning_rate': 7.934e-06, 'epoch': 1.33}\n",
      "{'loss': 27.75, 'learning_rate': 7.933e-06, 'epoch': 1.33}\n",
      "{'loss': 26.625, 'learning_rate': 7.932000000000001e-06, 'epoch': 1.33}\n",
      "{'loss': 29.125, 'learning_rate': 7.931e-06, 'epoch': 1.33}\n",
      "{'loss': 26.875, 'learning_rate': 7.93e-06, 'epoch': 1.33}\n",
      "{'loss': 26.375, 'learning_rate': 7.929000000000002e-06, 'epoch': 1.33}\n",
      "{'loss': 29.625, 'learning_rate': 7.928e-06, 'epoch': 1.33}\n",
      "{'loss': 27.75, 'learning_rate': 7.927e-06, 'epoch': 1.33}\n",
      "{'loss': 27.875, 'learning_rate': 7.926e-06, 'epoch': 1.33}\n",
      "{'loss': 27.875, 'learning_rate': 7.925000000000001e-06, 'epoch': 1.33}\n",
      "{'loss': 27.125, 'learning_rate': 7.924e-06, 'epoch': 1.33}\n",
      "{'loss': 27.875, 'learning_rate': 7.923e-06, 'epoch': 1.33}\n",
      "{'loss': 27.5, 'learning_rate': 7.922000000000001e-06, 'epoch': 1.33}\n",
      "{'loss': 26.875, 'learning_rate': 7.921000000000001e-06, 'epoch': 1.33}\n",
      "{'loss': 27.125, 'learning_rate': 7.92e-06, 'epoch': 1.34}\n",
      "{'loss': 26.5, 'learning_rate': 7.919000000000002e-06, 'epoch': 1.34}\n",
      "{'loss': 32.75, 'learning_rate': 7.918e-06, 'epoch': 1.34}\n",
      "{'loss': 27.5, 'learning_rate': 7.917e-06, 'epoch': 1.34}\n",
      "{'loss': 27.875, 'learning_rate': 7.916e-06, 'epoch': 1.34}\n",
      "{'loss': 28.375, 'learning_rate': 7.915000000000001e-06, 'epoch': 1.34}\n",
      "{'loss': 27.0, 'learning_rate': 7.914e-06, 'epoch': 1.34}\n",
      "{'loss': 27.25, 'learning_rate': 7.913e-06, 'epoch': 1.34}\n",
      "{'loss': 27.25, 'learning_rate': 7.912000000000001e-06, 'epoch': 1.34}\n",
      "{'loss': 26.375, 'learning_rate': 7.911000000000001e-06, 'epoch': 1.34}\n",
      "{'loss': 27.0, 'learning_rate': 7.91e-06, 'epoch': 1.34}\n",
      "{'loss': 27.75, 'learning_rate': 7.909000000000002e-06, 'epoch': 1.34}\n",
      "{'loss': 28.375, 'learning_rate': 7.908e-06, 'epoch': 1.34}\n",
      "{'loss': 28.0, 'learning_rate': 7.907e-06, 'epoch': 1.34}\n",
      "{'loss': 27.25, 'learning_rate': 7.906e-06, 'epoch': 1.34}\n",
      "{'loss': 29.25, 'learning_rate': 7.905e-06, 'epoch': 1.34}\n",
      "{'loss': 27.625, 'learning_rate': 7.904000000000001e-06, 'epoch': 1.35}\n",
      "{'loss': 28.0, 'learning_rate': 7.903e-06, 'epoch': 1.35}\n",
      "{'loss': 28.125, 'learning_rate': 7.902000000000002e-06, 'epoch': 1.35}\n",
      "{'loss': 27.625, 'learning_rate': 7.901000000000001e-06, 'epoch': 1.35}\n",
      "{'loss': 29.125, 'learning_rate': 7.9e-06, 'epoch': 1.35}\n",
      "{'loss': 28.375, 'learning_rate': 7.899000000000002e-06, 'epoch': 1.35}\n",
      "{'loss': 29.25, 'learning_rate': 7.898e-06, 'epoch': 1.35}\n",
      "{'loss': 27.75, 'learning_rate': 7.897e-06, 'epoch': 1.35}\n",
      "{'loss': 27.125, 'learning_rate': 7.896e-06, 'epoch': 1.35}\n",
      "{'loss': 27.875, 'learning_rate': 7.895e-06, 'epoch': 1.35}\n",
      "{'loss': 29.25, 'learning_rate': 7.894000000000001e-06, 'epoch': 1.35}\n",
      "{'loss': 26.375, 'learning_rate': 7.893e-06, 'epoch': 1.35}\n",
      "{'loss': 28.875, 'learning_rate': 7.892e-06, 'epoch': 1.35}\n",
      "{'loss': 29.875, 'learning_rate': 7.891000000000001e-06, 'epoch': 1.35}\n",
      "{'loss': 27.5, 'learning_rate': 7.89e-06, 'epoch': 1.35}\n",
      "{'loss': 27.375, 'learning_rate': 7.889000000000002e-06, 'epoch': 1.35}\n",
      "{'loss': 27.5, 'learning_rate': 7.888e-06, 'epoch': 1.36}\n",
      "{'loss': 30.125, 'learning_rate': 7.887000000000001e-06, 'epoch': 1.36}\n",
      "{'loss': 28.625, 'learning_rate': 7.886e-06, 'epoch': 1.36}\n",
      "{'loss': 28.375, 'learning_rate': 7.885e-06, 'epoch': 1.36}\n",
      "{'loss': 28.25, 'learning_rate': 7.884000000000001e-06, 'epoch': 1.36}\n",
      "{'loss': 28.25, 'learning_rate': 7.883e-06, 'epoch': 1.36}\n",
      "{'loss': 26.75, 'learning_rate': 7.882e-06, 'epoch': 1.36}\n",
      "{'loss': 27.875, 'learning_rate': 7.881000000000001e-06, 'epoch': 1.36}\n",
      "{'loss': 27.125, 'learning_rate': 7.88e-06, 'epoch': 1.36}\n",
      "{'loss': 27.5, 'learning_rate': 7.879e-06, 'epoch': 1.36}\n",
      "{'loss': 27.75, 'learning_rate': 7.878e-06, 'epoch': 1.36}\n",
      "{'loss': 28.125, 'learning_rate': 7.877000000000001e-06, 'epoch': 1.36}\n",
      "{'loss': 28.0, 'learning_rate': 7.876e-06, 'epoch': 1.36}\n",
      "{'loss': 27.0, 'learning_rate': 7.875e-06, 'epoch': 1.36}\n",
      "{'loss': 27.625, 'learning_rate': 7.874000000000001e-06, 'epoch': 1.36}\n",
      "{'loss': 29.375, 'learning_rate': 7.873e-06, 'epoch': 1.37}\n",
      "{'loss': 28.25, 'learning_rate': 7.872e-06, 'epoch': 1.37}\n",
      "{'loss': 27.125, 'learning_rate': 7.871000000000001e-06, 'epoch': 1.37}\n",
      "{'loss': 26.875, 'learning_rate': 7.870000000000001e-06, 'epoch': 1.37}\n",
      "{'loss': 27.25, 'learning_rate': 7.869e-06, 'epoch': 1.37}\n",
      "{'loss': 28.5, 'learning_rate': 7.868000000000002e-06, 'epoch': 1.37}\n",
      "{'loss': 29.0, 'learning_rate': 7.867e-06, 'epoch': 1.37}\n",
      "{'loss': 27.0, 'learning_rate': 7.866e-06, 'epoch': 1.37}\n",
      "{'loss': 27.875, 'learning_rate': 7.865e-06, 'epoch': 1.37}\n",
      "{'loss': 27.625, 'learning_rate': 7.864000000000001e-06, 'epoch': 1.37}\n",
      "{'loss': 30.75, 'learning_rate': 7.863e-06, 'epoch': 1.37}\n",
      "{'loss': 28.75, 'learning_rate': 7.862e-06, 'epoch': 1.37}\n",
      "{'loss': 27.125, 'learning_rate': 7.861000000000001e-06, 'epoch': 1.37}\n",
      "{'loss': 27.75, 'learning_rate': 7.860000000000001e-06, 'epoch': 1.37}\n",
      "{'loss': 27.75, 'learning_rate': 7.859e-06, 'epoch': 1.37}\n",
      "{'loss': 27.5, 'learning_rate': 7.858000000000002e-06, 'epoch': 1.37}\n",
      "{'loss': 27.0, 'learning_rate': 7.857e-06, 'epoch': 1.38}\n",
      "{'loss': 28.375, 'learning_rate': 7.856e-06, 'epoch': 1.38}\n",
      "{'loss': 27.75, 'learning_rate': 7.855e-06, 'epoch': 1.38}\n",
      "{'loss': 28.0, 'learning_rate': 7.854e-06, 'epoch': 1.38}\n",
      "{'loss': 28.125, 'learning_rate': 7.853000000000001e-06, 'epoch': 1.38}\n",
      "{'loss': 28.25, 'learning_rate': 7.852e-06, 'epoch': 1.38}\n",
      "{'loss': 27.5, 'learning_rate': 7.851000000000002e-06, 'epoch': 1.38}\n",
      "{'loss': 28.875, 'learning_rate': 7.850000000000001e-06, 'epoch': 1.38}\n",
      "{'loss': 27.125, 'learning_rate': 7.849e-06, 'epoch': 1.38}\n",
      "{'loss': 26.625, 'learning_rate': 7.848000000000002e-06, 'epoch': 1.38}\n",
      "{'loss': 27.125, 'learning_rate': 7.847e-06, 'epoch': 1.38}\n",
      "{'loss': 28.0, 'learning_rate': 7.846e-06, 'epoch': 1.38}\n",
      "{'loss': 27.25, 'learning_rate': 7.845e-06, 'epoch': 1.38}\n",
      "{'loss': 26.75, 'learning_rate': 7.844e-06, 'epoch': 1.38}\n",
      "{'loss': 29.25, 'learning_rate': 7.843000000000001e-06, 'epoch': 1.38}\n",
      "{'loss': 27.625, 'learning_rate': 7.842e-06, 'epoch': 1.39}\n",
      "{'loss': 28.0, 'learning_rate': 7.841000000000002e-06, 'epoch': 1.39}\n",
      "{'loss': 28.0, 'learning_rate': 7.840000000000001e-06, 'epoch': 1.39}\n",
      "{'loss': 26.875, 'learning_rate': 7.839e-06, 'epoch': 1.39}\n",
      "{'loss': 26.25, 'learning_rate': 7.838000000000002e-06, 'epoch': 1.39}\n",
      "{'loss': 28.625, 'learning_rate': 7.837e-06, 'epoch': 1.39}\n",
      "{'loss': 26.875, 'learning_rate': 7.836000000000001e-06, 'epoch': 1.39}\n",
      "{'loss': 27.25, 'learning_rate': 7.835e-06, 'epoch': 1.39}\n",
      "{'loss': 28.0, 'learning_rate': 7.834e-06, 'epoch': 1.39}\n",
      "{'loss': 27.625, 'learning_rate': 7.833000000000001e-06, 'epoch': 1.39}\n",
      "{'loss': 27.75, 'learning_rate': 7.832e-06, 'epoch': 1.39}\n",
      "{'loss': 27.0, 'learning_rate': 7.831e-06, 'epoch': 1.39}\n",
      "{'loss': 26.625, 'learning_rate': 7.830000000000001e-06, 'epoch': 1.39}\n",
      "{'loss': 27.375, 'learning_rate': 7.829e-06, 'epoch': 1.39}\n",
      "{'loss': 27.375, 'learning_rate': 7.828000000000002e-06, 'epoch': 1.39}\n",
      "{'loss': 29.125, 'learning_rate': 7.827e-06, 'epoch': 1.39}\n",
      "{'loss': 27.5, 'learning_rate': 7.826000000000001e-06, 'epoch': 1.4}\n",
      "{'loss': 27.375, 'learning_rate': 7.825e-06, 'epoch': 1.4}\n",
      "{'loss': 27.625, 'learning_rate': 7.824e-06, 'epoch': 1.4}\n",
      "{'loss': 26.75, 'learning_rate': 7.823000000000001e-06, 'epoch': 1.4}\n",
      "{'loss': 26.5, 'learning_rate': 7.822e-06, 'epoch': 1.4}\n",
      "{'loss': 27.125, 'learning_rate': 7.821e-06, 'epoch': 1.4}\n",
      "{'loss': 26.875, 'learning_rate': 7.820000000000001e-06, 'epoch': 1.4}\n",
      "{'loss': 26.5, 'learning_rate': 7.819000000000001e-06, 'epoch': 1.4}\n",
      "{'loss': 29.25, 'learning_rate': 7.818e-06, 'epoch': 1.4}\n",
      "{'loss': 27.875, 'learning_rate': 7.817e-06, 'epoch': 1.4}\n",
      "{'loss': 27.625, 'learning_rate': 7.816000000000001e-06, 'epoch': 1.4}\n",
      "{'loss': 27.375, 'learning_rate': 7.815e-06, 'epoch': 1.4}\n",
      "{'loss': 28.0, 'learning_rate': 7.814e-06, 'epoch': 1.4}\n",
      "{'loss': 27.75, 'learning_rate': 7.813000000000001e-06, 'epoch': 1.4}\n",
      "{'loss': 27.375, 'learning_rate': 7.812e-06, 'epoch': 1.4}\n",
      "{'loss': 28.875, 'learning_rate': 7.811e-06, 'epoch': 1.41}\n",
      "{'loss': 26.875, 'learning_rate': 7.810000000000001e-06, 'epoch': 1.41}\n",
      "{'loss': 28.0, 'learning_rate': 7.809000000000001e-06, 'epoch': 1.41}\n",
      "{'loss': 26.0, 'learning_rate': 7.808e-06, 'epoch': 1.41}\n",
      "{'loss': 27.5, 'learning_rate': 7.807e-06, 'epoch': 1.41}\n",
      "{'loss': 27.125, 'learning_rate': 7.806e-06, 'epoch': 1.41}\n",
      "{'loss': 27.125, 'learning_rate': 7.805e-06, 'epoch': 1.41}\n",
      "{'loss': 28.875, 'learning_rate': 7.804e-06, 'epoch': 1.41}\n",
      "{'loss': 31.0, 'learning_rate': 7.803000000000001e-06, 'epoch': 1.41}\n",
      "{'loss': 28.875, 'learning_rate': 7.802000000000001e-06, 'epoch': 1.41}\n",
      "{'loss': 28.5, 'learning_rate': 7.801e-06, 'epoch': 1.41}\n",
      "{'loss': 27.0, 'learning_rate': 7.800000000000002e-06, 'epoch': 1.41}\n",
      "{'loss': 30.0, 'learning_rate': 7.799000000000001e-06, 'epoch': 1.41}\n",
      "{'loss': 27.625, 'learning_rate': 7.798e-06, 'epoch': 1.41}\n",
      "{'loss': 28.125, 'learning_rate': 7.797e-06, 'epoch': 1.41}\n",
      "{'loss': 28.75, 'learning_rate': 7.796e-06, 'epoch': 1.41}\n",
      "{'loss': 27.0, 'learning_rate': 7.795e-06, 'epoch': 1.42}\n",
      "{'loss': 27.625, 'learning_rate': 7.794e-06, 'epoch': 1.42}\n",
      "{'loss': 27.5, 'learning_rate': 7.793e-06, 'epoch': 1.42}\n",
      "{'loss': 26.875, 'learning_rate': 7.792000000000001e-06, 'epoch': 1.42}\n",
      "{'loss': 27.625, 'learning_rate': 7.791e-06, 'epoch': 1.42}\n",
      "{'loss': 26.75, 'learning_rate': 7.790000000000002e-06, 'epoch': 1.42}\n",
      "{'loss': 27.5, 'learning_rate': 7.789000000000001e-06, 'epoch': 1.42}\n",
      "{'loss': 27.375, 'learning_rate': 7.788e-06, 'epoch': 1.42}\n",
      "{'loss': 27.375, 'learning_rate': 7.787e-06, 'epoch': 1.42}\n",
      "{'loss': 27.625, 'learning_rate': 7.786e-06, 'epoch': 1.42}\n",
      "{'loss': 29.875, 'learning_rate': 7.785000000000001e-06, 'epoch': 1.42}\n",
      "{'loss': 29.125, 'learning_rate': 7.784e-06, 'epoch': 1.42}\n",
      "{'loss': 27.125, 'learning_rate': 7.783e-06, 'epoch': 1.42}\n",
      "{'loss': 28.875, 'learning_rate': 7.782000000000001e-06, 'epoch': 1.42}\n",
      "{'loss': 27.0, 'learning_rate': 7.781e-06, 'epoch': 1.42}\n",
      "{'loss': 26.75, 'learning_rate': 7.78e-06, 'epoch': 1.42}\n",
      "{'loss': 27.0, 'learning_rate': 7.779000000000001e-06, 'epoch': 1.43}\n",
      "{'loss': 26.625, 'learning_rate': 7.778e-06, 'epoch': 1.43}\n",
      "{'loss': 28.375, 'learning_rate': 7.777e-06, 'epoch': 1.43}\n",
      "{'loss': 28.125, 'learning_rate': 7.776e-06, 'epoch': 1.43}\n",
      "{'loss': 27.25, 'learning_rate': 7.775000000000001e-06, 'epoch': 1.43}\n",
      "{'loss': 28.75, 'learning_rate': 7.774e-06, 'epoch': 1.43}\n",
      "{'loss': 27.25, 'learning_rate': 7.773e-06, 'epoch': 1.43}\n",
      "{'loss': 27.25, 'learning_rate': 7.772000000000001e-06, 'epoch': 1.43}\n",
      "{'loss': 29.625, 'learning_rate': 7.771e-06, 'epoch': 1.43}\n",
      "{'loss': 27.625, 'learning_rate': 7.77e-06, 'epoch': 1.43}\n",
      "{'loss': 27.125, 'learning_rate': 7.769000000000001e-06, 'epoch': 1.43}\n",
      "{'loss': 27.375, 'learning_rate': 7.768e-06, 'epoch': 1.43}\n",
      "{'loss': 28.25, 'learning_rate': 7.767e-06, 'epoch': 1.43}\n",
      "{'loss': 27.125, 'learning_rate': 7.766e-06, 'epoch': 1.43}\n",
      "{'loss': 27.625, 'learning_rate': 7.765000000000001e-06, 'epoch': 1.43}\n",
      "{'loss': 30.0, 'learning_rate': 7.764e-06, 'epoch': 1.44}\n",
      "{'loss': 29.75, 'learning_rate': 7.763e-06, 'epoch': 1.44}\n",
      "{'loss': 32.0, 'learning_rate': 7.762000000000001e-06, 'epoch': 1.44}\n",
      "{'loss': 27.625, 'learning_rate': 7.761e-06, 'epoch': 1.44}\n",
      "{'loss': 27.75, 'learning_rate': 7.76e-06, 'epoch': 1.44}\n",
      "{'loss': 26.5, 'learning_rate': 7.759000000000001e-06, 'epoch': 1.44}\n",
      "{'loss': 26.625, 'learning_rate': 7.758000000000001e-06, 'epoch': 1.44}\n",
      "{'loss': 27.875, 'learning_rate': 7.757e-06, 'epoch': 1.44}\n",
      "{'loss': 29.125, 'learning_rate': 7.756e-06, 'epoch': 1.44}\n",
      "{'loss': 28.5, 'learning_rate': 7.755000000000001e-06, 'epoch': 1.44}\n",
      "{'loss': 27.875, 'learning_rate': 7.754e-06, 'epoch': 1.44}\n",
      "{'loss': 28.5, 'learning_rate': 7.753e-06, 'epoch': 1.44}\n",
      "{'loss': 29.875, 'learning_rate': 7.752000000000001e-06, 'epoch': 1.44}\n",
      "{'loss': 27.125, 'learning_rate': 7.751e-06, 'epoch': 1.44}\n",
      "{'loss': 27.0, 'learning_rate': 7.75e-06, 'epoch': 1.44}\n",
      "{'loss': 28.0, 'learning_rate': 7.749000000000002e-06, 'epoch': 1.44}\n",
      "{'loss': 27.875, 'learning_rate': 7.748000000000001e-06, 'epoch': 1.45}\n",
      "{'loss': 27.875, 'learning_rate': 7.747e-06, 'epoch': 1.45}\n",
      "{'loss': 27.375, 'learning_rate': 7.746e-06, 'epoch': 1.45}\n",
      "{'loss': 27.5, 'learning_rate': 7.745e-06, 'epoch': 1.45}\n",
      "{'loss': 29.125, 'learning_rate': 7.744e-06, 'epoch': 1.45}\n",
      "{'loss': 27.0, 'learning_rate': 7.743e-06, 'epoch': 1.45}\n",
      "{'loss': 27.375, 'learning_rate': 7.742000000000001e-06, 'epoch': 1.45}\n",
      "{'loss': 27.625, 'learning_rate': 7.741000000000001e-06, 'epoch': 1.45}\n",
      "{'loss': 26.875, 'learning_rate': 7.74e-06, 'epoch': 1.45}\n",
      "{'loss': 27.875, 'learning_rate': 7.739000000000002e-06, 'epoch': 1.45}\n",
      "{'loss': 26.625, 'learning_rate': 7.738000000000001e-06, 'epoch': 1.45}\n",
      "{'loss': 27.375, 'learning_rate': 7.737e-06, 'epoch': 1.45}\n",
      "{'loss': 27.5, 'learning_rate': 7.736e-06, 'epoch': 1.45}\n",
      "{'loss': 27.5, 'learning_rate': 7.735e-06, 'epoch': 1.45}\n",
      "{'loss': 29.0, 'learning_rate': 7.734e-06, 'epoch': 1.45}\n",
      "{'loss': 27.5, 'learning_rate': 7.733e-06, 'epoch': 1.46}\n",
      "{'loss': 27.625, 'learning_rate': 7.732e-06, 'epoch': 1.46}\n",
      "{'loss': 27.625, 'learning_rate': 7.731000000000001e-06, 'epoch': 1.46}\n",
      "{'loss': 27.25, 'learning_rate': 7.73e-06, 'epoch': 1.46}\n",
      "{'loss': 27.5, 'learning_rate': 7.729000000000002e-06, 'epoch': 1.46}\n",
      "{'loss': 27.875, 'learning_rate': 7.728000000000001e-06, 'epoch': 1.46}\n",
      "{'loss': 27.875, 'learning_rate': 7.727e-06, 'epoch': 1.46}\n",
      "{'loss': 28.875, 'learning_rate': 7.726e-06, 'epoch': 1.46}\n",
      "{'loss': 27.75, 'learning_rate': 7.725e-06, 'epoch': 1.46}\n",
      "{'loss': 27.625, 'learning_rate': 7.724000000000001e-06, 'epoch': 1.46}\n",
      "{'loss': 28.375, 'learning_rate': 7.723e-06, 'epoch': 1.46}\n",
      "{'loss': 29.0, 'learning_rate': 7.722e-06, 'epoch': 1.46}\n",
      "{'loss': 26.625, 'learning_rate': 7.721000000000001e-06, 'epoch': 1.46}\n",
      "{'loss': 28.125, 'learning_rate': 7.72e-06, 'epoch': 1.46}\n",
      "{'loss': 28.375, 'learning_rate': 7.719e-06, 'epoch': 1.46}\n",
      "{'loss': 29.5, 'learning_rate': 7.718000000000001e-06, 'epoch': 1.46}\n",
      "{'loss': 29.625, 'learning_rate': 7.717e-06, 'epoch': 1.47}\n",
      "{'loss': 28.625, 'learning_rate': 7.716e-06, 'epoch': 1.47}\n",
      "{'loss': 27.75, 'learning_rate': 7.715e-06, 'epoch': 1.47}\n",
      "{'loss': 27.125, 'learning_rate': 7.714000000000001e-06, 'epoch': 1.47}\n",
      "{'loss': 27.0, 'learning_rate': 7.713e-06, 'epoch': 1.47}\n",
      "{'loss': 27.625, 'learning_rate': 7.712e-06, 'epoch': 1.47}\n",
      "{'loss': 29.375, 'learning_rate': 7.711000000000001e-06, 'epoch': 1.47}\n",
      "{'loss': 27.125, 'learning_rate': 7.71e-06, 'epoch': 1.47}\n",
      "{'loss': 27.125, 'learning_rate': 7.709e-06, 'epoch': 1.47}\n",
      "{'loss': 27.625, 'learning_rate': 7.708000000000001e-06, 'epoch': 1.47}\n",
      "{'loss': 27.125, 'learning_rate': 7.707000000000001e-06, 'epoch': 1.47}\n",
      "{'loss': 27.375, 'learning_rate': 7.706e-06, 'epoch': 1.47}\n",
      "{'loss': 27.75, 'learning_rate': 7.705e-06, 'epoch': 1.47}\n",
      "{'loss': 26.625, 'learning_rate': 7.704000000000001e-06, 'epoch': 1.47}\n",
      "{'loss': 27.375, 'learning_rate': 7.703e-06, 'epoch': 1.47}\n",
      "{'loss': 27.5, 'learning_rate': 7.702e-06, 'epoch': 1.47}\n",
      "{'loss': 28.0, 'learning_rate': 7.701000000000001e-06, 'epoch': 1.48}\n",
      "{'loss': 27.25, 'learning_rate': 7.7e-06, 'epoch': 1.48}\n",
      "{'loss': 29.75, 'learning_rate': 7.699e-06, 'epoch': 1.48}\n",
      "{'loss': 28.875, 'learning_rate': 7.698000000000002e-06, 'epoch': 1.48}\n",
      "{'loss': 28.0, 'learning_rate': 7.697000000000001e-06, 'epoch': 1.48}\n",
      "{'loss': 27.125, 'learning_rate': 7.696e-06, 'epoch': 1.48}\n",
      "{'loss': 27.125, 'learning_rate': 7.695e-06, 'epoch': 1.48}\n",
      "{'loss': 27.625, 'learning_rate': 7.694e-06, 'epoch': 1.48}\n",
      "{'loss': 27.125, 'learning_rate': 7.693e-06, 'epoch': 1.48}\n",
      "{'loss': 27.5, 'learning_rate': 7.692e-06, 'epoch': 1.48}\n",
      "{'loss': 27.75, 'learning_rate': 7.691000000000001e-06, 'epoch': 1.48}\n",
      "{'loss': 28.0, 'learning_rate': 7.690000000000001e-06, 'epoch': 1.48}\n",
      "{'loss': 29.75, 'learning_rate': 7.689e-06, 'epoch': 1.48}\n",
      "{'loss': 26.75, 'learning_rate': 7.688000000000002e-06, 'epoch': 1.48}\n",
      "{'loss': 27.375, 'learning_rate': 7.687000000000001e-06, 'epoch': 1.48}\n",
      "{'loss': 26.75, 'learning_rate': 7.686e-06, 'epoch': 1.49}\n",
      "{'loss': 27.625, 'learning_rate': 7.685e-06, 'epoch': 1.49}\n",
      "{'loss': 27.25, 'learning_rate': 7.684e-06, 'epoch': 1.49}\n",
      "{'loss': 26.75, 'learning_rate': 7.683e-06, 'epoch': 1.49}\n",
      "{'loss': 27.875, 'learning_rate': 7.682e-06, 'epoch': 1.49}\n",
      "{'loss': 27.5, 'learning_rate': 7.681000000000002e-06, 'epoch': 1.49}\n",
      "{'loss': 27.5, 'learning_rate': 7.680000000000001e-06, 'epoch': 1.49}\n",
      "{'loss': 27.625, 'learning_rate': 7.679e-06, 'epoch': 1.49}\n",
      "{'loss': 26.5, 'learning_rate': 7.678000000000002e-06, 'epoch': 1.49}\n",
      "{'loss': 28.125, 'learning_rate': 7.677000000000001e-06, 'epoch': 1.49}\n",
      "{'loss': 26.875, 'learning_rate': 7.676e-06, 'epoch': 1.49}\n",
      "{'loss': 27.0, 'learning_rate': 7.675e-06, 'epoch': 1.49}\n",
      "{'loss': 28.75, 'learning_rate': 7.674e-06, 'epoch': 1.49}\n",
      "{'loss': 28.875, 'learning_rate': 7.673000000000001e-06, 'epoch': 1.49}\n",
      "{'loss': 27.5, 'learning_rate': 7.672e-06, 'epoch': 1.49}\n",
      "{'loss': 27.75, 'learning_rate': 7.671e-06, 'epoch': 1.49}\n",
      "{'loss': 27.375, 'learning_rate': 7.670000000000001e-06, 'epoch': 1.5}\n",
      "{'loss': 26.875, 'learning_rate': 7.669e-06, 'epoch': 1.5}\n",
      "{'loss': 27.625, 'learning_rate': 7.668000000000002e-06, 'epoch': 1.5}\n",
      "{'loss': 26.625, 'learning_rate': 7.667000000000001e-06, 'epoch': 1.5}\n",
      "{'loss': 28.25, 'learning_rate': 7.666e-06, 'epoch': 1.5}\n",
      "{'loss': 28.5, 'learning_rate': 7.665e-06, 'epoch': 1.5}\n",
      "{'loss': 27.875, 'learning_rate': 7.664e-06, 'epoch': 1.5}\n",
      "{'loss': 28.375, 'learning_rate': 7.663000000000001e-06, 'epoch': 1.5}\n",
      "{'loss': 27.75, 'learning_rate': 7.662e-06, 'epoch': 1.5}\n",
      "{'loss': 27.625, 'learning_rate': 7.661e-06, 'epoch': 1.5}\n",
      "{'loss': 27.75, 'learning_rate': 7.660000000000001e-06, 'epoch': 1.5}\n",
      "{'loss': 26.875, 'learning_rate': 7.659e-06, 'epoch': 1.5}\n",
      "{'loss': 26.75, 'learning_rate': 7.658e-06, 'epoch': 1.5}\n",
      "{'loss': 26.75, 'learning_rate': 7.657000000000001e-06, 'epoch': 1.5}\n",
      "{'loss': 29.25, 'learning_rate': 7.656000000000001e-06, 'epoch': 1.5}\n",
      "{'loss': 27.125, 'learning_rate': 7.655e-06, 'epoch': 1.51}\n",
      "{'loss': 27.125, 'learning_rate': 7.654e-06, 'epoch': 1.51}\n",
      "{'loss': 26.875, 'learning_rate': 7.653000000000001e-06, 'epoch': 1.51}\n",
      "{'loss': 27.75, 'learning_rate': 7.652e-06, 'epoch': 1.51}\n",
      "{'loss': 27.5, 'learning_rate': 7.651e-06, 'epoch': 1.51}\n",
      "{'loss': 28.0, 'learning_rate': 7.650000000000001e-06, 'epoch': 1.51}\n",
      "{'loss': 27.5, 'learning_rate': 7.649e-06, 'epoch': 1.51}\n",
      "{'loss': 30.125, 'learning_rate': 7.648e-06, 'epoch': 1.51}\n",
      "{'loss': 29.0, 'learning_rate': 7.647000000000001e-06, 'epoch': 1.51}\n",
      "{'loss': 26.5, 'learning_rate': 7.646e-06, 'epoch': 1.51}\n",
      "{'loss': 27.75, 'learning_rate': 7.645e-06, 'epoch': 1.51}\n",
      "{'loss': 27.5, 'learning_rate': 7.644e-06, 'epoch': 1.51}\n",
      "{'loss': 27.875, 'learning_rate': 7.643000000000001e-06, 'epoch': 1.51}\n",
      "{'loss': 29.625, 'learning_rate': 7.642e-06, 'epoch': 1.51}\n",
      "{'loss': 27.25, 'learning_rate': 7.641e-06, 'epoch': 1.51}\n",
      "{'loss': 26.625, 'learning_rate': 7.640000000000001e-06, 'epoch': 1.51}\n",
      "{'loss': 28.125, 'learning_rate': 7.639000000000001e-06, 'epoch': 1.52}\n",
      "{'loss': 27.125, 'learning_rate': 7.638e-06, 'epoch': 1.52}\n",
      "{'loss': 27.375, 'learning_rate': 7.637000000000002e-06, 'epoch': 1.52}\n",
      "{'loss': 27.375, 'learning_rate': 7.636e-06, 'epoch': 1.52}\n",
      "{'loss': 28.375, 'learning_rate': 7.635e-06, 'epoch': 1.52}\n",
      "{'loss': 26.125, 'learning_rate': 7.634e-06, 'epoch': 1.52}\n",
      "{'loss': 27.25, 'learning_rate': 7.633e-06, 'epoch': 1.52}\n",
      "{'loss': 29.0, 'learning_rate': 7.632e-06, 'epoch': 1.52}\n",
      "{'loss': 27.5, 'learning_rate': 7.631e-06, 'epoch': 1.52}\n",
      "{'loss': 27.75, 'learning_rate': 7.630000000000001e-06, 'epoch': 1.52}\n",
      "{'loss': 27.25, 'learning_rate': 7.629000000000001e-06, 'epoch': 1.52}\n",
      "{'loss': 26.875, 'learning_rate': 7.628000000000001e-06, 'epoch': 1.52}\n",
      "{'loss': 27.875, 'learning_rate': 7.627000000000001e-06, 'epoch': 1.52}\n",
      "{'loss': 28.625, 'learning_rate': 7.626e-06, 'epoch': 1.52}\n",
      "{'loss': 27.125, 'learning_rate': 7.625e-06, 'epoch': 1.52}\n",
      "{'loss': 28.625, 'learning_rate': 7.624e-06, 'epoch': 1.53}\n",
      "{'loss': 29.625, 'learning_rate': 7.6230000000000005e-06, 'epoch': 1.53}\n",
      "{'loss': 27.75, 'learning_rate': 7.622000000000001e-06, 'epoch': 1.53}\n",
      "{'loss': 27.25, 'learning_rate': 7.621e-06, 'epoch': 1.53}\n",
      "{'loss': 29.875, 'learning_rate': 7.620000000000001e-06, 'epoch': 1.53}\n",
      "{'loss': 27.375, 'learning_rate': 7.619000000000001e-06, 'epoch': 1.53}\n",
      "{'loss': 28.125, 'learning_rate': 7.618000000000001e-06, 'epoch': 1.53}\n",
      "{'loss': 28.125, 'learning_rate': 7.617000000000001e-06, 'epoch': 1.53}\n",
      "{'loss': 29.75, 'learning_rate': 7.616000000000001e-06, 'epoch': 1.53}\n",
      "{'loss': 27.5, 'learning_rate': 7.615e-06, 'epoch': 1.53}\n",
      "{'loss': 28.0, 'learning_rate': 7.614e-06, 'epoch': 1.53}\n",
      "{'loss': 26.75, 'learning_rate': 7.613000000000001e-06, 'epoch': 1.53}\n",
      "{'loss': 29.375, 'learning_rate': 7.612e-06, 'epoch': 1.53}\n",
      "{'loss': 28.25, 'learning_rate': 7.6110000000000005e-06, 'epoch': 1.53}\n",
      "{'loss': 27.25, 'learning_rate': 7.610000000000001e-06, 'epoch': 1.53}\n",
      "{'loss': 27.0, 'learning_rate': 7.609000000000001e-06, 'epoch': 1.53}\n",
      "{'loss': 27.75, 'learning_rate': 7.608000000000001e-06, 'epoch': 1.54}\n",
      "{'loss': 28.5, 'learning_rate': 7.607000000000001e-06, 'epoch': 1.54}\n",
      "{'loss': 27.5, 'learning_rate': 7.606000000000001e-06, 'epoch': 1.54}\n",
      "{'loss': 28.625, 'learning_rate': 7.605e-06, 'epoch': 1.54}\n",
      "{'loss': 28.0, 'learning_rate': 7.604e-06, 'epoch': 1.54}\n",
      "{'loss': 27.625, 'learning_rate': 7.603000000000001e-06, 'epoch': 1.54}\n",
      "{'loss': 31.0, 'learning_rate': 7.602e-06, 'epoch': 1.54}\n",
      "{'loss': 29.0, 'learning_rate': 7.601000000000001e-06, 'epoch': 1.54}\n",
      "{'loss': 31.5, 'learning_rate': 7.600000000000001e-06, 'epoch': 1.54}\n",
      "{'loss': 27.625, 'learning_rate': 7.5990000000000004e-06, 'epoch': 1.54}\n",
      "{'loss': 27.625, 'learning_rate': 7.598000000000001e-06, 'epoch': 1.54}\n",
      "{'loss': 27.25, 'learning_rate': 7.597000000000001e-06, 'epoch': 1.54}\n",
      "{'loss': 27.25, 'learning_rate': 7.5960000000000015e-06, 'epoch': 1.54}\n",
      "{'loss': 26.375, 'learning_rate': 7.595e-06, 'epoch': 1.54}\n",
      "{'loss': 28.375, 'learning_rate': 7.5940000000000005e-06, 'epoch': 1.54}\n",
      "{'loss': 27.25, 'learning_rate': 7.593e-06, 'epoch': 1.54}\n",
      "{'loss': 26.375, 'learning_rate': 7.592e-06, 'epoch': 1.55}\n",
      "{'loss': 27.25, 'learning_rate': 7.591000000000001e-06, 'epoch': 1.55}\n",
      "{'loss': 26.625, 'learning_rate': 7.590000000000001e-06, 'epoch': 1.55}\n",
      "{'loss': 27.5, 'learning_rate': 7.5890000000000005e-06, 'epoch': 1.55}\n",
      "{'loss': 27.75, 'learning_rate': 7.588000000000001e-06, 'epoch': 1.55}\n",
      "{'loss': 27.0, 'learning_rate': 7.587000000000001e-06, 'epoch': 1.55}\n",
      "{'loss': 28.625, 'learning_rate': 7.586000000000001e-06, 'epoch': 1.55}\n",
      "{'loss': 28.5, 'learning_rate': 7.585e-06, 'epoch': 1.55}\n",
      "{'loss': 28.0, 'learning_rate': 7.5840000000000006e-06, 'epoch': 1.55}\n",
      "{'loss': 27.25, 'learning_rate': 7.583e-06, 'epoch': 1.55}\n",
      "{'loss': 27.625, 'learning_rate': 7.582e-06, 'epoch': 1.55}\n",
      "{'loss': 28.125, 'learning_rate': 7.581000000000001e-06, 'epoch': 1.55}\n",
      "{'loss': 28.375, 'learning_rate': 7.58e-06, 'epoch': 1.55}\n",
      "{'loss': 29.625, 'learning_rate': 7.579000000000001e-06, 'epoch': 1.55}\n",
      "{'loss': 26.875, 'learning_rate': 7.578000000000001e-06, 'epoch': 1.55}\n",
      "{'loss': 26.25, 'learning_rate': 7.577000000000001e-06, 'epoch': 1.56}\n",
      "{'loss': 27.75, 'learning_rate': 7.576000000000001e-06, 'epoch': 1.56}\n",
      "{'loss': 29.75, 'learning_rate': 7.575e-06, 'epoch': 1.56}\n",
      "{'loss': 27.625, 'learning_rate': 7.574e-06, 'epoch': 1.56}\n",
      "{'loss': 26.75, 'learning_rate': 7.573e-06, 'epoch': 1.56}\n",
      "{'loss': 28.125, 'learning_rate': 7.5720000000000005e-06, 'epoch': 1.56}\n",
      "{'loss': 27.5, 'learning_rate': 7.571000000000001e-06, 'epoch': 1.56}\n",
      "{'loss': 26.625, 'learning_rate': 7.57e-06, 'epoch': 1.56}\n",
      "{'loss': 28.125, 'learning_rate': 7.569000000000001e-06, 'epoch': 1.56}\n",
      "{'loss': 27.875, 'learning_rate': 7.568000000000001e-06, 'epoch': 1.56}\n",
      "{'loss': 27.125, 'learning_rate': 7.567000000000001e-06, 'epoch': 1.56}\n",
      "{'loss': 26.875, 'learning_rate': 7.566000000000001e-06, 'epoch': 1.56}\n",
      "{'loss': 28.125, 'learning_rate': 7.565e-06, 'epoch': 1.56}\n",
      "{'loss': 27.75, 'learning_rate': 7.564e-06, 'epoch': 1.56}\n",
      "{'loss': 26.75, 'learning_rate': 7.563e-06, 'epoch': 1.56}\n",
      "{'loss': 27.5, 'learning_rate': 7.562000000000001e-06, 'epoch': 1.56}\n",
      "{'loss': 28.0, 'learning_rate': 7.561000000000001e-06, 'epoch': 1.57}\n",
      "{'loss': 26.75, 'learning_rate': 7.5600000000000005e-06, 'epoch': 1.57}\n",
      "{'loss': 30.625, 'learning_rate': 7.559000000000001e-06, 'epoch': 1.57}\n",
      "{'loss': 27.875, 'learning_rate': 7.558000000000001e-06, 'epoch': 1.57}\n",
      "{'loss': 28.0, 'learning_rate': 7.557000000000001e-06, 'epoch': 1.57}\n",
      "{'loss': 26.875, 'learning_rate': 7.556000000000001e-06, 'epoch': 1.57}\n",
      "{'loss': 26.875, 'learning_rate': 7.5550000000000005e-06, 'epoch': 1.57}\n",
      "{'loss': 26.75, 'learning_rate': 7.554e-06, 'epoch': 1.57}\n",
      "{'loss': 26.875, 'learning_rate': 7.553e-06, 'epoch': 1.57}\n",
      "{'loss': 27.5, 'learning_rate': 7.552000000000001e-06, 'epoch': 1.57}\n",
      "{'loss': 26.875, 'learning_rate': 7.551e-06, 'epoch': 1.57}\n",
      "{'loss': 27.0, 'learning_rate': 7.5500000000000006e-06, 'epoch': 1.57}\n",
      "{'loss': 26.875, 'learning_rate': 7.549000000000001e-06, 'epoch': 1.57}\n",
      "{'loss': 28.75, 'learning_rate': 7.548000000000001e-06, 'epoch': 1.57}\n",
      "{'loss': 28.25, 'learning_rate': 7.547000000000001e-06, 'epoch': 1.57}\n",
      "{'loss': 27.25, 'learning_rate': 7.546000000000001e-06, 'epoch': 1.58}\n",
      "{'loss': 28.375, 'learning_rate': 7.545e-06, 'epoch': 1.58}\n",
      "{'loss': 29.125, 'learning_rate': 7.544e-06, 'epoch': 1.58}\n",
      "{'loss': 27.625, 'learning_rate': 7.5430000000000005e-06, 'epoch': 1.58}\n",
      "{'loss': 27.25, 'learning_rate': 7.542000000000001e-06, 'epoch': 1.58}\n",
      "{'loss': 27.375, 'learning_rate': 7.541e-06, 'epoch': 1.58}\n",
      "{'loss': 28.375, 'learning_rate': 7.540000000000001e-06, 'epoch': 1.58}\n",
      "{'loss': 27.375, 'learning_rate': 7.539000000000001e-06, 'epoch': 1.58}\n",
      "{'loss': 27.5, 'learning_rate': 7.5380000000000005e-06, 'epoch': 1.58}\n",
      "{'loss': 28.625, 'learning_rate': 7.537000000000001e-06, 'epoch': 1.58}\n",
      "{'loss': 27.375, 'learning_rate': 7.536000000000001e-06, 'epoch': 1.58}\n",
      "{'loss': 27.625, 'learning_rate': 7.535e-06, 'epoch': 1.58}\n",
      "{'loss': 27.25, 'learning_rate': 7.534e-06, 'epoch': 1.58}\n",
      "{'loss': 28.0, 'learning_rate': 7.5330000000000006e-06, 'epoch': 1.58}\n",
      "{'loss': 27.375, 'learning_rate': 7.532e-06, 'epoch': 1.58}\n",
      "{'loss': 28.125, 'learning_rate': 7.531e-06, 'epoch': 1.58}\n",
      "{'loss': 28.0, 'learning_rate': 7.530000000000001e-06, 'epoch': 1.59}\n",
      "{'loss': 28.125, 'learning_rate': 7.529000000000001e-06, 'epoch': 1.59}\n",
      "{'loss': 27.625, 'learning_rate': 7.528000000000001e-06, 'epoch': 1.59}\n",
      "{'loss': 29.25, 'learning_rate': 7.527000000000001e-06, 'epoch': 1.59}\n",
      "{'loss': 28.0, 'learning_rate': 7.526000000000001e-06, 'epoch': 1.59}\n",
      "{'loss': 28.875, 'learning_rate': 7.525e-06, 'epoch': 1.59}\n",
      "{'loss': 26.375, 'learning_rate': 7.524e-06, 'epoch': 1.59}\n",
      "{'loss': 27.625, 'learning_rate': 7.523000000000001e-06, 'epoch': 1.59}\n",
      "{'loss': 26.5, 'learning_rate': 7.522e-06, 'epoch': 1.59}\n",
      "{'loss': 26.375, 'learning_rate': 7.5210000000000005e-06, 'epoch': 1.59}\n",
      "{'loss': 28.25, 'learning_rate': 7.520000000000001e-06, 'epoch': 1.59}\n",
      "{'loss': 27.5, 'learning_rate': 7.519e-06, 'epoch': 1.59}\n",
      "{'loss': 27.375, 'learning_rate': 7.518000000000001e-06, 'epoch': 1.59}\n",
      "{'loss': 27.125, 'learning_rate': 7.517000000000001e-06, 'epoch': 1.59}\n",
      "{'loss': 27.375, 'learning_rate': 7.516000000000001e-06, 'epoch': 1.59}\n",
      "{'loss': 27.625, 'learning_rate': 7.515e-06, 'epoch': 1.59}\n",
      "{'loss': 28.375, 'learning_rate': 7.514e-06, 'epoch': 1.6}\n",
      "{'loss': 27.125, 'learning_rate': 7.513e-06, 'epoch': 1.6}\n",
      "{'loss': 27.625, 'learning_rate': 7.512e-06, 'epoch': 1.6}\n",
      "{'loss': 27.75, 'learning_rate': 7.511000000000001e-06, 'epoch': 1.6}\n",
      "{'loss': 27.25, 'learning_rate': 7.510000000000001e-06, 'epoch': 1.6}\n",
      "{'loss': 29.375, 'learning_rate': 7.5090000000000004e-06, 'epoch': 1.6}\n",
      "{'loss': 27.125, 'learning_rate': 7.508000000000001e-06, 'epoch': 1.6}\n",
      "{'loss': 26.875, 'learning_rate': 7.507000000000001e-06, 'epoch': 1.6}\n",
      "{'loss': 28.125, 'learning_rate': 7.506000000000001e-06, 'epoch': 1.6}\n",
      "{'loss': 27.5, 'learning_rate': 7.505e-06, 'epoch': 1.6}\n",
      "{'loss': 27.875, 'learning_rate': 7.5040000000000005e-06, 'epoch': 1.6}\n",
      "{'loss': 28.0, 'learning_rate': 7.503e-06, 'epoch': 1.6}\n",
      "{'loss': 28.25, 'learning_rate': 7.502e-06, 'epoch': 1.6}\n",
      "{'loss': 29.125, 'learning_rate': 7.501000000000001e-06, 'epoch': 1.6}\n",
      "{'loss': 28.0, 'learning_rate': 7.500000000000001e-06, 'epoch': 1.6}\n",
      "{'loss': 28.375, 'learning_rate': 7.4990000000000005e-06, 'epoch': 1.61}\n",
      "{'loss': 27.625, 'learning_rate': 7.498000000000001e-06, 'epoch': 1.61}\n",
      "{'loss': 29.125, 'learning_rate': 7.497000000000001e-06, 'epoch': 1.61}\n",
      "{'loss': 28.25, 'learning_rate': 7.496000000000001e-06, 'epoch': 1.61}\n",
      "{'loss': 26.625, 'learning_rate': 7.495000000000001e-06, 'epoch': 1.61}\n",
      "{'loss': 27.375, 'learning_rate': 7.494000000000001e-06, 'epoch': 1.61}\n",
      "{'loss': 28.625, 'learning_rate': 7.493e-06, 'epoch': 1.61}\n",
      "{'loss': 27.5, 'learning_rate': 7.4920000000000004e-06, 'epoch': 1.61}\n",
      "{'loss': 26.875, 'learning_rate': 7.491000000000001e-06, 'epoch': 1.61}\n",
      "{'loss': 28.25, 'learning_rate': 7.49e-06, 'epoch': 1.61}\n",
      "{'loss': 27.375, 'learning_rate': 7.489000000000001e-06, 'epoch': 1.61}\n",
      "{'loss': 27.75, 'learning_rate': 7.488000000000001e-06, 'epoch': 1.61}\n",
      "{'loss': 27.0, 'learning_rate': 7.487000000000001e-06, 'epoch': 1.61}\n",
      "{'loss': 27.625, 'learning_rate': 7.486000000000001e-06, 'epoch': 1.61}\n",
      "{'loss': 28.5, 'learning_rate': 7.485000000000001e-06, 'epoch': 1.61}\n",
      "{'loss': 27.75, 'learning_rate': 7.484e-06, 'epoch': 1.61}\n",
      "{'loss': 27.25, 'learning_rate': 7.483e-06, 'epoch': 1.62}\n",
      "{'loss': 28.125, 'learning_rate': 7.4820000000000005e-06, 'epoch': 1.62}\n",
      "{'loss': 26.875, 'learning_rate': 7.481000000000001e-06, 'epoch': 1.62}\n",
      "{'loss': 27.5, 'learning_rate': 7.48e-06, 'epoch': 1.62}\n",
      "{'loss': 29.25, 'learning_rate': 7.479000000000001e-06, 'epoch': 1.62}\n",
      "{'loss': 28.125, 'learning_rate': 7.478000000000001e-06, 'epoch': 1.62}\n",
      "{'loss': 26.625, 'learning_rate': 7.477000000000001e-06, 'epoch': 1.62}\n",
      "{'loss': 28.0, 'learning_rate': 7.476000000000001e-06, 'epoch': 1.62}\n",
      "{'loss': 28.25, 'learning_rate': 7.475000000000001e-06, 'epoch': 1.62}\n",
      "{'loss': 27.5, 'learning_rate': 7.474e-06, 'epoch': 1.62}\n",
      "{'loss': 29.125, 'learning_rate': 7.473e-06, 'epoch': 1.62}\n",
      "{'loss': 27.875, 'learning_rate': 7.472000000000001e-06, 'epoch': 1.62}\n",
      "{'loss': 26.625, 'learning_rate': 7.471e-06, 'epoch': 1.62}\n",
      "{'loss': 26.625, 'learning_rate': 7.4700000000000005e-06, 'epoch': 1.62}\n",
      "{'loss': 29.5, 'learning_rate': 7.469000000000001e-06, 'epoch': 1.62}\n",
      "{'loss': 29.0, 'learning_rate': 7.468000000000001e-06, 'epoch': 1.63}\n",
      "{'loss': 26.375, 'learning_rate': 7.467000000000001e-06, 'epoch': 1.63}\n",
      "{'loss': 27.125, 'learning_rate': 7.466000000000001e-06, 'epoch': 1.63}\n",
      "{'loss': 26.0, 'learning_rate': 7.465000000000001e-06, 'epoch': 1.63}\n",
      "{'loss': 27.75, 'learning_rate': 7.464e-06, 'epoch': 1.63}\n",
      "{'loss': 27.25, 'learning_rate': 7.463e-06, 'epoch': 1.63}\n",
      "{'loss': 28.75, 'learning_rate': 7.462000000000001e-06, 'epoch': 1.63}\n",
      "{'loss': 27.875, 'learning_rate': 7.461e-06, 'epoch': 1.63}\n",
      "{'loss': 26.75, 'learning_rate': 7.4600000000000006e-06, 'epoch': 1.63}\n",
      "{'loss': 27.375, 'learning_rate': 7.459000000000001e-06, 'epoch': 1.63}\n",
      "{'loss': 27.625, 'learning_rate': 7.458e-06, 'epoch': 1.63}\n",
      "{'loss': 27.875, 'learning_rate': 7.457000000000001e-06, 'epoch': 1.63}\n",
      "{'loss': 27.25, 'learning_rate': 7.456000000000001e-06, 'epoch': 1.63}\n",
      "{'loss': 27.75, 'learning_rate': 7.4550000000000015e-06, 'epoch': 1.63}\n",
      "{'loss': 27.5, 'learning_rate': 7.454e-06, 'epoch': 1.63}\n",
      "{'loss': 28.0, 'learning_rate': 7.4530000000000005e-06, 'epoch': 1.63}\n",
      "{'loss': 27.125, 'learning_rate': 7.452e-06, 'epoch': 1.64}\n",
      "{'loss': 27.5, 'learning_rate': 7.451e-06, 'epoch': 1.64}\n",
      "{'loss': 26.75, 'learning_rate': 7.450000000000001e-06, 'epoch': 1.64}\n",
      "{'loss': 26.875, 'learning_rate': 7.449000000000001e-06, 'epoch': 1.64}\n",
      "{'loss': 26.75, 'learning_rate': 7.4480000000000005e-06, 'epoch': 1.64}\n",
      "{'loss': 28.125, 'learning_rate': 7.447000000000001e-06, 'epoch': 1.64}\n",
      "{'loss': 28.25, 'learning_rate': 7.446000000000001e-06, 'epoch': 1.64}\n",
      "{'loss': 28.375, 'learning_rate': 7.445000000000001e-06, 'epoch': 1.64}\n",
      "{'loss': 27.875, 'learning_rate': 7.444e-06, 'epoch': 1.64}\n",
      "{'loss': 26.625, 'learning_rate': 7.4430000000000006e-06, 'epoch': 1.64}\n",
      "{'loss': 27.5, 'learning_rate': 7.442e-06, 'epoch': 1.64}\n",
      "{'loss': 26.625, 'learning_rate': 7.441e-06, 'epoch': 1.64}\n",
      "{'loss': 27.25, 'learning_rate': 7.440000000000001e-06, 'epoch': 1.64}\n",
      "{'loss': 27.875, 'learning_rate': 7.439e-06, 'epoch': 1.64}\n",
      "{'loss': 29.125, 'learning_rate': 7.438000000000001e-06, 'epoch': 1.64}\n",
      "{'loss': 26.5, 'learning_rate': 7.437000000000001e-06, 'epoch': 1.65}\n",
      "{'loss': 27.625, 'learning_rate': 7.436000000000001e-06, 'epoch': 1.65}\n",
      "{'loss': 28.25, 'learning_rate': 7.435000000000001e-06, 'epoch': 1.65}\n",
      "{'loss': 27.125, 'learning_rate': 7.434e-06, 'epoch': 1.65}\n",
      "{'loss': 27.0, 'learning_rate': 7.433e-06, 'epoch': 1.65}\n",
      "{'loss': 29.0, 'learning_rate': 7.432e-06, 'epoch': 1.65}\n",
      "{'loss': 27.25, 'learning_rate': 7.4310000000000005e-06, 'epoch': 1.65}\n",
      "{'loss': 28.75, 'learning_rate': 7.430000000000001e-06, 'epoch': 1.65}\n",
      "{'loss': 28.375, 'learning_rate': 7.429e-06, 'epoch': 1.65}\n",
      "{'loss': 28.375, 'learning_rate': 7.428000000000001e-06, 'epoch': 1.65}\n",
      "{'loss': 26.625, 'learning_rate': 7.427000000000001e-06, 'epoch': 1.65}\n",
      "{'loss': 27.625, 'learning_rate': 7.426000000000001e-06, 'epoch': 1.65}\n",
      "{'loss': 28.0, 'learning_rate': 7.425000000000001e-06, 'epoch': 1.65}\n",
      "{'loss': 28.0, 'learning_rate': 7.424e-06, 'epoch': 1.65}\n",
      "{'loss': 27.625, 'learning_rate': 7.423e-06, 'epoch': 1.65}\n",
      "{'loss': 28.25, 'learning_rate': 7.422e-06, 'epoch': 1.65}\n",
      "{'loss': 29.125, 'learning_rate': 7.421000000000001e-06, 'epoch': 1.66}\n",
      "{'loss': 28.375, 'learning_rate': 7.420000000000001e-06, 'epoch': 1.66}\n",
      "{'loss': 28.0, 'learning_rate': 7.4190000000000005e-06, 'epoch': 1.66}\n",
      "{'loss': 27.25, 'learning_rate': 7.418000000000001e-06, 'epoch': 1.66}\n",
      "{'loss': 28.125, 'learning_rate': 7.417000000000001e-06, 'epoch': 1.66}\n",
      "{'loss': 27.5, 'learning_rate': 7.416000000000001e-06, 'epoch': 1.66}\n",
      "{'loss': 28.375, 'learning_rate': 7.415000000000001e-06, 'epoch': 1.66}\n",
      "{'loss': 27.5, 'learning_rate': 7.4140000000000005e-06, 'epoch': 1.66}\n",
      "{'loss': 28.0, 'learning_rate': 7.413e-06, 'epoch': 1.66}\n",
      "{'loss': 26.875, 'learning_rate': 7.412e-06, 'epoch': 1.66}\n",
      "{'loss': 27.5, 'learning_rate': 7.411000000000001e-06, 'epoch': 1.66}\n",
      "{'loss': 27.75, 'learning_rate': 7.41e-06, 'epoch': 1.66}\n",
      "{'loss': 27.0, 'learning_rate': 7.4090000000000006e-06, 'epoch': 1.66}\n",
      "{'loss': 27.875, 'learning_rate': 7.408000000000001e-06, 'epoch': 1.66}\n",
      "{'loss': 28.625, 'learning_rate': 7.407000000000001e-06, 'epoch': 1.66}\n",
      "{'loss': 28.875, 'learning_rate': 7.406000000000001e-06, 'epoch': 1.66}\n",
      "{'loss': 27.125, 'learning_rate': 7.405000000000001e-06, 'epoch': 1.67}\n",
      "{'loss': 27.25, 'learning_rate': 7.404e-06, 'epoch': 1.67}\n",
      "{'loss': 27.5, 'learning_rate': 7.403e-06, 'epoch': 1.67}\n",
      "{'loss': 29.0, 'learning_rate': 7.4020000000000005e-06, 'epoch': 1.67}\n",
      "{'loss': 27.875, 'learning_rate': 7.401000000000001e-06, 'epoch': 1.67}\n",
      "{'loss': 29.0, 'learning_rate': 7.4e-06, 'epoch': 1.67}\n",
      "{'loss': 26.875, 'learning_rate': 7.399000000000001e-06, 'epoch': 1.67}\n",
      "{'loss': 26.25, 'learning_rate': 7.398000000000001e-06, 'epoch': 1.67}\n",
      "{'loss': 28.125, 'learning_rate': 7.3970000000000005e-06, 'epoch': 1.67}\n",
      "{'loss': 26.625, 'learning_rate': 7.396000000000001e-06, 'epoch': 1.67}\n",
      "{'loss': 28.375, 'learning_rate': 7.395000000000001e-06, 'epoch': 1.67}\n",
      "{'loss': 27.875, 'learning_rate': 7.394e-06, 'epoch': 1.67}\n",
      "{'loss': 26.5, 'learning_rate': 7.393e-06, 'epoch': 1.67}\n",
      "{'loss': 28.875, 'learning_rate': 7.3920000000000005e-06, 'epoch': 1.67}\n",
      "{'loss': 28.0, 'learning_rate': 7.391e-06, 'epoch': 1.67}\n",
      "{'loss': 27.0, 'learning_rate': 7.39e-06, 'epoch': 1.68}\n",
      "{'loss': 27.25, 'learning_rate': 7.389000000000001e-06, 'epoch': 1.68}\n",
      "{'loss': 26.75, 'learning_rate': 7.388000000000001e-06, 'epoch': 1.68}\n",
      "{'loss': 27.0, 'learning_rate': 7.387000000000001e-06, 'epoch': 1.68}\n",
      "{'loss': 27.25, 'learning_rate': 7.386000000000001e-06, 'epoch': 1.68}\n",
      "{'loss': 27.375, 'learning_rate': 7.385000000000001e-06, 'epoch': 1.68}\n",
      "{'loss': 28.5, 'learning_rate': 7.384e-06, 'epoch': 1.68}\n",
      "{'loss': 27.125, 'learning_rate': 7.383e-06, 'epoch': 1.68}\n",
      "{'loss': 28.0, 'learning_rate': 7.382000000000001e-06, 'epoch': 1.68}\n",
      "{'loss': 29.375, 'learning_rate': 7.381e-06, 'epoch': 1.68}\n",
      "{'loss': 28.0, 'learning_rate': 7.3800000000000005e-06, 'epoch': 1.68}\n",
      "{'loss': 27.375, 'learning_rate': 7.379000000000001e-06, 'epoch': 1.68}\n",
      "{'loss': 27.5, 'learning_rate': 7.378e-06, 'epoch': 1.68}\n",
      "{'loss': 26.125, 'learning_rate': 7.377000000000001e-06, 'epoch': 1.68}\n",
      "{'loss': 28.0, 'learning_rate': 7.376000000000001e-06, 'epoch': 1.68}\n",
      "{'loss': 27.0, 'learning_rate': 7.375000000000001e-06, 'epoch': 1.68}\n",
      "{'loss': 27.625, 'learning_rate': 7.374000000000001e-06, 'epoch': 1.69}\n",
      "{'loss': 27.375, 'learning_rate': 7.373e-06, 'epoch': 1.69}\n",
      "{'loss': 28.25, 'learning_rate': 7.372e-06, 'epoch': 1.69}\n",
      "{'loss': 28.0, 'learning_rate': 7.371e-06, 'epoch': 1.69}\n",
      "{'loss': 26.75, 'learning_rate': 7.370000000000001e-06, 'epoch': 1.69}\n",
      "{'loss': 29.125, 'learning_rate': 7.369000000000001e-06, 'epoch': 1.69}\n",
      "{'loss': 26.75, 'learning_rate': 7.3680000000000004e-06, 'epoch': 1.69}\n",
      "{'loss': 27.25, 'learning_rate': 7.367000000000001e-06, 'epoch': 1.69}\n",
      "{'loss': 28.0, 'learning_rate': 7.366000000000001e-06, 'epoch': 1.69}\n",
      "{'loss': 26.625, 'learning_rate': 7.365000000000001e-06, 'epoch': 1.69}\n",
      "{'loss': 27.25, 'learning_rate': 7.364000000000001e-06, 'epoch': 1.69}\n",
      "{'loss': 27.625, 'learning_rate': 7.3630000000000005e-06, 'epoch': 1.69}\n",
      "{'loss': 27.0, 'learning_rate': 7.362e-06, 'epoch': 1.69}\n",
      "{'loss': 28.25, 'learning_rate': 7.361e-06, 'epoch': 1.69}\n",
      "{'loss': 27.875, 'learning_rate': 7.360000000000001e-06, 'epoch': 1.69}\n",
      "{'loss': 27.125, 'learning_rate': 7.359e-06, 'epoch': 1.7}\n",
      "{'loss': 28.25, 'learning_rate': 7.3580000000000005e-06, 'epoch': 1.7}\n",
      "{'loss': 27.75, 'learning_rate': 7.357000000000001e-06, 'epoch': 1.7}\n",
      "{'loss': 28.625, 'learning_rate': 7.356000000000001e-06, 'epoch': 1.7}\n",
      "{'loss': 27.875, 'learning_rate': 7.355000000000001e-06, 'epoch': 1.7}\n",
      "{'loss': 26.375, 'learning_rate': 7.354000000000001e-06, 'epoch': 1.7}\n",
      "{'loss': 28.375, 'learning_rate': 7.353e-06, 'epoch': 1.7}\n",
      "{'loss': 27.5, 'learning_rate': 7.352e-06, 'epoch': 1.7}\n",
      "{'loss': 26.625, 'learning_rate': 7.3510000000000004e-06, 'epoch': 1.7}\n",
      "{'loss': 29.0, 'learning_rate': 7.350000000000001e-06, 'epoch': 1.7}\n",
      "{'loss': 28.0, 'learning_rate': 7.349e-06, 'epoch': 1.7}\n",
      "{'loss': 26.375, 'learning_rate': 7.348000000000001e-06, 'epoch': 1.7}\n",
      "{'loss': 27.75, 'learning_rate': 7.347000000000001e-06, 'epoch': 1.7}\n",
      "{'loss': 29.125, 'learning_rate': 7.346000000000001e-06, 'epoch': 1.7}\n",
      "{'loss': 27.125, 'learning_rate': 7.345000000000001e-06, 'epoch': 1.7}\n",
      "{'loss': 27.5, 'learning_rate': 7.344000000000001e-06, 'epoch': 1.7}\n",
      "{'loss': 27.375, 'learning_rate': 7.343e-06, 'epoch': 1.71}\n",
      "{'loss': 28.5, 'learning_rate': 7.342e-06, 'epoch': 1.71}\n",
      "{'loss': 28.0, 'learning_rate': 7.3410000000000005e-06, 'epoch': 1.71}\n",
      "{'loss': 27.125, 'learning_rate': 7.340000000000001e-06, 'epoch': 1.71}\n",
      "{'loss': 26.75, 'learning_rate': 7.339e-06, 'epoch': 1.71}\n",
      "{'loss': 29.75, 'learning_rate': 7.338000000000001e-06, 'epoch': 1.71}\n",
      "{'loss': 27.75, 'learning_rate': 7.337000000000001e-06, 'epoch': 1.71}\n",
      "{'loss': 26.875, 'learning_rate': 7.3360000000000006e-06, 'epoch': 1.71}\n",
      "{'loss': 27.25, 'learning_rate': 7.335000000000001e-06, 'epoch': 1.71}\n",
      "{'loss': 27.25, 'learning_rate': 7.334000000000001e-06, 'epoch': 1.71}\n",
      "{'loss': 28.0, 'learning_rate': 7.333e-06, 'epoch': 1.71}\n",
      "{'loss': 27.0, 'learning_rate': 7.332e-06, 'epoch': 1.71}\n",
      "{'loss': 27.125, 'learning_rate': 7.331000000000001e-06, 'epoch': 1.71}\n",
      "{'loss': 26.625, 'learning_rate': 7.33e-06, 'epoch': 1.71}\n",
      "{'loss': 27.0, 'learning_rate': 7.3290000000000005e-06, 'epoch': 1.71}\n",
      "{'loss': 27.25, 'learning_rate': 7.328000000000001e-06, 'epoch': 1.72}\n",
      "{'loss': 28.5, 'learning_rate': 7.327000000000001e-06, 'epoch': 1.72}\n",
      "{'loss': 27.375, 'learning_rate': 7.326000000000001e-06, 'epoch': 1.72}\n",
      "{'loss': 28.375, 'learning_rate': 7.325000000000001e-06, 'epoch': 1.72}\n",
      "{'loss': 26.75, 'learning_rate': 7.324000000000001e-06, 'epoch': 1.72}\n",
      "{'loss': 29.875, 'learning_rate': 7.323e-06, 'epoch': 1.72}\n",
      "{'loss': 29.875, 'learning_rate': 7.322e-06, 'epoch': 1.72}\n",
      "{'loss': 27.375, 'learning_rate': 7.321000000000001e-06, 'epoch': 1.72}\n",
      "{'loss': 29.0, 'learning_rate': 7.32e-06, 'epoch': 1.72}\n",
      "{'loss': 29.25, 'learning_rate': 7.3190000000000006e-06, 'epoch': 1.72}\n",
      "{'loss': 28.5, 'learning_rate': 7.318000000000001e-06, 'epoch': 1.72}\n",
      "{'loss': 28.0, 'learning_rate': 7.317e-06, 'epoch': 1.72}\n",
      "{'loss': 28.0, 'learning_rate': 7.316000000000001e-06, 'epoch': 1.72}\n",
      "{'loss': 27.625, 'learning_rate': 7.315000000000001e-06, 'epoch': 1.72}\n",
      "{'loss': 28.625, 'learning_rate': 7.3140000000000015e-06, 'epoch': 1.72}\n",
      "{'loss': 28.5, 'learning_rate': 7.313e-06, 'epoch': 1.72}\n",
      "{'loss': 29.875, 'learning_rate': 7.3120000000000005e-06, 'epoch': 1.73}\n",
      "{'loss': 28.5, 'learning_rate': 7.311e-06, 'epoch': 1.73}\n",
      "{'loss': 27.625, 'learning_rate': 7.31e-06, 'epoch': 1.73}\n",
      "{'loss': 26.875, 'learning_rate': 7.309000000000001e-06, 'epoch': 1.73}\n",
      "{'loss': 28.875, 'learning_rate': 7.308000000000001e-06, 'epoch': 1.73}\n",
      "{'loss': 28.75, 'learning_rate': 7.3070000000000005e-06, 'epoch': 1.73}\n",
      "{'loss': 27.0, 'learning_rate': 7.306000000000001e-06, 'epoch': 1.73}\n",
      "{'loss': 29.375, 'learning_rate': 7.305000000000001e-06, 'epoch': 1.73}\n",
      "{'loss': 27.0, 'learning_rate': 7.304000000000001e-06, 'epoch': 1.73}\n",
      "{'loss': 28.75, 'learning_rate': 7.303e-06, 'epoch': 1.73}\n",
      "{'loss': 27.75, 'learning_rate': 7.3020000000000006e-06, 'epoch': 1.73}\n",
      "{'loss': 28.875, 'learning_rate': 7.301e-06, 'epoch': 1.73}\n",
      "{'loss': 30.75, 'learning_rate': 7.3e-06, 'epoch': 1.73}\n",
      "{'loss': 27.125, 'learning_rate': 7.299000000000001e-06, 'epoch': 1.73}\n",
      "{'loss': 27.875, 'learning_rate': 7.298e-06, 'epoch': 1.73}\n",
      "{'loss': 28.25, 'learning_rate': 7.297000000000001e-06, 'epoch': 1.73}\n",
      "{'loss': 26.875, 'learning_rate': 7.296000000000001e-06, 'epoch': 1.74}\n",
      "{'loss': 27.375, 'learning_rate': 7.295000000000001e-06, 'epoch': 1.74}\n",
      "{'loss': 27.625, 'learning_rate': 7.294000000000001e-06, 'epoch': 1.74}\n",
      "{'loss': 26.875, 'learning_rate': 7.293e-06, 'epoch': 1.74}\n",
      "{'loss': 27.25, 'learning_rate': 7.292e-06, 'epoch': 1.74}\n",
      "{'loss': 27.875, 'learning_rate': 7.291e-06, 'epoch': 1.74}\n",
      "{'loss': 28.75, 'learning_rate': 7.2900000000000005e-06, 'epoch': 1.74}\n",
      "{'loss': 28.25, 'learning_rate': 7.289000000000001e-06, 'epoch': 1.74}\n",
      "{'loss': 27.375, 'learning_rate': 7.288e-06, 'epoch': 1.74}\n",
      "{'loss': 29.125, 'learning_rate': 7.287000000000001e-06, 'epoch': 1.74}\n",
      "{'loss': 27.0, 'learning_rate': 7.286000000000001e-06, 'epoch': 1.74}\n",
      "{'loss': 27.25, 'learning_rate': 7.2850000000000006e-06, 'epoch': 1.74}\n",
      "{'loss': 28.375, 'learning_rate': 7.284000000000001e-06, 'epoch': 1.74}\n",
      "{'loss': 29.25, 'learning_rate': 7.283e-06, 'epoch': 1.74}\n",
      "{'loss': 28.875, 'learning_rate': 7.282e-06, 'epoch': 1.74}\n",
      "{'loss': 28.0, 'learning_rate': 7.281e-06, 'epoch': 1.75}\n",
      "{'loss': 26.5, 'learning_rate': 7.280000000000001e-06, 'epoch': 1.75}\n",
      "{'loss': 27.875, 'learning_rate': 7.279e-06, 'epoch': 1.75}\n",
      "{'loss': 28.125, 'learning_rate': 7.2780000000000005e-06, 'epoch': 1.75}\n",
      "{'loss': 28.125, 'learning_rate': 7.277000000000001e-06, 'epoch': 1.75}\n",
      "{'loss': 27.75, 'learning_rate': 7.276000000000001e-06, 'epoch': 1.75}\n",
      "{'loss': 27.875, 'learning_rate': 7.275000000000001e-06, 'epoch': 1.75}\n",
      "{'loss': 28.375, 'learning_rate': 7.274000000000001e-06, 'epoch': 1.75}\n",
      "{'loss': 27.5, 'learning_rate': 7.273e-06, 'epoch': 1.75}\n",
      "{'loss': 27.25, 'learning_rate': 7.272e-06, 'epoch': 1.75}\n",
      "{'loss': 29.5, 'learning_rate': 7.271e-06, 'epoch': 1.75}\n",
      "{'loss': 26.625, 'learning_rate': 7.270000000000001e-06, 'epoch': 1.75}\n",
      "{'loss': 29.75, 'learning_rate': 7.269e-06, 'epoch': 1.75}\n",
      "{'loss': 28.75, 'learning_rate': 7.2680000000000005e-06, 'epoch': 1.75}\n",
      "{'loss': 29.625, 'learning_rate': 7.267000000000001e-06, 'epoch': 1.75}\n",
      "{'loss': 27.875, 'learning_rate': 7.266000000000001e-06, 'epoch': 1.75}\n",
      "{'loss': 26.875, 'learning_rate': 7.265000000000001e-06, 'epoch': 1.76}\n",
      "{'loss': 27.625, 'learning_rate': 7.264000000000001e-06, 'epoch': 1.76}\n",
      "{'loss': 26.625, 'learning_rate': 7.263e-06, 'epoch': 1.76}\n",
      "{'loss': 27.5, 'learning_rate': 7.262e-06, 'epoch': 1.76}\n",
      "{'loss': 26.75, 'learning_rate': 7.2610000000000004e-06, 'epoch': 1.76}\n",
      "{'loss': 27.0, 'learning_rate': 7.260000000000001e-06, 'epoch': 1.76}\n",
      "{'loss': 26.625, 'learning_rate': 7.259e-06, 'epoch': 1.76}\n",
      "{'loss': 27.0, 'learning_rate': 7.258000000000001e-06, 'epoch': 1.76}\n",
      "{'loss': 27.625, 'learning_rate': 7.257000000000001e-06, 'epoch': 1.76}\n",
      "{'loss': 27.5, 'learning_rate': 7.2560000000000005e-06, 'epoch': 1.76}\n",
      "{'loss': 27.375, 'learning_rate': 7.255000000000001e-06, 'epoch': 1.76}\n",
      "{'loss': 27.5, 'learning_rate': 7.254000000000001e-06, 'epoch': 1.76}\n",
      "{'loss': 27.375, 'learning_rate': 7.253e-06, 'epoch': 1.76}\n",
      "{'loss': 27.375, 'learning_rate': 7.252e-06, 'epoch': 1.76}\n",
      "{'loss': 27.5, 'learning_rate': 7.2510000000000005e-06, 'epoch': 1.76}\n",
      "{'loss': 27.5, 'learning_rate': 7.25e-06, 'epoch': 1.77}\n",
      "{'loss': 27.375, 'learning_rate': 7.249e-06, 'epoch': 1.77}\n",
      "{'loss': 28.125, 'learning_rate': 7.248000000000001e-06, 'epoch': 1.77}\n",
      "{'loss': 27.25, 'learning_rate': 7.247000000000001e-06, 'epoch': 1.77}\n",
      "{'loss': 27.5, 'learning_rate': 7.246000000000001e-06, 'epoch': 1.77}\n",
      "{'loss': 28.75, 'learning_rate': 7.245000000000001e-06, 'epoch': 1.77}\n",
      "{'loss': 28.0, 'learning_rate': 7.244000000000001e-06, 'epoch': 1.77}\n",
      "{'loss': 26.5, 'learning_rate': 7.243000000000001e-06, 'epoch': 1.77}\n",
      "{'loss': 29.0, 'learning_rate': 7.242e-06, 'epoch': 1.77}\n",
      "{'loss': 26.5, 'learning_rate': 7.241000000000001e-06, 'epoch': 1.77}\n",
      "{'loss': 27.5, 'learning_rate': 7.24e-06, 'epoch': 1.77}\n",
      "{'loss': 26.875, 'learning_rate': 7.2390000000000005e-06, 'epoch': 1.77}\n",
      "{'loss': 27.625, 'learning_rate': 7.238000000000001e-06, 'epoch': 1.77}\n",
      "{'loss': 26.75, 'learning_rate': 7.237e-06, 'epoch': 1.77}\n",
      "{'loss': 27.0, 'learning_rate': 7.236000000000001e-06, 'epoch': 1.77}\n",
      "{'loss': 28.5, 'learning_rate': 7.235000000000001e-06, 'epoch': 1.77}\n",
      "{'loss': 26.75, 'learning_rate': 7.234000000000001e-06, 'epoch': 1.78}\n",
      "{'loss': 27.625, 'learning_rate': 7.233000000000001e-06, 'epoch': 1.78}\n",
      "{'loss': 26.625, 'learning_rate': 7.232e-06, 'epoch': 1.78}\n",
      "{'loss': 27.375, 'learning_rate': 7.231e-06, 'epoch': 1.78}\n",
      "{'loss': 27.75, 'learning_rate': 7.23e-06, 'epoch': 1.78}\n",
      "{'loss': 27.375, 'learning_rate': 7.229000000000001e-06, 'epoch': 1.78}\n",
      "{'loss': 27.75, 'learning_rate': 7.228000000000001e-06, 'epoch': 1.78}\n",
      "{'loss': 26.75, 'learning_rate': 7.2270000000000004e-06, 'epoch': 1.78}\n",
      "{'loss': 27.375, 'learning_rate': 7.226000000000001e-06, 'epoch': 1.78}\n",
      "{'loss': 27.5, 'learning_rate': 7.225000000000001e-06, 'epoch': 1.78}\n",
      "{'loss': 28.25, 'learning_rate': 7.224000000000001e-06, 'epoch': 1.78}\n",
      "{'loss': 26.875, 'learning_rate': 7.223000000000001e-06, 'epoch': 1.78}\n",
      "{'loss': 27.375, 'learning_rate': 7.2220000000000005e-06, 'epoch': 1.78}\n",
      "{'loss': 28.125, 'learning_rate': 7.221e-06, 'epoch': 1.78}\n",
      "{'loss': 27.625, 'learning_rate': 7.22e-06, 'epoch': 1.78}\n",
      "{'loss': 27.75, 'learning_rate': 7.219000000000001e-06, 'epoch': 1.78}\n",
      "{'loss': 27.875, 'learning_rate': 7.218e-06, 'epoch': 1.79}\n",
      "{'loss': 28.375, 'learning_rate': 7.2170000000000005e-06, 'epoch': 1.79}\n",
      "{'loss': 29.125, 'learning_rate': 7.216000000000001e-06, 'epoch': 1.79}\n",
      "{'loss': 26.625, 'learning_rate': 7.215000000000001e-06, 'epoch': 1.79}\n",
      "{'loss': 26.875, 'learning_rate': 7.214000000000001e-06, 'epoch': 1.79}\n",
      "{'loss': 29.125, 'learning_rate': 7.213000000000001e-06, 'epoch': 1.79}\n",
      "{'loss': 29.125, 'learning_rate': 7.212e-06, 'epoch': 1.79}\n",
      "{'loss': 27.25, 'learning_rate': 7.211e-06, 'epoch': 1.79}\n",
      "{'loss': 27.0, 'learning_rate': 7.2100000000000004e-06, 'epoch': 1.79}\n",
      "{'loss': 28.375, 'learning_rate': 7.209000000000001e-06, 'epoch': 1.79}\n",
      "{'loss': 27.625, 'learning_rate': 7.208e-06, 'epoch': 1.79}\n",
      "{'loss': 29.375, 'learning_rate': 7.207000000000001e-06, 'epoch': 1.79}\n",
      "{'loss': 26.625, 'learning_rate': 7.206000000000001e-06, 'epoch': 1.79}\n",
      "{'loss': 29.625, 'learning_rate': 7.2050000000000005e-06, 'epoch': 1.79}\n",
      "{'loss': 27.375, 'learning_rate': 7.204000000000001e-06, 'epoch': 1.79}\n",
      "{'loss': 28.625, 'learning_rate': 7.203000000000001e-06, 'epoch': 1.8}\n",
      "{'loss': 28.0, 'learning_rate': 7.202e-06, 'epoch': 1.8}\n",
      "{'loss': 27.5, 'learning_rate': 7.201e-06, 'epoch': 1.8}\n",
      "{'loss': 26.5, 'learning_rate': 7.2000000000000005e-06, 'epoch': 1.8}\n",
      "{'loss': 29.125, 'learning_rate': 7.199e-06, 'epoch': 1.8}\n",
      "{'loss': 27.25, 'learning_rate': 7.198e-06, 'epoch': 1.8}\n",
      "{'loss': 27.25, 'learning_rate': 7.197000000000001e-06, 'epoch': 1.8}\n",
      "{'loss': 27.25, 'learning_rate': 7.196000000000001e-06, 'epoch': 1.8}\n",
      "{'loss': 26.75, 'learning_rate': 7.1950000000000006e-06, 'epoch': 1.8}\n",
      "{'loss': 29.125, 'learning_rate': 7.194000000000001e-06, 'epoch': 1.8}\n",
      "{'loss': 27.875, 'learning_rate': 7.193000000000001e-06, 'epoch': 1.8}\n",
      "{'loss': 27.0, 'learning_rate': 7.192e-06, 'epoch': 1.8}\n",
      "{'loss': 27.25, 'learning_rate': 7.191e-06, 'epoch': 1.8}\n",
      "{'loss': 27.75, 'learning_rate': 7.190000000000001e-06, 'epoch': 1.8}\n",
      "{'loss': 27.625, 'learning_rate': 7.189e-06, 'epoch': 1.8}\n",
      "{'loss': 28.375, 'learning_rate': 7.1880000000000005e-06, 'epoch': 1.8}\n",
      "{'loss': 26.75, 'learning_rate': 7.187000000000001e-06, 'epoch': 1.81}\n",
      "{'loss': 27.125, 'learning_rate': 7.186000000000001e-06, 'epoch': 1.81}\n",
      "{'loss': 30.625, 'learning_rate': 7.185000000000001e-06, 'epoch': 1.81}\n",
      "{'loss': 29.625, 'learning_rate': 7.184000000000001e-06, 'epoch': 1.81}\n",
      "{'loss': 26.75, 'learning_rate': 7.183000000000001e-06, 'epoch': 1.81}\n",
      "{'loss': 28.0, 'learning_rate': 7.182e-06, 'epoch': 1.81}\n",
      "{'loss': 27.25, 'learning_rate': 7.181e-06, 'epoch': 1.81}\n",
      "{'loss': 26.875, 'learning_rate': 7.180000000000001e-06, 'epoch': 1.81}\n",
      "{'loss': 28.125, 'learning_rate': 7.179e-06, 'epoch': 1.81}\n",
      "{'loss': 27.875, 'learning_rate': 7.1780000000000006e-06, 'epoch': 1.81}\n",
      "{'loss': 27.0, 'learning_rate': 7.177000000000001e-06, 'epoch': 1.81}\n",
      "{'loss': 28.875, 'learning_rate': 7.176e-06, 'epoch': 1.81}\n",
      "{'loss': 27.5, 'learning_rate': 7.175000000000001e-06, 'epoch': 1.81}\n",
      "{'loss': 26.125, 'learning_rate': 7.174000000000001e-06, 'epoch': 1.81}\n",
      "{'loss': 26.75, 'learning_rate': 7.1730000000000015e-06, 'epoch': 1.81}\n",
      "{'loss': 27.625, 'learning_rate': 7.172e-06, 'epoch': 1.82}\n",
      "{'loss': 26.75, 'learning_rate': 7.1710000000000005e-06, 'epoch': 1.82}\n",
      "{'loss': 27.125, 'learning_rate': 7.17e-06, 'epoch': 1.82}\n",
      "{'loss': 27.75, 'learning_rate': 7.169e-06, 'epoch': 1.82}\n",
      "{'loss': 28.0, 'learning_rate': 7.168000000000001e-06, 'epoch': 1.82}\n",
      "{'loss': 27.5, 'learning_rate': 7.167000000000001e-06, 'epoch': 1.82}\n",
      "{'loss': 27.625, 'learning_rate': 7.1660000000000005e-06, 'epoch': 1.82}\n",
      "{'loss': 27.375, 'learning_rate': 7.165000000000001e-06, 'epoch': 1.82}\n",
      "{'loss': 27.375, 'learning_rate': 7.164000000000001e-06, 'epoch': 1.82}\n",
      "{'loss': 28.625, 'learning_rate': 7.163000000000001e-06, 'epoch': 1.82}\n",
      "{'loss': 26.5, 'learning_rate': 7.162e-06, 'epoch': 1.82}\n",
      "{'loss': 27.375, 'learning_rate': 7.1610000000000006e-06, 'epoch': 1.82}\n",
      "{'loss': 27.75, 'learning_rate': 7.16e-06, 'epoch': 1.82}\n",
      "{'loss': 27.5, 'learning_rate': 7.159e-06, 'epoch': 1.82}\n",
      "{'loss': 28.0, 'learning_rate': 7.158000000000001e-06, 'epoch': 1.82}\n",
      "{'loss': 28.75, 'learning_rate': 7.157e-06, 'epoch': 1.82}\n",
      "{'loss': 27.25, 'learning_rate': 7.156000000000001e-06, 'epoch': 1.83}\n",
      "{'loss': 29.0, 'learning_rate': 7.155000000000001e-06, 'epoch': 1.83}\n",
      "{'loss': 27.25, 'learning_rate': 7.154000000000001e-06, 'epoch': 1.83}\n",
      "{'loss': 29.0, 'learning_rate': 7.153000000000001e-06, 'epoch': 1.83}\n",
      "{'loss': 27.375, 'learning_rate': 7.152e-06, 'epoch': 1.83}\n",
      "{'loss': 27.125, 'learning_rate': 7.151e-06, 'epoch': 1.83}\n",
      "{'loss': 28.875, 'learning_rate': 7.15e-06, 'epoch': 1.83}\n",
      "{'loss': 28.75, 'learning_rate': 7.1490000000000005e-06, 'epoch': 1.83}\n",
      "{'loss': 27.125, 'learning_rate': 7.148000000000001e-06, 'epoch': 1.83}\n",
      "{'loss': 28.25, 'learning_rate': 7.147e-06, 'epoch': 1.83}\n",
      "{'loss': 27.75, 'learning_rate': 7.146000000000001e-06, 'epoch': 1.83}\n",
      "{'loss': 27.25, 'learning_rate': 7.145000000000001e-06, 'epoch': 1.83}\n",
      "{'loss': 29.5, 'learning_rate': 7.1440000000000005e-06, 'epoch': 1.83}\n",
      "{'loss': 30.125, 'learning_rate': 7.143000000000001e-06, 'epoch': 1.83}\n",
      "{'loss': 28.125, 'learning_rate': 7.142e-06, 'epoch': 1.83}\n",
      "{'loss': 28.125, 'learning_rate': 7.141e-06, 'epoch': 1.84}\n",
      "{'loss': 27.125, 'learning_rate': 7.14e-06, 'epoch': 1.84}\n",
      "{'loss': 27.875, 'learning_rate': 7.139000000000001e-06, 'epoch': 1.84}\n",
      "{'loss': 28.0, 'learning_rate': 7.138e-06, 'epoch': 1.84}\n",
      "{'loss': 28.5, 'learning_rate': 7.1370000000000004e-06, 'epoch': 1.84}\n",
      "{'loss': 26.5, 'learning_rate': 7.136000000000001e-06, 'epoch': 1.84}\n",
      "{'loss': 28.625, 'learning_rate': 7.135000000000001e-06, 'epoch': 1.84}\n",
      "{'loss': 27.5, 'learning_rate': 7.134000000000001e-06, 'epoch': 1.84}\n",
      "{'loss': 27.75, 'learning_rate': 7.133000000000001e-06, 'epoch': 1.84}\n",
      "{'loss': 27.0, 'learning_rate': 7.132e-06, 'epoch': 1.84}\n",
      "{'loss': 27.625, 'learning_rate': 7.131e-06, 'epoch': 1.84}\n",
      "{'loss': 29.5, 'learning_rate': 7.13e-06, 'epoch': 1.84}\n",
      "{'loss': 26.75, 'learning_rate': 7.129000000000001e-06, 'epoch': 1.84}\n",
      "{'loss': 28.875, 'learning_rate': 7.128e-06, 'epoch': 1.84}\n",
      "{'loss': 27.25, 'learning_rate': 7.1270000000000005e-06, 'epoch': 1.84}\n",
      "{'loss': 27.375, 'learning_rate': 7.126000000000001e-06, 'epoch': 1.84}\n",
      "{'loss': 27.375, 'learning_rate': 7.125e-06, 'epoch': 1.85}\n",
      "{'loss': 26.75, 'learning_rate': 7.124000000000001e-06, 'epoch': 1.85}\n",
      "{'loss': 28.5, 'learning_rate': 7.123000000000001e-06, 'epoch': 1.85}\n",
      "{'loss': 27.75, 'learning_rate': 7.1220000000000014e-06, 'epoch': 1.85}\n",
      "{'loss': 26.875, 'learning_rate': 7.121e-06, 'epoch': 1.85}\n",
      "{'loss': 27.625, 'learning_rate': 7.1200000000000004e-06, 'epoch': 1.85}\n",
      "{'loss': 30.375, 'learning_rate': 7.119e-06, 'epoch': 1.85}\n",
      "{'loss': 27.75, 'learning_rate': 7.118e-06, 'epoch': 1.85}\n",
      "{'loss': 28.75, 'learning_rate': 7.117000000000001e-06, 'epoch': 1.85}\n",
      "{'loss': 26.625, 'learning_rate': 7.116000000000001e-06, 'epoch': 1.85}\n",
      "{'loss': 28.0, 'learning_rate': 7.1150000000000005e-06, 'epoch': 1.85}\n",
      "{'loss': 27.375, 'learning_rate': 7.114000000000001e-06, 'epoch': 1.85}\n",
      "{'loss': 27.625, 'learning_rate': 7.113000000000001e-06, 'epoch': 1.85}\n",
      "{'loss': 26.75, 'learning_rate': 7.1120000000000015e-06, 'epoch': 1.85}\n",
      "{'loss': 27.5, 'learning_rate': 7.111e-06, 'epoch': 1.85}\n",
      "{'loss': 27.375, 'learning_rate': 7.1100000000000005e-06, 'epoch': 1.85}\n",
      "{'loss': 28.375, 'learning_rate': 7.109e-06, 'epoch': 1.86}\n",
      "{'loss': 27.875, 'learning_rate': 7.108e-06, 'epoch': 1.86}\n",
      "{'loss': 28.75, 'learning_rate': 7.107000000000001e-06, 'epoch': 1.86}\n",
      "{'loss': 27.375, 'learning_rate': 7.106000000000001e-06, 'epoch': 1.86}\n",
      "{'loss': 26.625, 'learning_rate': 7.105000000000001e-06, 'epoch': 1.86}\n",
      "{'loss': 26.625, 'learning_rate': 7.104000000000001e-06, 'epoch': 1.86}\n",
      "{'loss': 28.125, 'learning_rate': 7.103000000000001e-06, 'epoch': 1.86}\n",
      "{'loss': 27.25, 'learning_rate': 7.102000000000001e-06, 'epoch': 1.86}\n",
      "{'loss': 27.125, 'learning_rate': 7.101e-06, 'epoch': 1.86}\n",
      "{'loss': 27.0, 'learning_rate': 7.100000000000001e-06, 'epoch': 1.86}\n",
      "{'loss': 28.75, 'learning_rate': 7.099e-06, 'epoch': 1.86}\n",
      "{'loss': 27.5, 'learning_rate': 7.0980000000000005e-06, 'epoch': 1.86}\n",
      "{'loss': 26.875, 'learning_rate': 7.097000000000001e-06, 'epoch': 1.86}\n",
      "{'loss': 27.125, 'learning_rate': 7.096e-06, 'epoch': 1.86}\n",
      "{'loss': 28.375, 'learning_rate': 7.095000000000001e-06, 'epoch': 1.86}\n",
      "{'loss': 27.375, 'learning_rate': 7.094000000000001e-06, 'epoch': 1.87}\n",
      "{'loss': 28.125, 'learning_rate': 7.093000000000001e-06, 'epoch': 1.87}\n",
      "{'loss': 27.125, 'learning_rate': 7.092000000000001e-06, 'epoch': 1.87}\n",
      "{'loss': 26.375, 'learning_rate': 7.091e-06, 'epoch': 1.87}\n",
      "{'loss': 27.0, 'learning_rate': 7.09e-06, 'epoch': 1.87}\n",
      "{'loss': 26.75, 'learning_rate': 7.089e-06, 'epoch': 1.87}\n",
      "{'loss': 26.375, 'learning_rate': 7.088000000000001e-06, 'epoch': 1.87}\n",
      "{'loss': 27.125, 'learning_rate': 7.087000000000001e-06, 'epoch': 1.87}\n",
      "{'loss': 27.875, 'learning_rate': 7.0860000000000004e-06, 'epoch': 1.87}\n",
      "{'loss': 28.625, 'learning_rate': 7.085000000000001e-06, 'epoch': 1.87}\n",
      "{'loss': 27.25, 'learning_rate': 7.084000000000001e-06, 'epoch': 1.87}\n",
      "{'loss': 28.0, 'learning_rate': 7.083000000000001e-06, 'epoch': 1.87}\n",
      "{'loss': 27.25, 'learning_rate': 7.082000000000001e-06, 'epoch': 1.87}\n",
      "{'loss': 29.125, 'learning_rate': 7.0810000000000005e-06, 'epoch': 1.87}\n",
      "{'loss': 28.625, 'learning_rate': 7.08e-06, 'epoch': 1.87}\n",
      "{'loss': 28.5, 'learning_rate': 7.079e-06, 'epoch': 1.87}\n",
      "{'loss': 27.5, 'learning_rate': 7.078000000000001e-06, 'epoch': 1.88}\n",
      "{'loss': 28.0, 'learning_rate': 7.077e-06, 'epoch': 1.88}\n",
      "{'loss': 26.75, 'learning_rate': 7.0760000000000005e-06, 'epoch': 1.88}\n",
      "{'loss': 28.125, 'learning_rate': 7.075000000000001e-06, 'epoch': 1.88}\n",
      "{'loss': 27.625, 'learning_rate': 7.074000000000001e-06, 'epoch': 1.88}\n",
      "{'loss': 28.0, 'learning_rate': 7.073000000000001e-06, 'epoch': 1.88}\n",
      "{'loss': 27.75, 'learning_rate': 7.072000000000001e-06, 'epoch': 1.88}\n",
      "{'loss': 27.5, 'learning_rate': 7.071e-06, 'epoch': 1.88}\n",
      "{'loss': 28.125, 'learning_rate': 7.07e-06, 'epoch': 1.88}\n",
      "{'loss': 26.75, 'learning_rate': 7.069e-06, 'epoch': 1.88}\n",
      "{'loss': 27.5, 'learning_rate': 7.068000000000001e-06, 'epoch': 1.88}\n",
      "{'loss': 28.625, 'learning_rate': 7.067e-06, 'epoch': 1.88}\n",
      "{'loss': 27.0, 'learning_rate': 7.066000000000001e-06, 'epoch': 1.88}\n",
      "{'loss': 27.5, 'learning_rate': 7.065000000000001e-06, 'epoch': 1.88}\n",
      "{'loss': 28.75, 'learning_rate': 7.0640000000000005e-06, 'epoch': 1.88}\n",
      "{'loss': 26.875, 'learning_rate': 7.063000000000001e-06, 'epoch': 1.89}\n",
      "{'loss': 27.75, 'learning_rate': 7.062000000000001e-06, 'epoch': 1.89}\n",
      "{'loss': 26.125, 'learning_rate': 7.061e-06, 'epoch': 1.89}\n",
      "{'loss': 28.625, 'learning_rate': 7.06e-06, 'epoch': 1.89}\n",
      "{'loss': 28.125, 'learning_rate': 7.0590000000000005e-06, 'epoch': 1.89}\n",
      "{'loss': 27.375, 'learning_rate': 7.058e-06, 'epoch': 1.89}\n",
      "{'loss': 29.0, 'learning_rate': 7.057e-06, 'epoch': 1.89}\n",
      "{'loss': 27.75, 'learning_rate': 7.056000000000001e-06, 'epoch': 1.89}\n",
      "{'loss': 26.625, 'learning_rate': 7.055000000000001e-06, 'epoch': 1.89}\n",
      "{'loss': 27.75, 'learning_rate': 7.0540000000000006e-06, 'epoch': 1.89}\n",
      "{'loss': 28.75, 'learning_rate': 7.053000000000001e-06, 'epoch': 1.89}\n",
      "{'loss': 27.625, 'learning_rate': 7.052000000000001e-06, 'epoch': 1.89}\n",
      "{'loss': 26.875, 'learning_rate': 7.051e-06, 'epoch': 1.89}\n",
      "{'loss': 27.75, 'learning_rate': 7.05e-06, 'epoch': 1.89}\n",
      "{'loss': 27.625, 'learning_rate': 7.049000000000001e-06, 'epoch': 1.89}\n",
      "{'loss': 28.625, 'learning_rate': 7.048e-06, 'epoch': 1.89}\n",
      "{'loss': 29.625, 'learning_rate': 7.0470000000000005e-06, 'epoch': 1.9}\n",
      "{'loss': 28.625, 'learning_rate': 7.046000000000001e-06, 'epoch': 1.9}\n",
      "{'loss': 27.5, 'learning_rate': 7.045e-06, 'epoch': 1.9}\n",
      "{'loss': 27.375, 'learning_rate': 7.044000000000001e-06, 'epoch': 1.9}\n",
      "{'loss': 27.25, 'learning_rate': 7.043000000000001e-06, 'epoch': 1.9}\n",
      "{'loss': 27.0, 'learning_rate': 7.042000000000001e-06, 'epoch': 1.9}\n",
      "{'loss': 27.875, 'learning_rate': 7.041e-06, 'epoch': 1.9}\n",
      "{'loss': 26.625, 'learning_rate': 7.04e-06, 'epoch': 1.9}\n",
      "{'loss': 27.375, 'learning_rate': 7.039e-06, 'epoch': 1.9}\n",
      "{'loss': 28.625, 'learning_rate': 7.038e-06, 'epoch': 1.9}\n",
      "{'loss': 26.0, 'learning_rate': 7.0370000000000006e-06, 'epoch': 1.9}\n",
      "{'loss': 27.0, 'learning_rate': 7.036000000000001e-06, 'epoch': 1.9}\n",
      "{'loss': 29.125, 'learning_rate': 7.035e-06, 'epoch': 1.9}\n",
      "{'loss': 26.375, 'learning_rate': 7.034000000000001e-06, 'epoch': 1.9}\n",
      "{'loss': 29.875, 'learning_rate': 7.033000000000001e-06, 'epoch': 1.9}\n",
      "{'loss': 27.125, 'learning_rate': 7.0320000000000015e-06, 'epoch': 1.91}\n",
      "{'loss': 28.125, 'learning_rate': 7.031e-06, 'epoch': 1.91}\n",
      "{'loss': 28.0, 'learning_rate': 7.0300000000000005e-06, 'epoch': 1.91}\n",
      "{'loss': 29.25, 'learning_rate': 7.029e-06, 'epoch': 1.91}\n",
      "{'loss': 26.875, 'learning_rate': 7.028e-06, 'epoch': 1.91}\n",
      "{'loss': 28.75, 'learning_rate': 7.027000000000001e-06, 'epoch': 1.91}\n",
      "{'loss': 26.75, 'learning_rate': 7.026000000000001e-06, 'epoch': 1.91}\n",
      "{'loss': 27.5, 'learning_rate': 7.0250000000000005e-06, 'epoch': 1.91}\n",
      "{'loss': 27.125, 'learning_rate': 7.024000000000001e-06, 'epoch': 1.91}\n",
      "{'loss': 27.125, 'learning_rate': 7.023000000000001e-06, 'epoch': 1.91}\n",
      "{'loss': 28.0, 'learning_rate': 7.022000000000001e-06, 'epoch': 1.91}\n",
      "{'loss': 27.75, 'learning_rate': 7.021e-06, 'epoch': 1.91}\n",
      "{'loss': 28.125, 'learning_rate': 7.0200000000000006e-06, 'epoch': 1.91}\n",
      "{'loss': 28.0, 'learning_rate': 7.019e-06, 'epoch': 1.91}\n",
      "{'loss': 27.0, 'learning_rate': 7.018e-06, 'epoch': 1.91}\n",
      "{'loss': 26.75, 'learning_rate': 7.017000000000001e-06, 'epoch': 1.91}\n",
      "{'loss': 27.625, 'learning_rate': 7.016e-06, 'epoch': 1.92}\n",
      "{'loss': 27.75, 'learning_rate': 7.015000000000001e-06, 'epoch': 1.92}\n",
      "{'loss': 29.5, 'learning_rate': 7.014000000000001e-06, 'epoch': 1.92}\n",
      "{'loss': 28.375, 'learning_rate': 7.013000000000001e-06, 'epoch': 1.92}\n",
      "{'loss': 27.25, 'learning_rate': 7.012000000000001e-06, 'epoch': 1.92}\n",
      "{'loss': 26.5, 'learning_rate': 7.011e-06, 'epoch': 1.92}\n",
      "{'loss': 28.625, 'learning_rate': 7.01e-06, 'epoch': 1.92}\n",
      "{'loss': 27.75, 'learning_rate': 7.009e-06, 'epoch': 1.92}\n",
      "{'loss': 31.25, 'learning_rate': 7.0080000000000005e-06, 'epoch': 1.92}\n",
      "{'loss': 28.375, 'learning_rate': 7.007000000000001e-06, 'epoch': 1.92}\n",
      "{'loss': 27.375, 'learning_rate': 7.006e-06, 'epoch': 1.92}\n",
      "{'loss': 27.0, 'learning_rate': 7.005000000000001e-06, 'epoch': 1.92}\n",
      "{'loss': 28.0, 'learning_rate': 7.004000000000001e-06, 'epoch': 1.92}\n",
      "{'loss': 27.5, 'learning_rate': 7.0030000000000005e-06, 'epoch': 1.92}\n",
      "{'loss': 26.875, 'learning_rate': 7.002000000000001e-06, 'epoch': 1.92}\n",
      "{'loss': 27.125, 'learning_rate': 7.001e-06, 'epoch': 1.92}\n",
      "{'loss': 26.0, 'learning_rate': 7e-06, 'epoch': 1.93}\n",
      "{'loss': 26.625, 'learning_rate': 6.999e-06, 'epoch': 1.93}\n",
      "{'loss': 27.5, 'learning_rate': 6.998000000000001e-06, 'epoch': 1.93}\n",
      "{'loss': 28.0, 'learning_rate': 6.997e-06, 'epoch': 1.93}\n",
      "{'loss': 27.25, 'learning_rate': 6.9960000000000004e-06, 'epoch': 1.93}\n",
      "{'loss': 28.75, 'learning_rate': 6.995000000000001e-06, 'epoch': 1.93}\n",
      "{'loss': 27.125, 'learning_rate': 6.994000000000001e-06, 'epoch': 1.93}\n",
      "{'loss': 27.5, 'learning_rate': 6.993000000000001e-06, 'epoch': 1.93}\n",
      "{'loss': 27.625, 'learning_rate': 6.992000000000001e-06, 'epoch': 1.93}\n",
      "{'loss': 27.5, 'learning_rate': 6.991000000000001e-06, 'epoch': 1.93}\n",
      "{'loss': 28.125, 'learning_rate': 6.99e-06, 'epoch': 1.93}\n",
      "{'loss': 27.0, 'learning_rate': 6.989e-06, 'epoch': 1.93}\n",
      "{'loss': 29.25, 'learning_rate': 6.988000000000001e-06, 'epoch': 1.93}\n",
      "{'loss': 26.75, 'learning_rate': 6.987e-06, 'epoch': 1.93}\n",
      "{'loss': 27.375, 'learning_rate': 6.9860000000000005e-06, 'epoch': 1.93}\n",
      "{'loss': 27.875, 'learning_rate': 6.985000000000001e-06, 'epoch': 1.94}\n",
      "{'loss': 27.125, 'learning_rate': 6.984e-06, 'epoch': 1.94}\n",
      "{'loss': 26.75, 'learning_rate': 6.983000000000001e-06, 'epoch': 1.94}\n",
      "{'loss': 29.375, 'learning_rate': 6.982000000000001e-06, 'epoch': 1.94}\n",
      "{'loss': 26.625, 'learning_rate': 6.9810000000000014e-06, 'epoch': 1.94}\n",
      "{'loss': 27.375, 'learning_rate': 6.98e-06, 'epoch': 1.94}\n",
      "{'loss': 26.75, 'learning_rate': 6.9790000000000004e-06, 'epoch': 1.94}\n",
      "{'loss': 30.75, 'learning_rate': 6.978e-06, 'epoch': 1.94}\n",
      "{'loss': 26.875, 'learning_rate': 6.977e-06, 'epoch': 1.94}\n",
      "{'loss': 28.75, 'learning_rate': 6.976000000000001e-06, 'epoch': 1.94}\n",
      "{'loss': 27.375, 'learning_rate': 6.975000000000001e-06, 'epoch': 1.94}\n",
      "{'loss': 27.375, 'learning_rate': 6.9740000000000005e-06, 'epoch': 1.94}\n",
      "{'loss': 26.625, 'learning_rate': 6.973000000000001e-06, 'epoch': 1.94}\n",
      "{'loss': 26.75, 'learning_rate': 6.972000000000001e-06, 'epoch': 1.94}\n",
      "{'loss': 27.625, 'learning_rate': 6.971000000000001e-06, 'epoch': 1.94}\n",
      "{'loss': 27.875, 'learning_rate': 6.97e-06, 'epoch': 1.94}\n",
      "{'loss': 28.375, 'learning_rate': 6.9690000000000005e-06, 'epoch': 1.95}\n",
      "{'loss': 28.75, 'learning_rate': 6.968e-06, 'epoch': 1.95}\n",
      "{'loss': 28.75, 'learning_rate': 6.967e-06, 'epoch': 1.95}\n",
      "{'loss': 28.125, 'learning_rate': 6.966000000000001e-06, 'epoch': 1.95}\n",
      "{'loss': 26.625, 'learning_rate': 6.965e-06, 'epoch': 1.95}\n",
      "{'loss': 26.875, 'learning_rate': 6.964000000000001e-06, 'epoch': 1.95}\n",
      "{'loss': 28.375, 'learning_rate': 6.963000000000001e-06, 'epoch': 1.95}\n",
      "{'loss': 27.5, 'learning_rate': 6.962000000000001e-06, 'epoch': 1.95}\n",
      "{'loss': 29.0, 'learning_rate': 6.961000000000001e-06, 'epoch': 1.95}\n",
      "{'loss': 27.25, 'learning_rate': 6.96e-06, 'epoch': 1.95}\n",
      "{'loss': 27.5, 'learning_rate': 6.959e-06, 'epoch': 1.95}\n",
      "{'loss': 26.375, 'learning_rate': 6.958e-06, 'epoch': 1.95}\n",
      "{'loss': 26.5, 'learning_rate': 6.9570000000000005e-06, 'epoch': 1.95}\n",
      "{'loss': 27.5, 'learning_rate': 6.956000000000001e-06, 'epoch': 1.95}\n",
      "{'loss': 26.125, 'learning_rate': 6.955e-06, 'epoch': 1.95}\n",
      "{'loss': 27.0, 'learning_rate': 6.954000000000001e-06, 'epoch': 1.96}\n",
      "{'loss': 27.75, 'learning_rate': 6.953000000000001e-06, 'epoch': 1.96}\n",
      "{'loss': 26.875, 'learning_rate': 6.952000000000001e-06, 'epoch': 1.96}\n",
      "{'loss': 27.375, 'learning_rate': 6.951000000000001e-06, 'epoch': 1.96}\n",
      "{'loss': 27.875, 'learning_rate': 6.95e-06, 'epoch': 1.96}\n",
      "{'loss': 27.125, 'learning_rate': 6.949e-06, 'epoch': 1.96}\n",
      "{'loss': 27.875, 'learning_rate': 6.948e-06, 'epoch': 1.96}\n",
      "{'loss': 27.25, 'learning_rate': 6.9470000000000006e-06, 'epoch': 1.96}\n",
      "{'loss': 29.625, 'learning_rate': 6.946000000000001e-06, 'epoch': 1.96}\n",
      "{'loss': 27.125, 'learning_rate': 6.945e-06, 'epoch': 1.96}\n",
      "{'loss': 27.625, 'learning_rate': 6.944000000000001e-06, 'epoch': 1.96}\n",
      "{'loss': 27.75, 'learning_rate': 6.943000000000001e-06, 'epoch': 1.96}\n",
      "{'loss': 27.0, 'learning_rate': 6.942000000000001e-06, 'epoch': 1.96}\n",
      "{'loss': 26.625, 'learning_rate': 6.941000000000001e-06, 'epoch': 1.96}\n",
      "{'loss': 27.375, 'learning_rate': 6.9400000000000005e-06, 'epoch': 1.96}\n",
      "{'loss': 27.625, 'learning_rate': 6.939e-06, 'epoch': 1.96}\n",
      "{'loss': 27.625, 'learning_rate': 6.938e-06, 'epoch': 1.97}\n",
      "{'loss': 29.875, 'learning_rate': 6.937000000000001e-06, 'epoch': 1.97}\n",
      "{'loss': 26.875, 'learning_rate': 6.936e-06, 'epoch': 1.97}\n",
      "{'loss': 29.0, 'learning_rate': 6.9350000000000005e-06, 'epoch': 1.97}\n",
      "{'loss': 26.875, 'learning_rate': 6.934000000000001e-06, 'epoch': 1.97}\n",
      "{'loss': 27.375, 'learning_rate': 6.933000000000001e-06, 'epoch': 1.97}\n",
      "{'loss': 28.25, 'learning_rate': 6.932000000000001e-06, 'epoch': 1.97}\n",
      "{'loss': 27.75, 'learning_rate': 6.931000000000001e-06, 'epoch': 1.97}\n",
      "{'loss': 28.0, 'learning_rate': 6.93e-06, 'epoch': 1.97}\n",
      "{'loss': 29.125, 'learning_rate': 6.929e-06, 'epoch': 1.97}\n",
      "{'loss': 27.75, 'learning_rate': 6.928e-06, 'epoch': 1.97}\n",
      "{'loss': 27.625, 'learning_rate': 6.927000000000001e-06, 'epoch': 1.97}\n",
      "{'loss': 27.75, 'learning_rate': 6.926e-06, 'epoch': 1.97}\n",
      "{'loss': 28.375, 'learning_rate': 6.925000000000001e-06, 'epoch': 1.97}\n",
      "{'loss': 26.75, 'learning_rate': 6.924000000000001e-06, 'epoch': 1.97}\n",
      "{'loss': 27.5, 'learning_rate': 6.9230000000000005e-06, 'epoch': 1.97}\n",
      "{'loss': 27.125, 'learning_rate': 6.922000000000001e-06, 'epoch': 1.98}\n",
      "{'loss': 27.75, 'learning_rate': 6.921000000000001e-06, 'epoch': 1.98}\n",
      "{'loss': 27.375, 'learning_rate': 6.92e-06, 'epoch': 1.98}\n",
      "{'loss': 27.75, 'learning_rate': 6.919e-06, 'epoch': 1.98}\n",
      "{'loss': 27.625, 'learning_rate': 6.9180000000000005e-06, 'epoch': 1.98}\n",
      "{'loss': 27.125, 'learning_rate': 6.917e-06, 'epoch': 1.98}\n",
      "{'loss': 28.375, 'learning_rate': 6.916e-06, 'epoch': 1.98}\n",
      "{'loss': 28.125, 'learning_rate': 6.915000000000001e-06, 'epoch': 1.98}\n",
      "{'loss': 27.25, 'learning_rate': 6.914000000000001e-06, 'epoch': 1.98}\n",
      "{'loss': 26.75, 'learning_rate': 6.9130000000000006e-06, 'epoch': 1.98}\n",
      "{'loss': 27.875, 'learning_rate': 6.912000000000001e-06, 'epoch': 1.98}\n",
      "{'loss': 27.5, 'learning_rate': 6.911000000000001e-06, 'epoch': 1.98}\n",
      "{'loss': 27.375, 'learning_rate': 6.91e-06, 'epoch': 1.98}\n",
      "{'loss': 28.25, 'learning_rate': 6.909e-06, 'epoch': 1.98}\n",
      "{'loss': 26.875, 'learning_rate': 6.908000000000001e-06, 'epoch': 1.98}\n",
      "{'loss': 26.75, 'learning_rate': 6.907e-06, 'epoch': 1.99}\n",
      "{'loss': 26.375, 'learning_rate': 6.9060000000000005e-06, 'epoch': 1.99}\n",
      "{'loss': 28.0, 'learning_rate': 6.905000000000001e-06, 'epoch': 1.99}\n",
      "{'loss': 28.125, 'learning_rate': 6.904e-06, 'epoch': 1.99}\n",
      "{'loss': 28.125, 'learning_rate': 6.903000000000001e-06, 'epoch': 1.99}\n",
      "{'loss': 28.25, 'learning_rate': 6.902000000000001e-06, 'epoch': 1.99}\n",
      "{'loss': 28.0, 'learning_rate': 6.901000000000001e-06, 'epoch': 1.99}\n",
      "{'loss': 27.375, 'learning_rate': 6.9e-06, 'epoch': 1.99}\n",
      "{'loss': 27.25, 'learning_rate': 6.899e-06, 'epoch': 1.99}\n",
      "{'loss': 27.125, 'learning_rate': 6.898e-06, 'epoch': 1.99}\n",
      "{'loss': 27.75, 'learning_rate': 6.897e-06, 'epoch': 1.99}\n",
      "{'loss': 26.75, 'learning_rate': 6.8960000000000006e-06, 'epoch': 1.99}\n",
      "{'loss': 27.5, 'learning_rate': 6.895000000000001e-06, 'epoch': 1.99}\n",
      "{'loss': 26.75, 'learning_rate': 6.894e-06, 'epoch': 1.99}\n",
      "{'loss': 27.375, 'learning_rate': 6.893000000000001e-06, 'epoch': 1.99}\n",
      "{'loss': 26.75, 'learning_rate': 6.892000000000001e-06, 'epoch': 1.99}\n",
      "{'loss': 27.875, 'learning_rate': 6.891000000000001e-06, 'epoch': 2.0}\n",
      "{'loss': 27.625, 'learning_rate': 6.89e-06, 'epoch': 2.0}\n",
      "{'loss': 27.5, 'learning_rate': 6.8890000000000004e-06, 'epoch': 2.0}\n",
      "{'loss': 27.5, 'learning_rate': 6.888e-06, 'epoch': 2.0}\n",
      "{'loss': 28.25, 'learning_rate': 6.887e-06, 'epoch': 2.0}\n",
      "{'loss': 27.375, 'learning_rate': 6.886000000000001e-06, 'epoch': 2.0}\n",
      "{'loss': 27.625, 'learning_rate': 6.885e-06, 'epoch': 2.0}\n",
      "{'loss': 27.5, 'learning_rate': 6.8840000000000005e-06, 'epoch': 2.0}\n",
      "{'loss': 28.25, 'learning_rate': 6.883000000000001e-06, 'epoch': 2.0}\n",
      "{'loss': 28.125, 'learning_rate': 6.882000000000001e-06, 'epoch': 2.0}\n",
      "{'loss': 27.5, 'learning_rate': 6.881000000000001e-06, 'epoch': 2.0}\n",
      "{'loss': 27.375, 'learning_rate': 6.88e-06, 'epoch': 2.0}\n",
      "{'loss': 28.5, 'learning_rate': 6.8790000000000005e-06, 'epoch': 2.0}\n",
      "{'loss': 29.75, 'learning_rate': 6.878e-06, 'epoch': 2.0}\n",
      "{'loss': 29.25, 'learning_rate': 6.877e-06, 'epoch': 2.0}\n",
      "{'loss': 27.0, 'learning_rate': 6.876000000000001e-06, 'epoch': 2.01}\n",
      "{'loss': 28.875, 'learning_rate': 6.875e-06, 'epoch': 2.01}\n",
      "{'loss': 27.0, 'learning_rate': 6.874000000000001e-06, 'epoch': 2.01}\n",
      "{'loss': 27.5, 'learning_rate': 6.873000000000001e-06, 'epoch': 2.01}\n",
      "{'loss': 27.75, 'learning_rate': 6.872000000000001e-06, 'epoch': 2.01}\n",
      "{'loss': 28.375, 'learning_rate': 6.871000000000001e-06, 'epoch': 2.01}\n",
      "{'loss': 26.875, 'learning_rate': 6.870000000000001e-06, 'epoch': 2.01}\n",
      "{'loss': 28.125, 'learning_rate': 6.869e-06, 'epoch': 2.01}\n",
      "{'loss': 27.375, 'learning_rate': 6.868e-06, 'epoch': 2.01}\n",
      "{'loss': 26.875, 'learning_rate': 6.8670000000000005e-06, 'epoch': 2.01}\n",
      "{'loss': 27.625, 'learning_rate': 6.866000000000001e-06, 'epoch': 2.01}\n",
      "{'loss': 28.75, 'learning_rate': 6.865e-06, 'epoch': 2.01}\n",
      "{'loss': 28.25, 'learning_rate': 6.864000000000001e-06, 'epoch': 2.01}\n",
      "{'loss': 26.5, 'learning_rate': 6.863000000000001e-06, 'epoch': 2.01}\n",
      "{'loss': 29.75, 'learning_rate': 6.8620000000000005e-06, 'epoch': 2.01}\n",
      "{'loss': 26.5, 'learning_rate': 6.861000000000001e-06, 'epoch': 2.01}\n",
      "{'loss': 26.5, 'learning_rate': 6.860000000000001e-06, 'epoch': 2.02}\n",
      "{'loss': 27.5, 'learning_rate': 6.859e-06, 'epoch': 2.02}\n",
      "{'loss': 28.625, 'learning_rate': 6.858e-06, 'epoch': 2.02}\n",
      "{'loss': 27.375, 'learning_rate': 6.857000000000001e-06, 'epoch': 2.02}\n",
      "{'loss': 28.25, 'learning_rate': 6.856e-06, 'epoch': 2.02}\n",
      "{'loss': 27.0, 'learning_rate': 6.8550000000000004e-06, 'epoch': 2.02}\n",
      "{'loss': 27.0, 'learning_rate': 6.854000000000001e-06, 'epoch': 2.02}\n",
      "{'loss': 28.25, 'learning_rate': 6.853000000000001e-06, 'epoch': 2.02}\n",
      "{'loss': 27.125, 'learning_rate': 6.852000000000001e-06, 'epoch': 2.02}\n",
      "{'loss': 27.25, 'learning_rate': 6.851000000000001e-06, 'epoch': 2.02}\n",
      "{'loss': 26.5, 'learning_rate': 6.850000000000001e-06, 'epoch': 2.02}\n",
      "{'loss': 27.875, 'learning_rate': 6.849e-06, 'epoch': 2.02}\n",
      "{'loss': 27.125, 'learning_rate': 6.848e-06, 'epoch': 2.02}\n",
      "{'loss': 27.125, 'learning_rate': 6.847000000000001e-06, 'epoch': 2.02}\n",
      "{'loss': 27.875, 'learning_rate': 6.846e-06, 'epoch': 2.02}\n",
      "{'loss': 27.875, 'learning_rate': 6.8450000000000005e-06, 'epoch': 2.03}\n",
      "{'loss': 26.75, 'learning_rate': 6.844000000000001e-06, 'epoch': 2.03}\n",
      "{'loss': 27.625, 'learning_rate': 6.843e-06, 'epoch': 2.03}\n",
      "{'loss': 27.625, 'learning_rate': 6.842000000000001e-06, 'epoch': 2.03}\n",
      "{'loss': 26.125, 'learning_rate': 6.841000000000001e-06, 'epoch': 2.03}\n",
      "{'loss': 28.125, 'learning_rate': 6.8400000000000014e-06, 'epoch': 2.03}\n",
      "{'loss': 27.5, 'learning_rate': 6.839e-06, 'epoch': 2.03}\n",
      "{'loss': 26.5, 'learning_rate': 6.8380000000000004e-06, 'epoch': 2.03}\n",
      "{'loss': 28.25, 'learning_rate': 6.837e-06, 'epoch': 2.03}\n",
      "{'loss': 28.125, 'learning_rate': 6.836e-06, 'epoch': 2.03}\n",
      "{'loss': 26.875, 'learning_rate': 6.835000000000001e-06, 'epoch': 2.03}\n",
      "{'loss': 29.25, 'learning_rate': 6.834000000000001e-06, 'epoch': 2.03}\n",
      "{'loss': 26.75, 'learning_rate': 6.8330000000000005e-06, 'epoch': 2.03}\n",
      "{'loss': 27.25, 'learning_rate': 6.832000000000001e-06, 'epoch': 2.03}\n",
      "{'loss': 28.5, 'learning_rate': 6.831000000000001e-06, 'epoch': 2.03}\n",
      "{'loss': 26.75, 'learning_rate': 6.830000000000001e-06, 'epoch': 2.03}\n",
      "{'loss': 28.625, 'learning_rate': 6.829e-06, 'epoch': 2.04}\n",
      "{'loss': 28.25, 'learning_rate': 6.8280000000000005e-06, 'epoch': 2.04}\n",
      "{'loss': 29.5, 'learning_rate': 6.827e-06, 'epoch': 2.04}\n",
      "{'loss': 28.5, 'learning_rate': 6.826e-06, 'epoch': 2.04}\n",
      "{'loss': 27.875, 'learning_rate': 6.825000000000001e-06, 'epoch': 2.04}\n",
      "{'loss': 28.0, 'learning_rate': 6.824e-06, 'epoch': 2.04}\n",
      "{'loss': 26.375, 'learning_rate': 6.8230000000000006e-06, 'epoch': 2.04}\n",
      "{'loss': 26.875, 'learning_rate': 6.822000000000001e-06, 'epoch': 2.04}\n",
      "{'loss': 27.375, 'learning_rate': 6.821000000000001e-06, 'epoch': 2.04}\n",
      "{'loss': 26.75, 'learning_rate': 6.820000000000001e-06, 'epoch': 2.04}\n",
      "{'loss': 27.75, 'learning_rate': 6.819e-06, 'epoch': 2.04}\n",
      "{'loss': 27.0, 'learning_rate': 6.818e-06, 'epoch': 2.04}\n",
      "{'loss': 28.5, 'learning_rate': 6.817e-06, 'epoch': 2.04}\n",
      "{'loss': 27.75, 'learning_rate': 6.8160000000000005e-06, 'epoch': 2.04}\n",
      "{'loss': 28.375, 'learning_rate': 6.815000000000001e-06, 'epoch': 2.04}\n",
      "{'loss': 28.0, 'learning_rate': 6.814e-06, 'epoch': 2.04}\n",
      "{'loss': 27.125, 'learning_rate': 6.813000000000001e-06, 'epoch': 2.05}\n",
      "{'loss': 26.75, 'learning_rate': 6.812000000000001e-06, 'epoch': 2.05}\n",
      "{'loss': 28.625, 'learning_rate': 6.811000000000001e-06, 'epoch': 2.05}\n",
      "{'loss': 27.25, 'learning_rate': 6.810000000000001e-06, 'epoch': 2.05}\n",
      "{'loss': 28.875, 'learning_rate': 6.809e-06, 'epoch': 2.05}\n",
      "{'loss': 26.75, 'learning_rate': 6.808e-06, 'epoch': 2.05}\n",
      "{'loss': 29.125, 'learning_rate': 6.807e-06, 'epoch': 2.05}\n",
      "{'loss': 29.75, 'learning_rate': 6.8060000000000006e-06, 'epoch': 2.05}\n",
      "{'loss': 27.25, 'learning_rate': 6.805000000000001e-06, 'epoch': 2.05}\n",
      "{'loss': 27.0, 'learning_rate': 6.804e-06, 'epoch': 2.05}\n",
      "{'loss': 27.5, 'learning_rate': 6.803000000000001e-06, 'epoch': 2.05}\n",
      "{'loss': 27.375, 'learning_rate': 6.802000000000001e-06, 'epoch': 2.05}\n",
      "{'loss': 28.5, 'learning_rate': 6.801000000000001e-06, 'epoch': 2.05}\n",
      "{'loss': 29.25, 'learning_rate': 6.800000000000001e-06, 'epoch': 2.05}\n",
      "{'loss': 27.75, 'learning_rate': 6.7990000000000005e-06, 'epoch': 2.05}\n",
      "{'loss': 27.125, 'learning_rate': 6.798e-06, 'epoch': 2.06}\n",
      "{'loss': 29.0, 'learning_rate': 6.797e-06, 'epoch': 2.06}\n",
      "{'loss': 26.625, 'learning_rate': 6.796000000000001e-06, 'epoch': 2.06}\n",
      "{'loss': 26.25, 'learning_rate': 6.795e-06, 'epoch': 2.06}\n",
      "{'loss': 26.75, 'learning_rate': 6.7940000000000005e-06, 'epoch': 2.06}\n",
      "{'loss': 26.625, 'learning_rate': 6.793000000000001e-06, 'epoch': 2.06}\n",
      "{'loss': 28.875, 'learning_rate': 6.792000000000001e-06, 'epoch': 2.06}\n",
      "{'loss': 27.125, 'learning_rate': 6.791000000000001e-06, 'epoch': 2.06}\n",
      "{'loss': 28.125, 'learning_rate': 6.790000000000001e-06, 'epoch': 2.06}\n",
      "{'loss': 28.5, 'learning_rate': 6.789e-06, 'epoch': 2.06}\n",
      "{'loss': 28.0, 'learning_rate': 6.788e-06, 'epoch': 2.06}\n",
      "{'loss': 26.875, 'learning_rate': 6.787e-06, 'epoch': 2.06}\n",
      "{'loss': 26.875, 'learning_rate': 6.786000000000001e-06, 'epoch': 2.06}\n",
      "{'loss': 28.25, 'learning_rate': 6.785e-06, 'epoch': 2.06}\n",
      "{'loss': 27.5, 'learning_rate': 6.784000000000001e-06, 'epoch': 2.06}\n",
      "{'loss': 27.25, 'learning_rate': 6.783000000000001e-06, 'epoch': 2.06}\n",
      "{'loss': 27.0, 'learning_rate': 6.7820000000000005e-06, 'epoch': 2.07}\n",
      "{'loss': 27.25, 'learning_rate': 6.781000000000001e-06, 'epoch': 2.07}\n",
      "{'loss': 27.25, 'learning_rate': 6.780000000000001e-06, 'epoch': 2.07}\n",
      "{'loss': 28.875, 'learning_rate': 6.779e-06, 'epoch': 2.07}\n",
      "{'loss': 27.125, 'learning_rate': 6.778e-06, 'epoch': 2.07}\n",
      "{'loss': 27.625, 'learning_rate': 6.7770000000000005e-06, 'epoch': 2.07}\n",
      "{'loss': 27.25, 'learning_rate': 6.776e-06, 'epoch': 2.07}\n",
      "{'loss': 27.5, 'learning_rate': 6.775e-06, 'epoch': 2.07}\n",
      "{'loss': 28.0, 'learning_rate': 6.774000000000001e-06, 'epoch': 2.07}\n",
      "{'loss': 27.75, 'learning_rate': 6.773000000000001e-06, 'epoch': 2.07}\n",
      "{'loss': 27.0, 'learning_rate': 6.7720000000000006e-06, 'epoch': 2.07}\n",
      "{'loss': 26.375, 'learning_rate': 6.771000000000001e-06, 'epoch': 2.07}\n",
      "{'loss': 27.875, 'learning_rate': 6.770000000000001e-06, 'epoch': 2.07}\n",
      "{'loss': 27.375, 'learning_rate': 6.769e-06, 'epoch': 2.07}\n",
      "{'loss': 26.875, 'learning_rate': 6.768e-06, 'epoch': 2.07}\n",
      "{'loss': 28.75, 'learning_rate': 6.767000000000001e-06, 'epoch': 2.08}\n",
      "{'loss': 27.0, 'learning_rate': 6.766e-06, 'epoch': 2.08}\n",
      "{'loss': 27.375, 'learning_rate': 6.7650000000000005e-06, 'epoch': 2.08}\n",
      "{'loss': 29.375, 'learning_rate': 6.764000000000001e-06, 'epoch': 2.08}\n",
      "{'loss': 27.625, 'learning_rate': 6.763e-06, 'epoch': 2.08}\n",
      "{'loss': 27.125, 'learning_rate': 6.762000000000001e-06, 'epoch': 2.08}\n",
      "{'loss': 28.375, 'learning_rate': 6.761000000000001e-06, 'epoch': 2.08}\n",
      "{'loss': 28.25, 'learning_rate': 6.760000000000001e-06, 'epoch': 2.08}\n",
      "{'loss': 27.25, 'learning_rate': 6.759e-06, 'epoch': 2.08}\n",
      "{'loss': 26.875, 'learning_rate': 6.758e-06, 'epoch': 2.08}\n",
      "{'loss': 27.75, 'learning_rate': 6.757e-06, 'epoch': 2.08}\n",
      "{'loss': 29.125, 'learning_rate': 6.756e-06, 'epoch': 2.08}\n",
      "{'loss': 29.125, 'learning_rate': 6.7550000000000005e-06, 'epoch': 2.08}\n",
      "{'loss': 27.625, 'learning_rate': 6.754000000000001e-06, 'epoch': 2.08}\n",
      "{'loss': 27.875, 'learning_rate': 6.753e-06, 'epoch': 2.08}\n",
      "{'loss': 29.0, 'learning_rate': 6.752000000000001e-06, 'epoch': 2.08}\n",
      "{'loss': 29.375, 'learning_rate': 6.751000000000001e-06, 'epoch': 2.09}\n",
      "{'loss': 26.875, 'learning_rate': 6.750000000000001e-06, 'epoch': 2.09}\n",
      "{'loss': 27.25, 'learning_rate': 6.749000000000001e-06, 'epoch': 2.09}\n",
      "{'loss': 29.625, 'learning_rate': 6.7480000000000004e-06, 'epoch': 2.09}\n",
      "{'loss': 27.75, 'learning_rate': 6.747e-06, 'epoch': 2.09}\n",
      "{'loss': 27.125, 'learning_rate': 6.746e-06, 'epoch': 2.09}\n",
      "{'loss': 28.875, 'learning_rate': 6.745000000000001e-06, 'epoch': 2.09}\n",
      "{'loss': 27.0, 'learning_rate': 6.744e-06, 'epoch': 2.09}\n",
      "{'loss': 28.25, 'learning_rate': 6.7430000000000005e-06, 'epoch': 2.09}\n",
      "{'loss': 29.5, 'learning_rate': 6.742000000000001e-06, 'epoch': 2.09}\n",
      "{'loss': 29.125, 'learning_rate': 6.741000000000001e-06, 'epoch': 2.09}\n",
      "{'loss': 26.625, 'learning_rate': 6.740000000000001e-06, 'epoch': 2.09}\n",
      "{'loss': 27.375, 'learning_rate': 6.739000000000001e-06, 'epoch': 2.09}\n",
      "{'loss': 26.75, 'learning_rate': 6.738e-06, 'epoch': 2.09}\n",
      "{'loss': 27.625, 'learning_rate': 6.737e-06, 'epoch': 2.09}\n",
      "{'loss': 27.75, 'learning_rate': 6.736e-06, 'epoch': 2.09}\n",
      "{'loss': 28.75, 'learning_rate': 6.735000000000001e-06, 'epoch': 2.1}\n",
      "{'loss': 27.5, 'learning_rate': 6.734e-06, 'epoch': 2.1}\n",
      "{'loss': 27.625, 'learning_rate': 6.733000000000001e-06, 'epoch': 2.1}\n",
      "{'loss': 27.5, 'learning_rate': 6.732000000000001e-06, 'epoch': 2.1}\n",
      "{'loss': 27.625, 'learning_rate': 6.731000000000001e-06, 'epoch': 2.1}\n",
      "{'loss': 27.375, 'learning_rate': 6.730000000000001e-06, 'epoch': 2.1}\n",
      "{'loss': 27.125, 'learning_rate': 6.729000000000001e-06, 'epoch': 2.1}\n",
      "{'loss': 26.625, 'learning_rate': 6.728e-06, 'epoch': 2.1}\n",
      "{'loss': 27.75, 'learning_rate': 6.727e-06, 'epoch': 2.1}\n",
      "{'loss': 28.25, 'learning_rate': 6.7260000000000005e-06, 'epoch': 2.1}\n",
      "{'loss': 29.375, 'learning_rate': 6.725000000000001e-06, 'epoch': 2.1}\n",
      "{'loss': 27.5, 'learning_rate': 6.724e-06, 'epoch': 2.1}\n",
      "{'loss': 28.125, 'learning_rate': 6.723000000000001e-06, 'epoch': 2.1}\n",
      "{'loss': 27.375, 'learning_rate': 6.722000000000001e-06, 'epoch': 2.1}\n",
      "{'loss': 27.5, 'learning_rate': 6.7210000000000005e-06, 'epoch': 2.1}\n",
      "{'loss': 29.25, 'learning_rate': 6.720000000000001e-06, 'epoch': 2.11}\n",
      "{'loss': 27.125, 'learning_rate': 6.719000000000001e-06, 'epoch': 2.11}\n",
      "{'loss': 27.625, 'learning_rate': 6.718e-06, 'epoch': 2.11}\n",
      "{'loss': 26.375, 'learning_rate': 6.717e-06, 'epoch': 2.11}\n",
      "{'loss': 27.75, 'learning_rate': 6.716000000000001e-06, 'epoch': 2.11}\n",
      "{'loss': 28.25, 'learning_rate': 6.715e-06, 'epoch': 2.11}\n",
      "{'loss': 27.375, 'learning_rate': 6.7140000000000004e-06, 'epoch': 2.11}\n",
      "{'loss': 27.875, 'learning_rate': 6.713000000000001e-06, 'epoch': 2.11}\n",
      "{'loss': 26.875, 'learning_rate': 6.712000000000001e-06, 'epoch': 2.11}\n",
      "{'loss': 27.125, 'learning_rate': 6.711000000000001e-06, 'epoch': 2.11}\n",
      "{'loss': 27.0, 'learning_rate': 6.710000000000001e-06, 'epoch': 2.11}\n",
      "{'loss': 28.25, 'learning_rate': 6.709000000000001e-06, 'epoch': 2.11}\n",
      "{'loss': 28.5, 'learning_rate': 6.708e-06, 'epoch': 2.11}\n",
      "{'loss': 27.625, 'learning_rate': 6.707e-06, 'epoch': 2.11}\n",
      "{'loss': 27.25, 'learning_rate': 6.706000000000001e-06, 'epoch': 2.11}\n",
      "{'loss': 27.875, 'learning_rate': 6.705e-06, 'epoch': 2.11}\n",
      "{'loss': 27.125, 'learning_rate': 6.7040000000000005e-06, 'epoch': 2.12}\n",
      "{'loss': 27.0, 'learning_rate': 6.703000000000001e-06, 'epoch': 2.12}\n",
      "{'loss': 28.375, 'learning_rate': 6.702e-06, 'epoch': 2.12}\n",
      "{'loss': 26.875, 'learning_rate': 6.701000000000001e-06, 'epoch': 2.12}\n",
      "{'loss': 27.125, 'learning_rate': 6.700000000000001e-06, 'epoch': 2.12}\n",
      "{'loss': 26.625, 'learning_rate': 6.699000000000001e-06, 'epoch': 2.12}\n",
      "{'loss': 26.875, 'learning_rate': 6.698e-06, 'epoch': 2.12}\n",
      "{'loss': 27.5, 'learning_rate': 6.6970000000000004e-06, 'epoch': 2.12}\n",
      "{'loss': 27.375, 'learning_rate': 6.696e-06, 'epoch': 2.12}\n",
      "{'loss': 28.0, 'learning_rate': 6.695e-06, 'epoch': 2.12}\n",
      "{'loss': 26.625, 'learning_rate': 6.694000000000001e-06, 'epoch': 2.12}\n",
      "{'loss': 28.75, 'learning_rate': 6.693000000000001e-06, 'epoch': 2.12}\n",
      "{'loss': 30.625, 'learning_rate': 6.6920000000000005e-06, 'epoch': 2.12}\n",
      "{'loss': 28.0, 'learning_rate': 6.691000000000001e-06, 'epoch': 2.12}\n",
      "{'loss': 27.0, 'learning_rate': 6.690000000000001e-06, 'epoch': 2.12}\n",
      "{'loss': 27.625, 'learning_rate': 6.689000000000001e-06, 'epoch': 2.13}\n",
      "{'loss': 28.75, 'learning_rate': 6.688e-06, 'epoch': 2.13}\n",
      "{'loss': 27.125, 'learning_rate': 6.6870000000000005e-06, 'epoch': 2.13}\n",
      "{'loss': 27.75, 'learning_rate': 6.686e-06, 'epoch': 2.13}\n",
      "{'loss': 27.125, 'learning_rate': 6.685e-06, 'epoch': 2.13}\n",
      "{'loss': 26.875, 'learning_rate': 6.684000000000001e-06, 'epoch': 2.13}\n",
      "{'loss': 27.0, 'learning_rate': 6.683e-06, 'epoch': 2.13}\n",
      "{'loss': 29.125, 'learning_rate': 6.6820000000000006e-06, 'epoch': 2.13}\n",
      "{'loss': 28.375, 'learning_rate': 6.681000000000001e-06, 'epoch': 2.13}\n",
      "{'loss': 28.25, 'learning_rate': 6.680000000000001e-06, 'epoch': 2.13}\n",
      "{'loss': 27.875, 'learning_rate': 6.679000000000001e-06, 'epoch': 2.13}\n",
      "{'loss': 27.875, 'learning_rate': 6.678e-06, 'epoch': 2.13}\n",
      "{'loss': 27.375, 'learning_rate': 6.677e-06, 'epoch': 2.13}\n",
      "{'loss': 27.25, 'learning_rate': 6.676e-06, 'epoch': 2.13}\n",
      "{'loss': 27.125, 'learning_rate': 6.6750000000000005e-06, 'epoch': 2.13}\n",
      "{'loss': 27.625, 'learning_rate': 6.674000000000001e-06, 'epoch': 2.13}\n",
      "{'loss': 27.125, 'learning_rate': 6.673e-06, 'epoch': 2.14}\n",
      "{'loss': 26.75, 'learning_rate': 6.672000000000001e-06, 'epoch': 2.14}\n",
      "{'loss': 27.0, 'learning_rate': 6.671000000000001e-06, 'epoch': 2.14}\n",
      "{'loss': 28.25, 'learning_rate': 6.6700000000000005e-06, 'epoch': 2.14}\n",
      "{'loss': 27.75, 'learning_rate': 6.669000000000001e-06, 'epoch': 2.14}\n",
      "{'loss': 26.25, 'learning_rate': 6.668e-06, 'epoch': 2.14}\n",
      "{'loss': 26.75, 'learning_rate': 6.667e-06, 'epoch': 2.14}\n",
      "{'loss': 26.625, 'learning_rate': 6.666e-06, 'epoch': 2.14}\n",
      "{'loss': 26.375, 'learning_rate': 6.6650000000000006e-06, 'epoch': 2.14}\n",
      "{'loss': 30.125, 'learning_rate': 6.664e-06, 'epoch': 2.14}\n",
      "{'loss': 27.625, 'learning_rate': 6.663e-06, 'epoch': 2.14}\n",
      "{'loss': 28.25, 'learning_rate': 6.662000000000001e-06, 'epoch': 2.14}\n",
      "{'loss': 27.875, 'learning_rate': 6.661000000000001e-06, 'epoch': 2.14}\n",
      "{'loss': 27.75, 'learning_rate': 6.660000000000001e-06, 'epoch': 2.14}\n",
      "{'loss': 27.125, 'learning_rate': 6.659000000000001e-06, 'epoch': 2.14}\n",
      "{'loss': 28.25, 'learning_rate': 6.658e-06, 'epoch': 2.15}\n",
      "{'loss': 29.125, 'learning_rate': 6.657e-06, 'epoch': 2.15}\n",
      "{'loss': 30.5, 'learning_rate': 6.656e-06, 'epoch': 2.15}\n",
      "{'loss': 28.375, 'learning_rate': 6.655000000000001e-06, 'epoch': 2.15}\n",
      "{'loss': 29.75, 'learning_rate': 6.654e-06, 'epoch': 2.15}\n",
      "{'loss': 27.125, 'learning_rate': 6.6530000000000005e-06, 'epoch': 2.15}\n",
      "{'loss': 29.125, 'learning_rate': 6.652000000000001e-06, 'epoch': 2.15}\n",
      "{'loss': 27.0, 'learning_rate': 6.651000000000001e-06, 'epoch': 2.15}\n",
      "{'loss': 26.875, 'learning_rate': 6.650000000000001e-06, 'epoch': 2.15}\n",
      "{'loss': 28.125, 'learning_rate': 6.649000000000001e-06, 'epoch': 2.15}\n",
      "{'loss': 27.375, 'learning_rate': 6.648e-06, 'epoch': 2.15}\n",
      "{'loss': 28.0, 'learning_rate': 6.647e-06, 'epoch': 2.15}\n",
      "{'loss': 27.875, 'learning_rate': 6.646e-06, 'epoch': 2.15}\n",
      "{'loss': 26.875, 'learning_rate': 6.645000000000001e-06, 'epoch': 2.15}\n",
      "{'loss': 28.75, 'learning_rate': 6.644e-06, 'epoch': 2.15}\n",
      "{'loss': 27.5, 'learning_rate': 6.643000000000001e-06, 'epoch': 2.15}\n",
      "{'loss': 28.125, 'learning_rate': 6.642000000000001e-06, 'epoch': 2.16}\n",
      "{'loss': 26.625, 'learning_rate': 6.6410000000000005e-06, 'epoch': 2.16}\n",
      "{'loss': 26.75, 'learning_rate': 6.640000000000001e-06, 'epoch': 2.16}\n",
      "{'loss': 28.625, 'learning_rate': 6.639000000000001e-06, 'epoch': 2.16}\n",
      "{'loss': 27.125, 'learning_rate': 6.638e-06, 'epoch': 2.16}\n",
      "{'loss': 27.0, 'learning_rate': 6.637e-06, 'epoch': 2.16}\n",
      "{'loss': 27.0, 'learning_rate': 6.6360000000000005e-06, 'epoch': 2.16}\n",
      "{'loss': 27.375, 'learning_rate': 6.635e-06, 'epoch': 2.16}\n",
      "{'loss': 31.25, 'learning_rate': 6.634e-06, 'epoch': 2.16}\n",
      "{'loss': 28.0, 'learning_rate': 6.633000000000001e-06, 'epoch': 2.16}\n",
      "{'loss': 28.875, 'learning_rate': 6.632000000000001e-06, 'epoch': 2.16}\n",
      "{'loss': 27.25, 'learning_rate': 6.6310000000000005e-06, 'epoch': 2.16}\n",
      "{'loss': 27.75, 'learning_rate': 6.630000000000001e-06, 'epoch': 2.16}\n",
      "{'loss': 28.125, 'learning_rate': 6.629000000000001e-06, 'epoch': 2.16}\n",
      "{'loss': 28.0, 'learning_rate': 6.628e-06, 'epoch': 2.16}\n",
      "{'loss': 28.625, 'learning_rate': 6.627e-06, 'epoch': 2.16}\n",
      "{'loss': 28.25, 'learning_rate': 6.626000000000001e-06, 'epoch': 2.17}\n",
      "{'loss': 27.875, 'learning_rate': 6.625e-06, 'epoch': 2.17}\n",
      "{'loss': 27.0, 'learning_rate': 6.6240000000000004e-06, 'epoch': 2.17}\n",
      "{'loss': 26.875, 'learning_rate': 6.623000000000001e-06, 'epoch': 2.17}\n",
      "{'loss': 27.875, 'learning_rate': 6.622e-06, 'epoch': 2.17}\n",
      "{'loss': 29.375, 'learning_rate': 6.621000000000001e-06, 'epoch': 2.17}\n",
      "{'loss': 28.5, 'learning_rate': 6.620000000000001e-06, 'epoch': 2.17}\n",
      "{'loss': 27.125, 'learning_rate': 6.619000000000001e-06, 'epoch': 2.17}\n",
      "{'loss': 28.0, 'learning_rate': 6.618000000000001e-06, 'epoch': 2.17}\n",
      "{'loss': 27.25, 'learning_rate': 6.617e-06, 'epoch': 2.17}\n",
      "{'loss': 27.25, 'learning_rate': 6.616e-06, 'epoch': 2.17}\n",
      "{'loss': 27.25, 'learning_rate': 6.615e-06, 'epoch': 2.17}\n",
      "{'loss': 26.125, 'learning_rate': 6.6140000000000005e-06, 'epoch': 2.17}\n",
      "{'loss': 27.375, 'learning_rate': 6.613000000000001e-06, 'epoch': 2.17}\n",
      "{'loss': 27.125, 'learning_rate': 6.612e-06, 'epoch': 2.17}\n",
      "{'loss': 27.125, 'learning_rate': 6.611000000000001e-06, 'epoch': 2.18}\n",
      "{'loss': 27.875, 'learning_rate': 6.610000000000001e-06, 'epoch': 2.18}\n",
      "{'loss': 27.0, 'learning_rate': 6.609000000000001e-06, 'epoch': 2.18}\n",
      "{'loss': 27.875, 'learning_rate': 6.608000000000001e-06, 'epoch': 2.18}\n",
      "{'loss': 28.125, 'learning_rate': 6.6070000000000004e-06, 'epoch': 2.18}\n",
      "{'loss': 27.25, 'learning_rate': 6.606e-06, 'epoch': 2.18}\n",
      "{'loss': 26.375, 'learning_rate': 6.605e-06, 'epoch': 2.18}\n",
      "{'loss': 26.75, 'learning_rate': 6.604000000000001e-06, 'epoch': 2.18}\n",
      "{'loss': 28.0, 'learning_rate': 6.603e-06, 'epoch': 2.18}\n",
      "{'loss': 27.125, 'learning_rate': 6.6020000000000005e-06, 'epoch': 2.18}\n",
      "{'loss': 28.875, 'learning_rate': 6.601000000000001e-06, 'epoch': 2.18}\n",
      "{'loss': 29.375, 'learning_rate': 6.600000000000001e-06, 'epoch': 2.18}\n",
      "{'loss': 27.625, 'learning_rate': 6.599000000000001e-06, 'epoch': 2.18}\n",
      "{'loss': 27.375, 'learning_rate': 6.598000000000001e-06, 'epoch': 2.18}\n",
      "{'loss': 27.0, 'learning_rate': 6.597e-06, 'epoch': 2.18}\n",
      "{'loss': 29.0, 'learning_rate': 6.596e-06, 'epoch': 2.18}\n",
      "{'loss': 26.125, 'learning_rate': 6.595e-06, 'epoch': 2.19}\n",
      "{'loss': 27.625, 'learning_rate': 6.594000000000001e-06, 'epoch': 2.19}\n",
      "{'loss': 28.375, 'learning_rate': 6.593e-06, 'epoch': 2.19}\n",
      "{'loss': 28.0, 'learning_rate': 6.592000000000001e-06, 'epoch': 2.19}\n",
      "{'loss': 28.375, 'learning_rate': 6.591000000000001e-06, 'epoch': 2.19}\n",
      "{'loss': 28.0, 'learning_rate': 6.5900000000000004e-06, 'epoch': 2.19}\n",
      "{'loss': 28.0, 'learning_rate': 6.589000000000001e-06, 'epoch': 2.19}\n",
      "{'loss': 26.875, 'learning_rate': 6.588000000000001e-06, 'epoch': 2.19}\n",
      "{'loss': 28.125, 'learning_rate': 6.587e-06, 'epoch': 2.19}\n",
      "{'loss': 27.375, 'learning_rate': 6.586e-06, 'epoch': 2.19}\n",
      "{'loss': 26.375, 'learning_rate': 6.5850000000000005e-06, 'epoch': 2.19}\n",
      "{'loss': 27.0, 'learning_rate': 6.584e-06, 'epoch': 2.19}\n",
      "{'loss': 29.5, 'learning_rate': 6.583e-06, 'epoch': 2.19}\n",
      "{'loss': 27.25, 'learning_rate': 6.582000000000001e-06, 'epoch': 2.19}\n",
      "{'loss': 28.125, 'learning_rate': 6.581000000000001e-06, 'epoch': 2.19}\n",
      "{'loss': 27.625, 'learning_rate': 6.5800000000000005e-06, 'epoch': 2.2}\n",
      "{'loss': 27.375, 'learning_rate': 6.579000000000001e-06, 'epoch': 2.2}\n",
      "{'loss': 29.0, 'learning_rate': 6.578000000000001e-06, 'epoch': 2.2}\n",
      "{'loss': 26.25, 'learning_rate': 6.577e-06, 'epoch': 2.2}\n",
      "{'loss': 28.625, 'learning_rate': 6.576e-06, 'epoch': 2.2}\n",
      "{'loss': 27.0, 'learning_rate': 6.5750000000000006e-06, 'epoch': 2.2}\n",
      "{'loss': 27.25, 'learning_rate': 6.574e-06, 'epoch': 2.2}\n",
      "{'loss': 27.75, 'learning_rate': 6.5730000000000004e-06, 'epoch': 2.2}\n",
      "{'loss': 28.875, 'learning_rate': 6.572000000000001e-06, 'epoch': 2.2}\n",
      "{'loss': 29.0, 'learning_rate': 6.571000000000001e-06, 'epoch': 2.2}\n",
      "{'loss': 27.5, 'learning_rate': 6.570000000000001e-06, 'epoch': 2.2}\n",
      "{'loss': 27.625, 'learning_rate': 6.569000000000001e-06, 'epoch': 2.2}\n",
      "{'loss': 29.125, 'learning_rate': 6.568000000000001e-06, 'epoch': 2.2}\n",
      "{'loss': 28.125, 'learning_rate': 6.567e-06, 'epoch': 2.2}\n",
      "{'loss': 26.875, 'learning_rate': 6.566e-06, 'epoch': 2.2}\n",
      "{'loss': 27.0, 'learning_rate': 6.565000000000001e-06, 'epoch': 2.2}\n",
      "{'loss': 26.25, 'learning_rate': 6.564e-06, 'epoch': 2.21}\n",
      "{'loss': 28.0, 'learning_rate': 6.5630000000000005e-06, 'epoch': 2.21}\n",
      "{'loss': 26.375, 'learning_rate': 6.562000000000001e-06, 'epoch': 2.21}\n",
      "{'loss': 26.75, 'learning_rate': 6.561e-06, 'epoch': 2.21}\n",
      "{'loss': 28.375, 'learning_rate': 6.560000000000001e-06, 'epoch': 2.21}\n",
      "{'loss': 31.5, 'learning_rate': 6.559000000000001e-06, 'epoch': 2.21}\n",
      "{'loss': 27.5, 'learning_rate': 6.558000000000001e-06, 'epoch': 2.21}\n",
      "{'loss': 27.5, 'learning_rate': 6.557e-06, 'epoch': 2.21}\n",
      "{'loss': 27.375, 'learning_rate': 6.556e-06, 'epoch': 2.21}\n",
      "{'loss': 27.625, 'learning_rate': 6.555e-06, 'epoch': 2.21}\n",
      "{'loss': 26.75, 'learning_rate': 6.554e-06, 'epoch': 2.21}\n",
      "{'loss': 26.75, 'learning_rate': 6.553000000000001e-06, 'epoch': 2.21}\n",
      "{'loss': 27.875, 'learning_rate': 6.552000000000001e-06, 'epoch': 2.21}\n",
      "{'loss': 26.875, 'learning_rate': 6.5510000000000005e-06, 'epoch': 2.21}\n",
      "{'loss': 28.0, 'learning_rate': 6.550000000000001e-06, 'epoch': 2.21}\n",
      "{'loss': 27.125, 'learning_rate': 6.549000000000001e-06, 'epoch': 2.22}\n",
      "{'loss': 29.75, 'learning_rate': 6.548000000000001e-06, 'epoch': 2.22}\n",
      "{'loss': 27.75, 'learning_rate': 6.547e-06, 'epoch': 2.22}\n",
      "{'loss': 27.0, 'learning_rate': 6.5460000000000005e-06, 'epoch': 2.22}\n",
      "{'loss': 27.5, 'learning_rate': 6.545e-06, 'epoch': 2.22}\n",
      "{'loss': 27.75, 'learning_rate': 6.544e-06, 'epoch': 2.22}\n",
      "{'loss': 28.125, 'learning_rate': 6.543000000000001e-06, 'epoch': 2.22}\n",
      "{'loss': 27.375, 'learning_rate': 6.542e-06, 'epoch': 2.22}\n",
      "{'loss': 27.125, 'learning_rate': 6.5410000000000006e-06, 'epoch': 2.22}\n",
      "{'loss': 30.25, 'learning_rate': 6.540000000000001e-06, 'epoch': 2.22}\n",
      "{'loss': 27.0, 'learning_rate': 6.539000000000001e-06, 'epoch': 2.22}\n",
      "{'loss': 28.375, 'learning_rate': 6.538000000000001e-06, 'epoch': 2.22}\n",
      "{'loss': 28.25, 'learning_rate': 6.537e-06, 'epoch': 2.22}\n",
      "{'loss': 27.75, 'learning_rate': 6.536e-06, 'epoch': 2.22}\n",
      "{'loss': 27.0, 'learning_rate': 6.535e-06, 'epoch': 2.22}\n",
      "{'loss': 26.875, 'learning_rate': 6.5340000000000005e-06, 'epoch': 2.22}\n",
      "{'loss': 27.875, 'learning_rate': 6.533000000000001e-06, 'epoch': 2.23}\n",
      "{'loss': 27.875, 'learning_rate': 6.532e-06, 'epoch': 2.23}\n",
      "{'loss': 27.0, 'learning_rate': 6.531000000000001e-06, 'epoch': 2.23}\n",
      "{'loss': 26.25, 'learning_rate': 6.530000000000001e-06, 'epoch': 2.23}\n",
      "{'loss': 26.875, 'learning_rate': 6.5290000000000005e-06, 'epoch': 2.23}\n",
      "{'loss': 26.625, 'learning_rate': 6.528000000000001e-06, 'epoch': 2.23}\n",
      "{'loss': 28.375, 'learning_rate': 6.527e-06, 'epoch': 2.23}\n",
      "{'loss': 26.875, 'learning_rate': 6.526e-06, 'epoch': 2.23}\n",
      "{'loss': 27.625, 'learning_rate': 6.525e-06, 'epoch': 2.23}\n",
      "{'loss': 28.0, 'learning_rate': 6.5240000000000006e-06, 'epoch': 2.23}\n",
      "{'loss': 29.5, 'learning_rate': 6.523e-06, 'epoch': 2.23}\n",
      "{'loss': 26.875, 'learning_rate': 6.522e-06, 'epoch': 2.23}\n",
      "{'loss': 27.5, 'learning_rate': 6.521000000000001e-06, 'epoch': 2.23}\n",
      "{'loss': 26.875, 'learning_rate': 6.520000000000001e-06, 'epoch': 2.23}\n",
      "{'loss': 28.375, 'learning_rate': 6.519000000000001e-06, 'epoch': 2.23}\n",
      "{'loss': 27.875, 'learning_rate': 6.518000000000001e-06, 'epoch': 2.23}\n",
      "{'loss': 27.5, 'learning_rate': 6.517e-06, 'epoch': 2.24}\n",
      "{'loss': 28.625, 'learning_rate': 6.516e-06, 'epoch': 2.24}\n",
      "{'loss': 27.375, 'learning_rate': 6.515e-06, 'epoch': 2.24}\n",
      "{'loss': 26.5, 'learning_rate': 6.514000000000001e-06, 'epoch': 2.24}\n",
      "{'loss': 29.625, 'learning_rate': 6.513e-06, 'epoch': 2.24}\n",
      "{'loss': 29.75, 'learning_rate': 6.5120000000000005e-06, 'epoch': 2.24}\n",
      "{'loss': 28.125, 'learning_rate': 6.511000000000001e-06, 'epoch': 2.24}\n",
      "{'loss': 28.125, 'learning_rate': 6.51e-06, 'epoch': 2.24}\n",
      "{'loss': 27.625, 'learning_rate': 6.509000000000001e-06, 'epoch': 2.24}\n",
      "{'loss': 28.375, 'learning_rate': 6.508000000000001e-06, 'epoch': 2.24}\n",
      "{'loss': 29.25, 'learning_rate': 6.507e-06, 'epoch': 2.24}\n",
      "{'loss': 28.0, 'learning_rate': 6.506e-06, 'epoch': 2.24}\n",
      "{'loss': 28.25, 'learning_rate': 6.505e-06, 'epoch': 2.24}\n",
      "{'loss': 27.5, 'learning_rate': 6.504e-06, 'epoch': 2.24}\n",
      "{'loss': 28.0, 'learning_rate': 6.503e-06, 'epoch': 2.24}\n",
      "{'loss': 28.0, 'learning_rate': 6.502000000000001e-06, 'epoch': 2.25}\n",
      "{'loss': 29.625, 'learning_rate': 6.501000000000001e-06, 'epoch': 2.25}\n",
      "{'loss': 28.625, 'learning_rate': 6.5000000000000004e-06, 'epoch': 2.25}\n",
      "{'loss': 27.5, 'learning_rate': 6.499000000000001e-06, 'epoch': 2.25}\n",
      "{'loss': 28.625, 'learning_rate': 6.498000000000001e-06, 'epoch': 2.25}\n",
      "{'loss': 27.5, 'learning_rate': 6.4970000000000015e-06, 'epoch': 2.25}\n",
      "{'loss': 28.125, 'learning_rate': 6.496e-06, 'epoch': 2.25}\n",
      "{'loss': 26.625, 'learning_rate': 6.4950000000000005e-06, 'epoch': 2.25}\n",
      "{'loss': 28.25, 'learning_rate': 6.494e-06, 'epoch': 2.25}\n",
      "{'loss': 27.875, 'learning_rate': 6.493e-06, 'epoch': 2.25}\n",
      "{'loss': 27.125, 'learning_rate': 6.492000000000001e-06, 'epoch': 2.25}\n",
      "{'loss': 27.75, 'learning_rate': 6.491000000000001e-06, 'epoch': 2.25}\n",
      "{'loss': 26.75, 'learning_rate': 6.4900000000000005e-06, 'epoch': 2.25}\n",
      "{'loss': 27.125, 'learning_rate': 6.489000000000001e-06, 'epoch': 2.25}\n",
      "{'loss': 28.75, 'learning_rate': 6.488000000000001e-06, 'epoch': 2.25}\n",
      "{'loss': 27.625, 'learning_rate': 6.487000000000001e-06, 'epoch': 2.25}\n",
      "{'loss': 27.25, 'learning_rate': 6.486e-06, 'epoch': 2.26}\n",
      "{'loss': 28.5, 'learning_rate': 6.485000000000001e-06, 'epoch': 2.26}\n",
      "{'loss': 27.75, 'learning_rate': 6.484e-06, 'epoch': 2.26}\n",
      "{'loss': 27.375, 'learning_rate': 6.4830000000000004e-06, 'epoch': 2.26}\n",
      "{'loss': 27.125, 'learning_rate': 6.482000000000001e-06, 'epoch': 2.26}\n",
      "{'loss': 27.125, 'learning_rate': 6.481e-06, 'epoch': 2.26}\n",
      "{'loss': 27.0, 'learning_rate': 6.480000000000001e-06, 'epoch': 2.26}\n",
      "{'loss': 27.875, 'learning_rate': 6.479000000000001e-06, 'epoch': 2.26}\n",
      "{'loss': 28.0, 'learning_rate': 6.478000000000001e-06, 'epoch': 2.26}\n",
      "{'loss': 27.625, 'learning_rate': 6.477000000000001e-06, 'epoch': 2.26}\n",
      "{'loss': 27.375, 'learning_rate': 6.476e-06, 'epoch': 2.26}\n",
      "{'loss': 26.375, 'learning_rate': 6.475e-06, 'epoch': 2.26}\n",
      "{'loss': 27.375, 'learning_rate': 6.474e-06, 'epoch': 2.26}\n",
      "{'loss': 27.5, 'learning_rate': 6.4730000000000005e-06, 'epoch': 2.26}\n",
      "{'loss': 27.0, 'learning_rate': 6.472000000000001e-06, 'epoch': 2.26}\n",
      "{'loss': 26.5, 'learning_rate': 6.471e-06, 'epoch': 2.27}\n",
      "{'loss': 27.0, 'learning_rate': 6.470000000000001e-06, 'epoch': 2.27}\n",
      "{'loss': 27.0, 'learning_rate': 6.469000000000001e-06, 'epoch': 2.27}\n",
      "{'loss': 29.375, 'learning_rate': 6.468000000000001e-06, 'epoch': 2.27}\n",
      "{'loss': 28.25, 'learning_rate': 6.467000000000001e-06, 'epoch': 2.27}\n",
      "{'loss': 27.5, 'learning_rate': 6.4660000000000004e-06, 'epoch': 2.27}\n",
      "{'loss': 27.25, 'learning_rate': 6.465e-06, 'epoch': 2.27}\n",
      "{'loss': 27.125, 'learning_rate': 6.464e-06, 'epoch': 2.27}\n",
      "{'loss': 28.125, 'learning_rate': 6.463000000000001e-06, 'epoch': 2.27}\n",
      "{'loss': 27.5, 'learning_rate': 6.462e-06, 'epoch': 2.27}\n",
      "{'loss': 27.375, 'learning_rate': 6.4610000000000005e-06, 'epoch': 2.27}\n",
      "{'loss': 29.625, 'learning_rate': 6.460000000000001e-06, 'epoch': 2.27}\n",
      "{'loss': 27.625, 'learning_rate': 6.459000000000001e-06, 'epoch': 2.27}\n",
      "{'loss': 28.125, 'learning_rate': 6.458000000000001e-06, 'epoch': 2.27}\n",
      "{'loss': 26.5, 'learning_rate': 6.457000000000001e-06, 'epoch': 2.27}\n",
      "{'loss': 26.625, 'learning_rate': 6.456e-06, 'epoch': 2.27}\n",
      "{'loss': 27.0, 'learning_rate': 6.455e-06, 'epoch': 2.28}\n",
      "{'loss': 27.125, 'learning_rate': 6.454e-06, 'epoch': 2.28}\n",
      "{'loss': 27.875, 'learning_rate': 6.453000000000001e-06, 'epoch': 2.28}\n",
      "{'loss': 26.875, 'learning_rate': 6.452e-06, 'epoch': 2.28}\n",
      "{'loss': 26.75, 'learning_rate': 6.451000000000001e-06, 'epoch': 2.28}\n",
      "{'loss': 29.0, 'learning_rate': 6.450000000000001e-06, 'epoch': 2.28}\n",
      "{'loss': 26.875, 'learning_rate': 6.4490000000000004e-06, 'epoch': 2.28}\n",
      "{'loss': 26.0, 'learning_rate': 6.448000000000001e-06, 'epoch': 2.28}\n",
      "{'loss': 29.125, 'learning_rate': 6.447000000000001e-06, 'epoch': 2.28}\n",
      "{'loss': 27.125, 'learning_rate': 6.446e-06, 'epoch': 2.28}\n",
      "{'loss': 26.5, 'learning_rate': 6.445e-06, 'epoch': 2.28}\n",
      "{'loss': 27.375, 'learning_rate': 6.4440000000000005e-06, 'epoch': 2.28}\n",
      "{'loss': 27.125, 'learning_rate': 6.443e-06, 'epoch': 2.28}\n",
      "{'loss': 27.25, 'learning_rate': 6.442e-06, 'epoch': 2.28}\n",
      "{'loss': 26.5, 'learning_rate': 6.441000000000001e-06, 'epoch': 2.28}\n",
      "{'loss': 27.875, 'learning_rate': 6.440000000000001e-06, 'epoch': 2.28}\n",
      "{'loss': 27.375, 'learning_rate': 6.4390000000000005e-06, 'epoch': 2.29}\n",
      "{'loss': 27.75, 'learning_rate': 6.438000000000001e-06, 'epoch': 2.29}\n",
      "{'loss': 28.125, 'learning_rate': 6.437000000000001e-06, 'epoch': 2.29}\n",
      "{'loss': 27.875, 'learning_rate': 6.436e-06, 'epoch': 2.29}\n",
      "{'loss': 27.25, 'learning_rate': 6.435e-06, 'epoch': 2.29}\n",
      "{'loss': 27.0, 'learning_rate': 6.4340000000000006e-06, 'epoch': 2.29}\n",
      "{'loss': 27.5, 'learning_rate': 6.433e-06, 'epoch': 2.29}\n",
      "{'loss': 28.375, 'learning_rate': 6.432e-06, 'epoch': 2.29}\n",
      "{'loss': 27.875, 'learning_rate': 6.431000000000001e-06, 'epoch': 2.29}\n",
      "{'loss': 27.625, 'learning_rate': 6.43e-06, 'epoch': 2.29}\n",
      "{'loss': 28.875, 'learning_rate': 6.429000000000001e-06, 'epoch': 2.29}\n",
      "{'loss': 27.875, 'learning_rate': 6.428000000000001e-06, 'epoch': 2.29}\n",
      "{'loss': 27.75, 'learning_rate': 6.427000000000001e-06, 'epoch': 2.29}\n",
      "{'loss': 27.875, 'learning_rate': 6.426e-06, 'epoch': 2.29}\n",
      "{'loss': 26.875, 'learning_rate': 6.425e-06, 'epoch': 2.29}\n",
      "{'loss': 27.5, 'learning_rate': 6.424e-06, 'epoch': 2.3}\n",
      "{'loss': 27.625, 'learning_rate': 6.423e-06, 'epoch': 2.3}\n",
      "{'loss': 27.375, 'learning_rate': 6.4220000000000005e-06, 'epoch': 2.3}\n",
      "{'loss': 26.875, 'learning_rate': 6.421000000000001e-06, 'epoch': 2.3}\n",
      "{'loss': 26.75, 'learning_rate': 6.42e-06, 'epoch': 2.3}\n",
      "{'loss': 28.5, 'learning_rate': 6.419000000000001e-06, 'epoch': 2.3}\n",
      "{'loss': 27.625, 'learning_rate': 6.418000000000001e-06, 'epoch': 2.3}\n",
      "{'loss': 27.25, 'learning_rate': 6.417000000000001e-06, 'epoch': 2.3}\n",
      "{'loss': 29.25, 'learning_rate': 6.416e-06, 'epoch': 2.3}\n",
      "{'loss': 26.875, 'learning_rate': 6.415e-06, 'epoch': 2.3}\n",
      "{'loss': 27.0, 'learning_rate': 6.414e-06, 'epoch': 2.3}\n",
      "{'loss': 28.625, 'learning_rate': 6.413e-06, 'epoch': 2.3}\n",
      "{'loss': 29.25, 'learning_rate': 6.412000000000001e-06, 'epoch': 2.3}\n",
      "{'loss': 26.5, 'learning_rate': 6.411000000000001e-06, 'epoch': 2.3}\n",
      "{'loss': 28.375, 'learning_rate': 6.4100000000000005e-06, 'epoch': 2.3}\n",
      "{'loss': 27.25, 'learning_rate': 6.409000000000001e-06, 'epoch': 2.3}\n",
      "{'loss': 28.25, 'learning_rate': 6.408000000000001e-06, 'epoch': 2.31}\n",
      "{'loss': 27.75, 'learning_rate': 6.407000000000001e-06, 'epoch': 2.31}\n",
      "{'loss': 29.75, 'learning_rate': 6.406e-06, 'epoch': 2.31}\n",
      "{'loss': 26.625, 'learning_rate': 6.4050000000000005e-06, 'epoch': 2.31}\n",
      "{'loss': 28.0, 'learning_rate': 6.404e-06, 'epoch': 2.31}\n",
      "{'loss': 27.5, 'learning_rate': 6.403e-06, 'epoch': 2.31}\n",
      "{'loss': 29.875, 'learning_rate': 6.402000000000001e-06, 'epoch': 2.31}\n",
      "{'loss': 27.125, 'learning_rate': 6.401e-06, 'epoch': 2.31}\n",
      "{'loss': 27.875, 'learning_rate': 6.4000000000000006e-06, 'epoch': 2.31}\n",
      "{'loss': 27.5, 'learning_rate': 6.399000000000001e-06, 'epoch': 2.31}\n",
      "{'loss': 26.875, 'learning_rate': 6.398000000000001e-06, 'epoch': 2.31}\n",
      "{'loss': 29.875, 'learning_rate': 6.397000000000001e-06, 'epoch': 2.31}\n",
      "{'loss': 29.5, 'learning_rate': 6.396e-06, 'epoch': 2.31}\n",
      "{'loss': 27.5, 'learning_rate': 6.395e-06, 'epoch': 2.31}\n",
      "{'loss': 28.375, 'learning_rate': 6.394e-06, 'epoch': 2.31}\n",
      "{'loss': 26.875, 'learning_rate': 6.3930000000000005e-06, 'epoch': 2.32}\n",
      "{'loss': 28.0, 'learning_rate': 6.392000000000001e-06, 'epoch': 2.32}\n",
      "{'loss': 30.0, 'learning_rate': 6.391e-06, 'epoch': 2.32}\n",
      "{'loss': 26.75, 'learning_rate': 6.390000000000001e-06, 'epoch': 2.32}\n",
      "{'loss': 27.0, 'learning_rate': 6.389000000000001e-06, 'epoch': 2.32}\n",
      "{'loss': 27.5, 'learning_rate': 6.3880000000000005e-06, 'epoch': 2.32}\n",
      "{'loss': 27.0, 'learning_rate': 6.387000000000001e-06, 'epoch': 2.32}\n",
      "{'loss': 27.5, 'learning_rate': 6.386e-06, 'epoch': 2.32}\n",
      "{'loss': 29.25, 'learning_rate': 6.385e-06, 'epoch': 2.32}\n",
      "{'loss': 27.125, 'learning_rate': 6.384e-06, 'epoch': 2.32}\n",
      "{'loss': 26.5, 'learning_rate': 6.3830000000000006e-06, 'epoch': 2.32}\n",
      "{'loss': 28.25, 'learning_rate': 6.382e-06, 'epoch': 2.32}\n",
      "{'loss': 27.75, 'learning_rate': 6.381e-06, 'epoch': 2.32}\n",
      "{'loss': 27.375, 'learning_rate': 6.380000000000001e-06, 'epoch': 2.32}\n",
      "{'loss': 27.75, 'learning_rate': 6.379000000000001e-06, 'epoch': 2.32}\n",
      "{'loss': 28.0, 'learning_rate': 6.378000000000001e-06, 'epoch': 2.32}\n",
      "{'loss': 27.375, 'learning_rate': 6.377000000000001e-06, 'epoch': 2.33}\n",
      "{'loss': 26.25, 'learning_rate': 6.376e-06, 'epoch': 2.33}\n",
      "{'loss': 26.625, 'learning_rate': 6.375e-06, 'epoch': 2.33}\n",
      "{'loss': 27.75, 'learning_rate': 6.374e-06, 'epoch': 2.33}\n",
      "{'loss': 27.0, 'learning_rate': 6.373000000000001e-06, 'epoch': 2.33}\n",
      "{'loss': 26.875, 'learning_rate': 6.372e-06, 'epoch': 2.33}\n",
      "{'loss': 26.875, 'learning_rate': 6.3710000000000005e-06, 'epoch': 2.33}\n",
      "{'loss': 26.875, 'learning_rate': 6.370000000000001e-06, 'epoch': 2.33}\n",
      "{'loss': 29.125, 'learning_rate': 6.369e-06, 'epoch': 2.33}\n",
      "{'loss': 26.875, 'learning_rate': 6.368000000000001e-06, 'epoch': 2.33}\n",
      "{'loss': 27.5, 'learning_rate': 6.367000000000001e-06, 'epoch': 2.33}\n",
      "{'loss': 27.875, 'learning_rate': 6.366000000000001e-06, 'epoch': 2.33}\n",
      "{'loss': 27.625, 'learning_rate': 6.365e-06, 'epoch': 2.33}\n",
      "{'loss': 27.875, 'learning_rate': 6.364e-06, 'epoch': 2.33}\n",
      "{'loss': 26.125, 'learning_rate': 6.363e-06, 'epoch': 2.33}\n",
      "{'loss': 26.375, 'learning_rate': 6.362e-06, 'epoch': 2.34}\n",
      "{'loss': 26.0, 'learning_rate': 6.361000000000001e-06, 'epoch': 2.34}\n",
      "{'loss': 27.625, 'learning_rate': 6.360000000000001e-06, 'epoch': 2.34}\n",
      "{'loss': 28.625, 'learning_rate': 6.3590000000000004e-06, 'epoch': 2.34}\n",
      "{'loss': 27.625, 'learning_rate': 6.358000000000001e-06, 'epoch': 2.34}\n",
      "{'loss': 26.75, 'learning_rate': 6.357000000000001e-06, 'epoch': 2.34}\n",
      "{'loss': 28.625, 'learning_rate': 6.356000000000001e-06, 'epoch': 2.34}\n",
      "{'loss': 27.5, 'learning_rate': 6.355e-06, 'epoch': 2.34}\n",
      "{'loss': 26.25, 'learning_rate': 6.3540000000000005e-06, 'epoch': 2.34}\n",
      "{'loss': 29.25, 'learning_rate': 6.353e-06, 'epoch': 2.34}\n",
      "{'loss': 28.0, 'learning_rate': 6.352e-06, 'epoch': 2.34}\n",
      "{'loss': 27.75, 'learning_rate': 6.351000000000001e-06, 'epoch': 2.34}\n",
      "{'loss': 27.125, 'learning_rate': 6.35e-06, 'epoch': 2.34}\n",
      "{'loss': 27.75, 'learning_rate': 6.3490000000000005e-06, 'epoch': 2.34}\n",
      "{'loss': 28.5, 'learning_rate': 6.348000000000001e-06, 'epoch': 2.34}\n",
      "{'loss': 27.125, 'learning_rate': 6.347000000000001e-06, 'epoch': 2.34}\n",
      "{'loss': 27.5, 'learning_rate': 6.346000000000001e-06, 'epoch': 2.35}\n",
      "{'loss': 27.25, 'learning_rate': 6.345e-06, 'epoch': 2.35}\n",
      "{'loss': 26.875, 'learning_rate': 6.344e-06, 'epoch': 2.35}\n",
      "{'loss': 27.125, 'learning_rate': 6.343e-06, 'epoch': 2.35}\n",
      "{'loss': 29.0, 'learning_rate': 6.3420000000000004e-06, 'epoch': 2.35}\n",
      "{'loss': 26.25, 'learning_rate': 6.341000000000001e-06, 'epoch': 2.35}\n",
      "{'loss': 27.25, 'learning_rate': 6.34e-06, 'epoch': 2.35}\n",
      "{'loss': 27.375, 'learning_rate': 6.339000000000001e-06, 'epoch': 2.35}\n",
      "{'loss': 29.125, 'learning_rate': 6.338000000000001e-06, 'epoch': 2.35}\n",
      "{'loss': 27.625, 'learning_rate': 6.337000000000001e-06, 'epoch': 2.35}\n",
      "{'loss': 27.875, 'learning_rate': 6.336000000000001e-06, 'epoch': 2.35}\n",
      "{'loss': 27.125, 'learning_rate': 6.335e-06, 'epoch': 2.35}\n",
      "{'loss': 27.125, 'learning_rate': 6.334e-06, 'epoch': 2.35}\n",
      "{'loss': 26.25, 'learning_rate': 6.333e-06, 'epoch': 2.35}\n",
      "{'loss': 27.5, 'learning_rate': 6.3320000000000005e-06, 'epoch': 2.35}\n",
      "{'loss': 26.875, 'learning_rate': 6.331000000000001e-06, 'epoch': 2.35}\n",
      "{'loss': 26.625, 'learning_rate': 6.33e-06, 'epoch': 2.36}\n",
      "{'loss': 26.75, 'learning_rate': 6.329000000000001e-06, 'epoch': 2.36}\n",
      "{'loss': 27.375, 'learning_rate': 6.328000000000001e-06, 'epoch': 2.36}\n",
      "{'loss': 27.25, 'learning_rate': 6.327000000000001e-06, 'epoch': 2.36}\n",
      "{'loss': 28.5, 'learning_rate': 6.326000000000001e-06, 'epoch': 2.36}\n",
      "{'loss': 27.25, 'learning_rate': 6.3250000000000004e-06, 'epoch': 2.36}\n",
      "{'loss': 26.5, 'learning_rate': 6.324e-06, 'epoch': 2.36}\n",
      "{'loss': 26.875, 'learning_rate': 6.323e-06, 'epoch': 2.36}\n",
      "{'loss': 27.0, 'learning_rate': 6.322000000000001e-06, 'epoch': 2.36}\n",
      "{'loss': 26.75, 'learning_rate': 6.321e-06, 'epoch': 2.36}\n",
      "{'loss': 28.125, 'learning_rate': 6.3200000000000005e-06, 'epoch': 2.36}\n",
      "{'loss': 27.25, 'learning_rate': 6.319000000000001e-06, 'epoch': 2.36}\n",
      "{'loss': 26.125, 'learning_rate': 6.318000000000001e-06, 'epoch': 2.36}\n",
      "{'loss': 26.625, 'learning_rate': 6.317000000000001e-06, 'epoch': 2.36}\n",
      "{'loss': 27.25, 'learning_rate': 6.316000000000001e-06, 'epoch': 2.36}\n",
      "{'loss': 27.125, 'learning_rate': 6.315e-06, 'epoch': 2.37}\n",
      "{'loss': 27.125, 'learning_rate': 6.314e-06, 'epoch': 2.37}\n",
      "{'loss': 27.375, 'learning_rate': 6.313e-06, 'epoch': 2.37}\n",
      "{'loss': 27.125, 'learning_rate': 6.312000000000001e-06, 'epoch': 2.37}\n",
      "{'loss': 28.375, 'learning_rate': 6.311e-06, 'epoch': 2.37}\n",
      "{'loss': 27.625, 'learning_rate': 6.3100000000000006e-06, 'epoch': 2.37}\n",
      "{'loss': 27.375, 'learning_rate': 6.309000000000001e-06, 'epoch': 2.37}\n",
      "{'loss': 27.625, 'learning_rate': 6.308e-06, 'epoch': 2.37}\n",
      "{'loss': 29.0, 'learning_rate': 6.307000000000001e-06, 'epoch': 2.37}\n",
      "{'loss': 26.875, 'learning_rate': 6.306000000000001e-06, 'epoch': 2.37}\n",
      "{'loss': 27.0, 'learning_rate': 6.305e-06, 'epoch': 2.37}\n",
      "{'loss': 26.25, 'learning_rate': 6.304e-06, 'epoch': 2.37}\n",
      "{'loss': 27.0, 'learning_rate': 6.3030000000000005e-06, 'epoch': 2.37}\n",
      "{'loss': 27.625, 'learning_rate': 6.302e-06, 'epoch': 2.37}\n",
      "{'loss': 27.375, 'learning_rate': 6.301e-06, 'epoch': 2.37}\n",
      "{'loss': 28.25, 'learning_rate': 6.300000000000001e-06, 'epoch': 2.37}\n",
      "{'loss': 27.875, 'learning_rate': 6.299000000000001e-06, 'epoch': 2.38}\n",
      "{'loss': 27.875, 'learning_rate': 6.2980000000000005e-06, 'epoch': 2.38}\n",
      "{'loss': 28.5, 'learning_rate': 6.297000000000001e-06, 'epoch': 2.38}\n",
      "{'loss': 28.625, 'learning_rate': 6.296000000000001e-06, 'epoch': 2.38}\n",
      "{'loss': 28.75, 'learning_rate': 6.295e-06, 'epoch': 2.38}\n",
      "{'loss': 27.75, 'learning_rate': 6.294e-06, 'epoch': 2.38}\n",
      "{'loss': 26.125, 'learning_rate': 6.2930000000000006e-06, 'epoch': 2.38}\n",
      "{'loss': 27.375, 'learning_rate': 6.292e-06, 'epoch': 2.38}\n",
      "{'loss': 28.0, 'learning_rate': 6.291e-06, 'epoch': 2.38}\n",
      "{'loss': 27.625, 'learning_rate': 6.290000000000001e-06, 'epoch': 2.38}\n",
      "{'loss': 27.75, 'learning_rate': 6.289e-06, 'epoch': 2.38}\n",
      "{'loss': 26.75, 'learning_rate': 6.288000000000001e-06, 'epoch': 2.38}\n",
      "{'loss': 27.875, 'learning_rate': 6.287000000000001e-06, 'epoch': 2.38}\n",
      "{'loss': 28.125, 'learning_rate': 6.286000000000001e-06, 'epoch': 2.38}\n",
      "{'loss': 26.625, 'learning_rate': 6.285e-06, 'epoch': 2.38}\n",
      "{'loss': 27.75, 'learning_rate': 6.284e-06, 'epoch': 2.39}\n",
      "{'loss': 28.625, 'learning_rate': 6.283e-06, 'epoch': 2.39}\n",
      "{'loss': 26.75, 'learning_rate': 6.282e-06, 'epoch': 2.39}\n",
      "{'loss': 29.5, 'learning_rate': 6.2810000000000005e-06, 'epoch': 2.39}\n",
      "{'loss': 27.625, 'learning_rate': 6.280000000000001e-06, 'epoch': 2.39}\n",
      "{'loss': 27.0, 'learning_rate': 6.279e-06, 'epoch': 2.39}\n",
      "{'loss': 26.5, 'learning_rate': 6.278000000000001e-06, 'epoch': 2.39}\n",
      "{'loss': 30.25, 'learning_rate': 6.277000000000001e-06, 'epoch': 2.39}\n",
      "{'loss': 27.25, 'learning_rate': 6.2760000000000006e-06, 'epoch': 2.39}\n",
      "{'loss': 27.25, 'learning_rate': 6.275e-06, 'epoch': 2.39}\n",
      "{'loss': 26.75, 'learning_rate': 6.274e-06, 'epoch': 2.39}\n",
      "{'loss': 26.875, 'learning_rate': 6.273e-06, 'epoch': 2.39}\n",
      "{'loss': 31.75, 'learning_rate': 6.272e-06, 'epoch': 2.39}\n",
      "{'loss': 28.625, 'learning_rate': 6.271000000000001e-06, 'epoch': 2.39}\n",
      "{'loss': 27.625, 'learning_rate': 6.27e-06, 'epoch': 2.39}\n",
      "{'loss': 26.75, 'learning_rate': 6.2690000000000005e-06, 'epoch': 2.39}\n",
      "{'loss': 27.375, 'learning_rate': 6.268000000000001e-06, 'epoch': 2.4}\n",
      "{'loss': 26.625, 'learning_rate': 6.267000000000001e-06, 'epoch': 2.4}\n",
      "{'loss': 27.625, 'learning_rate': 6.266000000000001e-06, 'epoch': 2.4}\n",
      "{'loss': 27.5, 'learning_rate': 6.265e-06, 'epoch': 2.4}\n",
      "{'loss': 28.875, 'learning_rate': 6.264e-06, 'epoch': 2.4}\n",
      "{'loss': 27.875, 'learning_rate': 6.263e-06, 'epoch': 2.4}\n",
      "{'loss': 28.875, 'learning_rate': 6.262e-06, 'epoch': 2.4}\n",
      "{'loss': 27.75, 'learning_rate': 6.261000000000001e-06, 'epoch': 2.4}\n",
      "{'loss': 27.625, 'learning_rate': 6.26e-06, 'epoch': 2.4}\n",
      "{'loss': 26.625, 'learning_rate': 6.2590000000000006e-06, 'epoch': 2.4}\n",
      "{'loss': 27.0, 'learning_rate': 6.258000000000001e-06, 'epoch': 2.4}\n",
      "{'loss': 28.75, 'learning_rate': 6.257000000000001e-06, 'epoch': 2.4}\n",
      "{'loss': 27.0, 'learning_rate': 6.256000000000001e-06, 'epoch': 2.4}\n",
      "{'loss': 27.5, 'learning_rate': 6.255e-06, 'epoch': 2.4}\n",
      "{'loss': 27.375, 'learning_rate': 6.254e-06, 'epoch': 2.4}\n",
      "{'loss': 30.375, 'learning_rate': 6.253e-06, 'epoch': 2.41}\n",
      "{'loss': 28.25, 'learning_rate': 6.2520000000000004e-06, 'epoch': 2.41}\n",
      "{'loss': 27.75, 'learning_rate': 6.251000000000001e-06, 'epoch': 2.41}\n",
      "{'loss': 28.125, 'learning_rate': 6.25e-06, 'epoch': 2.41}\n",
      "{'loss': 27.5, 'learning_rate': 6.249000000000001e-06, 'epoch': 2.41}\n",
      "{'loss': 27.5, 'learning_rate': 6.248000000000001e-06, 'epoch': 2.41}\n",
      "{'loss': 27.75, 'learning_rate': 6.2470000000000005e-06, 'epoch': 2.41}\n",
      "{'loss': 28.75, 'learning_rate': 6.246000000000001e-06, 'epoch': 2.41}\n",
      "{'loss': 27.5, 'learning_rate': 6.245000000000001e-06, 'epoch': 2.41}\n",
      "{'loss': 26.75, 'learning_rate': 6.244e-06, 'epoch': 2.41}\n",
      "{'loss': 27.625, 'learning_rate': 6.243e-06, 'epoch': 2.41}\n",
      "{'loss': 27.375, 'learning_rate': 6.2420000000000005e-06, 'epoch': 2.41}\n",
      "{'loss': 26.875, 'learning_rate': 6.241e-06, 'epoch': 2.41}\n",
      "{'loss': 28.875, 'learning_rate': 6.24e-06, 'epoch': 2.41}\n",
      "{'loss': 27.25, 'learning_rate': 6.239000000000001e-06, 'epoch': 2.41}\n",
      "{'loss': 28.0, 'learning_rate': 6.238000000000001e-06, 'epoch': 2.41}\n",
      "{'loss': 27.125, 'learning_rate': 6.237000000000001e-06, 'epoch': 2.42}\n",
      "{'loss': 27.875, 'learning_rate': 6.236000000000001e-06, 'epoch': 2.42}\n",
      "{'loss': 27.625, 'learning_rate': 6.235000000000001e-06, 'epoch': 2.42}\n",
      "{'loss': 26.375, 'learning_rate': 6.234e-06, 'epoch': 2.42}\n",
      "{'loss': 28.375, 'learning_rate': 6.233e-06, 'epoch': 2.42}\n",
      "{'loss': 30.25, 'learning_rate': 6.232000000000001e-06, 'epoch': 2.42}\n",
      "{'loss': 27.625, 'learning_rate': 6.231e-06, 'epoch': 2.42}\n",
      "{'loss': 27.5, 'learning_rate': 6.2300000000000005e-06, 'epoch': 2.42}\n",
      "{'loss': 28.625, 'learning_rate': 6.229000000000001e-06, 'epoch': 2.42}\n",
      "{'loss': 29.25, 'learning_rate': 6.228e-06, 'epoch': 2.42}\n",
      "{'loss': 25.625, 'learning_rate': 6.227000000000001e-06, 'epoch': 2.42}\n",
      "{'loss': 27.375, 'learning_rate': 6.226000000000001e-06, 'epoch': 2.42}\n",
      "{'loss': 26.75, 'learning_rate': 6.225000000000001e-06, 'epoch': 2.42}\n",
      "{'loss': 28.625, 'learning_rate': 6.224e-06, 'epoch': 2.42}\n",
      "{'loss': 27.875, 'learning_rate': 6.223e-06, 'epoch': 2.42}\n",
      "{'loss': 30.125, 'learning_rate': 6.222e-06, 'epoch': 2.42}\n",
      "{'loss': 27.25, 'learning_rate': 6.221e-06, 'epoch': 2.43}\n",
      "{'loss': 27.0, 'learning_rate': 6.220000000000001e-06, 'epoch': 2.43}\n",
      "{'loss': 27.0, 'learning_rate': 6.219000000000001e-06, 'epoch': 2.43}\n",
      "{'loss': 28.375, 'learning_rate': 6.2180000000000004e-06, 'epoch': 2.43}\n",
      "{'loss': 26.75, 'learning_rate': 6.217000000000001e-06, 'epoch': 2.43}\n",
      "{'loss': 27.25, 'learning_rate': 6.216000000000001e-06, 'epoch': 2.43}\n",
      "{'loss': 27.0, 'learning_rate': 6.215000000000001e-06, 'epoch': 2.43}\n",
      "{'loss': 28.125, 'learning_rate': 6.214e-06, 'epoch': 2.43}\n",
      "{'loss': 27.625, 'learning_rate': 6.2130000000000005e-06, 'epoch': 2.43}\n",
      "{'loss': 31.125, 'learning_rate': 6.212e-06, 'epoch': 2.43}\n",
      "{'loss': 27.875, 'learning_rate': 6.211e-06, 'epoch': 2.43}\n",
      "{'loss': 28.75, 'learning_rate': 6.210000000000001e-06, 'epoch': 2.43}\n",
      "{'loss': 27.5, 'learning_rate': 6.209e-06, 'epoch': 2.43}\n",
      "{'loss': 26.875, 'learning_rate': 6.2080000000000005e-06, 'epoch': 2.43}\n",
      "{'loss': 27.25, 'learning_rate': 6.207000000000001e-06, 'epoch': 2.43}\n",
      "{'loss': 27.0, 'learning_rate': 6.206000000000001e-06, 'epoch': 2.44}\n",
      "{'loss': 26.5, 'learning_rate': 6.205000000000001e-06, 'epoch': 2.44}\n",
      "{'loss': 26.5, 'learning_rate': 6.204e-06, 'epoch': 2.44}\n",
      "{'loss': 27.875, 'learning_rate': 6.203e-06, 'epoch': 2.44}\n",
      "{'loss': 27.0, 'learning_rate': 6.202e-06, 'epoch': 2.44}\n",
      "{'loss': 28.375, 'learning_rate': 6.2010000000000004e-06, 'epoch': 2.44}\n",
      "{'loss': 29.5, 'learning_rate': 6.200000000000001e-06, 'epoch': 2.44}\n",
      "{'loss': 27.875, 'learning_rate': 6.199e-06, 'epoch': 2.44}\n",
      "{'loss': 27.25, 'learning_rate': 6.198000000000001e-06, 'epoch': 2.44}\n",
      "{'loss': 27.625, 'learning_rate': 6.197000000000001e-06, 'epoch': 2.44}\n",
      "{'loss': 28.125, 'learning_rate': 6.196000000000001e-06, 'epoch': 2.44}\n",
      "{'loss': 26.5, 'learning_rate': 6.195000000000001e-06, 'epoch': 2.44}\n",
      "{'loss': 29.375, 'learning_rate': 6.194e-06, 'epoch': 2.44}\n",
      "{'loss': 27.125, 'learning_rate': 6.193e-06, 'epoch': 2.44}\n",
      "{'loss': 28.0, 'learning_rate': 6.192e-06, 'epoch': 2.44}\n",
      "{'loss': 29.75, 'learning_rate': 6.1910000000000005e-06, 'epoch': 2.44}\n",
      "{'loss': 28.0, 'learning_rate': 6.190000000000001e-06, 'epoch': 2.45}\n",
      "{'loss': 26.875, 'learning_rate': 6.189e-06, 'epoch': 2.45}\n",
      "{'loss': 29.75, 'learning_rate': 6.188000000000001e-06, 'epoch': 2.45}\n",
      "{'loss': 28.125, 'learning_rate': 6.187000000000001e-06, 'epoch': 2.45}\n",
      "{'loss': 27.375, 'learning_rate': 6.1860000000000006e-06, 'epoch': 2.45}\n",
      "{'loss': 27.125, 'learning_rate': 6.185000000000001e-06, 'epoch': 2.45}\n",
      "{'loss': 27.25, 'learning_rate': 6.184e-06, 'epoch': 2.45}\n",
      "{'loss': 27.625, 'learning_rate': 6.183e-06, 'epoch': 2.45}\n",
      "{'loss': 27.0, 'learning_rate': 6.182e-06, 'epoch': 2.45}\n",
      "{'loss': 27.25, 'learning_rate': 6.181000000000001e-06, 'epoch': 2.45}\n",
      "{'loss': 28.125, 'learning_rate': 6.18e-06, 'epoch': 2.45}\n",
      "{'loss': 27.25, 'learning_rate': 6.1790000000000005e-06, 'epoch': 2.45}\n",
      "{'loss': 27.25, 'learning_rate': 6.178000000000001e-06, 'epoch': 2.45}\n",
      "{'loss': 27.125, 'learning_rate': 6.177000000000001e-06, 'epoch': 2.45}\n",
      "{'loss': 27.25, 'learning_rate': 6.176000000000001e-06, 'epoch': 2.45}\n",
      "{'loss': 27.25, 'learning_rate': 6.175000000000001e-06, 'epoch': 2.46}\n",
      "{'loss': 27.625, 'learning_rate': 6.174e-06, 'epoch': 2.46}\n",
      "{'loss': 27.75, 'learning_rate': 6.173e-06, 'epoch': 2.46}\n",
      "{'loss': 27.5, 'learning_rate': 6.172e-06, 'epoch': 2.46}\n",
      "{'loss': 26.625, 'learning_rate': 6.171000000000001e-06, 'epoch': 2.46}\n",
      "{'loss': 30.375, 'learning_rate': 6.17e-06, 'epoch': 2.46}\n",
      "{'loss': 27.75, 'learning_rate': 6.1690000000000006e-06, 'epoch': 2.46}\n",
      "{'loss': 27.0, 'learning_rate': 6.168000000000001e-06, 'epoch': 2.46}\n",
      "{'loss': 27.75, 'learning_rate': 6.167e-06, 'epoch': 2.46}\n",
      "{'loss': 26.625, 'learning_rate': 6.166000000000001e-06, 'epoch': 2.46}\n",
      "{'loss': 27.5, 'learning_rate': 6.165000000000001e-06, 'epoch': 2.46}\n",
      "{'loss': 28.375, 'learning_rate': 6.164e-06, 'epoch': 2.46}\n",
      "{'loss': 29.125, 'learning_rate': 6.163e-06, 'epoch': 2.46}\n",
      "{'loss': 27.75, 'learning_rate': 6.1620000000000005e-06, 'epoch': 2.46}\n",
      "{'loss': 29.375, 'learning_rate': 6.161e-06, 'epoch': 2.46}\n",
      "{'loss': 29.625, 'learning_rate': 6.16e-06, 'epoch': 2.46}\n",
      "{'loss': 28.0, 'learning_rate': 6.159000000000001e-06, 'epoch': 2.47}\n",
      "{'loss': 28.875, 'learning_rate': 6.158000000000001e-06, 'epoch': 2.47}\n",
      "{'loss': 27.5, 'learning_rate': 6.1570000000000005e-06, 'epoch': 2.47}\n",
      "{'loss': 26.5, 'learning_rate': 6.156000000000001e-06, 'epoch': 2.47}\n",
      "{'loss': 29.0, 'learning_rate': 6.155000000000001e-06, 'epoch': 2.47}\n",
      "{'loss': 27.25, 'learning_rate': 6.154e-06, 'epoch': 2.47}\n",
      "{'loss': 28.375, 'learning_rate': 6.153e-06, 'epoch': 2.47}\n",
      "{'loss': 27.625, 'learning_rate': 6.1520000000000006e-06, 'epoch': 2.47}\n",
      "{'loss': 26.625, 'learning_rate': 6.151e-06, 'epoch': 2.47}\n",
      "{'loss': 27.625, 'learning_rate': 6.15e-06, 'epoch': 2.47}\n",
      "{'loss': 28.375, 'learning_rate': 6.149000000000001e-06, 'epoch': 2.47}\n",
      "{'loss': 28.75, 'learning_rate': 6.148e-06, 'epoch': 2.47}\n",
      "{'loss': 28.875, 'learning_rate': 6.147000000000001e-06, 'epoch': 2.47}\n",
      "{'loss': 28.375, 'learning_rate': 6.146000000000001e-06, 'epoch': 2.47}\n",
      "{'loss': 27.375, 'learning_rate': 6.145000000000001e-06, 'epoch': 2.47}\n",
      "{'loss': 27.125, 'learning_rate': 6.144e-06, 'epoch': 2.47}\n",
      "{'loss': 26.875, 'learning_rate': 6.143e-06, 'epoch': 2.48}\n",
      "{'loss': 29.375, 'learning_rate': 6.142e-06, 'epoch': 2.48}\n",
      "{'loss': 26.125, 'learning_rate': 6.141e-06, 'epoch': 2.48}\n",
      "{'loss': 26.0, 'learning_rate': 6.1400000000000005e-06, 'epoch': 2.48}\n",
      "{'loss': 27.75, 'learning_rate': 6.139000000000001e-06, 'epoch': 2.48}\n",
      "{'loss': 29.75, 'learning_rate': 6.138e-06, 'epoch': 2.48}\n",
      "{'loss': 27.875, 'learning_rate': 6.137000000000001e-06, 'epoch': 2.48}\n",
      "{'loss': 26.75, 'learning_rate': 6.136000000000001e-06, 'epoch': 2.48}\n",
      "{'loss': 26.75, 'learning_rate': 6.1350000000000006e-06, 'epoch': 2.48}\n",
      "{'loss': 27.25, 'learning_rate': 6.134e-06, 'epoch': 2.48}\n",
      "{'loss': 26.625, 'learning_rate': 6.133e-06, 'epoch': 2.48}\n",
      "{'loss': 27.125, 'learning_rate': 6.132e-06, 'epoch': 2.48}\n",
      "{'loss': 27.0, 'learning_rate': 6.131e-06, 'epoch': 2.48}\n",
      "{'loss': 27.75, 'learning_rate': 6.130000000000001e-06, 'epoch': 2.48}\n",
      "{'loss': 28.625, 'learning_rate': 6.129e-06, 'epoch': 2.48}\n",
      "{'loss': 27.75, 'learning_rate': 6.1280000000000005e-06, 'epoch': 2.49}\n",
      "{'loss': 27.75, 'learning_rate': 6.127000000000001e-06, 'epoch': 2.49}\n",
      "{'loss': 28.125, 'learning_rate': 6.126000000000001e-06, 'epoch': 2.49}\n",
      "{'loss': 27.125, 'learning_rate': 6.125000000000001e-06, 'epoch': 2.49}\n",
      "{'loss': 28.25, 'learning_rate': 6.124000000000001e-06, 'epoch': 2.49}\n",
      "{'loss': 28.25, 'learning_rate': 6.123e-06, 'epoch': 2.49}\n",
      "{'loss': 27.25, 'learning_rate': 6.122e-06, 'epoch': 2.49}\n",
      "{'loss': 29.0, 'learning_rate': 6.121e-06, 'epoch': 2.49}\n",
      "{'loss': 28.25, 'learning_rate': 6.120000000000001e-06, 'epoch': 2.49}\n",
      "{'loss': 28.125, 'learning_rate': 6.119e-06, 'epoch': 2.49}\n",
      "{'loss': 27.125, 'learning_rate': 6.1180000000000005e-06, 'epoch': 2.49}\n",
      "{'loss': 27.25, 'learning_rate': 6.117000000000001e-06, 'epoch': 2.49}\n",
      "{'loss': 32.25, 'learning_rate': 6.116000000000001e-06, 'epoch': 2.49}\n",
      "{'loss': 27.75, 'learning_rate': 6.115000000000001e-06, 'epoch': 2.49}\n",
      "{'loss': 29.625, 'learning_rate': 6.114000000000001e-06, 'epoch': 2.49}\n",
      "{'loss': 28.875, 'learning_rate': 6.113e-06, 'epoch': 2.49}\n",
      "{'loss': 27.625, 'learning_rate': 6.112e-06, 'epoch': 2.5}\n",
      "{'loss': 27.625, 'learning_rate': 6.1110000000000004e-06, 'epoch': 2.5}\n",
      "{'loss': 27.375, 'learning_rate': 6.110000000000001e-06, 'epoch': 2.5}\n",
      "{'loss': 27.75, 'learning_rate': 6.109e-06, 'epoch': 2.5}\n",
      "{'loss': 28.875, 'learning_rate': 6.108000000000001e-06, 'epoch': 2.5}\n",
      "{'loss': 27.5, 'learning_rate': 6.107000000000001e-06, 'epoch': 2.5}\n",
      "{'loss': 28.0, 'learning_rate': 6.1060000000000005e-06, 'epoch': 2.5}\n",
      "{'loss': 29.75, 'learning_rate': 6.105000000000001e-06, 'epoch': 2.5}\n",
      "{'loss': 27.25, 'learning_rate': 6.104000000000001e-06, 'epoch': 2.5}\n",
      "{'loss': 26.875, 'learning_rate': 6.103e-06, 'epoch': 2.5}\n",
      "{'loss': 28.875, 'learning_rate': 6.102e-06, 'epoch': 2.5}\n",
      "{'loss': 27.375, 'learning_rate': 6.1010000000000005e-06, 'epoch': 2.5}\n",
      "{'loss': 27.75, 'learning_rate': 6.1e-06, 'epoch': 2.5}\n",
      "{'loss': 27.5, 'learning_rate': 6.099e-06, 'epoch': 2.5}\n",
      "{'loss': 26.875, 'learning_rate': 6.098000000000001e-06, 'epoch': 2.5}\n",
      "{'loss': 30.125, 'learning_rate': 6.097000000000001e-06, 'epoch': 2.51}\n",
      "{'loss': 28.375, 'learning_rate': 6.096000000000001e-06, 'epoch': 2.51}\n",
      "{'loss': 29.5, 'learning_rate': 6.095000000000001e-06, 'epoch': 2.51}\n",
      "{'loss': 27.125, 'learning_rate': 6.094000000000001e-06, 'epoch': 2.51}\n",
      "{'loss': 27.25, 'learning_rate': 6.093e-06, 'epoch': 2.51}\n",
      "{'loss': 28.0, 'learning_rate': 6.092e-06, 'epoch': 2.51}\n",
      "{'loss': 28.625, 'learning_rate': 6.091000000000001e-06, 'epoch': 2.51}\n",
      "{'loss': 28.25, 'learning_rate': 6.09e-06, 'epoch': 2.51}\n",
      "{'loss': 26.375, 'learning_rate': 6.0890000000000005e-06, 'epoch': 2.51}\n",
      "{'loss': 27.125, 'learning_rate': 6.088000000000001e-06, 'epoch': 2.51}\n",
      "{'loss': 28.125, 'learning_rate': 6.087e-06, 'epoch': 2.51}\n",
      "{'loss': 26.875, 'learning_rate': 6.086000000000001e-06, 'epoch': 2.51}\n",
      "{'loss': 26.625, 'learning_rate': 6.085000000000001e-06, 'epoch': 2.51}\n",
      "{'loss': 26.625, 'learning_rate': 6.084000000000001e-06, 'epoch': 2.51}\n",
      "{'loss': 29.375, 'learning_rate': 6.083e-06, 'epoch': 2.51}\n",
      "{'loss': 27.0, 'learning_rate': 6.082e-06, 'epoch': 2.51}\n",
      "{'loss': 27.375, 'learning_rate': 6.081e-06, 'epoch': 2.52}\n",
      "{'loss': 26.5, 'learning_rate': 6.08e-06, 'epoch': 2.52}\n",
      "{'loss': 28.125, 'learning_rate': 6.079000000000001e-06, 'epoch': 2.52}\n",
      "{'loss': 28.125, 'learning_rate': 6.078000000000001e-06, 'epoch': 2.52}\n",
      "{'loss': 27.25, 'learning_rate': 6.0770000000000004e-06, 'epoch': 2.52}\n",
      "{'loss': 28.375, 'learning_rate': 6.076000000000001e-06, 'epoch': 2.52}\n",
      "{'loss': 26.875, 'learning_rate': 6.075000000000001e-06, 'epoch': 2.52}\n",
      "{'loss': 27.875, 'learning_rate': 6.074000000000001e-06, 'epoch': 2.52}\n",
      "{'loss': 29.875, 'learning_rate': 6.073e-06, 'epoch': 2.52}\n",
      "{'loss': 29.125, 'learning_rate': 6.0720000000000005e-06, 'epoch': 2.52}\n",
      "{'loss': 26.0, 'learning_rate': 6.071e-06, 'epoch': 2.52}\n",
      "{'loss': 28.625, 'learning_rate': 6.07e-06, 'epoch': 2.52}\n",
      "{'loss': 27.25, 'learning_rate': 6.069000000000001e-06, 'epoch': 2.52}\n",
      "{'loss': 27.375, 'learning_rate': 6.068e-06, 'epoch': 2.52}\n",
      "{'loss': 27.125, 'learning_rate': 6.0670000000000005e-06, 'epoch': 2.52}\n",
      "{'loss': 27.875, 'learning_rate': 6.066000000000001e-06, 'epoch': 2.53}\n",
      "{'loss': 27.375, 'learning_rate': 6.065000000000001e-06, 'epoch': 2.53}\n",
      "{'loss': 28.625, 'learning_rate': 6.064000000000001e-06, 'epoch': 2.53}\n",
      "{'loss': 29.125, 'learning_rate': 6.063e-06, 'epoch': 2.53}\n",
      "{'loss': 26.875, 'learning_rate': 6.062e-06, 'epoch': 2.53}\n",
      "{'loss': 26.625, 'learning_rate': 6.061e-06, 'epoch': 2.53}\n",
      "{'loss': 27.5, 'learning_rate': 6.0600000000000004e-06, 'epoch': 2.53}\n",
      "{'loss': 28.125, 'learning_rate': 6.059000000000001e-06, 'epoch': 2.53}\n",
      "{'loss': 28.375, 'learning_rate': 6.058e-06, 'epoch': 2.53}\n",
      "{'loss': 27.25, 'learning_rate': 6.057000000000001e-06, 'epoch': 2.53}\n",
      "{'loss': 27.875, 'learning_rate': 6.056000000000001e-06, 'epoch': 2.53}\n",
      "{'loss': 26.5, 'learning_rate': 6.0550000000000005e-06, 'epoch': 2.53}\n",
      "{'loss': 27.5, 'learning_rate': 6.054000000000001e-06, 'epoch': 2.53}\n",
      "{'loss': 26.75, 'learning_rate': 6.053e-06, 'epoch': 2.53}\n",
      "{'loss': 28.25, 'learning_rate': 6.052e-06, 'epoch': 2.53}\n",
      "{'loss': 26.5, 'learning_rate': 6.051e-06, 'epoch': 2.53}\n",
      "{'loss': 29.25, 'learning_rate': 6.0500000000000005e-06, 'epoch': 2.54}\n",
      "{'loss': 27.75, 'learning_rate': 6.049e-06, 'epoch': 2.54}\n",
      "{'loss': 26.875, 'learning_rate': 6.048e-06, 'epoch': 2.54}\n",
      "{'loss': 27.0, 'learning_rate': 6.047000000000001e-06, 'epoch': 2.54}\n",
      "{'loss': 27.625, 'learning_rate': 6.046000000000001e-06, 'epoch': 2.54}\n",
      "{'loss': 27.375, 'learning_rate': 6.0450000000000006e-06, 'epoch': 2.54}\n",
      "{'loss': 26.375, 'learning_rate': 6.044000000000001e-06, 'epoch': 2.54}\n",
      "{'loss': 29.375, 'learning_rate': 6.0429999999999996e-06, 'epoch': 2.54}\n",
      "{'loss': 27.875, 'learning_rate': 6.042e-06, 'epoch': 2.54}\n",
      "{'loss': 31.5, 'learning_rate': 6.041e-06, 'epoch': 2.54}\n",
      "{'loss': 27.5, 'learning_rate': 6.040000000000001e-06, 'epoch': 2.54}\n",
      "{'loss': 28.25, 'learning_rate': 6.039e-06, 'epoch': 2.54}\n",
      "{'loss': 26.5, 'learning_rate': 6.0380000000000005e-06, 'epoch': 2.54}\n",
      "{'loss': 27.25, 'learning_rate': 6.037000000000001e-06, 'epoch': 2.54}\n",
      "{'loss': 26.875, 'learning_rate': 6.036000000000001e-06, 'epoch': 2.54}\n",
      "{'loss': 26.125, 'learning_rate': 6.035000000000001e-06, 'epoch': 2.54}\n",
      "{'loss': 28.0, 'learning_rate': 6.034000000000001e-06, 'epoch': 2.55}\n",
      "{'loss': 29.25, 'learning_rate': 6.033e-06, 'epoch': 2.55}\n",
      "{'loss': 27.5, 'learning_rate': 6.032e-06, 'epoch': 2.55}\n",
      "{'loss': 28.5, 'learning_rate': 6.031e-06, 'epoch': 2.55}\n",
      "{'loss': 27.625, 'learning_rate': 6.030000000000001e-06, 'epoch': 2.55}\n",
      "{'loss': 27.25, 'learning_rate': 6.029e-06, 'epoch': 2.55}\n",
      "{'loss': 27.875, 'learning_rate': 6.0280000000000006e-06, 'epoch': 2.55}\n",
      "{'loss': 27.5, 'learning_rate': 6.027000000000001e-06, 'epoch': 2.55}\n",
      "{'loss': 26.75, 'learning_rate': 6.026e-06, 'epoch': 2.55}\n",
      "{'loss': 28.0, 'learning_rate': 6.025000000000001e-06, 'epoch': 2.55}\n",
      "{'loss': 27.875, 'learning_rate': 6.024000000000001e-06, 'epoch': 2.55}\n",
      "{'loss': 27.625, 'learning_rate': 6.023e-06, 'epoch': 2.55}\n",
      "{'loss': 27.5, 'learning_rate': 6.022e-06, 'epoch': 2.55}\n",
      "{'loss': 28.25, 'learning_rate': 6.0210000000000005e-06, 'epoch': 2.55}\n",
      "{'loss': 27.375, 'learning_rate': 6.02e-06, 'epoch': 2.55}\n",
      "{'loss': 28.5, 'learning_rate': 6.019e-06, 'epoch': 2.56}\n",
      "{'loss': 26.875, 'learning_rate': 6.018000000000001e-06, 'epoch': 2.56}\n",
      "{'loss': 26.625, 'learning_rate': 6.017000000000001e-06, 'epoch': 2.56}\n",
      "{'loss': 27.125, 'learning_rate': 6.0160000000000005e-06, 'epoch': 2.56}\n",
      "{'loss': 27.75, 'learning_rate': 6.015000000000001e-06, 'epoch': 2.56}\n",
      "{'loss': 28.5, 'learning_rate': 6.014000000000001e-06, 'epoch': 2.56}\n",
      "{'loss': 27.625, 'learning_rate': 6.013e-06, 'epoch': 2.56}\n",
      "{'loss': 27.375, 'learning_rate': 6.012e-06, 'epoch': 2.56}\n",
      "{'loss': 26.75, 'learning_rate': 6.0110000000000006e-06, 'epoch': 2.56}\n",
      "{'loss': 27.375, 'learning_rate': 6.01e-06, 'epoch': 2.56}\n",
      "{'loss': 30.25, 'learning_rate': 6.009e-06, 'epoch': 2.56}\n",
      "{'loss': 27.875, 'learning_rate': 6.008000000000001e-06, 'epoch': 2.56}\n",
      "{'loss': 27.0, 'learning_rate': 6.007e-06, 'epoch': 2.56}\n",
      "{'loss': 27.375, 'learning_rate': 6.006000000000001e-06, 'epoch': 2.56}\n",
      "{'loss': 27.375, 'learning_rate': 6.005000000000001e-06, 'epoch': 2.56}\n",
      "{'loss': 28.625, 'learning_rate': 6.004000000000001e-06, 'epoch': 2.56}\n",
      "{'loss': 26.75, 'learning_rate': 6.003e-06, 'epoch': 2.57}\n",
      "{'loss': 28.625, 'learning_rate': 6.002e-06, 'epoch': 2.57}\n",
      "{'loss': 27.375, 'learning_rate': 6.001e-06, 'epoch': 2.57}\n",
      "{'loss': 27.25, 'learning_rate': 6e-06, 'epoch': 2.57}\n",
      "{'loss': 29.375, 'learning_rate': 5.9990000000000005e-06, 'epoch': 2.57}\n",
      "{'loss': 28.375, 'learning_rate': 5.998000000000001e-06, 'epoch': 2.57}\n",
      "{'loss': 27.375, 'learning_rate': 5.997e-06, 'epoch': 2.57}\n",
      "{'loss': 27.75, 'learning_rate': 5.996000000000001e-06, 'epoch': 2.57}\n",
      "{'loss': 27.25, 'learning_rate': 5.995000000000001e-06, 'epoch': 2.57}\n",
      "{'loss': 26.875, 'learning_rate': 5.9940000000000005e-06, 'epoch': 2.57}\n",
      "{'loss': 27.375, 'learning_rate': 5.993000000000001e-06, 'epoch': 2.57}\n",
      "{'loss': 27.25, 'learning_rate': 5.992e-06, 'epoch': 2.57}\n",
      "{'loss': 26.875, 'learning_rate': 5.991e-06, 'epoch': 2.57}\n",
      "{'loss': 27.0, 'learning_rate': 5.99e-06, 'epoch': 2.57}\n",
      "{'loss': 27.0, 'learning_rate': 5.989000000000001e-06, 'epoch': 2.57}\n",
      "{'loss': 28.0, 'learning_rate': 5.988e-06, 'epoch': 2.58}\n",
      "{'loss': 28.625, 'learning_rate': 5.9870000000000004e-06, 'epoch': 2.58}\n",
      "{'loss': 28.125, 'learning_rate': 5.986000000000001e-06, 'epoch': 2.58}\n",
      "{'loss': 28.0, 'learning_rate': 5.985000000000001e-06, 'epoch': 2.58}\n",
      "{'loss': 28.75, 'learning_rate': 5.984000000000001e-06, 'epoch': 2.58}\n",
      "{'loss': 29.0, 'learning_rate': 5.983000000000001e-06, 'epoch': 2.58}\n",
      "{'loss': 27.75, 'learning_rate': 5.982e-06, 'epoch': 2.58}\n",
      "{'loss': 27.5, 'learning_rate': 5.981e-06, 'epoch': 2.58}\n",
      "{'loss': 26.75, 'learning_rate': 5.98e-06, 'epoch': 2.58}\n",
      "{'loss': 30.25, 'learning_rate': 5.979000000000001e-06, 'epoch': 2.58}\n",
      "{'loss': 28.25, 'learning_rate': 5.978e-06, 'epoch': 2.58}\n",
      "{'loss': 28.0, 'learning_rate': 5.9770000000000005e-06, 'epoch': 2.58}\n",
      "{'loss': 28.0, 'learning_rate': 5.976000000000001e-06, 'epoch': 2.58}\n",
      "{'loss': 26.875, 'learning_rate': 5.975e-06, 'epoch': 2.58}\n",
      "{'loss': 26.875, 'learning_rate': 5.974000000000001e-06, 'epoch': 2.58}\n",
      "{'loss': 28.5, 'learning_rate': 5.973000000000001e-06, 'epoch': 2.58}\n",
      "{'loss': 27.25, 'learning_rate': 5.972e-06, 'epoch': 2.59}\n",
      "{'loss': 27.25, 'learning_rate': 5.971e-06, 'epoch': 2.59}\n",
      "{'loss': 29.25, 'learning_rate': 5.9700000000000004e-06, 'epoch': 2.59}\n",
      "{'loss': 28.25, 'learning_rate': 5.969e-06, 'epoch': 2.59}\n",
      "{'loss': 27.75, 'learning_rate': 5.968e-06, 'epoch': 2.59}\n",
      "{'loss': 28.125, 'learning_rate': 5.967000000000001e-06, 'epoch': 2.59}\n",
      "{'loss': 28.375, 'learning_rate': 5.966000000000001e-06, 'epoch': 2.59}\n",
      "{'loss': 27.5, 'learning_rate': 5.9650000000000005e-06, 'epoch': 2.59}\n",
      "{'loss': 28.5, 'learning_rate': 5.964000000000001e-06, 'epoch': 2.59}\n",
      "{'loss': 27.0, 'learning_rate': 5.963000000000001e-06, 'epoch': 2.59}\n",
      "{'loss': 27.625, 'learning_rate': 5.962e-06, 'epoch': 2.59}\n",
      "{'loss': 27.5, 'learning_rate': 5.961e-06, 'epoch': 2.59}\n",
      "{'loss': 27.0, 'learning_rate': 5.9600000000000005e-06, 'epoch': 2.59}\n",
      "{'loss': 27.0, 'learning_rate': 5.959e-06, 'epoch': 2.59}\n",
      "{'loss': 26.625, 'learning_rate': 5.958e-06, 'epoch': 2.59}\n",
      "{'loss': 27.875, 'learning_rate': 5.957000000000001e-06, 'epoch': 2.59}\n",
      "{'loss': 27.0, 'learning_rate': 5.956000000000001e-06, 'epoch': 2.6}\n",
      "{'loss': 27.75, 'learning_rate': 5.955000000000001e-06, 'epoch': 2.6}\n",
      "{'loss': 28.25, 'learning_rate': 5.954000000000001e-06, 'epoch': 2.6}\n",
      "{'loss': 27.25, 'learning_rate': 5.953000000000001e-06, 'epoch': 2.6}\n",
      "{'loss': 27.0, 'learning_rate': 5.952e-06, 'epoch': 2.6}\n",
      "{'loss': 27.375, 'learning_rate': 5.951e-06, 'epoch': 2.6}\n",
      "{'loss': 28.75, 'learning_rate': 5.950000000000001e-06, 'epoch': 2.6}\n",
      "{'loss': 27.25, 'learning_rate': 5.949e-06, 'epoch': 2.6}\n",
      "{'loss': 27.0, 'learning_rate': 5.9480000000000005e-06, 'epoch': 2.6}\n",
      "{'loss': 28.75, 'learning_rate': 5.947000000000001e-06, 'epoch': 2.6}\n",
      "{'loss': 27.0, 'learning_rate': 5.946e-06, 'epoch': 2.6}\n",
      "{'loss': 27.5, 'learning_rate': 5.945000000000001e-06, 'epoch': 2.6}\n",
      "{'loss': 27.75, 'learning_rate': 5.944000000000001e-06, 'epoch': 2.6}\n",
      "{'loss': 27.75, 'learning_rate': 5.943000000000001e-06, 'epoch': 2.6}\n",
      "{'loss': 27.125, 'learning_rate': 5.942e-06, 'epoch': 2.6}\n",
      "{'loss': 27.375, 'learning_rate': 5.941e-06, 'epoch': 2.61}\n",
      "{'loss': 32.5, 'learning_rate': 5.94e-06, 'epoch': 2.61}\n",
      "{'loss': 27.0, 'learning_rate': 5.939e-06, 'epoch': 2.61}\n",
      "{'loss': 27.25, 'learning_rate': 5.9380000000000006e-06, 'epoch': 2.61}\n",
      "{'loss': 27.0, 'learning_rate': 5.937000000000001e-06, 'epoch': 2.61}\n",
      "{'loss': 27.125, 'learning_rate': 5.9360000000000004e-06, 'epoch': 2.61}\n",
      "{'loss': 29.125, 'learning_rate': 5.935000000000001e-06, 'epoch': 2.61}\n",
      "{'loss': 27.375, 'learning_rate': 5.934000000000001e-06, 'epoch': 2.61}\n",
      "{'loss': 26.625, 'learning_rate': 5.933000000000001e-06, 'epoch': 2.61}\n",
      "{'loss': 26.75, 'learning_rate': 5.932e-06, 'epoch': 2.61}\n",
      "{'loss': 27.25, 'learning_rate': 5.9310000000000005e-06, 'epoch': 2.61}\n",
      "{'loss': 28.75, 'learning_rate': 5.93e-06, 'epoch': 2.61}\n",
      "{'loss': 29.0, 'learning_rate': 5.929e-06, 'epoch': 2.61}\n",
      "{'loss': 28.0, 'learning_rate': 5.928000000000001e-06, 'epoch': 2.61}\n",
      "{'loss': 27.125, 'learning_rate': 5.927e-06, 'epoch': 2.61}\n",
      "{'loss': 26.5, 'learning_rate': 5.9260000000000005e-06, 'epoch': 2.61}\n",
      "{'loss': 27.375, 'learning_rate': 5.925000000000001e-06, 'epoch': 2.62}\n",
      "{'loss': 27.0, 'learning_rate': 5.924000000000001e-06, 'epoch': 2.62}\n",
      "{'loss': 27.875, 'learning_rate': 5.923000000000001e-06, 'epoch': 2.62}\n",
      "{'loss': 28.75, 'learning_rate': 5.922e-06, 'epoch': 2.62}\n",
      "{'loss': 26.875, 'learning_rate': 5.921e-06, 'epoch': 2.62}\n",
      "{'loss': 28.0, 'learning_rate': 5.92e-06, 'epoch': 2.62}\n",
      "{'loss': 27.375, 'learning_rate': 5.919e-06, 'epoch': 2.62}\n",
      "{'loss': 27.5, 'learning_rate': 5.918000000000001e-06, 'epoch': 2.62}\n",
      "{'loss': 28.75, 'learning_rate': 5.917e-06, 'epoch': 2.62}\n",
      "{'loss': 28.5, 'learning_rate': 5.916000000000001e-06, 'epoch': 2.62}\n",
      "{'loss': 26.875, 'learning_rate': 5.915000000000001e-06, 'epoch': 2.62}\n",
      "{'loss': 27.0, 'learning_rate': 5.9140000000000005e-06, 'epoch': 2.62}\n",
      "{'loss': 28.0, 'learning_rate': 5.913000000000001e-06, 'epoch': 2.62}\n",
      "{'loss': 26.625, 'learning_rate': 5.912e-06, 'epoch': 2.62}\n",
      "{'loss': 27.0, 'learning_rate': 5.911e-06, 'epoch': 2.62}\n",
      "{'loss': 27.25, 'learning_rate': 5.91e-06, 'epoch': 2.63}\n",
      "{'loss': 27.375, 'learning_rate': 5.9090000000000005e-06, 'epoch': 2.63}\n",
      "{'loss': 26.75, 'learning_rate': 5.908e-06, 'epoch': 2.63}\n",
      "{'loss': 26.5, 'learning_rate': 5.907e-06, 'epoch': 2.63}\n",
      "{'loss': 28.125, 'learning_rate': 5.906000000000001e-06, 'epoch': 2.63}\n",
      "{'loss': 27.0, 'learning_rate': 5.905000000000001e-06, 'epoch': 2.63}\n",
      "{'loss': 27.375, 'learning_rate': 5.9040000000000006e-06, 'epoch': 2.63}\n",
      "{'loss': 26.75, 'learning_rate': 5.903000000000001e-06, 'epoch': 2.63}\n",
      "{'loss': 26.875, 'learning_rate': 5.9019999999999996e-06, 'epoch': 2.63}\n",
      "{'loss': 27.875, 'learning_rate': 5.901e-06, 'epoch': 2.63}\n",
      "{'loss': 27.625, 'learning_rate': 5.9e-06, 'epoch': 2.63}\n",
      "{'loss': 27.5, 'learning_rate': 5.899000000000001e-06, 'epoch': 2.63}\n",
      "{'loss': 28.0, 'learning_rate': 5.898e-06, 'epoch': 2.63}\n",
      "{'loss': 27.25, 'learning_rate': 5.8970000000000005e-06, 'epoch': 2.63}\n",
      "{'loss': 27.625, 'learning_rate': 5.896000000000001e-06, 'epoch': 2.63}\n",
      "{'loss': 26.875, 'learning_rate': 5.895e-06, 'epoch': 2.63}\n",
      "{'loss': 28.625, 'learning_rate': 5.894000000000001e-06, 'epoch': 2.64}\n",
      "{'loss': 27.625, 'learning_rate': 5.893000000000001e-06, 'epoch': 2.64}\n",
      "{'loss': 27.875, 'learning_rate': 5.892e-06, 'epoch': 2.64}\n",
      "{'loss': 27.5, 'learning_rate': 5.891e-06, 'epoch': 2.64}\n",
      "{'loss': 27.0, 'learning_rate': 5.89e-06, 'epoch': 2.64}\n",
      "{'loss': 27.75, 'learning_rate': 5.889e-06, 'epoch': 2.64}\n",
      "{'loss': 27.125, 'learning_rate': 5.888e-06, 'epoch': 2.64}\n",
      "{'loss': 27.125, 'learning_rate': 5.8870000000000006e-06, 'epoch': 2.64}\n",
      "{'loss': 27.0, 'learning_rate': 5.886000000000001e-06, 'epoch': 2.64}\n",
      "{'loss': 29.125, 'learning_rate': 5.885e-06, 'epoch': 2.64}\n",
      "{'loss': 27.125, 'learning_rate': 5.884000000000001e-06, 'epoch': 2.64}\n",
      "{'loss': 27.125, 'learning_rate': 5.883000000000001e-06, 'epoch': 2.64}\n",
      "{'loss': 28.125, 'learning_rate': 5.882e-06, 'epoch': 2.64}\n",
      "{'loss': 28.5, 'learning_rate': 5.881e-06, 'epoch': 2.64}\n",
      "{'loss': 27.0, 'learning_rate': 5.8800000000000005e-06, 'epoch': 2.64}\n",
      "{'loss': 27.75, 'learning_rate': 5.879e-06, 'epoch': 2.65}\n",
      "{'loss': 28.0, 'learning_rate': 5.878e-06, 'epoch': 2.65}\n",
      "{'loss': 27.125, 'learning_rate': 5.877000000000001e-06, 'epoch': 2.65}\n",
      "{'loss': 28.5, 'learning_rate': 5.876000000000001e-06, 'epoch': 2.65}\n",
      "{'loss': 27.125, 'learning_rate': 5.8750000000000005e-06, 'epoch': 2.65}\n",
      "{'loss': 26.5, 'learning_rate': 5.874000000000001e-06, 'epoch': 2.65}\n",
      "{'loss': 27.5, 'learning_rate': 5.873000000000001e-06, 'epoch': 2.65}\n",
      "{'loss': 27.875, 'learning_rate': 5.872000000000001e-06, 'epoch': 2.65}\n",
      "{'loss': 28.25, 'learning_rate': 5.871e-06, 'epoch': 2.65}\n",
      "{'loss': 26.875, 'learning_rate': 5.8700000000000005e-06, 'epoch': 2.65}\n",
      "{'loss': 28.125, 'learning_rate': 5.869e-06, 'epoch': 2.65}\n",
      "{'loss': 27.0, 'learning_rate': 5.868e-06, 'epoch': 2.65}\n",
      "{'loss': 27.25, 'learning_rate': 5.867000000000001e-06, 'epoch': 2.65}\n",
      "{'loss': 27.25, 'learning_rate': 5.866e-06, 'epoch': 2.65}\n",
      "{'loss': 28.5, 'learning_rate': 5.865000000000001e-06, 'epoch': 2.65}\n",
      "{'loss': 27.625, 'learning_rate': 5.864000000000001e-06, 'epoch': 2.65}\n",
      "{'loss': 27.0, 'learning_rate': 5.863000000000001e-06, 'epoch': 2.66}\n",
      "{'loss': 28.375, 'learning_rate': 5.862000000000001e-06, 'epoch': 2.66}\n",
      "{'loss': 26.5, 'learning_rate': 5.861e-06, 'epoch': 2.66}\n",
      "{'loss': 27.875, 'learning_rate': 5.86e-06, 'epoch': 2.66}\n",
      "{'loss': 27.75, 'learning_rate': 5.859e-06, 'epoch': 2.66}\n",
      "{'loss': 27.0, 'learning_rate': 5.8580000000000005e-06, 'epoch': 2.66}\n",
      "{'loss': 26.5, 'learning_rate': 5.857000000000001e-06, 'epoch': 2.66}\n",
      "{'loss': 29.25, 'learning_rate': 5.856e-06, 'epoch': 2.66}\n",
      "{'loss': 26.125, 'learning_rate': 5.855000000000001e-06, 'epoch': 2.66}\n",
      "{'loss': 26.875, 'learning_rate': 5.854000000000001e-06, 'epoch': 2.66}\n",
      "{'loss': 28.25, 'learning_rate': 5.8530000000000005e-06, 'epoch': 2.66}\n",
      "{'loss': 26.75, 'learning_rate': 5.852000000000001e-06, 'epoch': 2.66}\n",
      "{'loss': 27.75, 'learning_rate': 5.851e-06, 'epoch': 2.66}\n",
      "{'loss': 27.0, 'learning_rate': 5.85e-06, 'epoch': 2.66}\n",
      "{'loss': 26.875, 'learning_rate': 5.849e-06, 'epoch': 2.66}\n",
      "{'loss': 27.625, 'learning_rate': 5.848000000000001e-06, 'epoch': 2.66}\n",
      "{'loss': 26.375, 'learning_rate': 5.847e-06, 'epoch': 2.67}\n",
      "{'loss': 26.5, 'learning_rate': 5.8460000000000004e-06, 'epoch': 2.67}\n",
      "{'loss': 28.25, 'learning_rate': 5.845000000000001e-06, 'epoch': 2.67}\n",
      "{'loss': 26.375, 'learning_rate': 5.844000000000001e-06, 'epoch': 2.67}\n",
      "{'loss': 27.5, 'learning_rate': 5.843000000000001e-06, 'epoch': 2.67}\n",
      "{'loss': 27.375, 'learning_rate': 5.842000000000001e-06, 'epoch': 2.67}\n",
      "{'loss': 27.125, 'learning_rate': 5.841e-06, 'epoch': 2.67}\n",
      "{'loss': 27.25, 'learning_rate': 5.84e-06, 'epoch': 2.67}\n",
      "{'loss': 29.75, 'learning_rate': 5.839e-06, 'epoch': 2.67}\n",
      "{'loss': 27.25, 'learning_rate': 5.838000000000001e-06, 'epoch': 2.67}\n",
      "{'loss': 30.75, 'learning_rate': 5.837e-06, 'epoch': 2.67}\n",
      "{'loss': 27.75, 'learning_rate': 5.8360000000000005e-06, 'epoch': 2.67}\n",
      "{'loss': 27.125, 'learning_rate': 5.835000000000001e-06, 'epoch': 2.67}\n",
      "{'loss': 28.25, 'learning_rate': 5.834e-06, 'epoch': 2.67}\n",
      "{'loss': 27.75, 'learning_rate': 5.833000000000001e-06, 'epoch': 2.67}\n",
      "{'loss': 27.75, 'learning_rate': 5.832000000000001e-06, 'epoch': 2.68}\n",
      "{'loss': 27.5, 'learning_rate': 5.831e-06, 'epoch': 2.68}\n",
      "{'loss': 28.0, 'learning_rate': 5.83e-06, 'epoch': 2.68}\n",
      "{'loss': 27.125, 'learning_rate': 5.8290000000000004e-06, 'epoch': 2.68}\n",
      "{'loss': 28.125, 'learning_rate': 5.828e-06, 'epoch': 2.68}\n",
      "{'loss': 28.125, 'learning_rate': 5.827e-06, 'epoch': 2.68}\n",
      "{'loss': 26.5, 'learning_rate': 5.826000000000001e-06, 'epoch': 2.68}\n",
      "{'loss': 27.625, 'learning_rate': 5.825000000000001e-06, 'epoch': 2.68}\n",
      "{'loss': 27.25, 'learning_rate': 5.8240000000000005e-06, 'epoch': 2.68}\n",
      "{'loss': 27.25, 'learning_rate': 5.823000000000001e-06, 'epoch': 2.68}\n",
      "{'loss': 27.25, 'learning_rate': 5.822000000000001e-06, 'epoch': 2.68}\n",
      "{'loss': 28.0, 'learning_rate': 5.821e-06, 'epoch': 2.68}\n",
      "{'loss': 27.375, 'learning_rate': 5.82e-06, 'epoch': 2.68}\n",
      "{'loss': 27.875, 'learning_rate': 5.8190000000000005e-06, 'epoch': 2.68}\n",
      "{'loss': 29.75, 'learning_rate': 5.818e-06, 'epoch': 2.68}\n",
      "{'loss': 27.625, 'learning_rate': 5.817e-06, 'epoch': 2.68}\n",
      "{'loss': 26.5, 'learning_rate': 5.816000000000001e-06, 'epoch': 2.69}\n",
      "{'loss': 27.375, 'learning_rate': 5.815e-06, 'epoch': 2.69}\n",
      "{'loss': 27.0, 'learning_rate': 5.814000000000001e-06, 'epoch': 2.69}\n",
      "{'loss': 27.875, 'learning_rate': 5.813000000000001e-06, 'epoch': 2.69}\n",
      "{'loss': 26.75, 'learning_rate': 5.812000000000001e-06, 'epoch': 2.69}\n",
      "{'loss': 27.125, 'learning_rate': 5.811e-06, 'epoch': 2.69}\n",
      "{'loss': 28.375, 'learning_rate': 5.81e-06, 'epoch': 2.69}\n",
      "{'loss': 26.75, 'learning_rate': 5.809e-06, 'epoch': 2.69}\n",
      "{'loss': 28.25, 'learning_rate': 5.808e-06, 'epoch': 2.69}\n",
      "{'loss': 27.0, 'learning_rate': 5.8070000000000005e-06, 'epoch': 2.69}\n",
      "{'loss': 28.0, 'learning_rate': 5.806000000000001e-06, 'epoch': 2.69}\n",
      "{'loss': 27.0, 'learning_rate': 5.805e-06, 'epoch': 2.69}\n",
      "{'loss': 27.625, 'learning_rate': 5.804000000000001e-06, 'epoch': 2.69}\n",
      "{'loss': 27.75, 'learning_rate': 5.803000000000001e-06, 'epoch': 2.69}\n",
      "{'loss': 27.0, 'learning_rate': 5.802000000000001e-06, 'epoch': 2.69}\n",
      "{'loss': 26.75, 'learning_rate': 5.801e-06, 'epoch': 2.7}\n",
      "{'loss': 26.75, 'learning_rate': 5.8e-06, 'epoch': 2.7}\n",
      "{'loss': 27.5, 'learning_rate': 5.799e-06, 'epoch': 2.7}\n",
      "{'loss': 27.5, 'learning_rate': 5.798e-06, 'epoch': 2.7}\n",
      "{'loss': 26.75, 'learning_rate': 5.7970000000000006e-06, 'epoch': 2.7}\n",
      "{'loss': 26.75, 'learning_rate': 5.796000000000001e-06, 'epoch': 2.7}\n",
      "{'loss': 27.5, 'learning_rate': 5.795e-06, 'epoch': 2.7}\n",
      "{'loss': 27.375, 'learning_rate': 5.794000000000001e-06, 'epoch': 2.7}\n",
      "{'loss': 26.625, 'learning_rate': 5.793000000000001e-06, 'epoch': 2.7}\n",
      "{'loss': 27.25, 'learning_rate': 5.792000000000001e-06, 'epoch': 2.7}\n",
      "{'loss': 27.625, 'learning_rate': 5.791e-06, 'epoch': 2.7}\n",
      "{'loss': 26.625, 'learning_rate': 5.7900000000000005e-06, 'epoch': 2.7}\n",
      "{'loss': 29.25, 'learning_rate': 5.789e-06, 'epoch': 2.7}\n",
      "{'loss': 28.5, 'learning_rate': 5.788e-06, 'epoch': 2.7}\n",
      "{'loss': 27.0, 'learning_rate': 5.787000000000001e-06, 'epoch': 2.7}\n",
      "{'loss': 27.375, 'learning_rate': 5.786e-06, 'epoch': 2.7}\n",
      "{'loss': 29.5, 'learning_rate': 5.7850000000000005e-06, 'epoch': 2.71}\n",
      "{'loss': 26.875, 'learning_rate': 5.784000000000001e-06, 'epoch': 2.71}\n",
      "{'loss': 27.25, 'learning_rate': 5.783000000000001e-06, 'epoch': 2.71}\n",
      "{'loss': 27.375, 'learning_rate': 5.782000000000001e-06, 'epoch': 2.71}\n",
      "{'loss': 26.25, 'learning_rate': 5.781e-06, 'epoch': 2.71}\n",
      "{'loss': 26.375, 'learning_rate': 5.78e-06, 'epoch': 2.71}\n",
      "{'loss': 29.375, 'learning_rate': 5.779e-06, 'epoch': 2.71}\n",
      "{'loss': 27.75, 'learning_rate': 5.778e-06, 'epoch': 2.71}\n",
      "{'loss': 27.375, 'learning_rate': 5.777000000000001e-06, 'epoch': 2.71}\n",
      "{'loss': 27.375, 'learning_rate': 5.776e-06, 'epoch': 2.71}\n",
      "{'loss': 27.0, 'learning_rate': 5.775000000000001e-06, 'epoch': 2.71}\n",
      "{'loss': 27.5, 'learning_rate': 5.774000000000001e-06, 'epoch': 2.71}\n",
      "{'loss': 26.875, 'learning_rate': 5.7730000000000005e-06, 'epoch': 2.71}\n",
      "{'loss': 26.875, 'learning_rate': 5.772000000000001e-06, 'epoch': 2.71}\n",
      "{'loss': 27.5, 'learning_rate': 5.771e-06, 'epoch': 2.71}\n",
      "{'loss': 29.25, 'learning_rate': 5.77e-06, 'epoch': 2.72}\n",
      "{'loss': 27.625, 'learning_rate': 5.769e-06, 'epoch': 2.72}\n",
      "{'loss': 28.5, 'learning_rate': 5.7680000000000005e-06, 'epoch': 2.72}\n",
      "{'loss': 27.25, 'learning_rate': 5.767e-06, 'epoch': 2.72}\n",
      "{'loss': 26.375, 'learning_rate': 5.766e-06, 'epoch': 2.72}\n",
      "{'loss': 28.25, 'learning_rate': 5.765000000000001e-06, 'epoch': 2.72}\n",
      "{'loss': 27.25, 'learning_rate': 5.764000000000001e-06, 'epoch': 2.72}\n",
      "{'loss': 27.375, 'learning_rate': 5.7630000000000006e-06, 'epoch': 2.72}\n",
      "{'loss': 27.25, 'learning_rate': 5.762000000000001e-06, 'epoch': 2.72}\n",
      "{'loss': 28.0, 'learning_rate': 5.7609999999999996e-06, 'epoch': 2.72}\n",
      "{'loss': 29.125, 'learning_rate': 5.76e-06, 'epoch': 2.72}\n",
      "{'loss': 29.125, 'learning_rate': 5.759e-06, 'epoch': 2.72}\n",
      "{'loss': 27.75, 'learning_rate': 5.758000000000001e-06, 'epoch': 2.72}\n",
      "{'loss': 29.875, 'learning_rate': 5.757e-06, 'epoch': 2.72}\n",
      "{'loss': 27.0, 'learning_rate': 5.7560000000000005e-06, 'epoch': 2.72}\n",
      "{'loss': 28.0, 'learning_rate': 5.755000000000001e-06, 'epoch': 2.72}\n",
      "{'loss': 27.25, 'learning_rate': 5.754e-06, 'epoch': 2.73}\n",
      "{'loss': 27.0, 'learning_rate': 5.753000000000001e-06, 'epoch': 2.73}\n",
      "{'loss': 27.625, 'learning_rate': 5.752000000000001e-06, 'epoch': 2.73}\n",
      "{'loss': 26.875, 'learning_rate': 5.751e-06, 'epoch': 2.73}\n",
      "{'loss': 27.5, 'learning_rate': 5.75e-06, 'epoch': 2.73}\n",
      "{'loss': 27.125, 'learning_rate': 5.749e-06, 'epoch': 2.73}\n",
      "{'loss': 26.5, 'learning_rate': 5.748e-06, 'epoch': 2.73}\n",
      "{'loss': 28.875, 'learning_rate': 5.747e-06, 'epoch': 2.73}\n",
      "{'loss': 27.375, 'learning_rate': 5.7460000000000006e-06, 'epoch': 2.73}\n",
      "{'loss': 27.0, 'learning_rate': 5.745000000000001e-06, 'epoch': 2.73}\n",
      "{'loss': 27.25, 'learning_rate': 5.744e-06, 'epoch': 2.73}\n",
      "{'loss': 27.5, 'learning_rate': 5.743000000000001e-06, 'epoch': 2.73}\n",
      "{'loss': 27.0, 'learning_rate': 5.742000000000001e-06, 'epoch': 2.73}\n",
      "{'loss': 27.625, 'learning_rate': 5.741000000000001e-06, 'epoch': 2.73}\n",
      "{'loss': 27.25, 'learning_rate': 5.74e-06, 'epoch': 2.73}\n",
      "{'loss': 29.375, 'learning_rate': 5.7390000000000004e-06, 'epoch': 2.73}\n",
      "{'loss': 27.625, 'learning_rate': 5.738e-06, 'epoch': 2.74}\n",
      "{'loss': 26.875, 'learning_rate': 5.737e-06, 'epoch': 2.74}\n",
      "{'loss': 27.875, 'learning_rate': 5.736000000000001e-06, 'epoch': 2.74}\n",
      "{'loss': 27.25, 'learning_rate': 5.735e-06, 'epoch': 2.74}\n",
      "{'loss': 29.625, 'learning_rate': 5.7340000000000005e-06, 'epoch': 2.74}\n",
      "{'loss': 27.75, 'learning_rate': 5.733000000000001e-06, 'epoch': 2.74}\n",
      "{'loss': 27.5, 'learning_rate': 5.732000000000001e-06, 'epoch': 2.74}\n",
      "{'loss': 27.5, 'learning_rate': 5.731000000000001e-06, 'epoch': 2.74}\n",
      "{'loss': 27.25, 'learning_rate': 5.73e-06, 'epoch': 2.74}\n",
      "{'loss': 27.375, 'learning_rate': 5.729e-06, 'epoch': 2.74}\n",
      "{'loss': 25.5, 'learning_rate': 5.728e-06, 'epoch': 2.74}\n",
      "{'loss': 28.75, 'learning_rate': 5.727e-06, 'epoch': 2.74}\n",
      "{'loss': 28.125, 'learning_rate': 5.726000000000001e-06, 'epoch': 2.74}\n",
      "{'loss': 29.5, 'learning_rate': 5.725e-06, 'epoch': 2.74}\n",
      "{'loss': 27.0, 'learning_rate': 5.724000000000001e-06, 'epoch': 2.74}\n",
      "{'loss': 27.375, 'learning_rate': 5.723000000000001e-06, 'epoch': 2.75}\n",
      "{'loss': 27.125, 'learning_rate': 5.722000000000001e-06, 'epoch': 2.75}\n",
      "{'loss': 27.25, 'learning_rate': 5.721000000000001e-06, 'epoch': 2.75}\n",
      "{'loss': 28.5, 'learning_rate': 5.72e-06, 'epoch': 2.75}\n",
      "{'loss': 27.25, 'learning_rate': 5.719e-06, 'epoch': 2.75}\n",
      "{'loss': 26.875, 'learning_rate': 5.718e-06, 'epoch': 2.75}\n",
      "{'loss': 28.875, 'learning_rate': 5.7170000000000005e-06, 'epoch': 2.75}\n",
      "{'loss': 27.0, 'learning_rate': 5.716000000000001e-06, 'epoch': 2.75}\n",
      "{'loss': 28.0, 'learning_rate': 5.715e-06, 'epoch': 2.75}\n",
      "{'loss': 27.375, 'learning_rate': 5.714000000000001e-06, 'epoch': 2.75}\n",
      "{'loss': 26.625, 'learning_rate': 5.713000000000001e-06, 'epoch': 2.75}\n",
      "{'loss': 28.25, 'learning_rate': 5.7120000000000005e-06, 'epoch': 2.75}\n",
      "{'loss': 30.0, 'learning_rate': 5.711000000000001e-06, 'epoch': 2.75}\n",
      "{'loss': 27.375, 'learning_rate': 5.71e-06, 'epoch': 2.75}\n",
      "{'loss': 26.5, 'learning_rate': 5.709e-06, 'epoch': 2.75}\n",
      "{'loss': 27.0, 'learning_rate': 5.708e-06, 'epoch': 2.75}\n",
      "{'loss': 27.5, 'learning_rate': 5.707000000000001e-06, 'epoch': 2.76}\n",
      "{'loss': 28.5, 'learning_rate': 5.706e-06, 'epoch': 2.76}\n",
      "{'loss': 27.625, 'learning_rate': 5.7050000000000004e-06, 'epoch': 2.76}\n",
      "{'loss': 27.375, 'learning_rate': 5.704000000000001e-06, 'epoch': 2.76}\n",
      "{'loss': 28.0, 'learning_rate': 5.703000000000001e-06, 'epoch': 2.76}\n",
      "{'loss': 28.625, 'learning_rate': 5.702000000000001e-06, 'epoch': 2.76}\n",
      "{'loss': 27.125, 'learning_rate': 5.701000000000001e-06, 'epoch': 2.76}\n",
      "{'loss': 29.125, 'learning_rate': 5.7e-06, 'epoch': 2.76}\n",
      "{'loss': 27.25, 'learning_rate': 5.699e-06, 'epoch': 2.76}\n",
      "{'loss': 26.875, 'learning_rate': 5.698e-06, 'epoch': 2.76}\n",
      "{'loss': 26.625, 'learning_rate': 5.697000000000001e-06, 'epoch': 2.76}\n",
      "{'loss': 27.0, 'learning_rate': 5.696e-06, 'epoch': 2.76}\n",
      "{'loss': 28.25, 'learning_rate': 5.6950000000000005e-06, 'epoch': 2.76}\n",
      "{'loss': 28.125, 'learning_rate': 5.694000000000001e-06, 'epoch': 2.76}\n",
      "{'loss': 27.75, 'learning_rate': 5.693e-06, 'epoch': 2.76}\n",
      "{'loss': 27.25, 'learning_rate': 5.692000000000001e-06, 'epoch': 2.77}\n",
      "{'loss': 28.0, 'learning_rate': 5.691000000000001e-06, 'epoch': 2.77}\n",
      "{'loss': 27.75, 'learning_rate': 5.69e-06, 'epoch': 2.77}\n",
      "{'loss': 27.5, 'learning_rate': 5.689e-06, 'epoch': 2.77}\n",
      "{'loss': 28.625, 'learning_rate': 5.6880000000000004e-06, 'epoch': 2.77}\n",
      "{'loss': 28.375, 'learning_rate': 5.687e-06, 'epoch': 2.77}\n",
      "{'loss': 27.25, 'learning_rate': 5.686e-06, 'epoch': 2.77}\n",
      "{'loss': 27.5, 'learning_rate': 5.685000000000001e-06, 'epoch': 2.77}\n",
      "{'loss': 26.875, 'learning_rate': 5.684000000000001e-06, 'epoch': 2.77}\n",
      "{'loss': 28.625, 'learning_rate': 5.6830000000000005e-06, 'epoch': 2.77}\n",
      "{'loss': 27.0, 'learning_rate': 5.682000000000001e-06, 'epoch': 2.77}\n",
      "{'loss': 27.375, 'learning_rate': 5.681000000000001e-06, 'epoch': 2.77}\n",
      "{'loss': 27.75, 'learning_rate': 5.68e-06, 'epoch': 2.77}\n",
      "{'loss': 27.375, 'learning_rate': 5.679e-06, 'epoch': 2.77}\n",
      "{'loss': 26.375, 'learning_rate': 5.6780000000000005e-06, 'epoch': 2.77}\n",
      "{'loss': 29.125, 'learning_rate': 5.677e-06, 'epoch': 2.77}\n",
      "{'loss': 27.125, 'learning_rate': 5.676e-06, 'epoch': 2.78}\n",
      "{'loss': 31.0, 'learning_rate': 5.675000000000001e-06, 'epoch': 2.78}\n",
      "{'loss': 28.375, 'learning_rate': 5.674e-06, 'epoch': 2.78}\n",
      "{'loss': 27.875, 'learning_rate': 5.6730000000000006e-06, 'epoch': 2.78}\n",
      "{'loss': 27.625, 'learning_rate': 5.672000000000001e-06, 'epoch': 2.78}\n",
      "{'loss': 26.375, 'learning_rate': 5.671000000000001e-06, 'epoch': 2.78}\n",
      "{'loss': 28.125, 'learning_rate': 5.67e-06, 'epoch': 2.78}\n",
      "{'loss': 28.125, 'learning_rate': 5.669e-06, 'epoch': 2.78}\n",
      "{'loss': 27.75, 'learning_rate': 5.668e-06, 'epoch': 2.78}\n",
      "{'loss': 26.875, 'learning_rate': 5.667e-06, 'epoch': 2.78}\n",
      "{'loss': 29.625, 'learning_rate': 5.6660000000000005e-06, 'epoch': 2.78}\n",
      "{'loss': 27.375, 'learning_rate': 5.665000000000001e-06, 'epoch': 2.78}\n",
      "{'loss': 27.375, 'learning_rate': 5.664e-06, 'epoch': 2.78}\n",
      "{'loss': 27.125, 'learning_rate': 5.663000000000001e-06, 'epoch': 2.78}\n",
      "{'loss': 29.25, 'learning_rate': 5.662000000000001e-06, 'epoch': 2.78}\n",
      "{'loss': 28.125, 'learning_rate': 5.6610000000000005e-06, 'epoch': 2.78}\n",
      "{'loss': 27.375, 'learning_rate': 5.66e-06, 'epoch': 2.79}\n",
      "{'loss': 28.875, 'learning_rate': 5.659e-06, 'epoch': 2.79}\n",
      "{'loss': 29.5, 'learning_rate': 5.658e-06, 'epoch': 2.79}\n",
      "{'loss': 27.125, 'learning_rate': 5.657e-06, 'epoch': 2.79}\n",
      "{'loss': 27.5, 'learning_rate': 5.6560000000000006e-06, 'epoch': 2.79}\n",
      "{'loss': 28.5, 'learning_rate': 5.655e-06, 'epoch': 2.79}\n",
      "{'loss': 27.75, 'learning_rate': 5.654e-06, 'epoch': 2.79}\n",
      "{'loss': 27.75, 'learning_rate': 5.653000000000001e-06, 'epoch': 2.79}\n",
      "{'loss': 28.0, 'learning_rate': 5.652000000000001e-06, 'epoch': 2.79}\n",
      "{'loss': 27.375, 'learning_rate': 5.651000000000001e-06, 'epoch': 2.79}\n",
      "{'loss': 27.875, 'learning_rate': 5.65e-06, 'epoch': 2.79}\n",
      "{'loss': 29.625, 'learning_rate': 5.649e-06, 'epoch': 2.79}\n",
      "{'loss': 28.375, 'learning_rate': 5.648e-06, 'epoch': 2.79}\n",
      "{'loss': 29.75, 'learning_rate': 5.647e-06, 'epoch': 2.79}\n",
      "{'loss': 28.25, 'learning_rate': 5.646000000000001e-06, 'epoch': 2.79}\n",
      "{'loss': 28.0, 'learning_rate': 5.645e-06, 'epoch': 2.8}\n",
      "{'loss': 27.375, 'learning_rate': 5.6440000000000005e-06, 'epoch': 2.8}\n",
      "{'loss': 30.0, 'learning_rate': 5.643000000000001e-06, 'epoch': 2.8}\n",
      "{'loss': 27.875, 'learning_rate': 5.642000000000001e-06, 'epoch': 2.8}\n",
      "{'loss': 26.875, 'learning_rate': 5.641000000000001e-06, 'epoch': 2.8}\n",
      "{'loss': 27.5, 'learning_rate': 5.64e-06, 'epoch': 2.8}\n",
      "{'loss': 28.0, 'learning_rate': 5.639e-06, 'epoch': 2.8}\n",
      "{'loss': 26.875, 'learning_rate': 5.638e-06, 'epoch': 2.8}\n",
      "{'loss': 27.25, 'learning_rate': 5.637e-06, 'epoch': 2.8}\n",
      "{'loss': 27.375, 'learning_rate': 5.636000000000001e-06, 'epoch': 2.8}\n",
      "{'loss': 33.5, 'learning_rate': 5.635e-06, 'epoch': 2.8}\n",
      "{'loss': 27.5, 'learning_rate': 5.634000000000001e-06, 'epoch': 2.8}\n",
      "{'loss': 27.0, 'learning_rate': 5.633000000000001e-06, 'epoch': 2.8}\n",
      "{'loss': 26.75, 'learning_rate': 5.6320000000000005e-06, 'epoch': 2.8}\n",
      "{'loss': 27.375, 'learning_rate': 5.631000000000001e-06, 'epoch': 2.8}\n",
      "{'loss': 28.875, 'learning_rate': 5.63e-06, 'epoch': 2.8}\n",
      "{'loss': 28.0, 'learning_rate': 5.629e-06, 'epoch': 2.81}\n",
      "{'loss': 27.375, 'learning_rate': 5.628e-06, 'epoch': 2.81}\n",
      "{'loss': 28.0, 'learning_rate': 5.6270000000000005e-06, 'epoch': 2.81}\n",
      "{'loss': 26.625, 'learning_rate': 5.626e-06, 'epoch': 2.81}\n",
      "{'loss': 27.375, 'learning_rate': 5.625e-06, 'epoch': 2.81}\n",
      "{'loss': 28.25, 'learning_rate': 5.624000000000001e-06, 'epoch': 2.81}\n",
      "{'loss': 29.75, 'learning_rate': 5.623000000000001e-06, 'epoch': 2.81}\n",
      "{'loss': 28.125, 'learning_rate': 5.6220000000000006e-06, 'epoch': 2.81}\n",
      "{'loss': 28.25, 'learning_rate': 5.621000000000001e-06, 'epoch': 2.81}\n",
      "{'loss': 26.0, 'learning_rate': 5.620000000000001e-06, 'epoch': 2.81}\n",
      "{'loss': 27.375, 'learning_rate': 5.619e-06, 'epoch': 2.81}\n",
      "{'loss': 27.125, 'learning_rate': 5.618e-06, 'epoch': 2.81}\n",
      "{'loss': 28.0, 'learning_rate': 5.617000000000001e-06, 'epoch': 2.81}\n",
      "{'loss': 28.0, 'learning_rate': 5.616e-06, 'epoch': 2.81}\n",
      "{'loss': 27.25, 'learning_rate': 5.6150000000000005e-06, 'epoch': 2.81}\n",
      "{'loss': 27.75, 'learning_rate': 5.614000000000001e-06, 'epoch': 2.82}\n",
      "{'loss': 28.25, 'learning_rate': 5.613e-06, 'epoch': 2.82}\n",
      "{'loss': 26.5, 'learning_rate': 5.612000000000001e-06, 'epoch': 2.82}\n",
      "{'loss': 27.75, 'learning_rate': 5.611000000000001e-06, 'epoch': 2.82}\n",
      "{'loss': 28.125, 'learning_rate': 5.610000000000001e-06, 'epoch': 2.82}\n",
      "{'loss': 27.875, 'learning_rate': 5.609e-06, 'epoch': 2.82}\n",
      "{'loss': 27.125, 'learning_rate': 5.608e-06, 'epoch': 2.82}\n",
      "{'loss': 28.25, 'learning_rate': 5.607e-06, 'epoch': 2.82}\n",
      "{'loss': 28.5, 'learning_rate': 5.606e-06, 'epoch': 2.82}\n",
      "{'loss': 26.625, 'learning_rate': 5.6050000000000005e-06, 'epoch': 2.82}\n",
      "{'loss': 28.25, 'learning_rate': 5.604000000000001e-06, 'epoch': 2.82}\n",
      "{'loss': 29.625, 'learning_rate': 5.603e-06, 'epoch': 2.82}\n",
      "{'loss': 27.5, 'learning_rate': 5.602000000000001e-06, 'epoch': 2.82}\n",
      "{'loss': 26.375, 'learning_rate': 5.601000000000001e-06, 'epoch': 2.82}\n",
      "{'loss': 27.625, 'learning_rate': 5.600000000000001e-06, 'epoch': 2.82}\n",
      "{'loss': 27.125, 'learning_rate': 5.599e-06, 'epoch': 2.82}\n",
      "{'loss': 26.625, 'learning_rate': 5.5980000000000004e-06, 'epoch': 2.83}\n",
      "{'loss': 26.75, 'learning_rate': 5.597e-06, 'epoch': 2.83}\n",
      "{'loss': 29.5, 'learning_rate': 5.596e-06, 'epoch': 2.83}\n",
      "{'loss': 27.625, 'learning_rate': 5.595000000000001e-06, 'epoch': 2.83}\n",
      "{'loss': 27.125, 'learning_rate': 5.594e-06, 'epoch': 2.83}\n",
      "{'loss': 28.125, 'learning_rate': 5.5930000000000005e-06, 'epoch': 2.83}\n",
      "{'loss': 28.25, 'learning_rate': 5.592000000000001e-06, 'epoch': 2.83}\n",
      "{'loss': 28.375, 'learning_rate': 5.591000000000001e-06, 'epoch': 2.83}\n",
      "{'loss': 28.25, 'learning_rate': 5.590000000000001e-06, 'epoch': 2.83}\n",
      "{'loss': 27.75, 'learning_rate': 5.589e-06, 'epoch': 2.83}\n",
      "{'loss': 27.625, 'learning_rate': 5.588e-06, 'epoch': 2.83}\n",
      "{'loss': 30.875, 'learning_rate': 5.587e-06, 'epoch': 2.83}\n",
      "{'loss': 28.875, 'learning_rate': 5.586e-06, 'epoch': 2.83}\n",
      "{'loss': 29.375, 'learning_rate': 5.585000000000001e-06, 'epoch': 2.83}\n",
      "{'loss': 26.375, 'learning_rate': 5.584e-06, 'epoch': 2.83}\n",
      "{'loss': 28.125, 'learning_rate': 5.583000000000001e-06, 'epoch': 2.84}\n",
      "{'loss': 27.125, 'learning_rate': 5.582000000000001e-06, 'epoch': 2.84}\n",
      "{'loss': 27.875, 'learning_rate': 5.581000000000001e-06, 'epoch': 2.84}\n",
      "{'loss': 28.0, 'learning_rate': 5.580000000000001e-06, 'epoch': 2.84}\n",
      "{'loss': 28.0, 'learning_rate': 5.579e-06, 'epoch': 2.84}\n",
      "{'loss': 27.125, 'learning_rate': 5.578e-06, 'epoch': 2.84}\n",
      "{'loss': 26.625, 'learning_rate': 5.577e-06, 'epoch': 2.84}\n",
      "{'loss': 27.125, 'learning_rate': 5.5760000000000005e-06, 'epoch': 2.84}\n",
      "{'loss': 27.375, 'learning_rate': 5.575000000000001e-06, 'epoch': 2.84}\n",
      "{'loss': 27.0, 'learning_rate': 5.574e-06, 'epoch': 2.84}\n",
      "{'loss': 28.25, 'learning_rate': 5.573000000000001e-06, 'epoch': 2.84}\n",
      "{'loss': 26.75, 'learning_rate': 5.572000000000001e-06, 'epoch': 2.84}\n",
      "{'loss': 28.375, 'learning_rate': 5.5710000000000005e-06, 'epoch': 2.84}\n",
      "{'loss': 28.25, 'learning_rate': 5.570000000000001e-06, 'epoch': 2.84}\n",
      "{'loss': 27.125, 'learning_rate': 5.569e-06, 'epoch': 2.84}\n",
      "{'loss': 29.0, 'learning_rate': 5.568e-06, 'epoch': 2.84}\n",
      "{'loss': 27.125, 'learning_rate': 5.567e-06, 'epoch': 2.85}\n",
      "{'loss': 27.375, 'learning_rate': 5.566000000000001e-06, 'epoch': 2.85}\n",
      "{'loss': 28.0, 'learning_rate': 5.565e-06, 'epoch': 2.85}\n",
      "{'loss': 28.25, 'learning_rate': 5.5640000000000004e-06, 'epoch': 2.85}\n",
      "{'loss': 29.5, 'learning_rate': 5.563000000000001e-06, 'epoch': 2.85}\n",
      "{'loss': 27.25, 'learning_rate': 5.562000000000001e-06, 'epoch': 2.85}\n",
      "{'loss': 26.75, 'learning_rate': 5.561000000000001e-06, 'epoch': 2.85}\n",
      "{'loss': 26.875, 'learning_rate': 5.560000000000001e-06, 'epoch': 2.85}\n",
      "{'loss': 26.625, 'learning_rate': 5.559e-06, 'epoch': 2.85}\n",
      "{'loss': 27.125, 'learning_rate': 5.558e-06, 'epoch': 2.85}\n",
      "{'loss': 26.875, 'learning_rate': 5.557e-06, 'epoch': 2.85}\n",
      "{'loss': 27.0, 'learning_rate': 5.556000000000001e-06, 'epoch': 2.85}\n",
      "{'loss': 27.5, 'learning_rate': 5.555e-06, 'epoch': 2.85}\n",
      "{'loss': 28.0, 'learning_rate': 5.5540000000000005e-06, 'epoch': 2.85}\n",
      "{'loss': 28.0, 'learning_rate': 5.553000000000001e-06, 'epoch': 2.85}\n",
      "{'loss': 29.5, 'learning_rate': 5.552e-06, 'epoch': 2.85}\n",
      "{'loss': 27.125, 'learning_rate': 5.551000000000001e-06, 'epoch': 2.86}\n",
      "{'loss': 27.5, 'learning_rate': 5.550000000000001e-06, 'epoch': 2.86}\n",
      "{'loss': 27.0, 'learning_rate': 5.549e-06, 'epoch': 2.86}\n",
      "{'loss': 29.0, 'learning_rate': 5.548e-06, 'epoch': 2.86}\n",
      "{'loss': 27.75, 'learning_rate': 5.547e-06, 'epoch': 2.86}\n",
      "{'loss': 27.125, 'learning_rate': 5.546e-06, 'epoch': 2.86}\n",
      "{'loss': 27.25, 'learning_rate': 5.545e-06, 'epoch': 2.86}\n",
      "{'loss': 27.375, 'learning_rate': 5.544000000000001e-06, 'epoch': 2.86}\n",
      "{'loss': 26.875, 'learning_rate': 5.543000000000001e-06, 'epoch': 2.86}\n",
      "{'loss': 27.5, 'learning_rate': 5.5420000000000005e-06, 'epoch': 2.86}\n",
      "{'loss': 28.125, 'learning_rate': 5.541000000000001e-06, 'epoch': 2.86}\n",
      "{'loss': 27.125, 'learning_rate': 5.540000000000001e-06, 'epoch': 2.86}\n",
      "{'loss': 28.25, 'learning_rate': 5.539e-06, 'epoch': 2.86}\n",
      "{'loss': 26.875, 'learning_rate': 5.538e-06, 'epoch': 2.86}\n",
      "{'loss': 27.25, 'learning_rate': 5.5370000000000005e-06, 'epoch': 2.86}\n",
      "{'loss': 27.875, 'learning_rate': 5.536e-06, 'epoch': 2.87}\n",
      "{'loss': 27.875, 'learning_rate': 5.535e-06, 'epoch': 2.87}\n",
      "{'loss': 27.25, 'learning_rate': 5.534000000000001e-06, 'epoch': 2.87}\n",
      "{'loss': 27.25, 'learning_rate': 5.533e-06, 'epoch': 2.87}\n",
      "{'loss': 27.375, 'learning_rate': 5.5320000000000006e-06, 'epoch': 2.87}\n",
      "{'loss': 27.375, 'learning_rate': 5.531000000000001e-06, 'epoch': 2.87}\n",
      "{'loss': 26.25, 'learning_rate': 5.530000000000001e-06, 'epoch': 2.87}\n",
      "{'loss': 27.25, 'learning_rate': 5.529e-06, 'epoch': 2.87}\n",
      "{'loss': 27.75, 'learning_rate': 5.528e-06, 'epoch': 2.87}\n",
      "{'loss': 27.375, 'learning_rate': 5.527e-06, 'epoch': 2.87}\n",
      "{'loss': 28.375, 'learning_rate': 5.526e-06, 'epoch': 2.87}\n",
      "{'loss': 27.875, 'learning_rate': 5.5250000000000005e-06, 'epoch': 2.87}\n",
      "{'loss': 27.375, 'learning_rate': 5.524000000000001e-06, 'epoch': 2.87}\n",
      "{'loss': 27.375, 'learning_rate': 5.523e-06, 'epoch': 2.87}\n",
      "{'loss': 27.875, 'learning_rate': 5.522000000000001e-06, 'epoch': 2.87}\n",
      "{'loss': 27.875, 'learning_rate': 5.521000000000001e-06, 'epoch': 2.87}\n",
      "{'loss': 27.125, 'learning_rate': 5.5200000000000005e-06, 'epoch': 2.88}\n",
      "{'loss': 27.375, 'learning_rate': 5.519e-06, 'epoch': 2.88}\n",
      "{'loss': 27.875, 'learning_rate': 5.518e-06, 'epoch': 2.88}\n",
      "{'loss': 27.625, 'learning_rate': 5.517e-06, 'epoch': 2.88}\n",
      "{'loss': 26.75, 'learning_rate': 5.516e-06, 'epoch': 2.88}\n",
      "{'loss': 29.0, 'learning_rate': 5.5150000000000006e-06, 'epoch': 2.88}\n",
      "{'loss': 27.5, 'learning_rate': 5.514e-06, 'epoch': 2.88}\n",
      "{'loss': 26.875, 'learning_rate': 5.513e-06, 'epoch': 2.88}\n",
      "{'loss': 27.875, 'learning_rate': 5.512000000000001e-06, 'epoch': 2.88}\n",
      "{'loss': 27.25, 'learning_rate': 5.511000000000001e-06, 'epoch': 2.88}\n",
      "{'loss': 26.625, 'learning_rate': 5.510000000000001e-06, 'epoch': 2.88}\n",
      "{'loss': 27.125, 'learning_rate': 5.509e-06, 'epoch': 2.88}\n",
      "{'loss': 29.375, 'learning_rate': 5.508e-06, 'epoch': 2.88}\n",
      "{'loss': 28.0, 'learning_rate': 5.507e-06, 'epoch': 2.88}\n",
      "{'loss': 27.5, 'learning_rate': 5.506e-06, 'epoch': 2.88}\n",
      "{'loss': 27.75, 'learning_rate': 5.505000000000001e-06, 'epoch': 2.89}\n",
      "{'loss': 26.75, 'learning_rate': 5.504e-06, 'epoch': 2.89}\n",
      "{'loss': 26.75, 'learning_rate': 5.5030000000000005e-06, 'epoch': 2.89}\n",
      "{'loss': 27.0, 'learning_rate': 5.502000000000001e-06, 'epoch': 2.89}\n",
      "{'loss': 30.125, 'learning_rate': 5.501000000000001e-06, 'epoch': 2.89}\n",
      "{'loss': 27.25, 'learning_rate': 5.500000000000001e-06, 'epoch': 2.89}\n",
      "{'loss': 26.5, 'learning_rate': 5.499000000000001e-06, 'epoch': 2.89}\n",
      "{'loss': 27.375, 'learning_rate': 5.498e-06, 'epoch': 2.89}\n",
      "{'loss': 27.25, 'learning_rate': 5.497e-06, 'epoch': 2.89}\n",
      "{'loss': 27.0, 'learning_rate': 5.496e-06, 'epoch': 2.89}\n",
      "{'loss': 26.875, 'learning_rate': 5.495000000000001e-06, 'epoch': 2.89}\n",
      "{'loss': 27.375, 'learning_rate': 5.494e-06, 'epoch': 2.89}\n",
      "{'loss': 28.375, 'learning_rate': 5.493000000000001e-06, 'epoch': 2.89}\n",
      "{'loss': 28.0, 'learning_rate': 5.492000000000001e-06, 'epoch': 2.89}\n",
      "{'loss': 27.875, 'learning_rate': 5.4910000000000005e-06, 'epoch': 2.89}\n",
      "{'loss': 29.375, 'learning_rate': 5.490000000000001e-06, 'epoch': 2.89}\n",
      "{'loss': 27.75, 'learning_rate': 5.489000000000001e-06, 'epoch': 2.9}\n",
      "{'loss': 28.625, 'learning_rate': 5.488e-06, 'epoch': 2.9}\n",
      "{'loss': 26.875, 'learning_rate': 5.487e-06, 'epoch': 2.9}\n",
      "{'loss': 28.375, 'learning_rate': 5.4860000000000005e-06, 'epoch': 2.9}\n",
      "{'loss': 28.25, 'learning_rate': 5.485e-06, 'epoch': 2.9}\n",
      "{'loss': 27.0, 'learning_rate': 5.484e-06, 'epoch': 2.9}\n",
      "{'loss': 28.875, 'learning_rate': 5.483000000000001e-06, 'epoch': 2.9}\n",
      "{'loss': 27.75, 'learning_rate': 5.482000000000001e-06, 'epoch': 2.9}\n",
      "{'loss': 27.875, 'learning_rate': 5.4810000000000005e-06, 'epoch': 2.9}\n",
      "{'loss': 26.875, 'learning_rate': 5.480000000000001e-06, 'epoch': 2.9}\n",
      "{'loss': 27.0, 'learning_rate': 5.479000000000001e-06, 'epoch': 2.9}\n",
      "{'loss': 26.875, 'learning_rate': 5.478e-06, 'epoch': 2.9}\n",
      "{'loss': 26.625, 'learning_rate': 5.477e-06, 'epoch': 2.9}\n",
      "{'loss': 28.375, 'learning_rate': 5.476000000000001e-06, 'epoch': 2.9}\n",
      "{'loss': 26.625, 'learning_rate': 5.475e-06, 'epoch': 2.9}\n",
      "{'loss': 28.0, 'learning_rate': 5.4740000000000004e-06, 'epoch': 2.91}\n",
      "{'loss': 27.5, 'learning_rate': 5.473000000000001e-06, 'epoch': 2.91}\n",
      "{'loss': 28.25, 'learning_rate': 5.472e-06, 'epoch': 2.91}\n",
      "{'loss': 27.875, 'learning_rate': 5.471000000000001e-06, 'epoch': 2.91}\n",
      "{'loss': 27.375, 'learning_rate': 5.470000000000001e-06, 'epoch': 2.91}\n",
      "{'loss': 27.75, 'learning_rate': 5.469000000000001e-06, 'epoch': 2.91}\n",
      "{'loss': 28.25, 'learning_rate': 5.468e-06, 'epoch': 2.91}\n",
      "{'loss': 29.375, 'learning_rate': 5.467e-06, 'epoch': 2.91}\n",
      "{'loss': 30.75, 'learning_rate': 5.466e-06, 'epoch': 2.91}\n",
      "{'loss': 27.125, 'learning_rate': 5.465e-06, 'epoch': 2.91}\n",
      "{'loss': 26.75, 'learning_rate': 5.4640000000000005e-06, 'epoch': 2.91}\n",
      "{'loss': 26.875, 'learning_rate': 5.463000000000001e-06, 'epoch': 2.91}\n",
      "{'loss': 27.875, 'learning_rate': 5.462e-06, 'epoch': 2.91}\n",
      "{'loss': 28.0, 'learning_rate': 5.461000000000001e-06, 'epoch': 2.91}\n",
      "{'loss': 27.125, 'learning_rate': 5.460000000000001e-06, 'epoch': 2.91}\n",
      "{'loss': 26.625, 'learning_rate': 5.459000000000001e-06, 'epoch': 2.91}\n",
      "{'loss': 29.875, 'learning_rate': 5.458e-06, 'epoch': 2.92}\n",
      "{'loss': 26.25, 'learning_rate': 5.4570000000000004e-06, 'epoch': 2.92}\n",
      "{'loss': 27.25, 'learning_rate': 5.456e-06, 'epoch': 2.92}\n",
      "{'loss': 26.375, 'learning_rate': 5.455e-06, 'epoch': 2.92}\n",
      "{'loss': 27.5, 'learning_rate': 5.454000000000001e-06, 'epoch': 2.92}\n",
      "{'loss': 26.5, 'learning_rate': 5.453e-06, 'epoch': 2.92}\n",
      "{'loss': 27.625, 'learning_rate': 5.4520000000000005e-06, 'epoch': 2.92}\n",
      "{'loss': 28.75, 'learning_rate': 5.451000000000001e-06, 'epoch': 2.92}\n",
      "{'loss': 27.625, 'learning_rate': 5.450000000000001e-06, 'epoch': 2.92}\n",
      "{'loss': 27.5, 'learning_rate': 5.449000000000001e-06, 'epoch': 2.92}\n",
      "{'loss': 28.0, 'learning_rate': 5.448e-06, 'epoch': 2.92}\n",
      "{'loss': 26.5, 'learning_rate': 5.447e-06, 'epoch': 2.92}\n",
      "{'loss': 27.125, 'learning_rate': 5.446e-06, 'epoch': 2.92}\n",
      "{'loss': 27.625, 'learning_rate': 5.445e-06, 'epoch': 2.92}\n",
      "{'loss': 27.5, 'learning_rate': 5.444000000000001e-06, 'epoch': 2.92}\n",
      "{'loss': 27.625, 'learning_rate': 5.443e-06, 'epoch': 2.92}\n",
      "{'loss': 27.0, 'learning_rate': 5.442000000000001e-06, 'epoch': 2.93}\n",
      "{'loss': 30.625, 'learning_rate': 5.441000000000001e-06, 'epoch': 2.93}\n",
      "{'loss': 28.625, 'learning_rate': 5.4400000000000004e-06, 'epoch': 2.93}\n",
      "{'loss': 27.125, 'learning_rate': 5.439000000000001e-06, 'epoch': 2.93}\n",
      "{'loss': 28.125, 'learning_rate': 5.438e-06, 'epoch': 2.93}\n",
      "{'loss': 28.75, 'learning_rate': 5.437e-06, 'epoch': 2.93}\n",
      "{'loss': 28.125, 'learning_rate': 5.436e-06, 'epoch': 2.93}\n",
      "{'loss': 27.0, 'learning_rate': 5.4350000000000005e-06, 'epoch': 2.93}\n",
      "{'loss': 30.0, 'learning_rate': 5.434e-06, 'epoch': 2.93}\n",
      "{'loss': 27.875, 'learning_rate': 5.433e-06, 'epoch': 2.93}\n",
      "{'loss': 26.625, 'learning_rate': 5.432000000000001e-06, 'epoch': 2.93}\n",
      "{'loss': 27.375, 'learning_rate': 5.431000000000001e-06, 'epoch': 2.93}\n",
      "{'loss': 28.0, 'learning_rate': 5.4300000000000005e-06, 'epoch': 2.93}\n",
      "{'loss': 28.25, 'learning_rate': 5.429000000000001e-06, 'epoch': 2.93}\n",
      "{'loss': 28.625, 'learning_rate': 5.4279999999999995e-06, 'epoch': 2.93}\n",
      "{'loss': 27.75, 'learning_rate': 5.427e-06, 'epoch': 2.94}\n",
      "{'loss': 28.625, 'learning_rate': 5.426e-06, 'epoch': 2.94}\n",
      "{'loss': 27.375, 'learning_rate': 5.4250000000000006e-06, 'epoch': 2.94}\n",
      "{'loss': 27.25, 'learning_rate': 5.424e-06, 'epoch': 2.94}\n",
      "{'loss': 27.125, 'learning_rate': 5.4230000000000004e-06, 'epoch': 2.94}\n",
      "{'loss': 27.125, 'learning_rate': 5.422000000000001e-06, 'epoch': 2.94}\n",
      "{'loss': 28.25, 'learning_rate': 5.421000000000001e-06, 'epoch': 2.94}\n",
      "{'loss': 27.5, 'learning_rate': 5.420000000000001e-06, 'epoch': 2.94}\n",
      "{'loss': 26.875, 'learning_rate': 5.419000000000001e-06, 'epoch': 2.94}\n",
      "{'loss': 27.5, 'learning_rate': 5.418e-06, 'epoch': 2.94}\n",
      "{'loss': 30.625, 'learning_rate': 5.417e-06, 'epoch': 2.94}\n",
      "{'loss': 28.25, 'learning_rate': 5.416e-06, 'epoch': 2.94}\n",
      "{'loss': 30.0, 'learning_rate': 5.415000000000001e-06, 'epoch': 2.94}\n",
      "{'loss': 27.875, 'learning_rate': 5.414e-06, 'epoch': 2.94}\n",
      "{'loss': 27.5, 'learning_rate': 5.4130000000000005e-06, 'epoch': 2.94}\n",
      "{'loss': 27.875, 'learning_rate': 5.412000000000001e-06, 'epoch': 2.94}\n",
      "{'loss': 27.75, 'learning_rate': 5.411e-06, 'epoch': 2.95}\n",
      "{'loss': 28.0, 'learning_rate': 5.410000000000001e-06, 'epoch': 2.95}\n",
      "{'loss': 28.25, 'learning_rate': 5.409000000000001e-06, 'epoch': 2.95}\n",
      "{'loss': 27.375, 'learning_rate': 5.408e-06, 'epoch': 2.95}\n",
      "{'loss': 28.125, 'learning_rate': 5.407e-06, 'epoch': 2.95}\n",
      "{'loss': 27.625, 'learning_rate': 5.406e-06, 'epoch': 2.95}\n",
      "{'loss': 27.375, 'learning_rate': 5.405e-06, 'epoch': 2.95}\n",
      "{'loss': 26.5, 'learning_rate': 5.404e-06, 'epoch': 2.95}\n",
      "{'loss': 26.75, 'learning_rate': 5.403000000000001e-06, 'epoch': 2.95}\n",
      "{'loss': 28.125, 'learning_rate': 5.402000000000001e-06, 'epoch': 2.95}\n",
      "{'loss': 28.625, 'learning_rate': 5.4010000000000005e-06, 'epoch': 2.95}\n",
      "{'loss': 29.25, 'learning_rate': 5.400000000000001e-06, 'epoch': 2.95}\n",
      "{'loss': 27.125, 'learning_rate': 5.399000000000001e-06, 'epoch': 2.95}\n",
      "{'loss': 27.0, 'learning_rate': 5.398e-06, 'epoch': 2.95}\n",
      "{'loss': 27.375, 'learning_rate': 5.397e-06, 'epoch': 2.95}\n",
      "{'loss': 27.75, 'learning_rate': 5.3960000000000005e-06, 'epoch': 2.96}\n",
      "{'loss': 28.25, 'learning_rate': 5.395e-06, 'epoch': 2.96}\n",
      "{'loss': 27.375, 'learning_rate': 5.394e-06, 'epoch': 2.96}\n",
      "{'loss': 27.125, 'learning_rate': 5.393000000000001e-06, 'epoch': 2.96}\n",
      "{'loss': 26.875, 'learning_rate': 5.392e-06, 'epoch': 2.96}\n",
      "{'loss': 27.25, 'learning_rate': 5.3910000000000006e-06, 'epoch': 2.96}\n",
      "{'loss': 28.875, 'learning_rate': 5.390000000000001e-06, 'epoch': 2.96}\n",
      "{'loss': 28.0, 'learning_rate': 5.389000000000001e-06, 'epoch': 2.96}\n",
      "{'loss': 27.75, 'learning_rate': 5.388e-06, 'epoch': 2.96}\n",
      "{'loss': 28.0, 'learning_rate': 5.387e-06, 'epoch': 2.96}\n",
      "{'loss': 26.5, 'learning_rate': 5.386e-06, 'epoch': 2.96}\n",
      "{'loss': 30.25, 'learning_rate': 5.385e-06, 'epoch': 2.96}\n",
      "{'loss': 27.25, 'learning_rate': 5.3840000000000005e-06, 'epoch': 2.96}\n",
      "{'loss': 27.625, 'learning_rate': 5.383000000000001e-06, 'epoch': 2.96}\n",
      "{'loss': 27.25, 'learning_rate': 5.382e-06, 'epoch': 2.96}\n",
      "{'loss': 26.125, 'learning_rate': 5.381000000000001e-06, 'epoch': 2.96}\n",
      "{'loss': 27.5, 'learning_rate': 5.380000000000001e-06, 'epoch': 2.97}\n",
      "{'loss': 28.0, 'learning_rate': 5.3790000000000005e-06, 'epoch': 2.97}\n",
      "{'loss': 28.625, 'learning_rate': 5.378e-06, 'epoch': 2.97}\n",
      "{'loss': 27.125, 'learning_rate': 5.377e-06, 'epoch': 2.97}\n",
      "{'loss': 27.125, 'learning_rate': 5.376e-06, 'epoch': 2.97}\n",
      "{'loss': 28.5, 'learning_rate': 5.375e-06, 'epoch': 2.97}\n",
      "{'loss': 27.5, 'learning_rate': 5.3740000000000006e-06, 'epoch': 2.97}\n",
      "{'loss': 27.5, 'learning_rate': 5.373e-06, 'epoch': 2.97}\n",
      "{'loss': 26.875, 'learning_rate': 5.372e-06, 'epoch': 2.97}\n",
      "{'loss': 26.875, 'learning_rate': 5.371000000000001e-06, 'epoch': 2.97}\n",
      "{'loss': 27.5, 'learning_rate': 5.370000000000001e-06, 'epoch': 2.97}\n",
      "{'loss': 27.25, 'learning_rate': 5.369000000000001e-06, 'epoch': 2.97}\n",
      "{'loss': 28.125, 'learning_rate': 5.368000000000001e-06, 'epoch': 2.97}\n",
      "{'loss': 26.875, 'learning_rate': 5.367e-06, 'epoch': 2.97}\n",
      "{'loss': 27.0, 'learning_rate': 5.366e-06, 'epoch': 2.97}\n",
      "{'loss': 28.625, 'learning_rate': 5.365e-06, 'epoch': 2.97}\n",
      "{'loss': 27.75, 'learning_rate': 5.364000000000001e-06, 'epoch': 2.98}\n",
      "{'loss': 27.75, 'learning_rate': 5.363e-06, 'epoch': 2.98}\n",
      "{'loss': 26.625, 'learning_rate': 5.3620000000000005e-06, 'epoch': 2.98}\n",
      "{'loss': 26.625, 'learning_rate': 5.361000000000001e-06, 'epoch': 2.98}\n",
      "{'loss': 27.5, 'learning_rate': 5.36e-06, 'epoch': 2.98}\n",
      "{'loss': 27.625, 'learning_rate': 5.359000000000001e-06, 'epoch': 2.98}\n",
      "{'loss': 27.625, 'learning_rate': 5.358000000000001e-06, 'epoch': 2.98}\n",
      "{'loss': 29.0, 'learning_rate': 5.357e-06, 'epoch': 2.98}\n",
      "{'loss': 28.375, 'learning_rate': 5.356e-06, 'epoch': 2.98}\n",
      "{'loss': 27.25, 'learning_rate': 5.355e-06, 'epoch': 2.98}\n",
      "{'loss': 28.5, 'learning_rate': 5.354e-06, 'epoch': 2.98}\n",
      "{'loss': 27.5, 'learning_rate': 5.353e-06, 'epoch': 2.98}\n",
      "{'loss': 28.0, 'learning_rate': 5.352000000000001e-06, 'epoch': 2.98}\n",
      "{'loss': 26.375, 'learning_rate': 5.351000000000001e-06, 'epoch': 2.98}\n",
      "{'loss': 30.0, 'learning_rate': 5.3500000000000004e-06, 'epoch': 2.98}\n",
      "{'loss': 27.125, 'learning_rate': 5.349000000000001e-06, 'epoch': 2.99}\n",
      "{'loss': 29.0, 'learning_rate': 5.348000000000001e-06, 'epoch': 2.99}\n",
      "{'loss': 28.625, 'learning_rate': 5.347e-06, 'epoch': 2.99}\n",
      "{'loss': 28.75, 'learning_rate': 5.346e-06, 'epoch': 2.99}\n",
      "{'loss': 26.875, 'learning_rate': 5.3450000000000005e-06, 'epoch': 2.99}\n",
      "{'loss': 27.125, 'learning_rate': 5.344e-06, 'epoch': 2.99}\n",
      "{'loss': 26.125, 'learning_rate': 5.343e-06, 'epoch': 2.99}\n",
      "{'loss': 27.125, 'learning_rate': 5.342000000000001e-06, 'epoch': 2.99}\n",
      "{'loss': 28.625, 'learning_rate': 5.341000000000001e-06, 'epoch': 2.99}\n",
      "{'loss': 29.75, 'learning_rate': 5.3400000000000005e-06, 'epoch': 2.99}\n",
      "{'loss': 27.125, 'learning_rate': 5.339000000000001e-06, 'epoch': 2.99}\n",
      "{'loss': 29.625, 'learning_rate': 5.338000000000001e-06, 'epoch': 2.99}\n",
      "{'loss': 27.25, 'learning_rate': 5.337e-06, 'epoch': 2.99}\n",
      "{'loss': 27.625, 'learning_rate': 5.336e-06, 'epoch': 2.99}\n",
      "{'loss': 26.625, 'learning_rate': 5.335000000000001e-06, 'epoch': 2.99}\n",
      "{'loss': 27.0, 'learning_rate': 5.334e-06, 'epoch': 2.99}\n",
      "{'loss': 28.25, 'learning_rate': 5.3330000000000004e-06, 'epoch': 3.0}\n",
      "{'loss': 27.125, 'learning_rate': 5.332000000000001e-06, 'epoch': 3.0}\n",
      "{'loss': 27.5, 'learning_rate': 5.331e-06, 'epoch': 3.0}\n",
      "{'loss': 27.375, 'learning_rate': 5.330000000000001e-06, 'epoch': 3.0}\n",
      "{'loss': 27.0, 'learning_rate': 5.329000000000001e-06, 'epoch': 3.0}\n",
      "{'loss': 26.875, 'learning_rate': 5.328000000000001e-06, 'epoch': 3.0}\n",
      "{'loss': 27.25, 'learning_rate': 5.327e-06, 'epoch': 3.0}\n",
      "{'loss': 26.875, 'learning_rate': 5.326e-06, 'epoch': 3.0}\n",
      "{'loss': 28.125, 'learning_rate': 5.325e-06, 'epoch': 3.0}\n",
      "{'loss': 28.0, 'learning_rate': 5.324e-06, 'epoch': 3.0}\n",
      "{'loss': 27.25, 'learning_rate': 5.3230000000000005e-06, 'epoch': 3.0}\n",
      "{'loss': 26.75, 'learning_rate': 5.322000000000001e-06, 'epoch': 3.0}\n",
      "{'loss': 29.375, 'learning_rate': 5.321e-06, 'epoch': 3.0}\n",
      "{'loss': 28.5, 'learning_rate': 5.320000000000001e-06, 'epoch': 3.0}\n",
      "{'loss': 28.25, 'learning_rate': 5.319000000000001e-06, 'epoch': 3.0}\n",
      "{'loss': 26.875, 'learning_rate': 5.318000000000001e-06, 'epoch': 3.01}\n",
      "{'loss': 28.625, 'learning_rate': 5.317e-06, 'epoch': 3.01}\n",
      "{'loss': 29.5, 'learning_rate': 5.3160000000000004e-06, 'epoch': 3.01}\n",
      "{'loss': 27.375, 'learning_rate': 5.315e-06, 'epoch': 3.01}\n",
      "{'loss': 28.0, 'learning_rate': 5.314e-06, 'epoch': 3.01}\n",
      "{'loss': 28.0, 'learning_rate': 5.313000000000001e-06, 'epoch': 3.01}\n",
      "{'loss': 27.0, 'learning_rate': 5.312e-06, 'epoch': 3.01}\n",
      "{'loss': 28.125, 'learning_rate': 5.3110000000000005e-06, 'epoch': 3.01}\n",
      "{'loss': 29.375, 'learning_rate': 5.310000000000001e-06, 'epoch': 3.01}\n",
      "{'loss': 26.875, 'learning_rate': 5.309000000000001e-06, 'epoch': 3.01}\n",
      "{'loss': 28.375, 'learning_rate': 5.308000000000001e-06, 'epoch': 3.01}\n",
      "{'loss': 27.375, 'learning_rate': 5.307e-06, 'epoch': 3.01}\n",
      "{'loss': 28.0, 'learning_rate': 5.306e-06, 'epoch': 3.01}\n",
      "{'loss': 28.375, 'learning_rate': 5.305e-06, 'epoch': 3.01}\n",
      "{'loss': 27.375, 'learning_rate': 5.304e-06, 'epoch': 3.01}\n",
      "{'loss': 28.625, 'learning_rate': 5.303000000000001e-06, 'epoch': 3.01}\n",
      "{'loss': 27.125, 'learning_rate': 5.302e-06, 'epoch': 3.02}\n",
      "{'loss': 27.75, 'learning_rate': 5.3010000000000006e-06, 'epoch': 3.02}\n",
      "{'loss': 28.0, 'learning_rate': 5.300000000000001e-06, 'epoch': 3.02}\n",
      "{'loss': 27.0, 'learning_rate': 5.2990000000000004e-06, 'epoch': 3.02}\n",
      "{'loss': 27.0, 'learning_rate': 5.298000000000001e-06, 'epoch': 3.02}\n",
      "{'loss': 27.75, 'learning_rate': 5.297e-06, 'epoch': 3.02}\n",
      "{'loss': 27.625, 'learning_rate': 5.296e-06, 'epoch': 3.02}\n",
      "{'loss': 26.75, 'learning_rate': 5.295e-06, 'epoch': 3.02}\n",
      "{'loss': 28.0, 'learning_rate': 5.2940000000000005e-06, 'epoch': 3.02}\n",
      "{'loss': 26.625, 'learning_rate': 5.293e-06, 'epoch': 3.02}\n",
      "{'loss': 27.5, 'learning_rate': 5.292e-06, 'epoch': 3.02}\n",
      "{'loss': 26.625, 'learning_rate': 5.291000000000001e-06, 'epoch': 3.02}\n",
      "{'loss': 28.25, 'learning_rate': 5.290000000000001e-06, 'epoch': 3.02}\n",
      "{'loss': 27.875, 'learning_rate': 5.2890000000000005e-06, 'epoch': 3.02}\n",
      "{'loss': 30.25, 'learning_rate': 5.288000000000001e-06, 'epoch': 3.02}\n",
      "{'loss': 27.375, 'learning_rate': 5.2869999999999995e-06, 'epoch': 3.03}\n",
      "{'loss': 27.125, 'learning_rate': 5.286e-06, 'epoch': 3.03}\n",
      "{'loss': 27.25, 'learning_rate': 5.285e-06, 'epoch': 3.03}\n",
      "{'loss': 28.0, 'learning_rate': 5.2840000000000006e-06, 'epoch': 3.03}\n",
      "{'loss': 27.125, 'learning_rate': 5.283e-06, 'epoch': 3.03}\n",
      "{'loss': 27.0, 'learning_rate': 5.282e-06, 'epoch': 3.03}\n",
      "{'loss': 27.5, 'learning_rate': 5.281000000000001e-06, 'epoch': 3.03}\n",
      "{'loss': 28.125, 'learning_rate': 5.28e-06, 'epoch': 3.03}\n",
      "{'loss': 27.125, 'learning_rate': 5.279000000000001e-06, 'epoch': 3.03}\n",
      "{'loss': 28.0, 'learning_rate': 5.278000000000001e-06, 'epoch': 3.03}\n",
      "{'loss': 28.75, 'learning_rate': 5.277e-06, 'epoch': 3.03}\n",
      "{'loss': 30.75, 'learning_rate': 5.276e-06, 'epoch': 3.03}\n",
      "{'loss': 26.5, 'learning_rate': 5.275e-06, 'epoch': 3.03}\n",
      "{'loss': 28.125, 'learning_rate': 5.274e-06, 'epoch': 3.03}\n",
      "{'loss': 28.25, 'learning_rate': 5.273e-06, 'epoch': 3.03}\n",
      "{'loss': 27.25, 'learning_rate': 5.2720000000000005e-06, 'epoch': 3.03}\n",
      "{'loss': 27.625, 'learning_rate': 5.271000000000001e-06, 'epoch': 3.04}\n",
      "{'loss': 28.375, 'learning_rate': 5.27e-06, 'epoch': 3.04}\n",
      "{'loss': 28.875, 'learning_rate': 5.269000000000001e-06, 'epoch': 3.04}\n",
      "{'loss': 28.0, 'learning_rate': 5.268000000000001e-06, 'epoch': 3.04}\n",
      "{'loss': 27.375, 'learning_rate': 5.267e-06, 'epoch': 3.04}\n",
      "{'loss': 28.0, 'learning_rate': 5.266e-06, 'epoch': 3.04}\n",
      "{'loss': 27.875, 'learning_rate': 5.265e-06, 'epoch': 3.04}\n",
      "{'loss': 27.5, 'learning_rate': 5.264e-06, 'epoch': 3.04}\n",
      "{'loss': 26.375, 'learning_rate': 5.263e-06, 'epoch': 3.04}\n",
      "{'loss': 26.5, 'learning_rate': 5.262000000000001e-06, 'epoch': 3.04}\n",
      "{'loss': 26.125, 'learning_rate': 5.261000000000001e-06, 'epoch': 3.04}\n",
      "{'loss': 28.25, 'learning_rate': 5.2600000000000005e-06, 'epoch': 3.04}\n",
      "{'loss': 28.25, 'learning_rate': 5.259000000000001e-06, 'epoch': 3.04}\n",
      "{'loss': 26.625, 'learning_rate': 5.258000000000001e-06, 'epoch': 3.04}\n",
      "{'loss': 27.125, 'learning_rate': 5.257e-06, 'epoch': 3.04}\n",
      "{'loss': 27.0, 'learning_rate': 5.256e-06, 'epoch': 3.04}\n",
      "{'loss': 27.0, 'learning_rate': 5.2550000000000005e-06, 'epoch': 3.05}\n",
      "{'loss': 29.625, 'learning_rate': 5.254e-06, 'epoch': 3.05}\n",
      "{'loss': 26.625, 'learning_rate': 5.253e-06, 'epoch': 3.05}\n",
      "{'loss': 28.5, 'learning_rate': 5.252000000000001e-06, 'epoch': 3.05}\n",
      "{'loss': 26.875, 'learning_rate': 5.251e-06, 'epoch': 3.05}\n",
      "{'loss': 27.375, 'learning_rate': 5.2500000000000006e-06, 'epoch': 3.05}\n",
      "{'loss': 27.25, 'learning_rate': 5.249000000000001e-06, 'epoch': 3.05}\n",
      "{'loss': 27.0, 'learning_rate': 5.248000000000001e-06, 'epoch': 3.05}\n",
      "{'loss': 28.25, 'learning_rate': 5.247000000000001e-06, 'epoch': 3.05}\n",
      "{'loss': 27.0, 'learning_rate': 5.246e-06, 'epoch': 3.05}\n",
      "{'loss': 26.875, 'learning_rate': 5.245e-06, 'epoch': 3.05}\n",
      "{'loss': 27.0, 'learning_rate': 5.244e-06, 'epoch': 3.05}\n",
      "{'loss': 27.125, 'learning_rate': 5.2430000000000005e-06, 'epoch': 3.05}\n",
      "{'loss': 27.25, 'learning_rate': 5.242000000000001e-06, 'epoch': 3.05}\n",
      "{'loss': 26.875, 'learning_rate': 5.241e-06, 'epoch': 3.05}\n",
      "{'loss': 28.125, 'learning_rate': 5.240000000000001e-06, 'epoch': 3.06}\n",
      "{'loss': 28.625, 'learning_rate': 5.239000000000001e-06, 'epoch': 3.06}\n",
      "{'loss': 26.75, 'learning_rate': 5.2380000000000005e-06, 'epoch': 3.06}\n",
      "{'loss': 27.75, 'learning_rate': 5.237000000000001e-06, 'epoch': 3.06}\n",
      "{'loss': 29.25, 'learning_rate': 5.236e-06, 'epoch': 3.06}\n",
      "{'loss': 27.0, 'learning_rate': 5.235e-06, 'epoch': 3.06}\n",
      "{'loss': 27.75, 'learning_rate': 5.234e-06, 'epoch': 3.06}\n",
      "{'loss': 30.0, 'learning_rate': 5.2330000000000005e-06, 'epoch': 3.06}\n",
      "{'loss': 27.625, 'learning_rate': 5.232e-06, 'epoch': 3.06}\n",
      "{'loss': 27.0, 'learning_rate': 5.231e-06, 'epoch': 3.06}\n",
      "{'loss': 27.25, 'learning_rate': 5.230000000000001e-06, 'epoch': 3.06}\n",
      "{'loss': 29.5, 'learning_rate': 5.229000000000001e-06, 'epoch': 3.06}\n",
      "{'loss': 28.125, 'learning_rate': 5.228000000000001e-06, 'epoch': 3.06}\n",
      "{'loss': 30.0, 'learning_rate': 5.227000000000001e-06, 'epoch': 3.06}\n",
      "{'loss': 26.375, 'learning_rate': 5.226e-06, 'epoch': 3.06}\n",
      "{'loss': 27.25, 'learning_rate': 5.225e-06, 'epoch': 3.06}\n",
      "{'loss': 28.125, 'learning_rate': 5.224e-06, 'epoch': 3.07}\n",
      "{'loss': 27.0, 'learning_rate': 5.223000000000001e-06, 'epoch': 3.07}\n",
      "{'loss': 26.25, 'learning_rate': 5.222e-06, 'epoch': 3.07}\n",
      "{'loss': 27.75, 'learning_rate': 5.2210000000000005e-06, 'epoch': 3.07}\n",
      "{'loss': 27.375, 'learning_rate': 5.220000000000001e-06, 'epoch': 3.07}\n",
      "{'loss': 27.625, 'learning_rate': 5.219e-06, 'epoch': 3.07}\n",
      "{'loss': 28.5, 'learning_rate': 5.218000000000001e-06, 'epoch': 3.07}\n",
      "{'loss': 27.5, 'learning_rate': 5.217000000000001e-06, 'epoch': 3.07}\n",
      "{'loss': 27.375, 'learning_rate': 5.216e-06, 'epoch': 3.07}\n",
      "{'loss': 27.875, 'learning_rate': 5.215e-06, 'epoch': 3.07}\n",
      "{'loss': 28.125, 'learning_rate': 5.214e-06, 'epoch': 3.07}\n",
      "{'loss': 26.5, 'learning_rate': 5.213e-06, 'epoch': 3.07}\n",
      "{'loss': 27.625, 'learning_rate': 5.212e-06, 'epoch': 3.07}\n",
      "{'loss': 26.75, 'learning_rate': 5.211000000000001e-06, 'epoch': 3.07}\n",
      "{'loss': 26.75, 'learning_rate': 5.210000000000001e-06, 'epoch': 3.07}\n",
      "{'loss': 27.5, 'learning_rate': 5.2090000000000004e-06, 'epoch': 3.08}\n",
      "{'loss': 26.875, 'learning_rate': 5.208000000000001e-06, 'epoch': 3.08}\n",
      "{'loss': 27.125, 'learning_rate': 5.207000000000001e-06, 'epoch': 3.08}\n",
      "{'loss': 29.125, 'learning_rate': 5.206e-06, 'epoch': 3.08}\n",
      "{'loss': 26.5, 'learning_rate': 5.205e-06, 'epoch': 3.08}\n",
      "{'loss': 27.125, 'learning_rate': 5.2040000000000005e-06, 'epoch': 3.08}\n",
      "{'loss': 30.375, 'learning_rate': 5.203e-06, 'epoch': 3.08}\n",
      "{'loss': 26.875, 'learning_rate': 5.202e-06, 'epoch': 3.08}\n",
      "{'loss': 27.125, 'learning_rate': 5.201000000000001e-06, 'epoch': 3.08}\n",
      "{'loss': 27.125, 'learning_rate': 5.2e-06, 'epoch': 3.08}\n",
      "{'loss': 26.625, 'learning_rate': 5.1990000000000005e-06, 'epoch': 3.08}\n",
      "{'loss': 27.625, 'learning_rate': 5.198000000000001e-06, 'epoch': 3.08}\n",
      "{'loss': 27.125, 'learning_rate': 5.197000000000001e-06, 'epoch': 3.08}\n",
      "{'loss': 26.875, 'learning_rate': 5.196e-06, 'epoch': 3.08}\n",
      "{'loss': 27.375, 'learning_rate': 5.195e-06, 'epoch': 3.08}\n",
      "{'loss': 27.375, 'learning_rate': 5.194e-06, 'epoch': 3.08}\n",
      "{'loss': 28.0, 'learning_rate': 5.193e-06, 'epoch': 3.09}\n",
      "{'loss': 26.75, 'learning_rate': 5.1920000000000004e-06, 'epoch': 3.09}\n",
      "{'loss': 27.5, 'learning_rate': 5.191000000000001e-06, 'epoch': 3.09}\n",
      "{'loss': 26.625, 'learning_rate': 5.19e-06, 'epoch': 3.09}\n",
      "{'loss': 28.0, 'learning_rate': 5.189000000000001e-06, 'epoch': 3.09}\n",
      "{'loss': 26.875, 'learning_rate': 5.188000000000001e-06, 'epoch': 3.09}\n",
      "{'loss': 26.75, 'learning_rate': 5.187000000000001e-06, 'epoch': 3.09}\n",
      "{'loss': 27.75, 'learning_rate': 5.186e-06, 'epoch': 3.09}\n",
      "{'loss': 26.75, 'learning_rate': 5.185e-06, 'epoch': 3.09}\n",
      "{'loss': 26.875, 'learning_rate': 5.184e-06, 'epoch': 3.09}\n",
      "{'loss': 26.75, 'learning_rate': 5.183e-06, 'epoch': 3.09}\n",
      "{'loss': 26.25, 'learning_rate': 5.1820000000000005e-06, 'epoch': 3.09}\n",
      "{'loss': 28.5, 'learning_rate': 5.181000000000001e-06, 'epoch': 3.09}\n",
      "{'loss': 27.375, 'learning_rate': 5.18e-06, 'epoch': 3.09}\n",
      "{'loss': 27.625, 'learning_rate': 5.179000000000001e-06, 'epoch': 3.09}\n",
      "{'loss': 27.375, 'learning_rate': 5.178000000000001e-06, 'epoch': 3.09}\n",
      "{'loss': 27.25, 'learning_rate': 5.177000000000001e-06, 'epoch': 3.1}\n",
      "{'loss': 27.375, 'learning_rate': 5.176e-06, 'epoch': 3.1}\n",
      "{'loss': 27.25, 'learning_rate': 5.1750000000000004e-06, 'epoch': 3.1}\n",
      "{'loss': 28.0, 'learning_rate': 5.174e-06, 'epoch': 3.1}\n",
      "{'loss': 26.875, 'learning_rate': 5.173e-06, 'epoch': 3.1}\n",
      "{'loss': 28.375, 'learning_rate': 5.172000000000001e-06, 'epoch': 3.1}\n",
      "{'loss': 28.625, 'learning_rate': 5.171e-06, 'epoch': 3.1}\n",
      "{'loss': 27.625, 'learning_rate': 5.1700000000000005e-06, 'epoch': 3.1}\n",
      "{'loss': 28.375, 'learning_rate': 5.169000000000001e-06, 'epoch': 3.1}\n",
      "{'loss': 26.75, 'learning_rate': 5.168000000000001e-06, 'epoch': 3.1}\n",
      "{'loss': 29.375, 'learning_rate': 5.167000000000001e-06, 'epoch': 3.1}\n",
      "{'loss': 28.25, 'learning_rate': 5.166e-06, 'epoch': 3.1}\n",
      "{'loss': 27.625, 'learning_rate': 5.165e-06, 'epoch': 3.1}\n",
      "{'loss': 27.5, 'learning_rate': 5.164e-06, 'epoch': 3.1}\n",
      "{'loss': 27.25, 'learning_rate': 5.163e-06, 'epoch': 3.1}\n",
      "{'loss': 26.125, 'learning_rate': 5.162000000000001e-06, 'epoch': 3.11}\n",
      "{'loss': 28.875, 'learning_rate': 5.161e-06, 'epoch': 3.11}\n",
      "{'loss': 27.25, 'learning_rate': 5.1600000000000006e-06, 'epoch': 3.11}\n",
      "{'loss': 27.75, 'learning_rate': 5.159000000000001e-06, 'epoch': 3.11}\n",
      "{'loss': 27.75, 'learning_rate': 5.158e-06, 'epoch': 3.11}\n",
      "{'loss': 27.375, 'learning_rate': 5.157000000000001e-06, 'epoch': 3.11}\n",
      "{'loss': 27.75, 'learning_rate': 5.156e-06, 'epoch': 3.11}\n",
      "{'loss': 27.25, 'learning_rate': 5.155e-06, 'epoch': 3.11}\n",
      "{'loss': 27.125, 'learning_rate': 5.154e-06, 'epoch': 3.11}\n",
      "{'loss': 28.0, 'learning_rate': 5.1530000000000005e-06, 'epoch': 3.11}\n",
      "{'loss': 26.625, 'learning_rate': 5.152e-06, 'epoch': 3.11}\n",
      "{'loss': 27.25, 'learning_rate': 5.151e-06, 'epoch': 3.11}\n",
      "{'loss': 28.875, 'learning_rate': 5.150000000000001e-06, 'epoch': 3.11}\n",
      "{'loss': 27.375, 'learning_rate': 5.149000000000001e-06, 'epoch': 3.11}\n",
      "{'loss': 27.5, 'learning_rate': 5.1480000000000005e-06, 'epoch': 3.11}\n",
      "{'loss': 27.375, 'learning_rate': 5.147000000000001e-06, 'epoch': 3.11}\n",
      "{'loss': 26.875, 'learning_rate': 5.1459999999999995e-06, 'epoch': 3.12}\n",
      "{'loss': 27.125, 'learning_rate': 5.145e-06, 'epoch': 3.12}\n",
      "{'loss': 27.625, 'learning_rate': 5.144e-06, 'epoch': 3.12}\n",
      "{'loss': 28.0, 'learning_rate': 5.1430000000000006e-06, 'epoch': 3.12}\n",
      "{'loss': 28.25, 'learning_rate': 5.142e-06, 'epoch': 3.12}\n",
      "{'loss': 27.5, 'learning_rate': 5.141e-06, 'epoch': 3.12}\n",
      "{'loss': 26.25, 'learning_rate': 5.140000000000001e-06, 'epoch': 3.12}\n",
      "{'loss': 27.0, 'learning_rate': 5.139e-06, 'epoch': 3.12}\n",
      "{'loss': 28.75, 'learning_rate': 5.138000000000001e-06, 'epoch': 3.12}\n",
      "{'loss': 28.125, 'learning_rate': 5.137000000000001e-06, 'epoch': 3.12}\n",
      "{'loss': 27.25, 'learning_rate': 5.136e-06, 'epoch': 3.12}\n",
      "{'loss': 27.25, 'learning_rate': 5.135e-06, 'epoch': 3.12}\n",
      "{'loss': 27.5, 'learning_rate': 5.134e-06, 'epoch': 3.12}\n",
      "{'loss': 27.375, 'learning_rate': 5.133e-06, 'epoch': 3.12}\n",
      "{'loss': 29.0, 'learning_rate': 5.132e-06, 'epoch': 3.12}\n",
      "{'loss': 27.125, 'learning_rate': 5.1310000000000005e-06, 'epoch': 3.13}\n",
      "{'loss': 27.75, 'learning_rate': 5.130000000000001e-06, 'epoch': 3.13}\n",
      "{'loss': 27.375, 'learning_rate': 5.129e-06, 'epoch': 3.13}\n",
      "{'loss': 27.5, 'learning_rate': 5.128000000000001e-06, 'epoch': 3.13}\n",
      "{'loss': 27.125, 'learning_rate': 5.127000000000001e-06, 'epoch': 3.13}\n",
      "{'loss': 28.375, 'learning_rate': 5.126e-06, 'epoch': 3.13}\n",
      "{'loss': 27.25, 'learning_rate': 5.125e-06, 'epoch': 3.13}\n",
      "{'loss': 29.125, 'learning_rate': 5.124e-06, 'epoch': 3.13}\n",
      "{'loss': 26.25, 'learning_rate': 5.123e-06, 'epoch': 3.13}\n",
      "{'loss': 27.5, 'learning_rate': 5.122e-06, 'epoch': 3.13}\n",
      "{'loss': 27.75, 'learning_rate': 5.121000000000001e-06, 'epoch': 3.13}\n",
      "{'loss': 27.625, 'learning_rate': 5.12e-06, 'epoch': 3.13}\n",
      "{'loss': 28.875, 'learning_rate': 5.1190000000000005e-06, 'epoch': 3.13}\n",
      "{'loss': 28.375, 'learning_rate': 5.118000000000001e-06, 'epoch': 3.13}\n",
      "{'loss': 28.75, 'learning_rate': 5.117000000000001e-06, 'epoch': 3.13}\n",
      "{'loss': 29.375, 'learning_rate': 5.116000000000001e-06, 'epoch': 3.13}\n",
      "{'loss': 27.625, 'learning_rate': 5.115e-06, 'epoch': 3.14}\n",
      "{'loss': 28.0, 'learning_rate': 5.114e-06, 'epoch': 3.14}\n",
      "{'loss': 27.625, 'learning_rate': 5.113e-06, 'epoch': 3.14}\n",
      "{'loss': 27.0, 'learning_rate': 5.112e-06, 'epoch': 3.14}\n",
      "{'loss': 27.125, 'learning_rate': 5.111000000000001e-06, 'epoch': 3.14}\n",
      "{'loss': 27.125, 'learning_rate': 5.11e-06, 'epoch': 3.14}\n",
      "{'loss': 28.375, 'learning_rate': 5.1090000000000006e-06, 'epoch': 3.14}\n",
      "{'loss': 27.625, 'learning_rate': 5.108000000000001e-06, 'epoch': 3.14}\n",
      "{'loss': 27.25, 'learning_rate': 5.107000000000001e-06, 'epoch': 3.14}\n",
      "{'loss': 28.125, 'learning_rate': 5.106000000000001e-06, 'epoch': 3.14}\n",
      "{'loss': 26.5, 'learning_rate': 5.105e-06, 'epoch': 3.14}\n",
      "{'loss': 27.125, 'learning_rate': 5.104e-06, 'epoch': 3.14}\n",
      "{'loss': 28.75, 'learning_rate': 5.103e-06, 'epoch': 3.14}\n",
      "{'loss': 27.0, 'learning_rate': 5.1020000000000004e-06, 'epoch': 3.14}\n",
      "{'loss': 27.0, 'learning_rate': 5.101000000000001e-06, 'epoch': 3.14}\n",
      "{'loss': 30.25, 'learning_rate': 5.1e-06, 'epoch': 3.15}\n",
      "{'loss': 29.0, 'learning_rate': 5.099000000000001e-06, 'epoch': 3.15}\n",
      "{'loss': 27.125, 'learning_rate': 5.098000000000001e-06, 'epoch': 3.15}\n",
      "{'loss': 28.75, 'learning_rate': 5.0970000000000005e-06, 'epoch': 3.15}\n",
      "{'loss': 26.5, 'learning_rate': 5.096000000000001e-06, 'epoch': 3.15}\n",
      "{'loss': 27.75, 'learning_rate': 5.095e-06, 'epoch': 3.15}\n",
      "{'loss': 30.125, 'learning_rate': 5.094e-06, 'epoch': 3.15}\n",
      "{'loss': 26.5, 'learning_rate': 5.093e-06, 'epoch': 3.15}\n",
      "{'loss': 27.375, 'learning_rate': 5.0920000000000005e-06, 'epoch': 3.15}\n",
      "{'loss': 27.875, 'learning_rate': 5.091e-06, 'epoch': 3.15}\n",
      "{'loss': 27.0, 'learning_rate': 5.09e-06, 'epoch': 3.15}\n",
      "{'loss': 27.625, 'learning_rate': 5.089000000000001e-06, 'epoch': 3.15}\n",
      "{'loss': 28.25, 'learning_rate': 5.088000000000001e-06, 'epoch': 3.15}\n",
      "{'loss': 27.875, 'learning_rate': 5.087000000000001e-06, 'epoch': 3.15}\n",
      "{'loss': 26.75, 'learning_rate': 5.086000000000001e-06, 'epoch': 3.15}\n",
      "{'loss': 28.625, 'learning_rate': 5.085e-06, 'epoch': 3.15}\n",
      "{'loss': 26.625, 'learning_rate': 5.084e-06, 'epoch': 3.16}\n",
      "{'loss': 26.25, 'learning_rate': 5.083e-06, 'epoch': 3.16}\n",
      "{'loss': 27.25, 'learning_rate': 5.082000000000001e-06, 'epoch': 3.16}\n",
      "{'loss': 27.5, 'learning_rate': 5.081e-06, 'epoch': 3.16}\n",
      "{'loss': 27.75, 'learning_rate': 5.0800000000000005e-06, 'epoch': 3.16}\n",
      "{'loss': 29.625, 'learning_rate': 5.079000000000001e-06, 'epoch': 3.16}\n",
      "{'loss': 26.75, 'learning_rate': 5.078e-06, 'epoch': 3.16}\n",
      "{'loss': 27.25, 'learning_rate': 5.077000000000001e-06, 'epoch': 3.16}\n",
      "{'loss': 26.625, 'learning_rate': 5.076000000000001e-06, 'epoch': 3.16}\n",
      "{'loss': 26.875, 'learning_rate': 5.075e-06, 'epoch': 3.16}\n",
      "{'loss': 26.875, 'learning_rate': 5.074e-06, 'epoch': 3.16}\n",
      "{'loss': 26.125, 'learning_rate': 5.073e-06, 'epoch': 3.16}\n",
      "{'loss': 27.125, 'learning_rate': 5.072e-06, 'epoch': 3.16}\n",
      "{'loss': 26.75, 'learning_rate': 5.071e-06, 'epoch': 3.16}\n",
      "{'loss': 27.25, 'learning_rate': 5.070000000000001e-06, 'epoch': 3.16}\n",
      "{'loss': 29.0, 'learning_rate': 5.069000000000001e-06, 'epoch': 3.16}\n",
      "{'loss': 27.75, 'learning_rate': 5.0680000000000004e-06, 'epoch': 3.17}\n",
      "{'loss': 27.5, 'learning_rate': 5.067000000000001e-06, 'epoch': 3.17}\n",
      "{'loss': 26.75, 'learning_rate': 5.066000000000001e-06, 'epoch': 3.17}\n",
      "{'loss': 26.75, 'learning_rate': 5.065e-06, 'epoch': 3.17}\n",
      "{'loss': 29.5, 'learning_rate': 5.064e-06, 'epoch': 3.17}\n",
      "{'loss': 29.625, 'learning_rate': 5.0630000000000005e-06, 'epoch': 3.17}\n",
      "{'loss': 27.5, 'learning_rate': 5.062e-06, 'epoch': 3.17}\n",
      "{'loss': 28.375, 'learning_rate': 5.061e-06, 'epoch': 3.17}\n",
      "{'loss': 26.875, 'learning_rate': 5.060000000000001e-06, 'epoch': 3.17}\n",
      "{'loss': 27.0, 'learning_rate': 5.059e-06, 'epoch': 3.17}\n",
      "{'loss': 28.125, 'learning_rate': 5.0580000000000005e-06, 'epoch': 3.17}\n",
      "{'loss': 27.625, 'learning_rate': 5.057000000000001e-06, 'epoch': 3.17}\n",
      "{'loss': 27.625, 'learning_rate': 5.056000000000001e-06, 'epoch': 3.17}\n",
      "{'loss': 26.375, 'learning_rate': 5.055e-06, 'epoch': 3.17}\n",
      "{'loss': 28.0, 'learning_rate': 5.054e-06, 'epoch': 3.17}\n",
      "{'loss': 27.75, 'learning_rate': 5.053e-06, 'epoch': 3.18}\n",
      "{'loss': 27.5, 'learning_rate': 5.052e-06, 'epoch': 3.18}\n",
      "{'loss': 30.25, 'learning_rate': 5.0510000000000004e-06, 'epoch': 3.18}\n",
      "{'loss': 27.25, 'learning_rate': 5.050000000000001e-06, 'epoch': 3.18}\n",
      "{'loss': 28.25, 'learning_rate': 5.049e-06, 'epoch': 3.18}\n",
      "{'loss': 28.0, 'learning_rate': 5.048000000000001e-06, 'epoch': 3.18}\n",
      "{'loss': 27.125, 'learning_rate': 5.047000000000001e-06, 'epoch': 3.18}\n",
      "{'loss': 27.875, 'learning_rate': 5.0460000000000005e-06, 'epoch': 3.18}\n",
      "{'loss': 29.5, 'learning_rate': 5.045e-06, 'epoch': 3.18}\n",
      "{'loss': 28.0, 'learning_rate': 5.044e-06, 'epoch': 3.18}\n",
      "{'loss': 26.75, 'learning_rate': 5.043e-06, 'epoch': 3.18}\n",
      "{'loss': 27.25, 'learning_rate': 5.042e-06, 'epoch': 3.18}\n",
      "{'loss': 27.0, 'learning_rate': 5.0410000000000005e-06, 'epoch': 3.18}\n",
      "{'loss': 26.5, 'learning_rate': 5.04e-06, 'epoch': 3.18}\n",
      "{'loss': 27.375, 'learning_rate': 5.039e-06, 'epoch': 3.18}\n",
      "{'loss': 27.375, 'learning_rate': 5.038000000000001e-06, 'epoch': 3.18}\n",
      "{'loss': 29.25, 'learning_rate': 5.037000000000001e-06, 'epoch': 3.19}\n",
      "{'loss': 27.375, 'learning_rate': 5.0360000000000006e-06, 'epoch': 3.19}\n",
      "{'loss': 27.625, 'learning_rate': 5.035e-06, 'epoch': 3.19}\n",
      "{'loss': 27.875, 'learning_rate': 5.0339999999999996e-06, 'epoch': 3.19}\n",
      "{'loss': 26.375, 'learning_rate': 5.033e-06, 'epoch': 3.19}\n",
      "{'loss': 27.5, 'learning_rate': 5.032e-06, 'epoch': 3.19}\n",
      "{'loss': 28.25, 'learning_rate': 5.031000000000001e-06, 'epoch': 3.19}\n",
      "{'loss': 26.875, 'learning_rate': 5.03e-06, 'epoch': 3.19}\n",
      "{'loss': 29.0, 'learning_rate': 5.0290000000000005e-06, 'epoch': 3.19}\n",
      "{'loss': 28.25, 'learning_rate': 5.028000000000001e-06, 'epoch': 3.19}\n",
      "{'loss': 26.625, 'learning_rate': 5.027000000000001e-06, 'epoch': 3.19}\n",
      "{'loss': 27.125, 'learning_rate': 5.026000000000001e-06, 'epoch': 3.19}\n",
      "{'loss': 26.5, 'learning_rate': 5.025e-06, 'epoch': 3.19}\n",
      "{'loss': 28.625, 'learning_rate': 5.024e-06, 'epoch': 3.19}\n",
      "{'loss': 28.5, 'learning_rate': 5.023e-06, 'epoch': 3.19}\n",
      "{'loss': 27.375, 'learning_rate': 5.022e-06, 'epoch': 3.2}\n",
      "{'loss': 27.875, 'learning_rate': 5.021000000000001e-06, 'epoch': 3.2}\n",
      "{'loss': 27.375, 'learning_rate': 5.02e-06, 'epoch': 3.2}\n",
      "{'loss': 29.0, 'learning_rate': 5.0190000000000006e-06, 'epoch': 3.2}\n",
      "{'loss': 27.25, 'learning_rate': 5.018000000000001e-06, 'epoch': 3.2}\n",
      "{'loss': 28.375, 'learning_rate': 5.017e-06, 'epoch': 3.2}\n",
      "{'loss': 26.375, 'learning_rate': 5.016000000000001e-06, 'epoch': 3.2}\n",
      "{'loss': 27.625, 'learning_rate': 5.015e-06, 'epoch': 3.2}\n",
      "{'loss': 26.625, 'learning_rate': 5.014e-06, 'epoch': 3.2}\n",
      "{'loss': 27.875, 'learning_rate': 5.013e-06, 'epoch': 3.2}\n",
      "{'loss': 26.75, 'learning_rate': 5.0120000000000005e-06, 'epoch': 3.2}\n",
      "{'loss': 27.5, 'learning_rate': 5.011e-06, 'epoch': 3.2}\n",
      "{'loss': 28.5, 'learning_rate': 5.01e-06, 'epoch': 3.2}\n",
      "{'loss': 27.625, 'learning_rate': 5.009000000000001e-06, 'epoch': 3.2}\n",
      "{'loss': 27.125, 'learning_rate': 5.008000000000001e-06, 'epoch': 3.2}\n",
      "{'loss': 30.0, 'learning_rate': 5.0070000000000005e-06, 'epoch': 3.2}\n",
      "{'loss': 27.375, 'learning_rate': 5.006000000000001e-06, 'epoch': 3.21}\n",
      "{'loss': 27.75, 'learning_rate': 5.0049999999999995e-06, 'epoch': 3.21}\n",
      "{'loss': 27.25, 'learning_rate': 5.004e-06, 'epoch': 3.21}\n",
      "{'loss': 28.75, 'learning_rate': 5.003e-06, 'epoch': 3.21}\n",
      "{'loss': 27.125, 'learning_rate': 5.0020000000000006e-06, 'epoch': 3.21}\n",
      "{'loss': 27.625, 'learning_rate': 5.001e-06, 'epoch': 3.21}\n",
      "{'loss': 30.25, 'learning_rate': 5e-06, 'epoch': 3.21}\n",
      "{'loss': 27.75, 'learning_rate': 4.999000000000001e-06, 'epoch': 3.21}\n",
      "{'loss': 27.875, 'learning_rate': 4.998e-06, 'epoch': 3.21}\n",
      "{'loss': 26.75, 'learning_rate': 4.997000000000001e-06, 'epoch': 3.21}\n",
      "{'loss': 28.125, 'learning_rate': 4.996e-06, 'epoch': 3.21}\n",
      "{'loss': 27.25, 'learning_rate': 4.9950000000000005e-06, 'epoch': 3.21}\n",
      "{'loss': 28.5, 'learning_rate': 4.994000000000001e-06, 'epoch': 3.21}\n",
      "{'loss': 27.75, 'learning_rate': 4.993e-06, 'epoch': 3.21}\n",
      "{'loss': 29.125, 'learning_rate': 4.992e-06, 'epoch': 3.21}\n",
      "{'loss': 27.875, 'learning_rate': 4.991e-06, 'epoch': 3.22}\n",
      "{'loss': 27.375, 'learning_rate': 4.9900000000000005e-06, 'epoch': 3.22}\n",
      "{'loss': 27.875, 'learning_rate': 4.989000000000001e-06, 'epoch': 3.22}\n",
      "{'loss': 29.625, 'learning_rate': 4.988e-06, 'epoch': 3.22}\n",
      "{'loss': 26.5, 'learning_rate': 4.987e-06, 'epoch': 3.22}\n",
      "{'loss': 27.5, 'learning_rate': 4.986e-06, 'epoch': 3.22}\n",
      "{'loss': 28.0, 'learning_rate': 4.9850000000000006e-06, 'epoch': 3.22}\n",
      "{'loss': 27.25, 'learning_rate': 4.984000000000001e-06, 'epoch': 3.22}\n",
      "{'loss': 26.75, 'learning_rate': 4.983e-06, 'epoch': 3.22}\n",
      "{'loss': 26.875, 'learning_rate': 4.982e-06, 'epoch': 3.22}\n",
      "{'loss': 29.25, 'learning_rate': 4.981e-06, 'epoch': 3.22}\n",
      "{'loss': 28.625, 'learning_rate': 4.980000000000001e-06, 'epoch': 3.22}\n",
      "{'loss': 27.25, 'learning_rate': 4.979e-06, 'epoch': 3.22}\n",
      "{'loss': 26.375, 'learning_rate': 4.9780000000000005e-06, 'epoch': 3.22}\n",
      "{'loss': 28.0, 'learning_rate': 4.977e-06, 'epoch': 3.22}\n",
      "{'loss': 28.875, 'learning_rate': 4.976e-06, 'epoch': 3.22}\n",
      "{'loss': 26.875, 'learning_rate': 4.975000000000001e-06, 'epoch': 3.23}\n",
      "{'loss': 28.125, 'learning_rate': 4.974e-06, 'epoch': 3.23}\n",
      "{'loss': 30.125, 'learning_rate': 4.9730000000000005e-06, 'epoch': 3.23}\n",
      "{'loss': 27.5, 'learning_rate': 4.972e-06, 'epoch': 3.23}\n",
      "{'loss': 27.25, 'learning_rate': 4.971e-06, 'epoch': 3.23}\n",
      "{'loss': 26.375, 'learning_rate': 4.970000000000001e-06, 'epoch': 3.23}\n",
      "{'loss': 27.125, 'learning_rate': 4.969e-06, 'epoch': 3.23}\n",
      "{'loss': 28.25, 'learning_rate': 4.9680000000000005e-06, 'epoch': 3.23}\n",
      "{'loss': 31.125, 'learning_rate': 4.967e-06, 'epoch': 3.23}\n",
      "{'loss': 27.875, 'learning_rate': 4.966e-06, 'epoch': 3.23}\n",
      "{'loss': 27.25, 'learning_rate': 4.965000000000001e-06, 'epoch': 3.23}\n",
      "{'loss': 28.375, 'learning_rate': 4.964e-06, 'epoch': 3.23}\n",
      "{'loss': 27.25, 'learning_rate': 4.963000000000001e-06, 'epoch': 3.23}\n",
      "{'loss': 27.5, 'learning_rate': 4.962e-06, 'epoch': 3.23}\n",
      "{'loss': 28.25, 'learning_rate': 4.9610000000000004e-06, 'epoch': 3.23}\n",
      "{'loss': 27.875, 'learning_rate': 4.960000000000001e-06, 'epoch': 3.23}\n",
      "{'loss': 26.5, 'learning_rate': 4.959e-06, 'epoch': 3.24}\n",
      "{'loss': 26.5, 'learning_rate': 4.958000000000001e-06, 'epoch': 3.24}\n",
      "{'loss': 28.0, 'learning_rate': 4.957e-06, 'epoch': 3.24}\n",
      "{'loss': 26.375, 'learning_rate': 4.9560000000000005e-06, 'epoch': 3.24}\n",
      "{'loss': 26.5, 'learning_rate': 4.955e-06, 'epoch': 3.24}\n",
      "{'loss': 27.75, 'learning_rate': 4.954e-06, 'epoch': 3.24}\n",
      "{'loss': 28.875, 'learning_rate': 4.953000000000001e-06, 'epoch': 3.24}\n",
      "{'loss': 27.125, 'learning_rate': 4.952e-06, 'epoch': 3.24}\n",
      "{'loss': 28.375, 'learning_rate': 4.9510000000000005e-06, 'epoch': 3.24}\n",
      "{'loss': 28.5, 'learning_rate': 4.95e-06, 'epoch': 3.24}\n",
      "{'loss': 27.125, 'learning_rate': 4.949e-06, 'epoch': 3.24}\n",
      "{'loss': 28.125, 'learning_rate': 4.948000000000001e-06, 'epoch': 3.24}\n",
      "{'loss': 26.75, 'learning_rate': 4.947e-06, 'epoch': 3.24}\n",
      "{'loss': 27.875, 'learning_rate': 4.946000000000001e-06, 'epoch': 3.24}\n",
      "{'loss': 27.375, 'learning_rate': 4.945e-06, 'epoch': 3.24}\n",
      "{'loss': 27.125, 'learning_rate': 4.9440000000000004e-06, 'epoch': 3.25}\n",
      "{'loss': 27.625, 'learning_rate': 4.943000000000001e-06, 'epoch': 3.25}\n",
      "{'loss': 28.375, 'learning_rate': 4.942e-06, 'epoch': 3.25}\n",
      "{'loss': 27.75, 'learning_rate': 4.941000000000001e-06, 'epoch': 3.25}\n",
      "{'loss': 28.875, 'learning_rate': 4.94e-06, 'epoch': 3.25}\n",
      "{'loss': 26.375, 'learning_rate': 4.9390000000000005e-06, 'epoch': 3.25}\n",
      "{'loss': 28.25, 'learning_rate': 4.938000000000001e-06, 'epoch': 3.25}\n",
      "{'loss': 26.75, 'learning_rate': 4.937e-06, 'epoch': 3.25}\n",
      "{'loss': 26.5, 'learning_rate': 4.936e-06, 'epoch': 3.25}\n",
      "{'loss': 27.75, 'learning_rate': 4.935e-06, 'epoch': 3.25}\n",
      "{'loss': 28.25, 'learning_rate': 4.9340000000000005e-06, 'epoch': 3.25}\n",
      "{'loss': 28.25, 'learning_rate': 4.933000000000001e-06, 'epoch': 3.25}\n",
      "{'loss': 27.75, 'learning_rate': 4.932e-06, 'epoch': 3.25}\n",
      "{'loss': 27.0, 'learning_rate': 4.931e-06, 'epoch': 3.25}\n",
      "{'loss': 29.0, 'learning_rate': 4.93e-06, 'epoch': 3.25}\n",
      "{'loss': 26.75, 'learning_rate': 4.929000000000001e-06, 'epoch': 3.25}\n",
      "{'loss': 27.0, 'learning_rate': 4.928000000000001e-06, 'epoch': 3.26}\n",
      "{'loss': 27.375, 'learning_rate': 4.9270000000000004e-06, 'epoch': 3.26}\n",
      "{'loss': 27.875, 'learning_rate': 4.926e-06, 'epoch': 3.26}\n",
      "{'loss': 28.875, 'learning_rate': 4.925e-06, 'epoch': 3.26}\n",
      "{'loss': 26.625, 'learning_rate': 4.924000000000001e-06, 'epoch': 3.26}\n",
      "{'loss': 27.0, 'learning_rate': 4.923000000000001e-06, 'epoch': 3.26}\n",
      "{'loss': 25.875, 'learning_rate': 4.9220000000000005e-06, 'epoch': 3.26}\n",
      "{'loss': 27.0, 'learning_rate': 4.921e-06, 'epoch': 3.26}\n",
      "{'loss': 29.0, 'learning_rate': 4.92e-06, 'epoch': 3.26}\n",
      "{'loss': 26.5, 'learning_rate': 4.919000000000001e-06, 'epoch': 3.26}\n",
      "{'loss': 28.375, 'learning_rate': 4.918e-06, 'epoch': 3.26}\n",
      "{'loss': 27.0, 'learning_rate': 4.9170000000000005e-06, 'epoch': 3.26}\n",
      "{'loss': 28.25, 'learning_rate': 4.916e-06, 'epoch': 3.26}\n",
      "{'loss': 27.0, 'learning_rate': 4.915e-06, 'epoch': 3.26}\n",
      "{'loss': 26.5, 'learning_rate': 4.914000000000001e-06, 'epoch': 3.26}\n",
      "{'loss': 27.25, 'learning_rate': 4.913e-06, 'epoch': 3.27}\n",
      "{'loss': 28.375, 'learning_rate': 4.9120000000000006e-06, 'epoch': 3.27}\n",
      "{'loss': 27.125, 'learning_rate': 4.911e-06, 'epoch': 3.27}\n",
      "{'loss': 26.875, 'learning_rate': 4.9100000000000004e-06, 'epoch': 3.27}\n",
      "{'loss': 26.875, 'learning_rate': 4.909000000000001e-06, 'epoch': 3.27}\n",
      "{'loss': 27.25, 'learning_rate': 4.908e-06, 'epoch': 3.27}\n",
      "{'loss': 28.625, 'learning_rate': 4.907000000000001e-06, 'epoch': 3.27}\n",
      "{'loss': 26.25, 'learning_rate': 4.906e-06, 'epoch': 3.27}\n",
      "{'loss': 26.75, 'learning_rate': 4.9050000000000005e-06, 'epoch': 3.27}\n",
      "{'loss': 27.125, 'learning_rate': 4.904000000000001e-06, 'epoch': 3.27}\n",
      "{'loss': 27.75, 'learning_rate': 4.903e-06, 'epoch': 3.27}\n",
      "{'loss': 27.375, 'learning_rate': 4.902000000000001e-06, 'epoch': 3.27}\n",
      "{'loss': 28.125, 'learning_rate': 4.901e-06, 'epoch': 3.27}\n",
      "{'loss': 27.625, 'learning_rate': 4.9000000000000005e-06, 'epoch': 3.27}\n",
      "{'loss': 26.5, 'learning_rate': 4.899e-06, 'epoch': 3.27}\n",
      "{'loss': 27.875, 'learning_rate': 4.898e-06, 'epoch': 3.27}\n",
      "{'loss': 27.25, 'learning_rate': 4.897000000000001e-06, 'epoch': 3.28}\n",
      "{'loss': 26.875, 'learning_rate': 4.896e-06, 'epoch': 3.28}\n",
      "{'loss': 27.375, 'learning_rate': 4.8950000000000006e-06, 'epoch': 3.28}\n",
      "{'loss': 28.5, 'learning_rate': 4.894e-06, 'epoch': 3.28}\n",
      "{'loss': 27.375, 'learning_rate': 4.893e-06, 'epoch': 3.28}\n",
      "{'loss': 27.125, 'learning_rate': 4.892000000000001e-06, 'epoch': 3.28}\n",
      "{'loss': 28.375, 'learning_rate': 4.891e-06, 'epoch': 3.28}\n",
      "{'loss': 27.5, 'learning_rate': 4.890000000000001e-06, 'epoch': 3.28}\n",
      "{'loss': 26.75, 'learning_rate': 4.889e-06, 'epoch': 3.28}\n",
      "{'loss': 28.125, 'learning_rate': 4.8880000000000005e-06, 'epoch': 3.28}\n",
      "{'loss': 28.375, 'learning_rate': 4.887000000000001e-06, 'epoch': 3.28}\n",
      "{'loss': 28.25, 'learning_rate': 4.886e-06, 'epoch': 3.28}\n",
      "{'loss': 27.0, 'learning_rate': 4.885000000000001e-06, 'epoch': 3.28}\n",
      "{'loss': 27.0, 'learning_rate': 4.884e-06, 'epoch': 3.28}\n",
      "{'loss': 27.125, 'learning_rate': 4.8830000000000005e-06, 'epoch': 3.28}\n",
      "{'loss': 26.625, 'learning_rate': 4.882000000000001e-06, 'epoch': 3.28}\n",
      "{'loss': 27.875, 'learning_rate': 4.881e-06, 'epoch': 3.29}\n",
      "{'loss': 27.125, 'learning_rate': 4.880000000000001e-06, 'epoch': 3.29}\n",
      "{'loss': 27.875, 'learning_rate': 4.879e-06, 'epoch': 3.29}\n",
      "{'loss': 27.125, 'learning_rate': 4.8780000000000006e-06, 'epoch': 3.29}\n",
      "{'loss': 29.5, 'learning_rate': 4.877000000000001e-06, 'epoch': 3.29}\n",
      "{'loss': 27.25, 'learning_rate': 4.876e-06, 'epoch': 3.29}\n",
      "{'loss': 27.875, 'learning_rate': 4.875e-06, 'epoch': 3.29}\n",
      "{'loss': 28.125, 'learning_rate': 4.874e-06, 'epoch': 3.29}\n",
      "{'loss': 28.75, 'learning_rate': 4.873000000000001e-06, 'epoch': 3.29}\n",
      "{'loss': 28.75, 'learning_rate': 4.872000000000001e-06, 'epoch': 3.29}\n",
      "{'loss': 27.75, 'learning_rate': 4.8710000000000005e-06, 'epoch': 3.29}\n",
      "{'loss': 28.0, 'learning_rate': 4.87e-06, 'epoch': 3.29}\n",
      "{'loss': 26.625, 'learning_rate': 4.869e-06, 'epoch': 3.29}\n",
      "{'loss': 28.625, 'learning_rate': 4.868000000000001e-06, 'epoch': 3.29}\n",
      "{'loss': 27.0, 'learning_rate': 4.867000000000001e-06, 'epoch': 3.29}\n",
      "{'loss': 28.375, 'learning_rate': 4.8660000000000005e-06, 'epoch': 3.3}\n",
      "{'loss': 27.125, 'learning_rate': 4.865e-06, 'epoch': 3.3}\n",
      "{'loss': 26.875, 'learning_rate': 4.864e-06, 'epoch': 3.3}\n",
      "{'loss': 27.875, 'learning_rate': 4.863000000000001e-06, 'epoch': 3.3}\n",
      "{'loss': 30.0, 'learning_rate': 4.862e-06, 'epoch': 3.3}\n",
      "{'loss': 27.875, 'learning_rate': 4.8610000000000006e-06, 'epoch': 3.3}\n",
      "{'loss': 26.875, 'learning_rate': 4.86e-06, 'epoch': 3.3}\n",
      "{'loss': 28.75, 'learning_rate': 4.859e-06, 'epoch': 3.3}\n",
      "{'loss': 26.5, 'learning_rate': 4.858000000000001e-06, 'epoch': 3.3}\n",
      "{'loss': 28.25, 'learning_rate': 4.857e-06, 'epoch': 3.3}\n",
      "{'loss': 30.0, 'learning_rate': 4.856e-06, 'epoch': 3.3}\n",
      "{'loss': 26.625, 'learning_rate': 4.855e-06, 'epoch': 3.3}\n",
      "{'loss': 26.75, 'learning_rate': 4.8540000000000005e-06, 'epoch': 3.3}\n",
      "{'loss': 30.0, 'learning_rate': 4.853000000000001e-06, 'epoch': 3.3}\n",
      "{'loss': 27.625, 'learning_rate': 4.852e-06, 'epoch': 3.3}\n",
      "{'loss': 26.75, 'learning_rate': 4.851e-06, 'epoch': 3.3}\n",
      "{'loss': 27.75, 'learning_rate': 4.85e-06, 'epoch': 3.31}\n",
      "{'loss': 27.25, 'learning_rate': 4.8490000000000005e-06, 'epoch': 3.31}\n",
      "{'loss': 28.875, 'learning_rate': 4.848000000000001e-06, 'epoch': 3.31}\n",
      "{'loss': 27.75, 'learning_rate': 4.847e-06, 'epoch': 3.31}\n",
      "{'loss': 26.5, 'learning_rate': 4.846e-06, 'epoch': 3.31}\n",
      "{'loss': 29.75, 'learning_rate': 4.845e-06, 'epoch': 3.31}\n",
      "{'loss': 28.625, 'learning_rate': 4.8440000000000005e-06, 'epoch': 3.31}\n",
      "{'loss': 27.875, 'learning_rate': 4.843000000000001e-06, 'epoch': 3.31}\n",
      "{'loss': 26.375, 'learning_rate': 4.842e-06, 'epoch': 3.31}\n",
      "{'loss': 27.625, 'learning_rate': 4.841e-06, 'epoch': 3.31}\n",
      "{'loss': 27.25, 'learning_rate': 4.84e-06, 'epoch': 3.31}\n",
      "{'loss': 27.0, 'learning_rate': 4.839000000000001e-06, 'epoch': 3.31}\n",
      "{'loss': 28.0, 'learning_rate': 4.838e-06, 'epoch': 3.31}\n",
      "{'loss': 27.375, 'learning_rate': 4.8370000000000004e-06, 'epoch': 3.31}\n",
      "{'loss': 29.25, 'learning_rate': 4.836e-06, 'epoch': 3.31}\n",
      "{'loss': 27.5, 'learning_rate': 4.835e-06, 'epoch': 3.32}\n",
      "{'loss': 26.875, 'learning_rate': 4.834000000000001e-06, 'epoch': 3.32}\n",
      "{'loss': 27.875, 'learning_rate': 4.833e-06, 'epoch': 3.32}\n",
      "{'loss': 28.625, 'learning_rate': 4.8320000000000005e-06, 'epoch': 3.32}\n",
      "{'loss': 28.375, 'learning_rate': 4.831e-06, 'epoch': 3.32}\n",
      "{'loss': 29.375, 'learning_rate': 4.83e-06, 'epoch': 3.32}\n",
      "{'loss': 27.75, 'learning_rate': 4.829000000000001e-06, 'epoch': 3.32}\n",
      "{'loss': 27.75, 'learning_rate': 4.828e-06, 'epoch': 3.32}\n",
      "{'loss': 28.5, 'learning_rate': 4.8270000000000005e-06, 'epoch': 3.32}\n",
      "{'loss': 26.5, 'learning_rate': 4.826e-06, 'epoch': 3.32}\n",
      "{'loss': 27.125, 'learning_rate': 4.825e-06, 'epoch': 3.32}\n",
      "{'loss': 26.75, 'learning_rate': 4.824000000000001e-06, 'epoch': 3.32}\n",
      "{'loss': 28.875, 'learning_rate': 4.823e-06, 'epoch': 3.32}\n",
      "{'loss': 26.25, 'learning_rate': 4.822000000000001e-06, 'epoch': 3.32}\n",
      "{'loss': 28.75, 'learning_rate': 4.821e-06, 'epoch': 3.32}\n",
      "{'loss': 28.625, 'learning_rate': 4.8200000000000004e-06, 'epoch': 3.32}\n",
      "{'loss': 28.0, 'learning_rate': 4.819e-06, 'epoch': 3.33}\n",
      "{'loss': 27.0, 'learning_rate': 4.818e-06, 'epoch': 3.33}\n",
      "{'loss': 27.875, 'learning_rate': 4.817000000000001e-06, 'epoch': 3.33}\n",
      "{'loss': 27.625, 'learning_rate': 4.816e-06, 'epoch': 3.33}\n",
      "{'loss': 27.875, 'learning_rate': 4.8150000000000005e-06, 'epoch': 3.33}\n",
      "{'loss': 26.75, 'learning_rate': 4.814e-06, 'epoch': 3.33}\n",
      "{'loss': 27.375, 'learning_rate': 4.813e-06, 'epoch': 3.33}\n",
      "{'loss': 26.875, 'learning_rate': 4.812000000000001e-06, 'epoch': 3.33}\n",
      "{'loss': 27.75, 'learning_rate': 4.811000000000001e-06, 'epoch': 3.33}\n",
      "{'loss': 28.375, 'learning_rate': 4.8100000000000005e-06, 'epoch': 3.33}\n",
      "{'loss': 27.25, 'learning_rate': 4.809e-06, 'epoch': 3.33}\n",
      "{'loss': 28.75, 'learning_rate': 4.808e-06, 'epoch': 3.33}\n",
      "{'loss': 26.5, 'learning_rate': 4.807000000000001e-06, 'epoch': 3.33}\n",
      "{'loss': 28.125, 'learning_rate': 4.806000000000001e-06, 'epoch': 3.33}\n",
      "{'loss': 26.5, 'learning_rate': 4.805000000000001e-06, 'epoch': 3.33}\n",
      "{'loss': 27.875, 'learning_rate': 4.804e-06, 'epoch': 3.34}\n",
      "{'loss': 28.375, 'learning_rate': 4.8030000000000004e-06, 'epoch': 3.34}\n",
      "{'loss': 27.625, 'learning_rate': 4.802000000000001e-06, 'epoch': 3.34}\n",
      "{'loss': 27.625, 'learning_rate': 4.801e-06, 'epoch': 3.34}\n",
      "{'loss': 27.375, 'learning_rate': 4.800000000000001e-06, 'epoch': 3.34}\n",
      "{'loss': 26.0, 'learning_rate': 4.799e-06, 'epoch': 3.34}\n",
      "{'loss': 29.25, 'learning_rate': 4.7980000000000005e-06, 'epoch': 3.34}\n",
      "{'loss': 28.375, 'learning_rate': 4.797000000000001e-06, 'epoch': 3.34}\n",
      "{'loss': 27.625, 'learning_rate': 4.796e-06, 'epoch': 3.34}\n",
      "{'loss': 27.0, 'learning_rate': 4.795e-06, 'epoch': 3.34}\n",
      "{'loss': 27.5, 'learning_rate': 4.794e-06, 'epoch': 3.34}\n",
      "{'loss': 27.125, 'learning_rate': 4.7930000000000005e-06, 'epoch': 3.34}\n",
      "{'loss': 27.0, 'learning_rate': 4.792000000000001e-06, 'epoch': 3.34}\n",
      "{'loss': 26.75, 'learning_rate': 4.791e-06, 'epoch': 3.34}\n",
      "{'loss': 27.875, 'learning_rate': 4.79e-06, 'epoch': 3.34}\n",
      "{'loss': 26.75, 'learning_rate': 4.789e-06, 'epoch': 3.34}\n",
      "{'loss': 27.875, 'learning_rate': 4.7880000000000006e-06, 'epoch': 3.35}\n",
      "{'loss': 28.625, 'learning_rate': 4.787000000000001e-06, 'epoch': 3.35}\n",
      "{'loss': 27.875, 'learning_rate': 4.7860000000000004e-06, 'epoch': 3.35}\n",
      "{'loss': 27.125, 'learning_rate': 4.785e-06, 'epoch': 3.35}\n",
      "{'loss': 28.125, 'learning_rate': 4.784e-06, 'epoch': 3.35}\n",
      "{'loss': 26.875, 'learning_rate': 4.783000000000001e-06, 'epoch': 3.35}\n",
      "{'loss': 27.75, 'learning_rate': 4.782e-06, 'epoch': 3.35}\n",
      "{'loss': 27.75, 'learning_rate': 4.7810000000000005e-06, 'epoch': 3.35}\n",
      "{'loss': 28.625, 'learning_rate': 4.78e-06, 'epoch': 3.35}\n",
      "{'loss': 29.625, 'learning_rate': 4.779e-06, 'epoch': 3.35}\n",
      "{'loss': 27.125, 'learning_rate': 4.778000000000001e-06, 'epoch': 3.35}\n",
      "{'loss': 27.5, 'learning_rate': 4.777e-06, 'epoch': 3.35}\n",
      "{'loss': 27.375, 'learning_rate': 4.7760000000000005e-06, 'epoch': 3.35}\n",
      "{'loss': 28.5, 'learning_rate': 4.775e-06, 'epoch': 3.35}\n",
      "{'loss': 26.625, 'learning_rate': 4.774e-06, 'epoch': 3.35}\n",
      "{'loss': 28.375, 'learning_rate': 4.773000000000001e-06, 'epoch': 3.35}\n",
      "{'loss': 26.25, 'learning_rate': 4.772e-06, 'epoch': 3.36}\n",
      "{'loss': 28.375, 'learning_rate': 4.7710000000000006e-06, 'epoch': 3.36}\n",
      "{'loss': 27.5, 'learning_rate': 4.77e-06, 'epoch': 3.36}\n",
      "{'loss': 28.5, 'learning_rate': 4.769e-06, 'epoch': 3.36}\n",
      "{'loss': 28.75, 'learning_rate': 4.768000000000001e-06, 'epoch': 3.36}\n",
      "{'loss': 28.125, 'learning_rate': 4.767e-06, 'epoch': 3.36}\n",
      "{'loss': 28.25, 'learning_rate': 4.766000000000001e-06, 'epoch': 3.36}\n",
      "{'loss': 29.0, 'learning_rate': 4.765e-06, 'epoch': 3.36}\n",
      "{'loss': 27.625, 'learning_rate': 4.7640000000000005e-06, 'epoch': 3.36}\n",
      "{'loss': 28.625, 'learning_rate': 4.763000000000001e-06, 'epoch': 3.36}\n",
      "{'loss': 27.0, 'learning_rate': 4.762e-06, 'epoch': 3.36}\n",
      "{'loss': 27.25, 'learning_rate': 4.761000000000001e-06, 'epoch': 3.36}\n",
      "{'loss': 27.0, 'learning_rate': 4.76e-06, 'epoch': 3.36}\n",
      "{'loss': 29.75, 'learning_rate': 4.7590000000000005e-06, 'epoch': 3.36}\n",
      "{'loss': 27.375, 'learning_rate': 4.758e-06, 'epoch': 3.36}\n",
      "{'loss': 26.375, 'learning_rate': 4.757e-06, 'epoch': 3.37}\n",
      "{'loss': 27.875, 'learning_rate': 4.756000000000001e-06, 'epoch': 3.37}\n",
      "{'loss': 27.25, 'learning_rate': 4.755e-06, 'epoch': 3.37}\n",
      "{'loss': 28.875, 'learning_rate': 4.7540000000000006e-06, 'epoch': 3.37}\n",
      "{'loss': 27.75, 'learning_rate': 4.753e-06, 'epoch': 3.37}\n",
      "{'loss': 27.75, 'learning_rate': 4.752e-06, 'epoch': 3.37}\n",
      "{'loss': 27.25, 'learning_rate': 4.751000000000001e-06, 'epoch': 3.37}\n",
      "{'loss': 28.25, 'learning_rate': 4.75e-06, 'epoch': 3.37}\n",
      "{'loss': 27.125, 'learning_rate': 4.749000000000001e-06, 'epoch': 3.37}\n",
      "{'loss': 27.0, 'learning_rate': 4.748e-06, 'epoch': 3.37}\n",
      "{'loss': 26.875, 'learning_rate': 4.7470000000000005e-06, 'epoch': 3.37}\n",
      "{'loss': 27.625, 'learning_rate': 4.746000000000001e-06, 'epoch': 3.37}\n",
      "{'loss': 28.125, 'learning_rate': 4.745e-06, 'epoch': 3.37}\n",
      "{'loss': 28.5, 'learning_rate': 4.744000000000001e-06, 'epoch': 3.37}\n",
      "{'loss': 27.125, 'learning_rate': 4.743e-06, 'epoch': 3.37}\n",
      "{'loss': 27.625, 'learning_rate': 4.7420000000000005e-06, 'epoch': 3.37}\n",
      "{'loss': 26.625, 'learning_rate': 4.741000000000001e-06, 'epoch': 3.38}\n",
      "{'loss': 27.375, 'learning_rate': 4.74e-06, 'epoch': 3.38}\n",
      "{'loss': 27.75, 'learning_rate': 4.739e-06, 'epoch': 3.38}\n",
      "{'loss': 27.375, 'learning_rate': 4.738e-06, 'epoch': 3.38}\n",
      "{'loss': 28.5, 'learning_rate': 4.7370000000000006e-06, 'epoch': 3.38}\n",
      "{'loss': 29.75, 'learning_rate': 4.736000000000001e-06, 'epoch': 3.38}\n",
      "{'loss': 27.0, 'learning_rate': 4.735e-06, 'epoch': 3.38}\n",
      "{'loss': 28.5, 'learning_rate': 4.734e-06, 'epoch': 3.38}\n",
      "{'loss': 28.5, 'learning_rate': 4.733e-06, 'epoch': 3.38}\n",
      "{'loss': 27.0, 'learning_rate': 4.732000000000001e-06, 'epoch': 3.38}\n",
      "{'loss': 29.25, 'learning_rate': 4.731000000000001e-06, 'epoch': 3.38}\n",
      "{'loss': 27.5, 'learning_rate': 4.7300000000000005e-06, 'epoch': 3.38}\n",
      "{'loss': 26.125, 'learning_rate': 4.729e-06, 'epoch': 3.38}\n",
      "{'loss': 27.25, 'learning_rate': 4.728e-06, 'epoch': 3.38}\n",
      "{'loss': 27.875, 'learning_rate': 4.727000000000001e-06, 'epoch': 3.38}\n",
      "{'loss': 27.5, 'learning_rate': 4.726000000000001e-06, 'epoch': 3.39}\n",
      "{'loss': 27.75, 'learning_rate': 4.7250000000000005e-06, 'epoch': 3.39}\n",
      "{'loss': 29.75, 'learning_rate': 4.724e-06, 'epoch': 3.39}\n",
      "{'loss': 28.0, 'learning_rate': 4.723e-06, 'epoch': 3.39}\n",
      "{'loss': 27.5, 'learning_rate': 4.722000000000001e-06, 'epoch': 3.39}\n",
      "{'loss': 28.5, 'learning_rate': 4.721e-06, 'epoch': 3.39}\n",
      "{'loss': 27.625, 'learning_rate': 4.7200000000000005e-06, 'epoch': 3.39}\n",
      "{'loss': 26.5, 'learning_rate': 4.719e-06, 'epoch': 3.39}\n",
      "{'loss': 27.125, 'learning_rate': 4.718e-06, 'epoch': 3.39}\n",
      "{'loss': 27.25, 'learning_rate': 4.717000000000001e-06, 'epoch': 3.39}\n",
      "{'loss': 27.125, 'learning_rate': 4.716e-06, 'epoch': 3.39}\n",
      "{'loss': 28.25, 'learning_rate': 4.715e-06, 'epoch': 3.39}\n",
      "{'loss': 27.75, 'learning_rate': 4.714e-06, 'epoch': 3.39}\n",
      "{'loss': 27.625, 'learning_rate': 4.7130000000000004e-06, 'epoch': 3.39}\n",
      "{'loss': 27.5, 'learning_rate': 4.712000000000001e-06, 'epoch': 3.39}\n",
      "{'loss': 27.75, 'learning_rate': 4.711e-06, 'epoch': 3.39}\n",
      "{'loss': 28.0, 'learning_rate': 4.71e-06, 'epoch': 3.4}\n",
      "{'loss': 27.125, 'learning_rate': 4.709e-06, 'epoch': 3.4}\n",
      "{'loss': 27.125, 'learning_rate': 4.7080000000000005e-06, 'epoch': 3.4}\n",
      "{'loss': 27.375, 'learning_rate': 4.707000000000001e-06, 'epoch': 3.4}\n",
      "{'loss': 27.625, 'learning_rate': 4.706e-06, 'epoch': 3.4}\n",
      "{'loss': 26.625, 'learning_rate': 4.705e-06, 'epoch': 3.4}\n",
      "{'loss': 27.375, 'learning_rate': 4.704e-06, 'epoch': 3.4}\n",
      "{'loss': 27.875, 'learning_rate': 4.7030000000000005e-06, 'epoch': 3.4}\n",
      "{'loss': 27.125, 'learning_rate': 4.702e-06, 'epoch': 3.4}\n",
      "{'loss': 27.125, 'learning_rate': 4.701e-06, 'epoch': 3.4}\n",
      "{'loss': 27.75, 'learning_rate': 4.7e-06, 'epoch': 3.4}\n",
      "{'loss': 26.875, 'learning_rate': 4.699e-06, 'epoch': 3.4}\n",
      "{'loss': 28.625, 'learning_rate': 4.698000000000001e-06, 'epoch': 3.4}\n",
      "{'loss': 27.5, 'learning_rate': 4.697e-06, 'epoch': 3.4}\n",
      "{'loss': 28.875, 'learning_rate': 4.6960000000000004e-06, 'epoch': 3.4}\n",
      "{'loss': 27.5, 'learning_rate': 4.695e-06, 'epoch': 3.41}\n",
      "{'loss': 27.125, 'learning_rate': 4.694e-06, 'epoch': 3.41}\n",
      "{'loss': 27.75, 'learning_rate': 4.693000000000001e-06, 'epoch': 3.41}\n",
      "{'loss': 26.75, 'learning_rate': 4.692e-06, 'epoch': 3.41}\n",
      "{'loss': 26.625, 'learning_rate': 4.6910000000000005e-06, 'epoch': 3.41}\n",
      "{'loss': 27.25, 'learning_rate': 4.69e-06, 'epoch': 3.41}\n",
      "{'loss': 30.0, 'learning_rate': 4.689e-06, 'epoch': 3.41}\n",
      "{'loss': 27.75, 'learning_rate': 4.688000000000001e-06, 'epoch': 3.41}\n",
      "{'loss': 27.5, 'learning_rate': 4.687e-06, 'epoch': 3.41}\n",
      "{'loss': 28.25, 'learning_rate': 4.6860000000000005e-06, 'epoch': 3.41}\n",
      "{'loss': 27.5, 'learning_rate': 4.685000000000001e-06, 'epoch': 3.41}\n",
      "{'loss': 28.125, 'learning_rate': 4.684e-06, 'epoch': 3.41}\n",
      "{'loss': 29.5, 'learning_rate': 4.683000000000001e-06, 'epoch': 3.41}\n",
      "{'loss': 28.0, 'learning_rate': 4.682e-06, 'epoch': 3.41}\n",
      "{'loss': 28.375, 'learning_rate': 4.681000000000001e-06, 'epoch': 3.41}\n",
      "{'loss': 26.875, 'learning_rate': 4.680000000000001e-06, 'epoch': 3.41}\n",
      "{'loss': 27.125, 'learning_rate': 4.6790000000000004e-06, 'epoch': 3.42}\n",
      "{'loss': 27.375, 'learning_rate': 4.678e-06, 'epoch': 3.42}\n",
      "{'loss': 26.875, 'learning_rate': 4.677e-06, 'epoch': 3.42}\n",
      "{'loss': 27.75, 'learning_rate': 4.676000000000001e-06, 'epoch': 3.42}\n",
      "{'loss': 27.5, 'learning_rate': 4.675000000000001e-06, 'epoch': 3.42}\n",
      "{'loss': 27.125, 'learning_rate': 4.6740000000000005e-06, 'epoch': 3.42}\n",
      "{'loss': 27.125, 'learning_rate': 4.673e-06, 'epoch': 3.42}\n",
      "{'loss': 29.5, 'learning_rate': 4.672e-06, 'epoch': 3.42}\n",
      "{'loss': 27.75, 'learning_rate': 4.671000000000001e-06, 'epoch': 3.42}\n",
      "{'loss': 29.125, 'learning_rate': 4.670000000000001e-06, 'epoch': 3.42}\n",
      "{'loss': 26.125, 'learning_rate': 4.6690000000000005e-06, 'epoch': 3.42}\n",
      "{'loss': 27.25, 'learning_rate': 4.668e-06, 'epoch': 3.42}\n",
      "{'loss': 27.625, 'learning_rate': 4.667e-06, 'epoch': 3.42}\n",
      "{'loss': 27.875, 'learning_rate': 4.666000000000001e-06, 'epoch': 3.42}\n",
      "{'loss': 26.75, 'learning_rate': 4.665e-06, 'epoch': 3.42}\n",
      "{'loss': 26.75, 'learning_rate': 4.664000000000001e-06, 'epoch': 3.42}\n",
      "{'loss': 28.625, 'learning_rate': 4.663e-06, 'epoch': 3.43}\n",
      "{'loss': 27.875, 'learning_rate': 4.6620000000000004e-06, 'epoch': 3.43}\n",
      "{'loss': 29.125, 'learning_rate': 4.661000000000001e-06, 'epoch': 3.43}\n",
      "{'loss': 26.375, 'learning_rate': 4.66e-06, 'epoch': 3.43}\n",
      "{'loss': 26.875, 'learning_rate': 4.659e-06, 'epoch': 3.43}\n",
      "{'loss': 26.375, 'learning_rate': 4.658e-06, 'epoch': 3.43}\n",
      "{'loss': 28.75, 'learning_rate': 4.6570000000000005e-06, 'epoch': 3.43}\n",
      "{'loss': 28.625, 'learning_rate': 4.656000000000001e-06, 'epoch': 3.43}\n",
      "{'loss': 26.75, 'learning_rate': 4.655e-06, 'epoch': 3.43}\n",
      "{'loss': 28.375, 'learning_rate': 4.654e-06, 'epoch': 3.43}\n",
      "{'loss': 27.25, 'learning_rate': 4.653e-06, 'epoch': 3.43}\n",
      "{'loss': 27.5, 'learning_rate': 4.6520000000000005e-06, 'epoch': 3.43}\n",
      "{'loss': 26.75, 'learning_rate': 4.651000000000001e-06, 'epoch': 3.43}\n",
      "{'loss': 29.625, 'learning_rate': 4.65e-06, 'epoch': 3.43}\n",
      "{'loss': 26.75, 'learning_rate': 4.649e-06, 'epoch': 3.43}\n",
      "{'loss': 27.25, 'learning_rate': 4.648e-06, 'epoch': 3.44}\n",
      "{'loss': 27.75, 'learning_rate': 4.6470000000000006e-06, 'epoch': 3.44}\n",
      "{'loss': 29.625, 'learning_rate': 4.646000000000001e-06, 'epoch': 3.44}\n",
      "{'loss': 28.125, 'learning_rate': 4.645e-06, 'epoch': 3.44}\n",
      "{'loss': 26.875, 'learning_rate': 4.644e-06, 'epoch': 3.44}\n",
      "{'loss': 27.25, 'learning_rate': 4.643e-06, 'epoch': 3.44}\n",
      "{'loss': 28.5, 'learning_rate': 4.642000000000001e-06, 'epoch': 3.44}\n",
      "{'loss': 27.5, 'learning_rate': 4.641e-06, 'epoch': 3.44}\n",
      "{'loss': 27.0, 'learning_rate': 4.6400000000000005e-06, 'epoch': 3.44}\n",
      "{'loss': 27.375, 'learning_rate': 4.639e-06, 'epoch': 3.44}\n",
      "{'loss': 26.25, 'learning_rate': 4.638e-06, 'epoch': 3.44}\n",
      "{'loss': 27.375, 'learning_rate': 4.637000000000001e-06, 'epoch': 3.44}\n",
      "{'loss': 27.375, 'learning_rate': 4.636e-06, 'epoch': 3.44}\n",
      "{'loss': 28.0, 'learning_rate': 4.6350000000000005e-06, 'epoch': 3.44}\n",
      "{'loss': 27.0, 'learning_rate': 4.634e-06, 'epoch': 3.44}\n",
      "{'loss': 27.625, 'learning_rate': 4.633e-06, 'epoch': 3.44}\n",
      "{'loss': 28.125, 'learning_rate': 4.632000000000001e-06, 'epoch': 3.45}\n",
      "{'loss': 28.125, 'learning_rate': 4.631e-06, 'epoch': 3.45}\n",
      "{'loss': 27.375, 'learning_rate': 4.6300000000000006e-06, 'epoch': 3.45}\n",
      "{'loss': 28.25, 'learning_rate': 4.629e-06, 'epoch': 3.45}\n",
      "{'loss': 27.875, 'learning_rate': 4.628e-06, 'epoch': 3.45}\n",
      "{'loss': 27.375, 'learning_rate': 4.627000000000001e-06, 'epoch': 3.45}\n",
      "{'loss': 27.375, 'learning_rate': 4.626e-06, 'epoch': 3.45}\n",
      "{'loss': 27.75, 'learning_rate': 4.625000000000001e-06, 'epoch': 3.45}\n",
      "{'loss': 27.0, 'learning_rate': 4.624e-06, 'epoch': 3.45}\n",
      "{'loss': 27.5, 'learning_rate': 4.6230000000000005e-06, 'epoch': 3.45}\n",
      "{'loss': 30.375, 'learning_rate': 4.622e-06, 'epoch': 3.45}\n",
      "{'loss': 27.875, 'learning_rate': 4.621e-06, 'epoch': 3.45}\n",
      "{'loss': 27.25, 'learning_rate': 4.620000000000001e-06, 'epoch': 3.45}\n",
      "{'loss': 27.375, 'learning_rate': 4.619e-06, 'epoch': 3.45}\n",
      "{'loss': 27.625, 'learning_rate': 4.6180000000000005e-06, 'epoch': 3.45}\n",
      "{'loss': 27.0, 'learning_rate': 4.617e-06, 'epoch': 3.46}\n",
      "{'loss': 27.375, 'learning_rate': 4.616e-06, 'epoch': 3.46}\n",
      "{'loss': 27.125, 'learning_rate': 4.615000000000001e-06, 'epoch': 3.46}\n",
      "{'loss': 27.0, 'learning_rate': 4.614e-06, 'epoch': 3.46}\n",
      "{'loss': 27.375, 'learning_rate': 4.6130000000000006e-06, 'epoch': 3.46}\n",
      "{'loss': 28.0, 'learning_rate': 4.612e-06, 'epoch': 3.46}\n",
      "{'loss': 28.75, 'learning_rate': 4.611e-06, 'epoch': 3.46}\n",
      "{'loss': 27.625, 'learning_rate': 4.610000000000001e-06, 'epoch': 3.46}\n",
      "{'loss': 26.375, 'learning_rate': 4.609e-06, 'epoch': 3.46}\n",
      "{'loss': 28.375, 'learning_rate': 4.608000000000001e-06, 'epoch': 3.46}\n",
      "{'loss': 26.625, 'learning_rate': 4.607e-06, 'epoch': 3.46}\n",
      "{'loss': 27.875, 'learning_rate': 4.6060000000000005e-06, 'epoch': 3.46}\n",
      "{'loss': 26.875, 'learning_rate': 4.605000000000001e-06, 'epoch': 3.46}\n",
      "{'loss': 26.875, 'learning_rate': 4.604e-06, 'epoch': 3.46}\n",
      "{'loss': 27.75, 'learning_rate': 4.603000000000001e-06, 'epoch': 3.46}\n",
      "{'loss': 27.625, 'learning_rate': 4.602e-06, 'epoch': 3.46}\n",
      "{'loss': 26.25, 'learning_rate': 4.6010000000000005e-06, 'epoch': 3.47}\n",
      "{'loss': 27.375, 'learning_rate': 4.600000000000001e-06, 'epoch': 3.47}\n",
      "{'loss': 26.625, 'learning_rate': 4.599e-06, 'epoch': 3.47}\n",
      "{'loss': 27.375, 'learning_rate': 4.598e-06, 'epoch': 3.47}\n",
      "{'loss': 27.875, 'learning_rate': 4.597e-06, 'epoch': 3.47}\n",
      "{'loss': 27.875, 'learning_rate': 4.5960000000000006e-06, 'epoch': 3.47}\n",
      "{'loss': 29.25, 'learning_rate': 4.595000000000001e-06, 'epoch': 3.47}\n",
      "{'loss': 27.125, 'learning_rate': 4.594e-06, 'epoch': 3.47}\n",
      "{'loss': 27.125, 'learning_rate': 4.593e-06, 'epoch': 3.47}\n",
      "{'loss': 28.5, 'learning_rate': 4.592e-06, 'epoch': 3.47}\n",
      "{'loss': 27.875, 'learning_rate': 4.591000000000001e-06, 'epoch': 3.47}\n",
      "{'loss': 28.0, 'learning_rate': 4.590000000000001e-06, 'epoch': 3.47}\n",
      "{'loss': 27.375, 'learning_rate': 4.5890000000000004e-06, 'epoch': 3.47}\n",
      "{'loss': 27.875, 'learning_rate': 4.588e-06, 'epoch': 3.47}\n",
      "{'loss': 29.875, 'learning_rate': 4.587e-06, 'epoch': 3.47}\n",
      "{'loss': 27.125, 'learning_rate': 4.586000000000001e-06, 'epoch': 3.47}\n",
      "{'loss': 29.0, 'learning_rate': 4.585e-06, 'epoch': 3.48}\n",
      "{'loss': 26.875, 'learning_rate': 4.5840000000000005e-06, 'epoch': 3.48}\n",
      "{'loss': 26.75, 'learning_rate': 4.583e-06, 'epoch': 3.48}\n",
      "{'loss': 27.75, 'learning_rate': 4.582e-06, 'epoch': 3.48}\n",
      "{'loss': 27.875, 'learning_rate': 4.581000000000001e-06, 'epoch': 3.48}\n",
      "{'loss': 29.125, 'learning_rate': 4.58e-06, 'epoch': 3.48}\n",
      "{'loss': 29.5, 'learning_rate': 4.579e-06, 'epoch': 3.48}\n",
      "{'loss': 27.625, 'learning_rate': 4.578e-06, 'epoch': 3.48}\n",
      "{'loss': 27.625, 'learning_rate': 4.577e-06, 'epoch': 3.48}\n",
      "{'loss': 27.875, 'learning_rate': 4.576000000000001e-06, 'epoch': 3.48}\n",
      "{'loss': 28.125, 'learning_rate': 4.575e-06, 'epoch': 3.48}\n",
      "{'loss': 27.0, 'learning_rate': 4.574e-06, 'epoch': 3.48}\n",
      "{'loss': 28.0, 'learning_rate': 4.573e-06, 'epoch': 3.48}\n",
      "{'loss': 27.875, 'learning_rate': 4.5720000000000004e-06, 'epoch': 3.48}\n",
      "{'loss': 27.75, 'learning_rate': 4.571000000000001e-06, 'epoch': 3.48}\n",
      "{'loss': 28.5, 'learning_rate': 4.57e-06, 'epoch': 3.49}\n",
      "{'loss': 29.0, 'learning_rate': 4.569e-06, 'epoch': 3.49}\n",
      "{'loss': 28.5, 'learning_rate': 4.568e-06, 'epoch': 3.49}\n",
      "{'loss': 29.25, 'learning_rate': 4.5670000000000005e-06, 'epoch': 3.49}\n",
      "{'loss': 26.75, 'learning_rate': 4.566000000000001e-06, 'epoch': 3.49}\n",
      "{'loss': 26.75, 'learning_rate': 4.565e-06, 'epoch': 3.49}\n",
      "{'loss': 27.25, 'learning_rate': 4.564e-06, 'epoch': 3.49}\n",
      "{'loss': 26.875, 'learning_rate': 4.563e-06, 'epoch': 3.49}\n",
      "{'loss': 27.25, 'learning_rate': 4.5620000000000005e-06, 'epoch': 3.49}\n",
      "{'loss': 28.375, 'learning_rate': 4.561e-06, 'epoch': 3.49}\n",
      "{'loss': 28.125, 'learning_rate': 4.56e-06, 'epoch': 3.49}\n",
      "{'loss': 27.125, 'learning_rate': 4.559000000000001e-06, 'epoch': 3.49}\n",
      "{'loss': 29.375, 'learning_rate': 4.558e-06, 'epoch': 3.49}\n",
      "{'loss': 27.0, 'learning_rate': 4.557000000000001e-06, 'epoch': 3.49}\n",
      "{'loss': 27.25, 'learning_rate': 4.556e-06, 'epoch': 3.49}\n",
      "{'loss': 27.75, 'learning_rate': 4.5550000000000004e-06, 'epoch': 3.49}\n",
      "{'loss': 29.0, 'learning_rate': 4.554000000000001e-06, 'epoch': 3.5}\n",
      "{'loss': 28.0, 'learning_rate': 4.553e-06, 'epoch': 3.5}\n",
      "{'loss': 26.625, 'learning_rate': 4.552000000000001e-06, 'epoch': 3.5}\n",
      "{'loss': 26.5, 'learning_rate': 4.551e-06, 'epoch': 3.5}\n",
      "{'loss': 29.625, 'learning_rate': 4.5500000000000005e-06, 'epoch': 3.5}\n",
      "{'loss': 27.25, 'learning_rate': 4.549000000000001e-06, 'epoch': 3.5}\n",
      "{'loss': 28.5, 'learning_rate': 4.548e-06, 'epoch': 3.5}\n",
      "{'loss': 27.375, 'learning_rate': 4.547000000000001e-06, 'epoch': 3.5}\n",
      "{'loss': 28.125, 'learning_rate': 4.546e-06, 'epoch': 3.5}\n",
      "{'loss': 32.0, 'learning_rate': 4.5450000000000005e-06, 'epoch': 3.5}\n",
      "{'loss': 27.125, 'learning_rate': 4.544000000000001e-06, 'epoch': 3.5}\n",
      "{'loss': 26.5, 'learning_rate': 4.543e-06, 'epoch': 3.5}\n",
      "{'loss': 27.25, 'learning_rate': 4.542e-06, 'epoch': 3.5}\n",
      "{'loss': 29.625, 'learning_rate': 4.541e-06, 'epoch': 3.5}\n",
      "{'loss': 27.625, 'learning_rate': 4.540000000000001e-06, 'epoch': 3.5}\n",
      "{'loss': 28.375, 'learning_rate': 4.539000000000001e-06, 'epoch': 3.51}\n",
      "{'loss': 28.75, 'learning_rate': 4.5380000000000004e-06, 'epoch': 3.51}\n",
      "{'loss': 27.25, 'learning_rate': 4.537e-06, 'epoch': 3.51}\n",
      "{'loss': 27.125, 'learning_rate': 4.536e-06, 'epoch': 3.51}\n",
      "{'loss': 27.625, 'learning_rate': 4.535000000000001e-06, 'epoch': 3.51}\n",
      "{'loss': 27.25, 'learning_rate': 4.534000000000001e-06, 'epoch': 3.51}\n",
      "{'loss': 26.875, 'learning_rate': 4.5330000000000005e-06, 'epoch': 3.51}\n",
      "{'loss': 26.625, 'learning_rate': 4.532e-06, 'epoch': 3.51}\n",
      "{'loss': 28.75, 'learning_rate': 4.531e-06, 'epoch': 3.51}\n",
      "{'loss': 27.625, 'learning_rate': 4.530000000000001e-06, 'epoch': 3.51}\n",
      "{'loss': 27.5, 'learning_rate': 4.529000000000001e-06, 'epoch': 3.51}\n",
      "{'loss': 28.125, 'learning_rate': 4.5280000000000005e-06, 'epoch': 3.51}\n",
      "{'loss': 27.625, 'learning_rate': 4.527e-06, 'epoch': 3.51}\n",
      "{'loss': 27.75, 'learning_rate': 4.526e-06, 'epoch': 3.51}\n",
      "{'loss': 28.875, 'learning_rate': 4.525000000000001e-06, 'epoch': 3.51}\n",
      "{'loss': 27.625, 'learning_rate': 4.524e-06, 'epoch': 3.51}\n",
      "{'loss': 27.125, 'learning_rate': 4.5230000000000006e-06, 'epoch': 3.52}\n",
      "{'loss': 26.875, 'learning_rate': 4.522e-06, 'epoch': 3.52}\n",
      "{'loss': 27.5, 'learning_rate': 4.521e-06, 'epoch': 3.52}\n",
      "{'loss': 26.75, 'learning_rate': 4.520000000000001e-06, 'epoch': 3.52}\n",
      "{'loss': 26.75, 'learning_rate': 4.519e-06, 'epoch': 3.52}\n",
      "{'loss': 31.0, 'learning_rate': 4.518e-06, 'epoch': 3.52}\n",
      "{'loss': 28.75, 'learning_rate': 4.517e-06, 'epoch': 3.52}\n",
      "{'loss': 27.125, 'learning_rate': 4.5160000000000005e-06, 'epoch': 3.52}\n",
      "{'loss': 28.5, 'learning_rate': 4.515000000000001e-06, 'epoch': 3.52}\n",
      "{'loss': 27.75, 'learning_rate': 4.514e-06, 'epoch': 3.52}\n",
      "{'loss': 28.25, 'learning_rate': 4.513e-06, 'epoch': 3.52}\n",
      "{'loss': 29.25, 'learning_rate': 4.512e-06, 'epoch': 3.52}\n",
      "{'loss': 27.625, 'learning_rate': 4.5110000000000005e-06, 'epoch': 3.52}\n",
      "{'loss': 29.125, 'learning_rate': 4.510000000000001e-06, 'epoch': 3.52}\n",
      "{'loss': 26.875, 'learning_rate': 4.509e-06, 'epoch': 3.52}\n",
      "{'loss': 28.0, 'learning_rate': 4.508e-06, 'epoch': 3.53}\n",
      "{'loss': 27.5, 'learning_rate': 4.507e-06, 'epoch': 3.53}\n",
      "{'loss': 28.625, 'learning_rate': 4.5060000000000006e-06, 'epoch': 3.53}\n",
      "{'loss': 27.0, 'learning_rate': 4.505e-06, 'epoch': 3.53}\n",
      "{'loss': 28.75, 'learning_rate': 4.504e-06, 'epoch': 3.53}\n",
      "{'loss': 27.0, 'learning_rate': 4.503e-06, 'epoch': 3.53}\n",
      "{'loss': 28.875, 'learning_rate': 4.502e-06, 'epoch': 3.53}\n",
      "{'loss': 27.0, 'learning_rate': 4.501000000000001e-06, 'epoch': 3.53}\n",
      "{'loss': 26.625, 'learning_rate': 4.5e-06, 'epoch': 3.53}\n",
      "{'loss': 26.875, 'learning_rate': 4.4990000000000005e-06, 'epoch': 3.53}\n",
      "{'loss': 28.5, 'learning_rate': 4.498e-06, 'epoch': 3.53}\n",
      "{'loss': 27.25, 'learning_rate': 4.497e-06, 'epoch': 3.53}\n",
      "{'loss': 27.0, 'learning_rate': 4.496000000000001e-06, 'epoch': 3.53}\n",
      "{'loss': 27.875, 'learning_rate': 4.495e-06, 'epoch': 3.53}\n",
      "{'loss': 28.375, 'learning_rate': 4.4940000000000005e-06, 'epoch': 3.53}\n",
      "{'loss': 28.5, 'learning_rate': 4.493e-06, 'epoch': 3.53}\n",
      "{'loss': 27.625, 'learning_rate': 4.492e-06, 'epoch': 3.54}\n",
      "{'loss': 28.5, 'learning_rate': 4.491000000000001e-06, 'epoch': 3.54}\n",
      "{'loss': 27.625, 'learning_rate': 4.49e-06, 'epoch': 3.54}\n",
      "{'loss': 26.75, 'learning_rate': 4.4890000000000006e-06, 'epoch': 3.54}\n",
      "{'loss': 26.625, 'learning_rate': 4.488e-06, 'epoch': 3.54}\n",
      "{'loss': 28.25, 'learning_rate': 4.487e-06, 'epoch': 3.54}\n",
      "{'loss': 29.0, 'learning_rate': 4.486000000000001e-06, 'epoch': 3.54}\n",
      "{'loss': 27.125, 'learning_rate': 4.485e-06, 'epoch': 3.54}\n",
      "{'loss': 26.0, 'learning_rate': 4.484000000000001e-06, 'epoch': 3.54}\n",
      "{'loss': 28.25, 'learning_rate': 4.483e-06, 'epoch': 3.54}\n",
      "{'loss': 28.25, 'learning_rate': 4.4820000000000005e-06, 'epoch': 3.54}\n",
      "{'loss': 26.875, 'learning_rate': 4.481e-06, 'epoch': 3.54}\n",
      "{'loss': 27.75, 'learning_rate': 4.48e-06, 'epoch': 3.54}\n",
      "{'loss': 28.875, 'learning_rate': 4.479000000000001e-06, 'epoch': 3.54}\n",
      "{'loss': 28.5, 'learning_rate': 4.478e-06, 'epoch': 3.54}\n",
      "{'loss': 27.625, 'learning_rate': 4.4770000000000005e-06, 'epoch': 3.54}\n",
      "{'loss': 27.0, 'learning_rate': 4.476e-06, 'epoch': 3.55}\n",
      "{'loss': 27.125, 'learning_rate': 4.475e-06, 'epoch': 3.55}\n",
      "{'loss': 27.375, 'learning_rate': 4.474000000000001e-06, 'epoch': 3.55}\n",
      "{'loss': 27.375, 'learning_rate': 4.473e-06, 'epoch': 3.55}\n",
      "{'loss': 27.25, 'learning_rate': 4.4720000000000006e-06, 'epoch': 3.55}\n",
      "{'loss': 27.25, 'learning_rate': 4.471e-06, 'epoch': 3.55}\n",
      "{'loss': 27.625, 'learning_rate': 4.47e-06, 'epoch': 3.55}\n",
      "{'loss': 27.75, 'learning_rate': 4.469000000000001e-06, 'epoch': 3.55}\n",
      "{'loss': 26.5, 'learning_rate': 4.468e-06, 'epoch': 3.55}\n",
      "{'loss': 28.375, 'learning_rate': 4.467000000000001e-06, 'epoch': 3.55}\n",
      "{'loss': 26.625, 'learning_rate': 4.466e-06, 'epoch': 3.55}\n",
      "{'loss': 27.5, 'learning_rate': 4.4650000000000004e-06, 'epoch': 3.55}\n",
      "{'loss': 27.375, 'learning_rate': 4.464000000000001e-06, 'epoch': 3.55}\n",
      "{'loss': 27.75, 'learning_rate': 4.463e-06, 'epoch': 3.55}\n",
      "{'loss': 28.625, 'learning_rate': 4.462e-06, 'epoch': 3.55}\n",
      "{'loss': 27.5, 'learning_rate': 4.461e-06, 'epoch': 3.56}\n",
      "{'loss': 27.25, 'learning_rate': 4.4600000000000005e-06, 'epoch': 3.56}\n",
      "{'loss': 27.25, 'learning_rate': 4.459000000000001e-06, 'epoch': 3.56}\n",
      "{'loss': 27.125, 'learning_rate': 4.458e-06, 'epoch': 3.56}\n",
      "{'loss': 27.125, 'learning_rate': 4.457e-06, 'epoch': 3.56}\n",
      "{'loss': 26.625, 'learning_rate': 4.456e-06, 'epoch': 3.56}\n",
      "{'loss': 27.0, 'learning_rate': 4.4550000000000005e-06, 'epoch': 3.56}\n",
      "{'loss': 26.875, 'learning_rate': 4.454000000000001e-06, 'epoch': 3.56}\n",
      "{'loss': 26.75, 'learning_rate': 4.453e-06, 'epoch': 3.56}\n",
      "{'loss': 27.875, 'learning_rate': 4.452e-06, 'epoch': 3.56}\n",
      "{'loss': 27.875, 'learning_rate': 4.451e-06, 'epoch': 3.56}\n",
      "{'loss': 27.125, 'learning_rate': 4.450000000000001e-06, 'epoch': 3.56}\n",
      "{'loss': 28.75, 'learning_rate': 4.449000000000001e-06, 'epoch': 3.56}\n",
      "{'loss': 28.125, 'learning_rate': 4.4480000000000004e-06, 'epoch': 3.56}\n",
      "{'loss': 28.25, 'learning_rate': 4.447e-06, 'epoch': 3.56}\n",
      "{'loss': 28.0, 'learning_rate': 4.446e-06, 'epoch': 3.56}\n",
      "{'loss': 27.125, 'learning_rate': 4.445000000000001e-06, 'epoch': 3.57}\n",
      "{'loss': 27.5, 'learning_rate': 4.444e-06, 'epoch': 3.57}\n",
      "{'loss': 26.875, 'learning_rate': 4.4430000000000005e-06, 'epoch': 3.57}\n",
      "{'loss': 28.0, 'learning_rate': 4.442e-06, 'epoch': 3.57}\n",
      "{'loss': 27.375, 'learning_rate': 4.441e-06, 'epoch': 3.57}\n",
      "{'loss': 27.5, 'learning_rate': 4.440000000000001e-06, 'epoch': 3.57}\n",
      "{'loss': 27.5, 'learning_rate': 4.439e-06, 'epoch': 3.57}\n",
      "{'loss': 27.875, 'learning_rate': 4.438e-06, 'epoch': 3.57}\n",
      "{'loss': 28.0, 'learning_rate': 4.437e-06, 'epoch': 3.57}\n",
      "{'loss': 26.875, 'learning_rate': 4.436e-06, 'epoch': 3.57}\n",
      "{'loss': 28.125, 'learning_rate': 4.435000000000001e-06, 'epoch': 3.57}\n",
      "{'loss': 27.25, 'learning_rate': 4.434e-06, 'epoch': 3.57}\n",
      "{'loss': 28.375, 'learning_rate': 4.433000000000001e-06, 'epoch': 3.57}\n",
      "{'loss': 26.5, 'learning_rate': 4.432e-06, 'epoch': 3.57}\n",
      "{'loss': 26.625, 'learning_rate': 4.4310000000000004e-06, 'epoch': 3.57}\n",
      "{'loss': 27.625, 'learning_rate': 4.430000000000001e-06, 'epoch': 3.58}\n",
      "{'loss': 26.75, 'learning_rate': 4.429e-06, 'epoch': 3.58}\n",
      "{'loss': 29.75, 'learning_rate': 4.428000000000001e-06, 'epoch': 3.58}\n",
      "{'loss': 27.125, 'learning_rate': 4.427e-06, 'epoch': 3.58}\n",
      "{'loss': 27.0, 'learning_rate': 4.4260000000000005e-06, 'epoch': 3.58}\n",
      "{'loss': 28.625, 'learning_rate': 4.425e-06, 'epoch': 3.58}\n",
      "{'loss': 27.5, 'learning_rate': 4.424e-06, 'epoch': 3.58}\n",
      "{'loss': 26.5, 'learning_rate': 4.423000000000001e-06, 'epoch': 3.58}\n",
      "{'loss': 26.75, 'learning_rate': 4.422e-06, 'epoch': 3.58}\n",
      "{'loss': 26.75, 'learning_rate': 4.4210000000000005e-06, 'epoch': 3.58}\n",
      "{'loss': 26.625, 'learning_rate': 4.42e-06, 'epoch': 3.58}\n",
      "{'loss': 28.375, 'learning_rate': 4.419e-06, 'epoch': 3.58}\n",
      "{'loss': 27.25, 'learning_rate': 4.418000000000001e-06, 'epoch': 3.58}\n",
      "{'loss': 28.875, 'learning_rate': 4.417e-06, 'epoch': 3.58}\n",
      "{'loss': 26.125, 'learning_rate': 4.416000000000001e-06, 'epoch': 3.58}\n",
      "{'loss': 26.375, 'learning_rate': 4.415e-06, 'epoch': 3.58}\n",
      "{'loss': 26.75, 'learning_rate': 4.4140000000000004e-06, 'epoch': 3.59}\n",
      "{'loss': 30.25, 'learning_rate': 4.413000000000001e-06, 'epoch': 3.59}\n",
      "{'loss': 29.75, 'learning_rate': 4.412e-06, 'epoch': 3.59}\n",
      "{'loss': 26.875, 'learning_rate': 4.411000000000001e-06, 'epoch': 3.59}\n",
      "{'loss': 28.0, 'learning_rate': 4.41e-06, 'epoch': 3.59}\n",
      "{'loss': 28.5, 'learning_rate': 4.4090000000000005e-06, 'epoch': 3.59}\n",
      "{'loss': 28.0, 'learning_rate': 4.408000000000001e-06, 'epoch': 3.59}\n",
      "{'loss': 26.375, 'learning_rate': 4.407e-06, 'epoch': 3.59}\n",
      "{'loss': 27.75, 'learning_rate': 4.406000000000001e-06, 'epoch': 3.59}\n",
      "{'loss': 26.875, 'learning_rate': 4.405e-06, 'epoch': 3.59}\n",
      "{'loss': 28.625, 'learning_rate': 4.4040000000000005e-06, 'epoch': 3.59}\n",
      "{'loss': 26.75, 'learning_rate': 4.403000000000001e-06, 'epoch': 3.59}\n",
      "{'loss': 27.125, 'learning_rate': 4.402e-06, 'epoch': 3.59}\n",
      "{'loss': 27.75, 'learning_rate': 4.401e-06, 'epoch': 3.59}\n",
      "{'loss': 29.125, 'learning_rate': 4.4e-06, 'epoch': 3.59}\n",
      "{'loss': 27.25, 'learning_rate': 4.3990000000000006e-06, 'epoch': 3.59}\n",
      "{'loss': 26.875, 'learning_rate': 4.398000000000001e-06, 'epoch': 3.6}\n",
      "{'loss': 27.875, 'learning_rate': 4.397e-06, 'epoch': 3.6}\n",
      "{'loss': 28.5, 'learning_rate': 4.396e-06, 'epoch': 3.6}\n",
      "{'loss': 28.375, 'learning_rate': 4.395e-06, 'epoch': 3.6}\n",
      "{'loss': 28.25, 'learning_rate': 4.394000000000001e-06, 'epoch': 3.6}\n",
      "{'loss': 27.375, 'learning_rate': 4.393000000000001e-06, 'epoch': 3.6}\n",
      "{'loss': 27.75, 'learning_rate': 4.3920000000000005e-06, 'epoch': 3.6}\n",
      "{'loss': 27.125, 'learning_rate': 4.391e-06, 'epoch': 3.6}\n",
      "{'loss': 28.375, 'learning_rate': 4.39e-06, 'epoch': 3.6}\n",
      "{'loss': 28.25, 'learning_rate': 4.389000000000001e-06, 'epoch': 3.6}\n",
      "{'loss': 26.625, 'learning_rate': 4.388e-06, 'epoch': 3.6}\n",
      "{'loss': 29.375, 'learning_rate': 4.3870000000000005e-06, 'epoch': 3.6}\n",
      "{'loss': 29.625, 'learning_rate': 4.386e-06, 'epoch': 3.6}\n",
      "{'loss': 26.875, 'learning_rate': 4.385e-06, 'epoch': 3.6}\n",
      "{'loss': 27.875, 'learning_rate': 4.384000000000001e-06, 'epoch': 3.6}\n",
      "{'loss': 27.75, 'learning_rate': 4.383e-06, 'epoch': 3.61}\n",
      "{'loss': 28.25, 'learning_rate': 4.382e-06, 'epoch': 3.61}\n",
      "{'loss': 27.625, 'learning_rate': 4.381e-06, 'epoch': 3.61}\n",
      "{'loss': 27.875, 'learning_rate': 4.38e-06, 'epoch': 3.61}\n",
      "{'loss': 26.25, 'learning_rate': 4.379000000000001e-06, 'epoch': 3.61}\n",
      "{'loss': 27.375, 'learning_rate': 4.378e-06, 'epoch': 3.61}\n",
      "{'loss': 26.875, 'learning_rate': 4.377e-06, 'epoch': 3.61}\n",
      "{'loss': 26.75, 'learning_rate': 4.376e-06, 'epoch': 3.61}\n",
      "{'loss': 26.375, 'learning_rate': 4.3750000000000005e-06, 'epoch': 3.61}\n",
      "{'loss': 28.625, 'learning_rate': 4.374000000000001e-06, 'epoch': 3.61}\n",
      "{'loss': 28.875, 'learning_rate': 4.373e-06, 'epoch': 3.61}\n",
      "{'loss': 27.625, 'learning_rate': 4.372e-06, 'epoch': 3.61}\n",
      "{'loss': 26.75, 'learning_rate': 4.371e-06, 'epoch': 3.61}\n",
      "{'loss': 29.5, 'learning_rate': 4.3700000000000005e-06, 'epoch': 3.61}\n",
      "{'loss': 27.5, 'learning_rate': 4.369000000000001e-06, 'epoch': 3.61}\n",
      "{'loss': 26.875, 'learning_rate': 4.368e-06, 'epoch': 3.61}\n",
      "{'loss': 27.75, 'learning_rate': 4.367e-06, 'epoch': 3.62}\n",
      "{'loss': 28.375, 'learning_rate': 4.366e-06, 'epoch': 3.62}\n",
      "{'loss': 27.75, 'learning_rate': 4.3650000000000006e-06, 'epoch': 3.62}\n",
      "{'loss': 29.0, 'learning_rate': 4.364e-06, 'epoch': 3.62}\n",
      "{'loss': 27.5, 'learning_rate': 4.363e-06, 'epoch': 3.62}\n",
      "{'loss': 28.5, 'learning_rate': 4.362e-06, 'epoch': 3.62}\n",
      "{'loss': 28.625, 'learning_rate': 4.361e-06, 'epoch': 3.62}\n",
      "{'loss': 27.0, 'learning_rate': 4.360000000000001e-06, 'epoch': 3.62}\n",
      "{'loss': 28.125, 'learning_rate': 4.359e-06, 'epoch': 3.62}\n",
      "{'loss': 26.125, 'learning_rate': 4.3580000000000005e-06, 'epoch': 3.62}\n",
      "{'loss': 27.625, 'learning_rate': 4.357e-06, 'epoch': 3.62}\n",
      "{'loss': 27.625, 'learning_rate': 4.356e-06, 'epoch': 3.62}\n",
      "{'loss': 28.5, 'learning_rate': 4.355000000000001e-06, 'epoch': 3.62}\n",
      "{'loss': 29.25, 'learning_rate': 4.354e-06, 'epoch': 3.62}\n",
      "{'loss': 27.625, 'learning_rate': 4.3530000000000005e-06, 'epoch': 3.62}\n",
      "{'loss': 28.5, 'learning_rate': 4.352e-06, 'epoch': 3.63}\n",
      "{'loss': 27.25, 'learning_rate': 4.351e-06, 'epoch': 3.63}\n",
      "{'loss': 27.25, 'learning_rate': 4.350000000000001e-06, 'epoch': 3.63}\n",
      "{'loss': 28.5, 'learning_rate': 4.349e-06, 'epoch': 3.63}\n",
      "{'loss': 28.875, 'learning_rate': 4.3480000000000006e-06, 'epoch': 3.63}\n",
      "{'loss': 27.75, 'learning_rate': 4.347e-06, 'epoch': 3.63}\n",
      "{'loss': 26.5, 'learning_rate': 4.346e-06, 'epoch': 3.63}\n",
      "{'loss': 28.125, 'learning_rate': 4.345000000000001e-06, 'epoch': 3.63}\n",
      "{'loss': 27.375, 'learning_rate': 4.344e-06, 'epoch': 3.63}\n",
      "{'loss': 26.625, 'learning_rate': 4.343000000000001e-06, 'epoch': 3.63}\n",
      "{'loss': 28.375, 'learning_rate': 4.342e-06, 'epoch': 3.63}\n",
      "{'loss': 27.125, 'learning_rate': 4.3410000000000005e-06, 'epoch': 3.63}\n",
      "{'loss': 27.25, 'learning_rate': 4.34e-06, 'epoch': 3.63}\n",
      "{'loss': 27.625, 'learning_rate': 4.339e-06, 'epoch': 3.63}\n",
      "{'loss': 28.5, 'learning_rate': 4.338000000000001e-06, 'epoch': 3.63}\n",
      "{'loss': 28.375, 'learning_rate': 4.337e-06, 'epoch': 3.63}\n",
      "{'loss': 27.75, 'learning_rate': 4.3360000000000005e-06, 'epoch': 3.64}\n",
      "{'loss': 26.875, 'learning_rate': 4.335e-06, 'epoch': 3.64}\n",
      "{'loss': 26.5, 'learning_rate': 4.334e-06, 'epoch': 3.64}\n",
      "{'loss': 27.25, 'learning_rate': 4.333000000000001e-06, 'epoch': 3.64}\n",
      "{'loss': 28.875, 'learning_rate': 4.332e-06, 'epoch': 3.64}\n",
      "{'loss': 28.25, 'learning_rate': 4.3310000000000005e-06, 'epoch': 3.64}\n",
      "{'loss': 26.375, 'learning_rate': 4.33e-06, 'epoch': 3.64}\n",
      "{'loss': 28.625, 'learning_rate': 4.329e-06, 'epoch': 3.64}\n",
      "{'loss': 27.75, 'learning_rate': 4.328000000000001e-06, 'epoch': 3.64}\n",
      "{'loss': 27.25, 'learning_rate': 4.327e-06, 'epoch': 3.64}\n",
      "{'loss': 27.375, 'learning_rate': 4.326000000000001e-06, 'epoch': 3.64}\n",
      "{'loss': 28.125, 'learning_rate': 4.325e-06, 'epoch': 3.64}\n",
      "{'loss': 29.125, 'learning_rate': 4.3240000000000004e-06, 'epoch': 3.64}\n",
      "{'loss': 28.125, 'learning_rate': 4.323000000000001e-06, 'epoch': 3.64}\n",
      "{'loss': 28.0, 'learning_rate': 4.322e-06, 'epoch': 3.64}\n",
      "{'loss': 29.5, 'learning_rate': 4.321e-06, 'epoch': 3.65}\n",
      "{'loss': 27.125, 'learning_rate': 4.32e-06, 'epoch': 3.65}\n",
      "{'loss': 30.0, 'learning_rate': 4.3190000000000005e-06, 'epoch': 3.65}\n",
      "{'loss': 27.25, 'learning_rate': 4.318000000000001e-06, 'epoch': 3.65}\n",
      "{'loss': 29.0, 'learning_rate': 4.317e-06, 'epoch': 3.65}\n",
      "{'loss': 26.5, 'learning_rate': 4.316e-06, 'epoch': 3.65}\n",
      "{'loss': 28.5, 'learning_rate': 4.315e-06, 'epoch': 3.65}\n",
      "{'loss': 29.5, 'learning_rate': 4.3140000000000005e-06, 'epoch': 3.65}\n",
      "{'loss': 27.875, 'learning_rate': 4.313000000000001e-06, 'epoch': 3.65}\n",
      "{'loss': 30.375, 'learning_rate': 4.312e-06, 'epoch': 3.65}\n",
      "{'loss': 28.25, 'learning_rate': 4.311e-06, 'epoch': 3.65}\n",
      "{'loss': 27.75, 'learning_rate': 4.31e-06, 'epoch': 3.65}\n",
      "{'loss': 27.25, 'learning_rate': 4.309000000000001e-06, 'epoch': 3.65}\n",
      "{'loss': 28.125, 'learning_rate': 4.308000000000001e-06, 'epoch': 3.65}\n",
      "{'loss': 29.125, 'learning_rate': 4.3070000000000004e-06, 'epoch': 3.65}\n",
      "{'loss': 27.625, 'learning_rate': 4.306e-06, 'epoch': 3.65}\n",
      "{'loss': 27.0, 'learning_rate': 4.305e-06, 'epoch': 3.66}\n",
      "{'loss': 27.5, 'learning_rate': 4.304000000000001e-06, 'epoch': 3.66}\n",
      "{'loss': 29.375, 'learning_rate': 4.303e-06, 'epoch': 3.66}\n",
      "{'loss': 28.375, 'learning_rate': 4.3020000000000005e-06, 'epoch': 3.66}\n",
      "{'loss': 28.5, 'learning_rate': 4.301e-06, 'epoch': 3.66}\n",
      "{'loss': 27.125, 'learning_rate': 4.3e-06, 'epoch': 3.66}\n",
      "{'loss': 27.875, 'learning_rate': 4.299000000000001e-06, 'epoch': 3.66}\n",
      "{'loss': 27.875, 'learning_rate': 4.298e-06, 'epoch': 3.66}\n",
      "{'loss': 26.375, 'learning_rate': 4.2970000000000005e-06, 'epoch': 3.66}\n",
      "{'loss': 28.125, 'learning_rate': 4.296e-06, 'epoch': 3.66}\n",
      "{'loss': 26.875, 'learning_rate': 4.295e-06, 'epoch': 3.66}\n",
      "{'loss': 27.625, 'learning_rate': 4.294000000000001e-06, 'epoch': 3.66}\n",
      "{'loss': 28.875, 'learning_rate': 4.293e-06, 'epoch': 3.66}\n",
      "{'loss': 26.875, 'learning_rate': 4.292000000000001e-06, 'epoch': 3.66}\n",
      "{'loss': 26.625, 'learning_rate': 4.291e-06, 'epoch': 3.66}\n",
      "{'loss': 27.625, 'learning_rate': 4.2900000000000004e-06, 'epoch': 3.66}\n",
      "{'loss': 27.25, 'learning_rate': 4.289000000000001e-06, 'epoch': 3.67}\n",
      "{'loss': 27.625, 'learning_rate': 4.288e-06, 'epoch': 3.67}\n",
      "{'loss': 26.5, 'learning_rate': 4.287000000000001e-06, 'epoch': 3.67}\n",
      "{'loss': 26.875, 'learning_rate': 4.286e-06, 'epoch': 3.67}\n",
      "{'loss': 26.625, 'learning_rate': 4.2850000000000005e-06, 'epoch': 3.67}\n",
      "{'loss': 29.0, 'learning_rate': 4.284e-06, 'epoch': 3.67}\n",
      "{'loss': 27.5, 'learning_rate': 4.283e-06, 'epoch': 3.67}\n",
      "{'loss': 26.75, 'learning_rate': 4.282000000000001e-06, 'epoch': 3.67}\n",
      "{'loss': 26.0, 'learning_rate': 4.281e-06, 'epoch': 3.67}\n",
      "{'loss': 27.625, 'learning_rate': 4.2800000000000005e-06, 'epoch': 3.67}\n",
      "{'loss': 26.625, 'learning_rate': 4.279e-06, 'epoch': 3.67}\n",
      "{'loss': 27.25, 'learning_rate': 4.278e-06, 'epoch': 3.67}\n",
      "{'loss': 28.375, 'learning_rate': 4.277000000000001e-06, 'epoch': 3.67}\n",
      "{'loss': 27.625, 'learning_rate': 4.276e-06, 'epoch': 3.67}\n",
      "{'loss': 29.25, 'learning_rate': 4.2750000000000006e-06, 'epoch': 3.67}\n",
      "{'loss': 27.375, 'learning_rate': 4.274e-06, 'epoch': 3.68}\n",
      "{'loss': 28.625, 'learning_rate': 4.2730000000000004e-06, 'epoch': 3.68}\n",
      "{'loss': 27.5, 'learning_rate': 4.272000000000001e-06, 'epoch': 3.68}\n",
      "{'loss': 28.125, 'learning_rate': 4.271e-06, 'epoch': 3.68}\n",
      "{'loss': 28.75, 'learning_rate': 4.270000000000001e-06, 'epoch': 3.68}\n",
      "{'loss': 27.375, 'learning_rate': 4.269e-06, 'epoch': 3.68}\n",
      "{'loss': 28.5, 'learning_rate': 4.2680000000000005e-06, 'epoch': 3.68}\n",
      "{'loss': 28.0, 'learning_rate': 4.267000000000001e-06, 'epoch': 3.68}\n",
      "{'loss': 28.5, 'learning_rate': 4.266e-06, 'epoch': 3.68}\n",
      "{'loss': 27.0, 'learning_rate': 4.265000000000001e-06, 'epoch': 3.68}\n",
      "{'loss': 26.375, 'learning_rate': 4.264e-06, 'epoch': 3.68}\n",
      "{'loss': 27.125, 'learning_rate': 4.2630000000000005e-06, 'epoch': 3.68}\n",
      "{'loss': 28.75, 'learning_rate': 4.262000000000001e-06, 'epoch': 3.68}\n",
      "{'loss': 27.25, 'learning_rate': 4.261e-06, 'epoch': 3.68}\n",
      "{'loss': 26.75, 'learning_rate': 4.26e-06, 'epoch': 3.68}\n",
      "{'loss': 27.625, 'learning_rate': 4.259e-06, 'epoch': 3.68}\n",
      "{'loss': 27.125, 'learning_rate': 4.2580000000000006e-06, 'epoch': 3.69}\n",
      "{'loss': 28.25, 'learning_rate': 4.257000000000001e-06, 'epoch': 3.69}\n",
      "{'loss': 27.5, 'learning_rate': 4.256e-06, 'epoch': 3.69}\n",
      "{'loss': 30.375, 'learning_rate': 4.255e-06, 'epoch': 3.69}\n",
      "{'loss': 28.375, 'learning_rate': 4.254e-06, 'epoch': 3.69}\n",
      "{'loss': 27.625, 'learning_rate': 4.253000000000001e-06, 'epoch': 3.69}\n",
      "{'loss': 28.5, 'learning_rate': 4.252000000000001e-06, 'epoch': 3.69}\n",
      "{'loss': 28.625, 'learning_rate': 4.2510000000000005e-06, 'epoch': 3.69}\n",
      "{'loss': 27.5, 'learning_rate': 4.25e-06, 'epoch': 3.69}\n",
      "{'loss': 27.875, 'learning_rate': 4.249e-06, 'epoch': 3.69}\n",
      "{'loss': 27.0, 'learning_rate': 4.248000000000001e-06, 'epoch': 3.69}\n",
      "{'loss': 26.875, 'learning_rate': 4.247e-06, 'epoch': 3.69}\n",
      "{'loss': 27.0, 'learning_rate': 4.2460000000000005e-06, 'epoch': 3.69}\n",
      "{'loss': 27.875, 'learning_rate': 4.245e-06, 'epoch': 3.69}\n",
      "{'loss': 26.75, 'learning_rate': 4.244e-06, 'epoch': 3.69}\n",
      "{'loss': 28.625, 'learning_rate': 4.243000000000001e-06, 'epoch': 3.7}\n",
      "{'loss': 28.125, 'learning_rate': 4.242e-06, 'epoch': 3.7}\n",
      "{'loss': 27.0, 'learning_rate': 4.241e-06, 'epoch': 3.7}\n",
      "{'loss': 29.375, 'learning_rate': 4.24e-06, 'epoch': 3.7}\n",
      "{'loss': 27.25, 'learning_rate': 4.239e-06, 'epoch': 3.7}\n",
      "{'loss': 26.375, 'learning_rate': 4.238000000000001e-06, 'epoch': 3.7}\n",
      "{'loss': 28.0, 'learning_rate': 4.237e-06, 'epoch': 3.7}\n",
      "{'loss': 27.125, 'learning_rate': 4.236e-06, 'epoch': 3.7}\n",
      "{'loss': 27.0, 'learning_rate': 4.235e-06, 'epoch': 3.7}\n",
      "{'loss': 28.0, 'learning_rate': 4.2340000000000005e-06, 'epoch': 3.7}\n",
      "{'loss': 28.375, 'learning_rate': 4.233000000000001e-06, 'epoch': 3.7}\n",
      "{'loss': 27.75, 'learning_rate': 4.232e-06, 'epoch': 3.7}\n",
      "{'loss': 27.625, 'learning_rate': 4.231e-06, 'epoch': 3.7}\n",
      "{'loss': 29.625, 'learning_rate': 4.23e-06, 'epoch': 3.7}\n",
      "{'loss': 26.5, 'learning_rate': 4.2290000000000005e-06, 'epoch': 3.7}\n",
      "{'loss': 27.5, 'learning_rate': 4.228000000000001e-06, 'epoch': 3.7}\n",
      "{'loss': 27.625, 'learning_rate': 4.227e-06, 'epoch': 3.71}\n",
      "{'loss': 27.875, 'learning_rate': 4.226e-06, 'epoch': 3.71}\n",
      "{'loss': 28.875, 'learning_rate': 4.225e-06, 'epoch': 3.71}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/frog/Code/NLP/NLP_source_code/GenerativeAI/Generative-AI-with-LLMs-main/Week-2/Lab_2_fine_tune_generative_ai_model.ipynb Cell 34\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/GenerativeAI/Generative-AI-with-LLMs-main/Week-2/Lab_2_fine_tune_generative_ai_model.ipynb#Y226sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/anaconda3/envs/learning_dl/lib/python3.11/site-packages/transformers/trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1554\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1555\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1556\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1557\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1558\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1559\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1560\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/learning_dl/lib/python3.11/site-packages/transformers/trainer.py:1837\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1834\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m   1836\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1837\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1839\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1840\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1841\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1842\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1843\u001b[0m ):\n\u001b[1;32m   1844\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1845\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/anaconda3/envs/learning_dl/lib/python3.11/site-packages/transformers/trainer.py:2693\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2691\u001b[0m         scaled_loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m   2692\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2693\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccelerator\u001b[39m.\u001b[39;49mbackward(loss)\n\u001b[1;32m   2695\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mdetach() \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m~/anaconda3/envs/learning_dl/lib/python3.11/site-packages/accelerate/accelerator.py:1853\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1851\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mscale(loss)\u001b[39m.\u001b[39mbackward(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1852\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1853\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/learning_dl/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/learning_dl/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSI1MCIgdmlld0JveD0iMCAwIDgwMCA1MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxkZWZzPgogICAgICAgIDxsaW5lYXJHcmFkaWVudCBpZD0iZmFkZUdyYWRpZW50IiB4MT0iMCIgeDI9IjEiPgogICAgICAgICAgICA8c3RvcCBvZmZzZXQ9IjAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIi8+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMTAwJSIgc3RvcC1jb2xvcj0iI0YwRjBGMCIgc3RvcC1vcGFjaXR5PSIwIi8+CiAgICAgICAgPC9saW5lYXJHcmFkaWVudD4KICAgICAgICA8bWFzayBpZD0iZmFkZU1hc2siPgogICAgICAgICAgICA8cmVjdCB4PSIwIiB5PSIwIiB3aWR0aD0iNzUwIiBoZWlnaHQ9IjUwIiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSI1MCIgZmlsbD0idXJsKCNmYWRlR3JhZGllbnQpIi8+CiAgICAgICAgPC9tYXNrPgogICAgPC9kZWZzPgogICAgPHBhdGggZD0iTTI1LDUwIFEwLDUwIDAsMjUgTDUwLDMgTDk3LDI1IEw3OTcsMjUgTDc5Nyw1MCBMMjUsNTAgWiIgZmlsbD0iI0YwRjBGMCIgc3Ryb2tlPSIjRTBFMEUwIiBzdHJva2Utd2lkdGg9IjEiIG1hc2s9InVybCgjZmFkZU1hc2spIi8+Cjwvc3ZnPgo=\" alt=\"Time alert close\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a fully fine-tuned version of the model would take a few hours on a GPU. To save time, download a checkpoint of the fully fine-tuned model to use in the rest of this notebook. This fully fine-tuned model will also be referred to as the **instruct model** in this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./dialogue-summary-training-1695137377'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./dialogue-summary-training-1695137377/tokenizer_config.json',\n",
       " './dialogue-summary-training-1695137377/special_tokens_map.json',\n",
       " './dialogue-summary-training-1695137377/tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "zsh:1: command not found: aws\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive s3://dlai-generative-ai/models/flan-dialogue-summary-checkpoint/ ./flan-dialogue-summary-checkpoint/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The size of the downloaded instruct model is approximately 1GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 945M May 15 10:25 ./flan-dialogue-summary-checkpoint/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "!ls -alh ./flan-dialogue-summary-checkpoint/pytorch_model.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Create an instance of the `AutoModelForSeq2SeqLM` class for the instruct model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruct_model = AutoModelForSeq2SeqLM.from_pretrained(output_dir, torch_dtype=torch.bfloat16)\n",
    "# instruct_model = AutoModelForSeq2SeqLM.from_pretrained(\"./flan-dialogue-summary-checkpoint\", torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2.3'></a>\n",
    "### 2.3 - Evaluate the Model Qualitatively (Human Evaluation)\n",
    "\n",
    "As with many GenAI applications, a qualitative approach where you ask yourself the question \"Is my model behaving the way it is supposed to?\" is usually a good starting point. In the example below (the same one we started this notebook with), you can see how the fine-tuned model is able to create a reasonable summary of the dialogue compared to the original inability to understand what is being asked of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = 200\n",
    "dialogue = dataset['test'][index]['dialogue']\n",
    "human_baseline_summary = dataset['test'][index]['summary']\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "original_model = original_model.to(device)\n",
    "instruct_model = instruct_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model_outputs = original_model.generate(input_ids=input_ids.to(device), generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
    "original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "instruct_model_outputs = instruct_model.generate(input_ids=input_ids.to(device), generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
    "instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "ORIGINAL MODEL:\n",
      "#Person1#: Have you considered upgrading your system?\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INSTRUCT MODEL:\n",
      "You might want to upgrade your computer.\n"
     ]
    }
   ],
   "source": [
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{human_baseline_summary}')\n",
    "print(dash_line)\n",
    "print(f'ORIGINAL MODEL:\\n{original_model_text_output}')\n",
    "print(dash_line)\n",
    "print(f'INSTRUCT MODEL:\\n{instruct_model_text_output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2.4'></a>\n",
    "### 2.4 - Evaluate the Model Quantitatively (with ROUGE Metric)\n",
    "\n",
    "The [ROUGE metric](https://en.wikipedia.org/wiki/ROUGE_(metric)) helps quantify the validity of summarizations produced by models. It compares summarizations to a \"baseline\" summary which is usually created by a human. While not perfect, it does indicate the overall increase in summarization effectiveness that we have accomplished by fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the outputs for the sample of the test dataset (only 10 dialogues and summaries to save time), and save the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human_baseline_summaries</th>\n",
       "      <th>original_model_summaries</th>\n",
       "      <th>instruct_model_summaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ms. Dawson helps #Person1# to write a memo to ...</td>\n",
       "      <td>Employees are required to use the \"Insert Mess...</td>\n",
       "      <td>This memo is to be distributed to all employee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In order to prevent employees from wasting tim...</td>\n",
       "      <td>New policy on instant messaging.</td>\n",
       "      <td>This memo is to be distributed to all employee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ms. Dawson takes a dictation for #Person1# abo...</td>\n",
       "      <td>The memo will be distributed to all employees ...</td>\n",
       "      <td>This memo is to be distributed to all employee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Person2# arrives late because of traffic jam....</td>\n",
       "      <td>I'm not sure why you're so upset about the tra...</td>\n",
       "      <td>Taking public transport to work is a good idea.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Person2# decides to follow #Person1#'s sugges...</td>\n",
       "      <td>I'm a car-less person.</td>\n",
       "      <td>Taking public transport to work is a good idea.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#Person2# complains to #Person1# about the tra...</td>\n",
       "      <td>The new driver is a shady driver who is a bit ...</td>\n",
       "      <td>Taking public transport to work is a good idea.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#Person1# tells Kate that Masha and Hero get d...</td>\n",
       "      <td>Masha and Hero are getting divorced.</td>\n",
       "      <td>Masha and Hero are getting divorced.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#Person1# tells Kate that Masha and Hero are g...</td>\n",
       "      <td>Masha and Hero are getting a divorce.</td>\n",
       "      <td>Masha and Hero are getting divorced.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>#Person1# and Kate talk about the divorce betw...</td>\n",
       "      <td>Masha and Hero are getting divorced.</td>\n",
       "      <td>Masha and Hero are getting divorced.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#Person1# and Brian are at the birthday party ...</td>\n",
       "      <td>Brian's birthday is coming up.</td>\n",
       "      <td>Brian's birthday is coming up.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            human_baseline_summaries  \\\n",
       "0  Ms. Dawson helps #Person1# to write a memo to ...   \n",
       "1  In order to prevent employees from wasting tim...   \n",
       "2  Ms. Dawson takes a dictation for #Person1# abo...   \n",
       "3  #Person2# arrives late because of traffic jam....   \n",
       "4  #Person2# decides to follow #Person1#'s sugges...   \n",
       "5  #Person2# complains to #Person1# about the tra...   \n",
       "6  #Person1# tells Kate that Masha and Hero get d...   \n",
       "7  #Person1# tells Kate that Masha and Hero are g...   \n",
       "8  #Person1# and Kate talk about the divorce betw...   \n",
       "9  #Person1# and Brian are at the birthday party ...   \n",
       "\n",
       "                            original_model_summaries  \\\n",
       "0  Employees are required to use the \"Insert Mess...   \n",
       "1                   New policy on instant messaging.   \n",
       "2  The memo will be distributed to all employees ...   \n",
       "3  I'm not sure why you're so upset about the tra...   \n",
       "4                             I'm a car-less person.   \n",
       "5  The new driver is a shady driver who is a bit ...   \n",
       "6               Masha and Hero are getting divorced.   \n",
       "7              Masha and Hero are getting a divorce.   \n",
       "8               Masha and Hero are getting divorced.   \n",
       "9                     Brian's birthday is coming up.   \n",
       "\n",
       "                            instruct_model_summaries  \n",
       "0  This memo is to be distributed to all employee...  \n",
       "1  This memo is to be distributed to all employee...  \n",
       "2  This memo is to be distributed to all employee...  \n",
       "3    Taking public transport to work is a good idea.  \n",
       "4    Taking public transport to work is a good idea.  \n",
       "5    Taking public transport to work is a good idea.  \n",
       "6               Masha and Hero are getting divorced.  \n",
       "7               Masha and Hero are getting divorced.  \n",
       "8               Masha and Hero are getting divorced.  \n",
       "9                     Brian's birthday is coming up.  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogues = dataset['test'][0:10]['dialogue']\n",
    "human_baseline_summaries = dataset['test'][0:10]['summary']\n",
    "\n",
    "original_model_summaries = []\n",
    "instruct_model_summaries = []\n",
    "\n",
    "for _, dialogue in enumerate(dialogues):\n",
    "    prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "Summary: \"\"\"\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "    original_model_outputs = original_model.generate(input_ids=input_ids.to(device), generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
    "    original_model_summaries.append(original_model_text_output)\n",
    "\n",
    "    instruct_model_outputs = instruct_model.generate(input_ids=input_ids.to(device), generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
    "    instruct_model_summaries.append(instruct_model_text_output)\n",
    "    \n",
    "zipped_summaries = list(zip(human_baseline_summaries, original_model_summaries, instruct_model_summaries))\n",
    " \n",
    "df = pd.DataFrame(zipped_summaries, columns = ['human_baseline_summaries', 'original_model_summaries', 'instruct_model_summaries'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Evaluate the models computing ROUGE metrics. Notice the improvement in the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL MODEL:\n",
      "{'rouge1': 0.23843426316468674, 'rouge2': 0.09537366980845242, 'rougeL': 0.20206132540022143, 'rougeLsum': 0.2058183263035638}\n",
      "INSTRUCT MODEL:\n",
      "{'rouge1': 0.28647748040489973, 'rouge2': 0.13497482028216662, 'rougeL': 0.23619027925479535, 'rougeLsum': 0.23930701616185485}\n"
     ]
    }
   ],
   "source": [
    "original_model_results = rouge.compute(\n",
    "    predictions=original_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "instruct_model_results = rouge.compute(\n",
    "    predictions=instruct_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(instruct_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "print('ORIGINAL MODEL:')\n",
    "print(original_model_results)\n",
    "print('INSTRUCT MODEL:')\n",
    "print(instruct_model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `data/dialogue-summary-training-results.csv` contains a pre-populated list of all model results which you can use to evaluate on a larger section of data. Let's do that for each of the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL MODEL:\n",
      "{'rouge1': 0.2334158581572823, 'rouge2': 0.07603964187010573, 'rougeL': 0.20145520923859048, 'rougeLsum': 0.20145899339006135}\n",
      "INSTRUCT MODEL:\n",
      "{'rouge1': 0.42161291557556113, 'rouge2': 0.18035380596301792, 'rougeL': 0.3384439349963909, 'rougeLsum': 0.33835653595561666}\n"
     ]
    }
   ],
   "source": [
    "results = pd.read_csv(\"data/dialogue-summary-training-results.csv\")\n",
    "\n",
    "human_baseline_summaries = results['human_baseline_summaries'].values\n",
    "original_model_summaries = results['original_model_summaries'].values\n",
    "instruct_model_summaries = results['instruct_model_summaries'].values\n",
    "\n",
    "original_model_results = rouge.compute(\n",
    "    predictions=original_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "instruct_model_results = rouge.compute(\n",
    "    predictions=instruct_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(instruct_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "print('ORIGINAL MODEL:')\n",
    "print(original_model_results)\n",
    "print('INSTRUCT MODEL:')\n",
    "print(instruct_model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The results show substantial improvement in all ROUGE metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute percentage improvement of INSTRUCT MODEL over HUMAN BASELINE\n",
      "rouge1: 18.82%\n",
      "rouge2: 10.43%\n",
      "rougeL: 13.70%\n",
      "rougeLsum: 13.69%\n"
     ]
    }
   ],
   "source": [
    "print(\"Absolute percentage improvement of INSTRUCT MODEL over HUMAN BASELINE\")\n",
    "\n",
    "improvement = (np.array(list(instruct_model_results.values())) - np.array(list(original_model_results.values())))\n",
    "for key, value in zip(instruct_model_results.keys(), improvement):\n",
    "    print(f'{key}: {value*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Perform Parameter Efficient Fine-Tuning (PEFT)\n",
    "\n",
    "Now, let's perform **Parameter Efficient Fine-Tuning (PEFT)** fine-tuning as opposed to \"full fine-tuning\" as you did above. PEFT is a form of instruction fine-tuning that is much more efficient than full fine-tuning - with comparable evaluation results as you will see soon. \n",
    "\n",
    "PEFT is a generic term that includes **Low-Rank Adaptation (LoRA)** and prompt tuning (which is NOT THE SAME as prompt engineering!). In most cases, when someone says PEFT, they typically mean LoRA. LoRA, at a very high level, allows the user to fine-tune their model using fewer compute resources (in some cases, a single GPU). After fine-tuning for a specific task, use case, or tenant with LoRA, the result is that the original LLM remains unchanged and a newly-trained LoRA adapter emerges. This LoRA adapter is much, much smaller than the original LLM - on the order of a single-digit % of the original LLM size (MBs vs GBs).  \n",
    "\n",
    "That said, at inference time, the LoRA adapter needs to be reunited and combined with its original LLM to serve the inference request.  The benefit, however, is that many LoRA adapters can re-use the original LLM which reduces overall memory requirements when serving multiple tasks and use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.1'></a>\n",
    "### 3.1 - Setup the PEFT/LoRA model for Fine-Tuning\n",
    "\n",
    "You need to set up the PEFT/LoRA model for fine-tuning with a new layer/parameter adapter. Using PEFT/LoRA, you are freezing the underlying LLM and only training the adapter. Have a look at the LoRA configuration below. Note the rank (`r`) hyper-parameter, which defines the rank/dimension of the adapter to be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32, # Rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM # FLAN-T5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Add LoRA adapter layers/parameters to the original LLM to be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 3538944\n",
      "all model parameters: 251116800\n",
      "percentage of trainable model parameters: 1.41%\n"
     ]
    }
   ],
   "source": [
    "peft_model = get_peft_model(original_model, \n",
    "                            lora_config)\n",
    "print(print_number_of_trainable_model_parameters(peft_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name='3.2'></a>\n",
    "### 3.2 - Train PEFT Adapter\n",
    "\n",
    "Define training arguments and create `Trainer` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = f'./peft-dialogue-summary-training-{str(int(time.time()))}'\n",
    "\n",
    "peft_training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    auto_find_batch_size=True,\n",
    "    learning_rate=1e-3, # Higher learning rate than full fine-tuning.\n",
    "    num_train_epochs=1,\n",
    "    logging_steps=1,\n",
    "    max_steps=1000   \n",
    ")\n",
    "    \n",
    "peft_trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=peft_training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now everything is ready to train the PEFT adapter and save the model.\n",
    "\n",
    "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSIxMjUiIHZpZXdCb3g9IjAgMCA4MDAgMTI1IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogICAgPGRlZnM+CiAgICAgICAgPGxpbmVhckdyYWRpZW50IGlkPSJmYWRlR3JhZGllbnQiIHgxPSIwIiB4Mj0iMSI+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMCUiIHN0b3AtY29sb3I9IiNGMEYwRjAiLz4KICAgICAgICAgICAgPHN0b3Agb2Zmc2V0PSIxMDAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIiBzdG9wLW9wYWNpdHk9IjAiLz4KICAgICAgICA8L2xpbmVhckdyYWRpZW50PgogICAgICAgIDxtYXNrIGlkPSJmYWRlTWFzayI+CiAgICAgICAgICAgIDxyZWN0IHg9IjAiIHk9IjAiIHdpZHRoPSI3NTAiIGhlaWdodD0iMTI1IiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSIxMjUiIGZpbGw9InVybCgjZmFkZUdyYWRpZW50KSIvPgogICAgICAgIDwvbWFzaz4KICAgIDwvZGVmcz4KICAgIDxwYXRoIGQ9Ik0zLDUwIEE1MCw1MCAwIDAgMSA1MywzIEw3OTcsMyBMNzk3LDk3IEw5Nyw5NyBMNTAsMTE1IEwzLDk3IFoiIGZpbGw9IiNGMEYwRjAiIHN0cm9rZT0iI0UwRTBFMCIgc3Ryb2tlLXdpZHRoPSIxIiBtYXNrPSJ1cmwoI2ZhZGVNYXNrKSIvPgogICAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgcj0iMzAiIGZpbGw9IiM1N2M0ZjgiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIxIi8+CiAgICA8Y2lyY2xlIGN4PSI1MCIgY3k9IjUwIiByPSIyNSIgZmlsbD0iI0YwRjBGMCIvPgogICAgPGxpbmUgeDE9IjUwIiB5MT0iNTAiIHgyPSI1MCIgeTI9IjMwIiBzdHJva2U9IiM1N2M0ZjgiIHN0cm9rZS13aWR0aD0iMyIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIi8+CiAgICA8bGluZSB4MT0iNTAiIHkxPSI1MCIgeDI9IjY1IiB5Mj0iNTAiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIzIiBzdHJva2UtbGluZWNhcD0icm91bmQiLz4KICAgIDx0ZXh0IHg9IjEwMCIgeT0iMzQiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIxNCIgZmlsbD0iIzMzMzMzMyI+VGhlIG5leHQgY2VsbCBtYXkgdGFrZSBhIGZldyBtaW51dGVzIHRvIHJ1bi48L3RleHQ+Cjwvc3ZnPgo=\" alt=\"Time alert open medium\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a97cee6c15de451cbd19c6bcf0d4b033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 26.375, 'learning_rate': 0.0009999, 'epoch': 0.0}\n",
      "{'loss': 26.0, 'learning_rate': 0.0009998000000000001, 'epoch': 0.0}\n",
      "{'loss': 24.875, 'learning_rate': 0.0009997, 'epoch': 0.0}\n",
      "{'loss': 20.875, 'learning_rate': 0.0009996, 'epoch': 0.0}\n",
      "{'loss': 17.5, 'learning_rate': 0.0009995000000000002, 'epoch': 0.0}\n",
      "{'loss': 14.75, 'learning_rate': 0.0009994, 'epoch': 0.0}\n",
      "{'loss': 13.0625, 'learning_rate': 0.0009993, 'epoch': 0.0}\n",
      "{'loss': 8.8125, 'learning_rate': 0.0009992, 'epoch': 0.01}\n",
      "{'loss': 6.2188, 'learning_rate': 0.0009991, 'epoch': 0.01}\n",
      "{'loss': 5.4062, 'learning_rate': 0.000999, 'epoch': 0.01}\n",
      "{'loss': 5.8125, 'learning_rate': 0.0009989, 'epoch': 0.01}\n",
      "{'loss': 4.75, 'learning_rate': 0.0009988, 'epoch': 0.01}\n",
      "{'loss': 4.5625, 'learning_rate': 0.0009987000000000002, 'epoch': 0.01}\n",
      "{'loss': 4.5, 'learning_rate': 0.0009986, 'epoch': 0.01}\n",
      "{'loss': 4.4062, 'learning_rate': 0.0009985, 'epoch': 0.01}\n",
      "{'loss': 4.3438, 'learning_rate': 0.0009984, 'epoch': 0.01}\n",
      "{'loss': 4.2188, 'learning_rate': 0.0009983, 'epoch': 0.01}\n",
      "{'loss': 4.5625, 'learning_rate': 0.0009982, 'epoch': 0.01}\n",
      "{'loss': 4.1875, 'learning_rate': 0.0009981, 'epoch': 0.01}\n",
      "{'loss': 3.9688, 'learning_rate': 0.000998, 'epoch': 0.01}\n",
      "{'loss': 3.7969, 'learning_rate': 0.0009979000000000001, 'epoch': 0.01}\n",
      "{'loss': 3.5938, 'learning_rate': 0.0009978, 'epoch': 0.01}\n",
      "{'loss': 3.3906, 'learning_rate': 0.0009977, 'epoch': 0.01}\n",
      "{'loss': 3.1094, 'learning_rate': 0.0009976, 'epoch': 0.02}\n",
      "{'loss': 2.9688, 'learning_rate': 0.0009975000000000001, 'epoch': 0.02}\n",
      "{'loss': 2.7656, 'learning_rate': 0.0009974, 'epoch': 0.02}\n",
      "{'loss': 2.75, 'learning_rate': 0.0009973, 'epoch': 0.02}\n",
      "{'loss': 2.4219, 'learning_rate': 0.0009972, 'epoch': 0.02}\n",
      "{'loss': 2.2188, 'learning_rate': 0.0009971000000000001, 'epoch': 0.02}\n",
      "{'loss': 2.1719, 'learning_rate': 0.000997, 'epoch': 0.02}\n",
      "{'loss': 2.0312, 'learning_rate': 0.0009969, 'epoch': 0.02}\n",
      "{'loss': 1.7656, 'learning_rate': 0.0009968, 'epoch': 0.02}\n",
      "{'loss': 1.8125, 'learning_rate': 0.0009967, 'epoch': 0.02}\n",
      "{'loss': 1.5391, 'learning_rate': 0.0009966, 'epoch': 0.02}\n",
      "{'loss': 1.7344, 'learning_rate': 0.0009965, 'epoch': 0.02}\n",
      "{'loss': 1.2188, 'learning_rate': 0.0009964, 'epoch': 0.02}\n",
      "{'loss': 1.1484, 'learning_rate': 0.0009962999999999999, 'epoch': 0.02}\n",
      "{'loss': 1.0469, 'learning_rate': 0.0009962, 'epoch': 0.02}\n",
      "{'loss': 0.9531, 'learning_rate': 0.0009961, 'epoch': 0.03}\n",
      "{'loss': 0.8672, 'learning_rate': 0.000996, 'epoch': 0.03}\n",
      "{'loss': 0.7773, 'learning_rate': 0.0009959, 'epoch': 0.03}\n",
      "{'loss': 0.7461, 'learning_rate': 0.0009958, 'epoch': 0.03}\n",
      "{'loss': 0.6992, 'learning_rate': 0.0009957, 'epoch': 0.03}\n",
      "{'loss': 0.6367, 'learning_rate': 0.0009956000000000001, 'epoch': 0.03}\n",
      "{'loss': 0.6172, 'learning_rate': 0.0009955, 'epoch': 0.03}\n",
      "{'loss': 0.5625, 'learning_rate': 0.0009954, 'epoch': 0.03}\n",
      "{'loss': 0.5156, 'learning_rate': 0.0009953, 'epoch': 0.03}\n",
      "{'loss': 0.4941, 'learning_rate': 0.0009952, 'epoch': 0.03}\n",
      "{'loss': 0.4727, 'learning_rate': 0.0009951, 'epoch': 0.03}\n",
      "{'loss': 0.4258, 'learning_rate': 0.000995, 'epoch': 0.03}\n",
      "{'loss': 0.418, 'learning_rate': 0.0009949, 'epoch': 0.03}\n",
      "{'loss': 0.3984, 'learning_rate': 0.0009948000000000001, 'epoch': 0.03}\n",
      "{'loss': 0.5156, 'learning_rate': 0.0009947, 'epoch': 0.03}\n",
      "{'loss': 0.4062, 'learning_rate': 0.0009946, 'epoch': 0.03}\n",
      "{'loss': 0.4043, 'learning_rate': 0.0009945000000000002, 'epoch': 0.04}\n",
      "{'loss': 0.4023, 'learning_rate': 0.0009943999999999999, 'epoch': 0.04}\n",
      "{'loss': 0.3262, 'learning_rate': 0.0009943, 'epoch': 0.04}\n",
      "{'loss': 0.3184, 'learning_rate': 0.0009942, 'epoch': 0.04}\n",
      "{'loss': 0.3125, 'learning_rate': 0.0009941, 'epoch': 0.04}\n",
      "{'loss': 0.3105, 'learning_rate': 0.000994, 'epoch': 0.04}\n",
      "{'loss': 0.3613, 'learning_rate': 0.0009939, 'epoch': 0.04}\n",
      "{'loss': 0.2891, 'learning_rate': 0.0009938, 'epoch': 0.04}\n",
      "{'loss': 0.2812, 'learning_rate': 0.0009937000000000001, 'epoch': 0.04}\n",
      "{'loss': 0.5391, 'learning_rate': 0.0009936, 'epoch': 0.04}\n",
      "{'loss': 0.2246, 'learning_rate': 0.0009935, 'epoch': 0.04}\n",
      "{'loss': 0.3887, 'learning_rate': 0.0009934, 'epoch': 0.04}\n",
      "{'loss': 0.252, 'learning_rate': 0.0009933, 'epoch': 0.04}\n",
      "{'loss': 0.2598, 'learning_rate': 0.0009932, 'epoch': 0.04}\n",
      "{'loss': 0.25, 'learning_rate': 0.0009931, 'epoch': 0.04}\n",
      "{'loss': 0.2295, 'learning_rate': 0.000993, 'epoch': 0.04}\n",
      "{'loss': 0.2539, 'learning_rate': 0.0009929000000000001, 'epoch': 0.05}\n",
      "{'loss': 0.2178, 'learning_rate': 0.0009928, 'epoch': 0.05}\n",
      "{'loss': 0.1836, 'learning_rate': 0.0009927, 'epoch': 0.05}\n",
      "{'loss': 0.2432, 'learning_rate': 0.0009926000000000002, 'epoch': 0.05}\n",
      "{'loss': 0.2637, 'learning_rate': 0.0009925000000000001, 'epoch': 0.05}\n",
      "{'loss': 0.2373, 'learning_rate': 0.0009924, 'epoch': 0.05}\n",
      "{'loss': 0.2754, 'learning_rate': 0.0009923, 'epoch': 0.05}\n",
      "{'loss': 0.2285, 'learning_rate': 0.0009922, 'epoch': 0.05}\n",
      "{'loss': 0.3145, 'learning_rate': 0.0009921, 'epoch': 0.05}\n",
      "{'loss': 0.3203, 'learning_rate': 0.000992, 'epoch': 0.05}\n",
      "{'loss': 0.2158, 'learning_rate': 0.0009919, 'epoch': 0.05}\n",
      "{'loss': 0.1826, 'learning_rate': 0.0009918, 'epoch': 0.05}\n",
      "{'loss': 0.2852, 'learning_rate': 0.0009917, 'epoch': 0.05}\n",
      "{'loss': 0.252, 'learning_rate': 0.0009916, 'epoch': 0.05}\n",
      "{'loss': 0.2168, 'learning_rate': 0.0009915, 'epoch': 0.05}\n",
      "{'loss': 0.2139, 'learning_rate': 0.0009914, 'epoch': 0.06}\n",
      "{'loss': 0.2207, 'learning_rate': 0.0009913, 'epoch': 0.06}\n",
      "{'loss': 0.2773, 'learning_rate': 0.0009912, 'epoch': 0.06}\n",
      "{'loss': 0.2354, 'learning_rate': 0.0009911, 'epoch': 0.06}\n",
      "{'loss': 0.2539, 'learning_rate': 0.000991, 'epoch': 0.06}\n",
      "{'loss': 0.2559, 'learning_rate': 0.0009909, 'epoch': 0.06}\n",
      "{'loss': 0.2715, 'learning_rate': 0.0009908, 'epoch': 0.06}\n",
      "{'loss': 0.3125, 'learning_rate': 0.0009907, 'epoch': 0.06}\n",
      "{'loss': 0.4121, 'learning_rate': 0.0009906000000000001, 'epoch': 0.06}\n",
      "{'loss': 0.2891, 'learning_rate': 0.0009905, 'epoch': 0.06}\n",
      "{'loss': 0.3164, 'learning_rate': 0.0009904, 'epoch': 0.06}\n",
      "{'loss': 0.3496, 'learning_rate': 0.0009903, 'epoch': 0.06}\n",
      "{'loss': 0.4043, 'learning_rate': 0.0009901999999999999, 'epoch': 0.06}\n",
      "{'loss': 0.3379, 'learning_rate': 0.0009901, 'epoch': 0.06}\n",
      "{'loss': 0.1992, 'learning_rate': 0.00099, 'epoch': 0.06}\n",
      "{'loss': 0.2734, 'learning_rate': 0.0009899, 'epoch': 0.06}\n",
      "{'loss': 0.3066, 'learning_rate': 0.0009898, 'epoch': 0.07}\n",
      "{'loss': 0.2471, 'learning_rate': 0.0009897, 'epoch': 0.07}\n",
      "{'loss': 0.3945, 'learning_rate': 0.0009896, 'epoch': 0.07}\n",
      "{'loss': 0.2695, 'learning_rate': 0.0009895000000000001, 'epoch': 0.07}\n",
      "{'loss': 0.25, 'learning_rate': 0.0009893999999999999, 'epoch': 0.07}\n",
      "{'loss': 0.2891, 'learning_rate': 0.0009893, 'epoch': 0.07}\n",
      "{'loss': 0.2129, 'learning_rate': 0.0009892, 'epoch': 0.07}\n",
      "{'loss': 0.2539, 'learning_rate': 0.0009891, 'epoch': 0.07}\n",
      "{'loss': 0.1758, 'learning_rate': 0.000989, 'epoch': 0.07}\n",
      "{'loss': 0.3066, 'learning_rate': 0.0009889, 'epoch': 0.07}\n",
      "{'loss': 0.1943, 'learning_rate': 0.0009888, 'epoch': 0.07}\n",
      "{'loss': 0.3418, 'learning_rate': 0.0009887000000000001, 'epoch': 0.07}\n",
      "{'loss': 0.1982, 'learning_rate': 0.0009886, 'epoch': 0.07}\n",
      "{'loss': 0.2236, 'learning_rate': 0.0009885, 'epoch': 0.07}\n",
      "{'loss': 0.2793, 'learning_rate': 0.0009884, 'epoch': 0.07}\n",
      "{'loss': 0.1943, 'learning_rate': 0.0009883, 'epoch': 0.08}\n",
      "{'loss': 0.3086, 'learning_rate': 0.0009882, 'epoch': 0.08}\n",
      "{'loss': 0.2109, 'learning_rate': 0.0009881, 'epoch': 0.08}\n",
      "{'loss': 0.2021, 'learning_rate': 0.000988, 'epoch': 0.08}\n",
      "{'loss': 0.1826, 'learning_rate': 0.0009879, 'epoch': 0.08}\n",
      "{'loss': 0.1895, 'learning_rate': 0.0009878, 'epoch': 0.08}\n",
      "{'loss': 0.2002, 'learning_rate': 0.0009877, 'epoch': 0.08}\n",
      "{'loss': 0.249, 'learning_rate': 0.0009876000000000002, 'epoch': 0.08}\n",
      "{'loss': 0.2051, 'learning_rate': 0.0009875, 'epoch': 0.08}\n",
      "{'loss': 0.1982, 'learning_rate': 0.0009874, 'epoch': 0.08}\n",
      "{'loss': 0.1787, 'learning_rate': 0.0009873, 'epoch': 0.08}\n",
      "{'loss': 0.1846, 'learning_rate': 0.0009872, 'epoch': 0.08}\n",
      "{'loss': 0.1924, 'learning_rate': 0.0009871, 'epoch': 0.08}\n",
      "{'loss': 0.1895, 'learning_rate': 0.000987, 'epoch': 0.08}\n",
      "{'loss': 0.1758, 'learning_rate': 0.0009869, 'epoch': 0.08}\n",
      "{'loss': 0.1592, 'learning_rate': 0.0009868000000000001, 'epoch': 0.08}\n",
      "{'loss': 0.1582, 'learning_rate': 0.0009867, 'epoch': 0.09}\n",
      "{'loss': 0.1816, 'learning_rate': 0.0009866, 'epoch': 0.09}\n",
      "{'loss': 0.2021, 'learning_rate': 0.0009865, 'epoch': 0.09}\n",
      "{'loss': 0.1602, 'learning_rate': 0.0009864000000000001, 'epoch': 0.09}\n",
      "{'loss': 0.1582, 'learning_rate': 0.0009863, 'epoch': 0.09}\n",
      "{'loss': 0.2949, 'learning_rate': 0.0009862, 'epoch': 0.09}\n",
      "{'loss': 0.1699, 'learning_rate': 0.0009861, 'epoch': 0.09}\n",
      "{'loss': 0.2139, 'learning_rate': 0.0009860000000000001, 'epoch': 0.09}\n",
      "{'loss': 0.1504, 'learning_rate': 0.0009859, 'epoch': 0.09}\n",
      "{'loss': 0.1777, 'learning_rate': 0.0009858, 'epoch': 0.09}\n",
      "{'loss': 0.1797, 'learning_rate': 0.0009857, 'epoch': 0.09}\n",
      "{'loss': 0.1729, 'learning_rate': 0.0009856, 'epoch': 0.09}\n",
      "{'loss': 0.1226, 'learning_rate': 0.0009855, 'epoch': 0.09}\n",
      "{'loss': 0.1436, 'learning_rate': 0.0009854, 'epoch': 0.09}\n",
      "{'loss': 0.1709, 'learning_rate': 0.0009853, 'epoch': 0.09}\n",
      "{'loss': 0.1973, 'learning_rate': 0.0009851999999999999, 'epoch': 0.09}\n",
      "{'loss': 0.168, 'learning_rate': 0.0009851, 'epoch': 0.1}\n",
      "{'loss': 0.1484, 'learning_rate': 0.000985, 'epoch': 0.1}\n",
      "{'loss': 0.166, 'learning_rate': 0.0009849, 'epoch': 0.1}\n",
      "{'loss': 0.1719, 'learning_rate': 0.0009848, 'epoch': 0.1}\n",
      "{'loss': 0.1738, 'learning_rate': 0.0009847, 'epoch': 0.1}\n",
      "{'loss': 0.2715, 'learning_rate': 0.0009846, 'epoch': 0.1}\n",
      "{'loss': 0.1514, 'learning_rate': 0.0009845000000000001, 'epoch': 0.1}\n",
      "{'loss': 0.1953, 'learning_rate': 0.0009844, 'epoch': 0.1}\n",
      "{'loss': 0.1797, 'learning_rate': 0.0009843, 'epoch': 0.1}\n",
      "{'loss': 0.1963, 'learning_rate': 0.0009842, 'epoch': 0.1}\n",
      "{'loss': 0.1426, 'learning_rate': 0.0009841, 'epoch': 0.1}\n",
      "{'loss': 0.1621, 'learning_rate': 0.000984, 'epoch': 0.1}\n",
      "{'loss': 0.1924, 'learning_rate': 0.0009839, 'epoch': 0.1}\n",
      "{'loss': 0.2354, 'learning_rate': 0.0009838, 'epoch': 0.1}\n",
      "{'loss': 0.2139, 'learning_rate': 0.0009837000000000001, 'epoch': 0.1}\n",
      "{'loss': 0.1504, 'learning_rate': 0.0009836, 'epoch': 0.11}\n",
      "{'loss': 0.1934, 'learning_rate': 0.0009835, 'epoch': 0.11}\n",
      "{'loss': 0.1846, 'learning_rate': 0.0009834000000000002, 'epoch': 0.11}\n",
      "{'loss': 0.1582, 'learning_rate': 0.0009832999999999999, 'epoch': 0.11}\n",
      "{'loss': 0.1895, 'learning_rate': 0.0009832, 'epoch': 0.11}\n",
      "{'loss': 0.1504, 'learning_rate': 0.0009831, 'epoch': 0.11}\n",
      "{'loss': 0.1387, 'learning_rate': 0.000983, 'epoch': 0.11}\n",
      "{'loss': 0.1377, 'learning_rate': 0.0009829, 'epoch': 0.11}\n",
      "{'loss': 0.1504, 'learning_rate': 0.0009828, 'epoch': 0.11}\n",
      "{'loss': 0.2158, 'learning_rate': 0.0009827, 'epoch': 0.11}\n",
      "{'loss': 0.1992, 'learning_rate': 0.0009826000000000001, 'epoch': 0.11}\n",
      "{'loss': 0.2002, 'learning_rate': 0.0009825, 'epoch': 0.11}\n",
      "{'loss': 0.1982, 'learning_rate': 0.0009824, 'epoch': 0.11}\n",
      "{'loss': 0.1797, 'learning_rate': 0.0009823, 'epoch': 0.11}\n",
      "{'loss': 0.1216, 'learning_rate': 0.0009822, 'epoch': 0.11}\n",
      "{'loss': 0.2275, 'learning_rate': 0.0009821, 'epoch': 0.11}\n",
      "{'loss': 0.1836, 'learning_rate': 0.000982, 'epoch': 0.12}\n",
      "{'loss': 0.1621, 'learning_rate': 0.0009819, 'epoch': 0.12}\n",
      "{'loss': 0.2021, 'learning_rate': 0.0009818000000000001, 'epoch': 0.12}\n",
      "{'loss': 0.1475, 'learning_rate': 0.0009817, 'epoch': 0.12}\n",
      "{'loss': 0.1641, 'learning_rate': 0.0009816, 'epoch': 0.12}\n",
      "{'loss': 0.1992, 'learning_rate': 0.0009815000000000002, 'epoch': 0.12}\n",
      "{'loss': 0.1406, 'learning_rate': 0.0009814000000000001, 'epoch': 0.12}\n",
      "{'loss': 0.1562, 'learning_rate': 0.0009813, 'epoch': 0.12}\n",
      "{'loss': 0.2256, 'learning_rate': 0.0009812, 'epoch': 0.12}\n",
      "{'loss': 0.1875, 'learning_rate': 0.0009811, 'epoch': 0.12}\n",
      "{'loss': 0.1426, 'learning_rate': 0.000981, 'epoch': 0.12}\n",
      "{'loss': 0.1885, 'learning_rate': 0.0009809, 'epoch': 0.12}\n",
      "{'loss': 0.1992, 'learning_rate': 0.0009808, 'epoch': 0.12}\n",
      "{'loss': 0.1748, 'learning_rate': 0.0009807, 'epoch': 0.12}\n",
      "{'loss': 0.1787, 'learning_rate': 0.0009806, 'epoch': 0.12}\n",
      "{'loss': 0.1348, 'learning_rate': 0.0009805, 'epoch': 0.13}\n",
      "{'loss': 0.1426, 'learning_rate': 0.0009804, 'epoch': 0.13}\n",
      "{'loss': 0.1738, 'learning_rate': 0.0009803, 'epoch': 0.13}\n",
      "{'loss': 0.1177, 'learning_rate': 0.0009802, 'epoch': 0.13}\n",
      "{'loss': 0.1357, 'learning_rate': 0.0009801, 'epoch': 0.13}\n",
      "{'loss': 0.1602, 'learning_rate': 0.00098, 'epoch': 0.13}\n",
      "{'loss': 0.1543, 'learning_rate': 0.0009799, 'epoch': 0.13}\n",
      "{'loss': 0.1514, 'learning_rate': 0.0009798, 'epoch': 0.13}\n",
      "{'loss': 0.1865, 'learning_rate': 0.0009797, 'epoch': 0.13}\n",
      "{'loss': 0.127, 'learning_rate': 0.0009796, 'epoch': 0.13}\n",
      "{'loss': 0.1553, 'learning_rate': 0.0009795000000000001, 'epoch': 0.13}\n",
      "{'loss': 0.2041, 'learning_rate': 0.0009794, 'epoch': 0.13}\n",
      "{'loss': 0.1338, 'learning_rate': 0.0009793, 'epoch': 0.13}\n",
      "{'loss': 0.1797, 'learning_rate': 0.0009792, 'epoch': 0.13}\n",
      "{'loss': 0.1226, 'learning_rate': 0.0009791, 'epoch': 0.13}\n",
      "{'loss': 0.1582, 'learning_rate': 0.000979, 'epoch': 0.13}\n",
      "{'loss': 0.1367, 'learning_rate': 0.0009789, 'epoch': 0.14}\n",
      "{'loss': 0.1865, 'learning_rate': 0.0009788, 'epoch': 0.14}\n",
      "{'loss': 0.1729, 'learning_rate': 0.0009787, 'epoch': 0.14}\n",
      "{'loss': 0.1631, 'learning_rate': 0.0009786, 'epoch': 0.14}\n",
      "{'loss': 0.1318, 'learning_rate': 0.0009785, 'epoch': 0.14}\n",
      "{'loss': 0.1543, 'learning_rate': 0.0009784000000000001, 'epoch': 0.14}\n",
      "{'loss': 0.2266, 'learning_rate': 0.0009782999999999999, 'epoch': 0.14}\n",
      "{'loss': 0.1758, 'learning_rate': 0.0009782, 'epoch': 0.14}\n",
      "{'loss': 0.166, 'learning_rate': 0.0009781, 'epoch': 0.14}\n",
      "{'loss': 0.1201, 'learning_rate': 0.000978, 'epoch': 0.14}\n",
      "{'loss': 0.1387, 'learning_rate': 0.0009779, 'epoch': 0.14}\n",
      "{'loss': 0.1221, 'learning_rate': 0.0009778, 'epoch': 0.14}\n",
      "{'loss': 0.124, 'learning_rate': 0.0009777, 'epoch': 0.14}\n",
      "{'loss': 0.1631, 'learning_rate': 0.0009776000000000001, 'epoch': 0.14}\n",
      "{'loss': 0.165, 'learning_rate': 0.0009775, 'epoch': 0.14}\n",
      "{'loss': 0.1826, 'learning_rate': 0.0009774, 'epoch': 0.15}\n",
      "{'loss': 0.125, 'learning_rate': 0.0009773, 'epoch': 0.15}\n",
      "{'loss': 0.1396, 'learning_rate': 0.0009772, 'epoch': 0.15}\n",
      "{'loss': 0.1436, 'learning_rate': 0.0009771, 'epoch': 0.15}\n",
      "{'loss': 0.1504, 'learning_rate': 0.000977, 'epoch': 0.15}\n",
      "{'loss': 0.1553, 'learning_rate': 0.0009769, 'epoch': 0.15}\n",
      "{'loss': 0.1572, 'learning_rate': 0.0009768, 'epoch': 0.15}\n",
      "{'loss': 0.1147, 'learning_rate': 0.0009767, 'epoch': 0.15}\n",
      "{'loss': 0.1455, 'learning_rate': 0.0009766, 'epoch': 0.15}\n",
      "{'loss': 0.1318, 'learning_rate': 0.0009765, 'epoch': 0.15}\n",
      "{'loss': 0.165, 'learning_rate': 0.0009764000000000001, 'epoch': 0.15}\n",
      "{'loss': 0.1318, 'learning_rate': 0.0009762999999999999, 'epoch': 0.15}\n",
      "{'loss': 0.1826, 'learning_rate': 0.0009762, 'epoch': 0.15}\n",
      "{'loss': 0.1387, 'learning_rate': 0.0009761, 'epoch': 0.15}\n",
      "{'loss': 0.168, 'learning_rate': 0.000976, 'epoch': 0.15}\n",
      "{'loss': 0.1348, 'learning_rate': 0.0009759, 'epoch': 0.15}\n",
      "{'loss': 0.1445, 'learning_rate': 0.0009758, 'epoch': 0.16}\n",
      "{'loss': 0.1729, 'learning_rate': 0.0009757, 'epoch': 0.16}\n",
      "{'loss': 0.1562, 'learning_rate': 0.0009756000000000001, 'epoch': 0.16}\n",
      "{'loss': 0.1768, 'learning_rate': 0.0009755, 'epoch': 0.16}\n",
      "{'loss': 0.126, 'learning_rate': 0.0009754000000000001, 'epoch': 0.16}\n",
      "{'loss': 0.084, 'learning_rate': 0.0009753, 'epoch': 0.16}\n",
      "{'loss': 0.1484, 'learning_rate': 0.0009752, 'epoch': 0.16}\n",
      "{'loss': 0.127, 'learning_rate': 0.0009751, 'epoch': 0.16}\n",
      "{'loss': 0.1279, 'learning_rate': 0.000975, 'epoch': 0.16}\n",
      "{'loss': 0.1689, 'learning_rate': 0.0009749, 'epoch': 0.16}\n",
      "{'loss': 0.208, 'learning_rate': 0.0009748000000000001, 'epoch': 0.16}\n",
      "{'loss': 0.1367, 'learning_rate': 0.0009747, 'epoch': 0.16}\n",
      "{'loss': 0.167, 'learning_rate': 0.0009746, 'epoch': 0.16}\n",
      "{'loss': 0.1396, 'learning_rate': 0.0009745000000000001, 'epoch': 0.16}\n",
      "{'loss': 0.1582, 'learning_rate': 0.0009744, 'epoch': 0.16}\n",
      "{'loss': 0.1572, 'learning_rate': 0.0009743000000000001, 'epoch': 0.16}\n",
      "{'loss': 0.2051, 'learning_rate': 0.0009741999999999999, 'epoch': 0.17}\n",
      "{'loss': 0.2002, 'learning_rate': 0.0009741, 'epoch': 0.17}\n",
      "{'loss': 0.1357, 'learning_rate': 0.000974, 'epoch': 0.17}\n",
      "{'loss': 0.1523, 'learning_rate': 0.0009739, 'epoch': 0.17}\n",
      "{'loss': 0.1465, 'learning_rate': 0.0009738, 'epoch': 0.17}\n",
      "{'loss': 0.1465, 'learning_rate': 0.0009737, 'epoch': 0.17}\n",
      "{'loss': 0.1445, 'learning_rate': 0.0009736, 'epoch': 0.17}\n",
      "{'loss': 0.1621, 'learning_rate': 0.0009735000000000001, 'epoch': 0.17}\n",
      "{'loss': 0.1465, 'learning_rate': 0.0009734, 'epoch': 0.17}\n",
      "{'loss': 0.167, 'learning_rate': 0.0009733000000000001, 'epoch': 0.17}\n",
      "{'loss': 0.1309, 'learning_rate': 0.0009732, 'epoch': 0.17}\n",
      "{'loss': 0.1475, 'learning_rate': 0.0009731, 'epoch': 0.17}\n",
      "{'loss': 0.1484, 'learning_rate': 0.000973, 'epoch': 0.17}\n",
      "{'loss': 0.1245, 'learning_rate': 0.0009729, 'epoch': 0.17}\n",
      "{'loss': 0.1357, 'learning_rate': 0.0009728, 'epoch': 0.17}\n",
      "{'loss': 0.165, 'learning_rate': 0.0009727000000000001, 'epoch': 0.18}\n",
      "{'loss': 0.1357, 'learning_rate': 0.0009726, 'epoch': 0.18}\n",
      "{'loss': 0.1543, 'learning_rate': 0.0009725000000000001, 'epoch': 0.18}\n",
      "{'loss': 0.1445, 'learning_rate': 0.0009724000000000001, 'epoch': 0.18}\n",
      "{'loss': 0.1426, 'learning_rate': 0.0009723, 'epoch': 0.18}\n",
      "{'loss': 0.1245, 'learning_rate': 0.0009722, 'epoch': 0.18}\n",
      "{'loss': 0.1484, 'learning_rate': 0.0009720999999999999, 'epoch': 0.18}\n",
      "{'loss': 0.1494, 'learning_rate': 0.000972, 'epoch': 0.18}\n",
      "{'loss': 0.1426, 'learning_rate': 0.0009719, 'epoch': 0.18}\n",
      "{'loss': 0.1758, 'learning_rate': 0.0009718, 'epoch': 0.18}\n",
      "{'loss': 0.104, 'learning_rate': 0.0009717, 'epoch': 0.18}\n",
      "{'loss': 0.1572, 'learning_rate': 0.0009716000000000001, 'epoch': 0.18}\n",
      "{'loss': 0.1484, 'learning_rate': 0.0009715, 'epoch': 0.18}\n",
      "{'loss': 0.127, 'learning_rate': 0.0009714000000000001, 'epoch': 0.18}\n",
      "{'loss': 0.1235, 'learning_rate': 0.0009713, 'epoch': 0.18}\n",
      "{'loss': 0.1357, 'learning_rate': 0.0009712, 'epoch': 0.18}\n",
      "{'loss': 0.1699, 'learning_rate': 0.0009711, 'epoch': 0.19}\n",
      "{'loss': 0.1387, 'learning_rate': 0.000971, 'epoch': 0.19}\n",
      "{'loss': 0.1553, 'learning_rate': 0.0009709, 'epoch': 0.19}\n",
      "{'loss': 0.1514, 'learning_rate': 0.0009708000000000001, 'epoch': 0.19}\n",
      "{'loss': 0.1299, 'learning_rate': 0.0009707, 'epoch': 0.19}\n",
      "{'loss': 0.166, 'learning_rate': 0.0009706000000000001, 'epoch': 0.19}\n",
      "{'loss': 0.1465, 'learning_rate': 0.0009705, 'epoch': 0.19}\n",
      "{'loss': 0.123, 'learning_rate': 0.0009704000000000001, 'epoch': 0.19}\n",
      "{'loss': 0.1494, 'learning_rate': 0.0009703000000000001, 'epoch': 0.19}\n",
      "{'loss': 0.1475, 'learning_rate': 0.0009702, 'epoch': 0.19}\n",
      "{'loss': 0.1484, 'learning_rate': 0.0009701, 'epoch': 0.19}\n",
      "{'loss': 0.1719, 'learning_rate': 0.0009699999999999999, 'epoch': 0.19}\n",
      "{'loss': 0.1484, 'learning_rate': 0.0009699, 'epoch': 0.19}\n",
      "{'loss': 0.0996, 'learning_rate': 0.0009698, 'epoch': 0.19}\n",
      "{'loss': 0.1328, 'learning_rate': 0.0009697, 'epoch': 0.19}\n",
      "{'loss': 0.1406, 'learning_rate': 0.0009696, 'epoch': 0.2}\n",
      "{'loss': 0.1289, 'learning_rate': 0.0009695000000000001, 'epoch': 0.2}\n",
      "{'loss': 0.1387, 'learning_rate': 0.0009694, 'epoch': 0.2}\n",
      "{'loss': 0.1338, 'learning_rate': 0.0009693000000000001, 'epoch': 0.2}\n",
      "{'loss': 0.1758, 'learning_rate': 0.0009691999999999999, 'epoch': 0.2}\n",
      "{'loss': 0.1309, 'learning_rate': 0.0009691, 'epoch': 0.2}\n",
      "{'loss': 0.106, 'learning_rate': 0.000969, 'epoch': 0.2}\n",
      "{'loss': 0.1631, 'learning_rate': 0.0009689, 'epoch': 0.2}\n",
      "{'loss': 0.1611, 'learning_rate': 0.0009688, 'epoch': 0.2}\n",
      "{'loss': 0.123, 'learning_rate': 0.0009687000000000001, 'epoch': 0.2}\n",
      "{'loss': 0.1338, 'learning_rate': 0.0009686, 'epoch': 0.2}\n",
      "{'loss': 0.1309, 'learning_rate': 0.0009685000000000001, 'epoch': 0.2}\n",
      "{'loss': 0.1348, 'learning_rate': 0.0009684, 'epoch': 0.2}\n",
      "{'loss': 0.1348, 'learning_rate': 0.0009683000000000001, 'epoch': 0.2}\n",
      "{'loss': 0.1455, 'learning_rate': 0.0009682, 'epoch': 0.2}\n",
      "{'loss': 0.1572, 'learning_rate': 0.0009681, 'epoch': 0.2}\n",
      "{'loss': 0.127, 'learning_rate': 0.000968, 'epoch': 0.21}\n",
      "{'loss': 0.1455, 'learning_rate': 0.0009679, 'epoch': 0.21}\n",
      "{'loss': 0.1157, 'learning_rate': 0.0009678, 'epoch': 0.21}\n",
      "{'loss': 0.123, 'learning_rate': 0.0009677, 'epoch': 0.21}\n",
      "{'loss': 0.1475, 'learning_rate': 0.0009676, 'epoch': 0.21}\n",
      "{'loss': 0.1235, 'learning_rate': 0.0009675, 'epoch': 0.21}\n",
      "{'loss': 0.1226, 'learning_rate': 0.0009674000000000001, 'epoch': 0.21}\n",
      "{'loss': 0.1235, 'learning_rate': 0.0009673, 'epoch': 0.21}\n",
      "{'loss': 0.1455, 'learning_rate': 0.0009672, 'epoch': 0.21}\n",
      "{'loss': 0.1914, 'learning_rate': 0.0009670999999999999, 'epoch': 0.21}\n",
      "{'loss': 0.165, 'learning_rate': 0.000967, 'epoch': 0.21}\n",
      "{'loss': 0.1426, 'learning_rate': 0.0009669, 'epoch': 0.21}\n",
      "{'loss': 0.1021, 'learning_rate': 0.0009668, 'epoch': 0.21}\n",
      "{'loss': 0.1001, 'learning_rate': 0.0009667, 'epoch': 0.21}\n",
      "{'loss': 0.1172, 'learning_rate': 0.0009666000000000001, 'epoch': 0.21}\n",
      "{'loss': 0.1357, 'learning_rate': 0.0009665, 'epoch': 0.22}\n",
      "{'loss': 0.1147, 'learning_rate': 0.0009664000000000001, 'epoch': 0.22}\n",
      "{'loss': 0.1533, 'learning_rate': 0.0009663, 'epoch': 0.22}\n",
      "{'loss': 0.1436, 'learning_rate': 0.0009662, 'epoch': 0.22}\n",
      "{'loss': 0.1396, 'learning_rate': 0.0009661, 'epoch': 0.22}\n",
      "{'loss': 0.1074, 'learning_rate': 0.000966, 'epoch': 0.22}\n",
      "{'loss': 0.165, 'learning_rate': 0.0009659, 'epoch': 0.22}\n",
      "{'loss': 0.124, 'learning_rate': 0.0009658000000000001, 'epoch': 0.22}\n",
      "{'loss': 0.1367, 'learning_rate': 0.0009657, 'epoch': 0.22}\n",
      "{'loss': 0.1611, 'learning_rate': 0.0009656, 'epoch': 0.22}\n",
      "{'loss': 0.1172, 'learning_rate': 0.0009655, 'epoch': 0.22}\n",
      "{'loss': 0.165, 'learning_rate': 0.0009654, 'epoch': 0.22}\n",
      "{'loss': 0.1367, 'learning_rate': 0.0009653000000000001, 'epoch': 0.22}\n",
      "{'loss': 0.1631, 'learning_rate': 0.0009651999999999999, 'epoch': 0.22}\n",
      "{'loss': 0.1152, 'learning_rate': 0.0009651, 'epoch': 0.22}\n",
      "{'loss': 0.1465, 'learning_rate': 0.000965, 'epoch': 0.22}\n",
      "{'loss': 0.1289, 'learning_rate': 0.0009649, 'epoch': 0.23}\n",
      "{'loss': 0.125, 'learning_rate': 0.0009648, 'epoch': 0.23}\n",
      "{'loss': 0.1953, 'learning_rate': 0.0009647, 'epoch': 0.23}\n",
      "{'loss': 0.1758, 'learning_rate': 0.0009646, 'epoch': 0.23}\n",
      "{'loss': 0.1045, 'learning_rate': 0.0009645000000000001, 'epoch': 0.23}\n",
      "{'loss': 0.1396, 'learning_rate': 0.0009644, 'epoch': 0.23}\n",
      "{'loss': 0.1196, 'learning_rate': 0.0009643000000000001, 'epoch': 0.23}\n",
      "{'loss': 0.1328, 'learning_rate': 0.0009642, 'epoch': 0.23}\n",
      "{'loss': 0.1299, 'learning_rate': 0.0009641, 'epoch': 0.23}\n",
      "{'loss': 0.1196, 'learning_rate': 0.000964, 'epoch': 0.23}\n",
      "{'loss': 0.1299, 'learning_rate': 0.0009639, 'epoch': 0.23}\n",
      "{'loss': 0.1328, 'learning_rate': 0.0009638, 'epoch': 0.23}\n",
      "{'loss': 0.127, 'learning_rate': 0.0009637000000000001, 'epoch': 0.23}\n",
      "{'loss': 0.165, 'learning_rate': 0.0009636, 'epoch': 0.23}\n",
      "{'loss': 0.1104, 'learning_rate': 0.0009635000000000001, 'epoch': 0.23}\n",
      "{'loss': 0.1445, 'learning_rate': 0.0009634000000000001, 'epoch': 0.23}\n",
      "{'loss': 0.1299, 'learning_rate': 0.0009633, 'epoch': 0.24}\n",
      "{'loss': 0.1157, 'learning_rate': 0.0009632, 'epoch': 0.24}\n",
      "{'loss': 0.1025, 'learning_rate': 0.0009630999999999999, 'epoch': 0.24}\n",
      "{'loss': 0.1885, 'learning_rate': 0.000963, 'epoch': 0.24}\n",
      "{'loss': 0.1172, 'learning_rate': 0.0009629, 'epoch': 0.24}\n",
      "{'loss': 0.1377, 'learning_rate': 0.0009628, 'epoch': 0.24}\n",
      "{'loss': 0.1699, 'learning_rate': 0.0009627, 'epoch': 0.24}\n",
      "{'loss': 0.1484, 'learning_rate': 0.0009626, 'epoch': 0.24}\n",
      "{'loss': 0.1138, 'learning_rate': 0.0009625, 'epoch': 0.24}\n",
      "{'loss': 0.1118, 'learning_rate': 0.0009624000000000001, 'epoch': 0.24}\n",
      "{'loss': 0.1357, 'learning_rate': 0.0009623, 'epoch': 0.24}\n",
      "{'loss': 0.1523, 'learning_rate': 0.0009622000000000001, 'epoch': 0.24}\n",
      "{'loss': 0.126, 'learning_rate': 0.0009621, 'epoch': 0.24}\n",
      "{'loss': 0.1138, 'learning_rate': 0.000962, 'epoch': 0.24}\n",
      "{'loss': 0.1514, 'learning_rate': 0.0009619, 'epoch': 0.24}\n",
      "{'loss': 0.0815, 'learning_rate': 0.0009618, 'epoch': 0.25}\n",
      "{'loss': 0.1279, 'learning_rate': 0.0009617, 'epoch': 0.25}\n",
      "{'loss': 0.1045, 'learning_rate': 0.0009616000000000001, 'epoch': 0.25}\n",
      "{'loss': 0.1299, 'learning_rate': 0.0009615, 'epoch': 0.25}\n",
      "{'loss': 0.127, 'learning_rate': 0.0009614000000000001, 'epoch': 0.25}\n",
      "{'loss': 0.1553, 'learning_rate': 0.0009613000000000001, 'epoch': 0.25}\n",
      "{'loss': 0.123, 'learning_rate': 0.0009612, 'epoch': 0.25}\n",
      "{'loss': 0.0972, 'learning_rate': 0.0009611, 'epoch': 0.25}\n",
      "{'loss': 0.1113, 'learning_rate': 0.0009609999999999999, 'epoch': 0.25}\n",
      "{'loss': 0.1035, 'learning_rate': 0.0009609, 'epoch': 0.25}\n",
      "{'loss': 0.1128, 'learning_rate': 0.0009608, 'epoch': 0.25}\n",
      "{'loss': 0.1318, 'learning_rate': 0.0009607, 'epoch': 0.25}\n",
      "{'loss': 0.1406, 'learning_rate': 0.0009606, 'epoch': 0.25}\n",
      "{'loss': 0.1206, 'learning_rate': 0.0009605000000000001, 'epoch': 0.25}\n",
      "{'loss': 0.1709, 'learning_rate': 0.0009604, 'epoch': 0.25}\n",
      "{'loss': 0.1377, 'learning_rate': 0.0009603000000000001, 'epoch': 0.25}\n",
      "{'loss': 0.1099, 'learning_rate': 0.0009602, 'epoch': 0.26}\n",
      "{'loss': 0.1455, 'learning_rate': 0.0009601, 'epoch': 0.26}\n",
      "{'loss': 0.1245, 'learning_rate': 0.00096, 'epoch': 0.26}\n",
      "{'loss': 0.1235, 'learning_rate': 0.0009599, 'epoch': 0.26}\n",
      "{'loss': 0.1621, 'learning_rate': 0.0009598, 'epoch': 0.26}\n",
      "{'loss': 0.1543, 'learning_rate': 0.0009597000000000001, 'epoch': 0.26}\n",
      "{'loss': 0.1211, 'learning_rate': 0.0009596, 'epoch': 0.26}\n",
      "{'loss': 0.1367, 'learning_rate': 0.0009595000000000001, 'epoch': 0.26}\n",
      "{'loss': 0.1533, 'learning_rate': 0.0009594, 'epoch': 0.26}\n",
      "{'loss': 0.1523, 'learning_rate': 0.0009593000000000001, 'epoch': 0.26}\n",
      "{'loss': 0.105, 'learning_rate': 0.0009592000000000001, 'epoch': 0.26}\n",
      "{'loss': 0.1123, 'learning_rate': 0.0009591, 'epoch': 0.26}\n",
      "{'loss': 0.1338, 'learning_rate': 0.000959, 'epoch': 0.26}\n",
      "{'loss': 0.0757, 'learning_rate': 0.0009588999999999999, 'epoch': 0.26}\n",
      "{'loss': 0.1187, 'learning_rate': 0.0009588, 'epoch': 0.26}\n",
      "{'loss': 0.1475, 'learning_rate': 0.0009587, 'epoch': 0.27}\n",
      "{'loss': 0.166, 'learning_rate': 0.0009586, 'epoch': 0.27}\n",
      "{'loss': 0.1309, 'learning_rate': 0.0009585, 'epoch': 0.27}\n",
      "{'loss': 0.1196, 'learning_rate': 0.0009584000000000001, 'epoch': 0.27}\n",
      "{'loss': 0.1182, 'learning_rate': 0.0009583, 'epoch': 0.27}\n",
      "{'loss': 0.1201, 'learning_rate': 0.0009582000000000001, 'epoch': 0.27}\n",
      "{'loss': 0.1475, 'learning_rate': 0.0009580999999999999, 'epoch': 0.27}\n",
      "{'loss': 0.1089, 'learning_rate': 0.000958, 'epoch': 0.27}\n",
      "{'loss': 0.1592, 'learning_rate': 0.0009579, 'epoch': 0.27}\n",
      "{'loss': 0.1455, 'learning_rate': 0.0009578, 'epoch': 0.27}\n",
      "{'loss': 0.1572, 'learning_rate': 0.0009577, 'epoch': 0.27}\n",
      "{'loss': 0.1235, 'learning_rate': 0.0009576000000000001, 'epoch': 0.27}\n",
      "{'loss': 0.1309, 'learning_rate': 0.0009575, 'epoch': 0.27}\n",
      "{'loss': 0.1377, 'learning_rate': 0.0009574000000000001, 'epoch': 0.27}\n",
      "{'loss': 0.2109, 'learning_rate': 0.0009573, 'epoch': 0.27}\n",
      "{'loss': 0.1396, 'learning_rate': 0.0009572000000000001, 'epoch': 0.27}\n",
      "{'loss': 0.1357, 'learning_rate': 0.0009571, 'epoch': 0.28}\n",
      "{'loss': 0.1309, 'learning_rate': 0.000957, 'epoch': 0.28}\n",
      "{'loss': 0.1187, 'learning_rate': 0.0009569, 'epoch': 0.28}\n",
      "{'loss': 0.126, 'learning_rate': 0.0009568000000000001, 'epoch': 0.28}\n",
      "{'loss': 0.1289, 'learning_rate': 0.0009567, 'epoch': 0.28}\n",
      "{'loss': 0.1035, 'learning_rate': 0.0009566, 'epoch': 0.28}\n",
      "{'loss': 0.127, 'learning_rate': 0.0009565, 'epoch': 0.28}\n",
      "{'loss': 0.1177, 'learning_rate': 0.0009564, 'epoch': 0.28}\n",
      "{'loss': 0.1104, 'learning_rate': 0.0009563000000000001, 'epoch': 0.28}\n",
      "{'loss': 0.103, 'learning_rate': 0.0009562, 'epoch': 0.28}\n",
      "{'loss': 0.1357, 'learning_rate': 0.0009561, 'epoch': 0.28}\n",
      "{'loss': 0.1582, 'learning_rate': 0.0009559999999999999, 'epoch': 0.28}\n",
      "{'loss': 0.1309, 'learning_rate': 0.0009559, 'epoch': 0.28}\n",
      "{'loss': 0.105, 'learning_rate': 0.0009558, 'epoch': 0.28}\n",
      "{'loss': 0.127, 'learning_rate': 0.0009557, 'epoch': 0.28}\n",
      "{'loss': 0.124, 'learning_rate': 0.0009556, 'epoch': 0.28}\n",
      "{'loss': 0.1758, 'learning_rate': 0.0009555000000000001, 'epoch': 0.29}\n",
      "{'loss': 0.1133, 'learning_rate': 0.0009554, 'epoch': 0.29}\n",
      "{'loss': 0.1836, 'learning_rate': 0.0009553000000000001, 'epoch': 0.29}\n",
      "{'loss': 0.127, 'learning_rate': 0.0009552, 'epoch': 0.29}\n",
      "{'loss': 0.1099, 'learning_rate': 0.0009551, 'epoch': 0.29}\n",
      "{'loss': 0.1699, 'learning_rate': 0.000955, 'epoch': 0.29}\n",
      "{'loss': 0.0981, 'learning_rate': 0.0009549, 'epoch': 0.29}\n",
      "{'loss': 0.1079, 'learning_rate': 0.0009548, 'epoch': 0.29}\n",
      "{'loss': 0.1475, 'learning_rate': 0.0009547000000000001, 'epoch': 0.29}\n",
      "{'loss': 0.1592, 'learning_rate': 0.0009546, 'epoch': 0.29}\n",
      "{'loss': 0.1406, 'learning_rate': 0.0009545, 'epoch': 0.29}\n",
      "{'loss': 0.1484, 'learning_rate': 0.0009544, 'epoch': 0.29}\n",
      "{'loss': 0.1299, 'learning_rate': 0.0009543, 'epoch': 0.29}\n",
      "{'loss': 0.1494, 'learning_rate': 0.0009542000000000001, 'epoch': 0.29}\n",
      "{'loss': 0.0811, 'learning_rate': 0.0009540999999999999, 'epoch': 0.29}\n",
      "{'loss': 0.1543, 'learning_rate': 0.000954, 'epoch': 0.3}\n",
      "{'loss': 0.1147, 'learning_rate': 0.0009539, 'epoch': 0.3}\n",
      "{'loss': 0.0986, 'learning_rate': 0.0009538, 'epoch': 0.3}\n",
      "{'loss': 0.123, 'learning_rate': 0.0009537, 'epoch': 0.3}\n",
      "{'loss': 0.1084, 'learning_rate': 0.0009536, 'epoch': 0.3}\n",
      "{'loss': 0.1099, 'learning_rate': 0.0009535, 'epoch': 0.3}\n",
      "{'loss': 0.1191, 'learning_rate': 0.0009534000000000001, 'epoch': 0.3}\n",
      "{'loss': 0.1426, 'learning_rate': 0.0009533, 'epoch': 0.3}\n",
      "{'loss': 0.1055, 'learning_rate': 0.0009532000000000001, 'epoch': 0.3}\n",
      "{'loss': 0.1177, 'learning_rate': 0.0009531, 'epoch': 0.3}\n",
      "{'loss': 0.1338, 'learning_rate': 0.000953, 'epoch': 0.3}\n",
      "{'loss': 0.1289, 'learning_rate': 0.0009529, 'epoch': 0.3}\n",
      "{'loss': 0.1621, 'learning_rate': 0.0009528, 'epoch': 0.3}\n",
      "{'loss': 0.1113, 'learning_rate': 0.0009527, 'epoch': 0.3}\n",
      "{'loss': 0.1338, 'learning_rate': 0.0009526000000000001, 'epoch': 0.3}\n",
      "{'loss': 0.1543, 'learning_rate': 0.0009525, 'epoch': 0.3}\n",
      "{'loss': 0.1079, 'learning_rate': 0.0009524000000000001, 'epoch': 0.31}\n",
      "{'loss': 0.1045, 'learning_rate': 0.0009523000000000001, 'epoch': 0.31}\n",
      "{'loss': 0.1367, 'learning_rate': 0.0009522, 'epoch': 0.31}\n",
      "{'loss': 0.1318, 'learning_rate': 0.0009521, 'epoch': 0.31}\n",
      "{'loss': 0.1235, 'learning_rate': 0.0009519999999999999, 'epoch': 0.31}\n",
      "{'loss': 0.1357, 'learning_rate': 0.0009519, 'epoch': 0.31}\n",
      "{'loss': 0.1328, 'learning_rate': 0.0009518, 'epoch': 0.31}\n",
      "{'loss': 0.1426, 'learning_rate': 0.0009517, 'epoch': 0.31}\n",
      "{'loss': 0.1582, 'learning_rate': 0.0009516, 'epoch': 0.31}\n",
      "{'loss': 0.1147, 'learning_rate': 0.0009515, 'epoch': 0.31}\n",
      "{'loss': 0.1162, 'learning_rate': 0.0009514, 'epoch': 0.31}\n",
      "{'loss': 0.1494, 'learning_rate': 0.0009513000000000001, 'epoch': 0.31}\n",
      "{'loss': 0.1191, 'learning_rate': 0.0009512, 'epoch': 0.31}\n",
      "{'loss': 0.127, 'learning_rate': 0.0009511, 'epoch': 0.31}\n",
      "{'loss': 0.126, 'learning_rate': 0.000951, 'epoch': 0.31}\n",
      "{'loss': 0.0972, 'learning_rate': 0.0009509, 'epoch': 0.32}\n",
      "{'loss': 0.1113, 'learning_rate': 0.0009508, 'epoch': 0.32}\n",
      "{'loss': 0.1157, 'learning_rate': 0.0009507, 'epoch': 0.32}\n",
      "{'loss': 0.1523, 'learning_rate': 0.0009506, 'epoch': 0.32}\n",
      "{'loss': 0.1465, 'learning_rate': 0.0009505000000000001, 'epoch': 0.32}\n",
      "{'loss': 0.1289, 'learning_rate': 0.0009504, 'epoch': 0.32}\n",
      "{'loss': 0.1177, 'learning_rate': 0.0009503000000000001, 'epoch': 0.32}\n",
      "{'loss': 0.1445, 'learning_rate': 0.0009502000000000001, 'epoch': 0.32}\n",
      "{'loss': 0.1641, 'learning_rate': 0.0009501, 'epoch': 0.32}\n",
      "{'loss': 0.1406, 'learning_rate': 0.00095, 'epoch': 0.32}\n",
      "{'loss': 0.1328, 'learning_rate': 0.0009498999999999999, 'epoch': 0.32}\n",
      "{'loss': 0.1357, 'learning_rate': 0.0009498, 'epoch': 0.32}\n",
      "{'loss': 0.1182, 'learning_rate': 0.0009497, 'epoch': 0.32}\n",
      "{'loss': 0.1084, 'learning_rate': 0.0009496, 'epoch': 0.32}\n",
      "{'loss': 0.1572, 'learning_rate': 0.0009495, 'epoch': 0.32}\n",
      "{'loss': 0.1143, 'learning_rate': 0.0009494000000000001, 'epoch': 0.32}\n",
      "{'loss': 0.126, 'learning_rate': 0.0009493, 'epoch': 0.33}\n",
      "{'loss': 0.1328, 'learning_rate': 0.0009492000000000001, 'epoch': 0.33}\n",
      "{'loss': 0.126, 'learning_rate': 0.0009491, 'epoch': 0.33}\n",
      "{'loss': 0.1465, 'learning_rate': 0.000949, 'epoch': 0.33}\n",
      "{'loss': 0.1289, 'learning_rate': 0.0009489, 'epoch': 0.33}\n",
      "{'loss': 0.1348, 'learning_rate': 0.0009488, 'epoch': 0.33}\n",
      "{'loss': 0.1465, 'learning_rate': 0.0009487, 'epoch': 0.33}\n",
      "{'loss': 0.1226, 'learning_rate': 0.0009486000000000001, 'epoch': 0.33}\n",
      "{'loss': 0.1235, 'learning_rate': 0.0009485, 'epoch': 0.33}\n",
      "{'loss': 0.1387, 'learning_rate': 0.0009484000000000001, 'epoch': 0.33}\n",
      "{'loss': 0.1475, 'learning_rate': 0.0009483, 'epoch': 0.33}\n",
      "{'loss': 0.1533, 'learning_rate': 0.0009482000000000001, 'epoch': 0.33}\n",
      "{'loss': 0.1592, 'learning_rate': 0.0009481000000000001, 'epoch': 0.33}\n",
      "{'loss': 0.1377, 'learning_rate': 0.000948, 'epoch': 0.33}\n",
      "{'loss': 0.1074, 'learning_rate': 0.0009479, 'epoch': 0.33}\n",
      "{'loss': 0.1416, 'learning_rate': 0.0009477999999999999, 'epoch': 0.34}\n",
      "{'loss': 0.1113, 'learning_rate': 0.0009477, 'epoch': 0.34}\n",
      "{'loss': 0.168, 'learning_rate': 0.0009476, 'epoch': 0.34}\n",
      "{'loss': 0.1216, 'learning_rate': 0.0009475, 'epoch': 0.34}\n",
      "{'loss': 0.1494, 'learning_rate': 0.0009474, 'epoch': 0.34}\n",
      "{'loss': 0.1201, 'learning_rate': 0.0009473000000000001, 'epoch': 0.34}\n",
      "{'loss': 0.0898, 'learning_rate': 0.0009472, 'epoch': 0.34}\n",
      "{'loss': 0.0981, 'learning_rate': 0.0009471000000000001, 'epoch': 0.34}\n",
      "{'loss': 0.1328, 'learning_rate': 0.0009469999999999999, 'epoch': 0.34}\n",
      "{'loss': 0.1328, 'learning_rate': 0.0009469, 'epoch': 0.34}\n",
      "{'loss': 0.1245, 'learning_rate': 0.0009468, 'epoch': 0.34}\n",
      "{'loss': 0.1187, 'learning_rate': 0.0009467, 'epoch': 0.34}\n",
      "{'loss': 0.1167, 'learning_rate': 0.0009466, 'epoch': 0.34}\n",
      "{'loss': 0.1074, 'learning_rate': 0.0009465000000000001, 'epoch': 0.34}\n",
      "{'loss': 0.103, 'learning_rate': 0.0009464, 'epoch': 0.34}\n",
      "{'loss': 0.1182, 'learning_rate': 0.0009463000000000001, 'epoch': 0.34}\n",
      "{'loss': 0.0898, 'learning_rate': 0.0009462, 'epoch': 0.35}\n",
      "{'loss': 0.104, 'learning_rate': 0.0009461000000000001, 'epoch': 0.35}\n",
      "{'loss': 0.1475, 'learning_rate': 0.000946, 'epoch': 0.35}\n",
      "{'loss': 0.0947, 'learning_rate': 0.0009459, 'epoch': 0.35}\n",
      "{'loss': 0.0913, 'learning_rate': 0.0009458, 'epoch': 0.35}\n",
      "{'loss': 0.0903, 'learning_rate': 0.0009457000000000001, 'epoch': 0.35}\n",
      "{'loss': 0.1553, 'learning_rate': 0.0009456, 'epoch': 0.35}\n",
      "{'loss': 0.0859, 'learning_rate': 0.0009455, 'epoch': 0.35}\n",
      "{'loss': 0.1309, 'learning_rate': 0.0009454, 'epoch': 0.35}\n",
      "{'loss': 0.1279, 'learning_rate': 0.0009453, 'epoch': 0.35}\n",
      "{'loss': 0.1533, 'learning_rate': 0.0009452000000000001, 'epoch': 0.35}\n",
      "{'loss': 0.1094, 'learning_rate': 0.0009451, 'epoch': 0.35}\n",
      "{'loss': 0.0991, 'learning_rate': 0.000945, 'epoch': 0.35}\n",
      "{'loss': 0.0981, 'learning_rate': 0.0009448999999999999, 'epoch': 0.35}\n",
      "{'loss': 0.1016, 'learning_rate': 0.0009448, 'epoch': 0.35}\n",
      "{'loss': 0.1201, 'learning_rate': 0.0009447, 'epoch': 0.35}\n",
      "{'loss': 0.1221, 'learning_rate': 0.0009446, 'epoch': 0.36}\n",
      "{'loss': 0.1396, 'learning_rate': 0.0009445, 'epoch': 0.36}\n",
      "{'loss': 0.1226, 'learning_rate': 0.0009444000000000001, 'epoch': 0.36}\n",
      "{'loss': 0.125, 'learning_rate': 0.0009443, 'epoch': 0.36}\n",
      "{'loss': 0.125, 'learning_rate': 0.0009442000000000001, 'epoch': 0.36}\n",
      "{'loss': 0.1699, 'learning_rate': 0.0009441, 'epoch': 0.36}\n",
      "{'loss': 0.127, 'learning_rate': 0.000944, 'epoch': 0.36}\n",
      "{'loss': 0.127, 'learning_rate': 0.0009439, 'epoch': 0.36}\n",
      "{'loss': 0.127, 'learning_rate': 0.0009438, 'epoch': 0.36}\n",
      "{'loss': 0.1729, 'learning_rate': 0.0009437, 'epoch': 0.36}\n",
      "{'loss': 0.1738, 'learning_rate': 0.0009436000000000001, 'epoch': 0.36}\n",
      "{'loss': 0.1436, 'learning_rate': 0.0009435, 'epoch': 0.36}\n",
      "{'loss': 0.1318, 'learning_rate': 0.0009434000000000001, 'epoch': 0.36}\n",
      "{'loss': 0.1436, 'learning_rate': 0.0009433, 'epoch': 0.36}\n",
      "{'loss': 0.1318, 'learning_rate': 0.0009432, 'epoch': 0.36}\n",
      "{'loss': 0.1299, 'learning_rate': 0.0009431000000000001, 'epoch': 0.37}\n",
      "{'loss': 0.1387, 'learning_rate': 0.0009429999999999999, 'epoch': 0.37}\n",
      "{'loss': 0.1152, 'learning_rate': 0.0009429, 'epoch': 0.37}\n",
      "{'loss': 0.1211, 'learning_rate': 0.0009428, 'epoch': 0.37}\n",
      "{'loss': 0.0996, 'learning_rate': 0.0009427, 'epoch': 0.37}\n",
      "{'loss': 0.125, 'learning_rate': 0.0009426, 'epoch': 0.37}\n",
      "{'loss': 0.0903, 'learning_rate': 0.0009425, 'epoch': 0.37}\n",
      "{'loss': 0.1152, 'learning_rate': 0.0009424, 'epoch': 0.37}\n",
      "{'loss': 0.1064, 'learning_rate': 0.0009423000000000001, 'epoch': 0.37}\n",
      "{'loss': 0.1123, 'learning_rate': 0.0009422, 'epoch': 0.37}\n",
      "{'loss': 0.1436, 'learning_rate': 0.0009421000000000001, 'epoch': 0.37}\n",
      "{'loss': 0.0957, 'learning_rate': 0.000942, 'epoch': 0.37}\n",
      "{'loss': 0.1787, 'learning_rate': 0.0009419, 'epoch': 0.37}\n",
      "{'loss': 0.1113, 'learning_rate': 0.0009418, 'epoch': 0.37}\n",
      "{'loss': 0.103, 'learning_rate': 0.0009417, 'epoch': 0.37}\n",
      "{'loss': 0.1348, 'learning_rate': 0.0009416, 'epoch': 0.37}\n",
      "{'loss': 0.1187, 'learning_rate': 0.0009415000000000001, 'epoch': 0.38}\n",
      "{'loss': 0.1377, 'learning_rate': 0.0009414, 'epoch': 0.38}\n",
      "{'loss': 0.1826, 'learning_rate': 0.0009413000000000001, 'epoch': 0.38}\n",
      "{'loss': 0.1152, 'learning_rate': 0.0009412000000000001, 'epoch': 0.38}\n",
      "{'loss': 0.124, 'learning_rate': 0.0009411, 'epoch': 0.38}\n",
      "{'loss': 0.1011, 'learning_rate': 0.000941, 'epoch': 0.38}\n",
      "{'loss': 0.1357, 'learning_rate': 0.0009408999999999999, 'epoch': 0.38}\n",
      "{'loss': 0.1216, 'learning_rate': 0.0009408, 'epoch': 0.38}\n",
      "{'loss': 0.0908, 'learning_rate': 0.0009407, 'epoch': 0.38}\n",
      "{'loss': 0.1094, 'learning_rate': 0.0009406, 'epoch': 0.38}\n",
      "{'loss': 0.1113, 'learning_rate': 0.0009405, 'epoch': 0.38}\n",
      "{'loss': 0.0903, 'learning_rate': 0.0009404, 'epoch': 0.38}\n",
      "{'loss': 0.127, 'learning_rate': 0.0009403, 'epoch': 0.38}\n",
      "{'loss': 0.1221, 'learning_rate': 0.0009402000000000001, 'epoch': 0.38}\n",
      "{'loss': 0.104, 'learning_rate': 0.0009401, 'epoch': 0.38}\n",
      "{'loss': 0.1182, 'learning_rate': 0.00094, 'epoch': 0.39}\n",
      "{'loss': 0.1406, 'learning_rate': 0.0009399, 'epoch': 0.39}\n",
      "{'loss': 0.1289, 'learning_rate': 0.0009398, 'epoch': 0.39}\n",
      "{'loss': 0.0933, 'learning_rate': 0.0009397, 'epoch': 0.39}\n",
      "{'loss': 0.1631, 'learning_rate': 0.0009396, 'epoch': 0.39}\n",
      "{'loss': 0.1318, 'learning_rate': 0.0009395, 'epoch': 0.39}\n",
      "{'loss': 0.1055, 'learning_rate': 0.0009394000000000001, 'epoch': 0.39}\n",
      "{'loss': 0.0986, 'learning_rate': 0.0009393, 'epoch': 0.39}\n",
      "{'loss': 0.1196, 'learning_rate': 0.0009392000000000001, 'epoch': 0.39}\n",
      "{'loss': 0.0981, 'learning_rate': 0.0009391000000000001, 'epoch': 0.39}\n",
      "{'loss': 0.1177, 'learning_rate': 0.000939, 'epoch': 0.39}\n",
      "{'loss': 0.127, 'learning_rate': 0.0009389, 'epoch': 0.39}\n",
      "{'loss': 0.1875, 'learning_rate': 0.0009387999999999999, 'epoch': 0.39}\n",
      "{'loss': 0.1357, 'learning_rate': 0.0009387, 'epoch': 0.39}\n",
      "{'loss': 0.1436, 'learning_rate': 0.0009386, 'epoch': 0.39}\n",
      "{'loss': 0.1367, 'learning_rate': 0.0009385, 'epoch': 0.39}\n",
      "{'loss': 0.0972, 'learning_rate': 0.0009384, 'epoch': 0.4}\n",
      "{'loss': 0.1396, 'learning_rate': 0.0009383000000000001, 'epoch': 0.4}\n",
      "{'loss': 0.2227, 'learning_rate': 0.0009382, 'epoch': 0.4}\n",
      "{'loss': 0.1162, 'learning_rate': 0.0009381000000000001, 'epoch': 0.4}\n",
      "{'loss': 0.1128, 'learning_rate': 0.0009379999999999999, 'epoch': 0.4}\n",
      "{'loss': 0.1235, 'learning_rate': 0.0009379, 'epoch': 0.4}\n",
      "{'loss': 0.1069, 'learning_rate': 0.0009378, 'epoch': 0.4}\n",
      "{'loss': 0.1167, 'learning_rate': 0.0009377, 'epoch': 0.4}\n",
      "{'loss': 0.1177, 'learning_rate': 0.0009376, 'epoch': 0.4}\n",
      "{'loss': 0.0894, 'learning_rate': 0.0009375, 'epoch': 0.4}\n",
      "{'loss': 0.1426, 'learning_rate': 0.0009374, 'epoch': 0.4}\n",
      "{'loss': 0.1147, 'learning_rate': 0.0009373000000000001, 'epoch': 0.4}\n",
      "{'loss': 0.1494, 'learning_rate': 0.0009372, 'epoch': 0.4}\n",
      "{'loss': 0.0762, 'learning_rate': 0.0009371000000000001, 'epoch': 0.4}\n",
      "{'loss': 0.1289, 'learning_rate': 0.0009370000000000001, 'epoch': 0.4}\n",
      "{'loss': 0.1621, 'learning_rate': 0.0009369, 'epoch': 0.41}\n",
      "{'loss': 0.127, 'learning_rate': 0.0009368, 'epoch': 0.41}\n",
      "{'loss': 0.1187, 'learning_rate': 0.0009367, 'epoch': 0.41}\n",
      "{'loss': 0.1172, 'learning_rate': 0.0009366, 'epoch': 0.41}\n",
      "{'loss': 0.1396, 'learning_rate': 0.0009365, 'epoch': 0.41}\n",
      "{'loss': 0.1582, 'learning_rate': 0.0009364, 'epoch': 0.41}\n",
      "{'loss': 0.125, 'learning_rate': 0.0009363, 'epoch': 0.41}\n",
      "{'loss': 0.1426, 'learning_rate': 0.0009362000000000001, 'epoch': 0.41}\n",
      "{'loss': 0.1426, 'learning_rate': 0.0009361, 'epoch': 0.41}\n",
      "{'loss': 0.1377, 'learning_rate': 0.0009360000000000001, 'epoch': 0.41}\n",
      "{'loss': 0.1416, 'learning_rate': 0.0009358999999999999, 'epoch': 0.41}\n",
      "{'loss': 0.1147, 'learning_rate': 0.0009358, 'epoch': 0.41}\n",
      "{'loss': 0.0859, 'learning_rate': 0.0009357, 'epoch': 0.41}\n",
      "{'loss': 0.1562, 'learning_rate': 0.0009356, 'epoch': 0.41}\n",
      "{'loss': 0.1309, 'learning_rate': 0.0009355, 'epoch': 0.41}\n",
      "{'loss': 0.1001, 'learning_rate': 0.0009354000000000001, 'epoch': 0.41}\n",
      "{'loss': 0.123, 'learning_rate': 0.0009353, 'epoch': 0.42}\n",
      "{'loss': 0.1182, 'learning_rate': 0.0009352000000000001, 'epoch': 0.42}\n",
      "{'loss': 0.1318, 'learning_rate': 0.0009351, 'epoch': 0.42}\n",
      "{'loss': 0.1089, 'learning_rate': 0.0009350000000000001, 'epoch': 0.42}\n",
      "{'loss': 0.1055, 'learning_rate': 0.0009349, 'epoch': 0.42}\n",
      "{'loss': 0.1211, 'learning_rate': 0.0009348, 'epoch': 0.42}\n",
      "{'loss': 0.1299, 'learning_rate': 0.0009347, 'epoch': 0.42}\n",
      "{'loss': 0.1416, 'learning_rate': 0.0009346000000000001, 'epoch': 0.42}\n",
      "{'loss': 0.1216, 'learning_rate': 0.0009345, 'epoch': 0.42}\n",
      "{'loss': 0.1055, 'learning_rate': 0.0009344, 'epoch': 0.42}\n",
      "{'loss': 0.1602, 'learning_rate': 0.0009343, 'epoch': 0.42}\n",
      "{'loss': 0.1118, 'learning_rate': 0.0009342, 'epoch': 0.42}\n",
      "{'loss': 0.1318, 'learning_rate': 0.0009341000000000001, 'epoch': 0.42}\n",
      "{'loss': 0.1572, 'learning_rate': 0.000934, 'epoch': 0.42}\n",
      "{'loss': 0.127, 'learning_rate': 0.0009339, 'epoch': 0.42}\n",
      "{'loss': 0.1338, 'learning_rate': 0.0009337999999999999, 'epoch': 0.42}\n",
      "{'loss': 0.1045, 'learning_rate': 0.0009337, 'epoch': 0.43}\n",
      "{'loss': 0.1621, 'learning_rate': 0.0009336, 'epoch': 0.43}\n",
      "{'loss': 0.1016, 'learning_rate': 0.0009335, 'epoch': 0.43}\n",
      "{'loss': 0.1143, 'learning_rate': 0.0009334, 'epoch': 0.43}\n",
      "{'loss': 0.1094, 'learning_rate': 0.0009333000000000001, 'epoch': 0.43}\n",
      "{'loss': 0.1289, 'learning_rate': 0.0009332, 'epoch': 0.43}\n",
      "{'loss': 0.1157, 'learning_rate': 0.0009331000000000001, 'epoch': 0.43}\n",
      "{'loss': 0.1187, 'learning_rate': 0.000933, 'epoch': 0.43}\n",
      "{'loss': 0.21, 'learning_rate': 0.0009329, 'epoch': 0.43}\n",
      "{'loss': 0.165, 'learning_rate': 0.0009328, 'epoch': 0.43}\n",
      "{'loss': 0.1318, 'learning_rate': 0.0009327, 'epoch': 0.43}\n",
      "{'loss': 0.0967, 'learning_rate': 0.0009326, 'epoch': 0.43}\n",
      "{'loss': 0.1177, 'learning_rate': 0.0009325000000000001, 'epoch': 0.43}\n",
      "{'loss': 0.1465, 'learning_rate': 0.0009324, 'epoch': 0.43}\n",
      "{'loss': 0.1631, 'learning_rate': 0.0009323000000000001, 'epoch': 0.43}\n",
      "{'loss': 0.125, 'learning_rate': 0.0009322, 'epoch': 0.44}\n",
      "{'loss': 0.1191, 'learning_rate': 0.0009321, 'epoch': 0.44}\n",
      "{'loss': 0.104, 'learning_rate': 0.0009320000000000001, 'epoch': 0.44}\n",
      "{'loss': 0.1582, 'learning_rate': 0.0009318999999999999, 'epoch': 0.44}\n",
      "{'loss': 0.1553, 'learning_rate': 0.0009318, 'epoch': 0.44}\n",
      "{'loss': 0.1387, 'learning_rate': 0.0009317, 'epoch': 0.44}\n",
      "{'loss': 0.1055, 'learning_rate': 0.0009316, 'epoch': 0.44}\n",
      "{'loss': 0.1406, 'learning_rate': 0.0009315, 'epoch': 0.44}\n",
      "{'loss': 0.0991, 'learning_rate': 0.0009314, 'epoch': 0.44}\n",
      "{'loss': 0.1157, 'learning_rate': 0.0009313, 'epoch': 0.44}\n",
      "{'loss': 0.1816, 'learning_rate': 0.0009312000000000001, 'epoch': 0.44}\n",
      "{'loss': 0.1533, 'learning_rate': 0.0009311, 'epoch': 0.44}\n",
      "{'loss': 0.1143, 'learning_rate': 0.0009310000000000001, 'epoch': 0.44}\n",
      "{'loss': 0.1113, 'learning_rate': 0.0009309, 'epoch': 0.44}\n",
      "{'loss': 0.1206, 'learning_rate': 0.0009308, 'epoch': 0.44}\n",
      "{'loss': 0.125, 'learning_rate': 0.0009307, 'epoch': 0.44}\n",
      "{'loss': 0.0947, 'learning_rate': 0.0009306, 'epoch': 0.45}\n",
      "{'loss': 0.126, 'learning_rate': 0.0009305, 'epoch': 0.45}\n",
      "{'loss': 0.1318, 'learning_rate': 0.0009304000000000001, 'epoch': 0.45}\n",
      "{'loss': 0.1172, 'learning_rate': 0.0009303, 'epoch': 0.45}\n",
      "{'loss': 0.1011, 'learning_rate': 0.0009302000000000001, 'epoch': 0.45}\n",
      "{'loss': 0.1572, 'learning_rate': 0.0009301000000000001, 'epoch': 0.45}\n",
      "{'loss': 0.1216, 'learning_rate': 0.00093, 'epoch': 0.45}\n",
      "{'loss': 0.1553, 'learning_rate': 0.0009299, 'epoch': 0.45}\n",
      "{'loss': 0.1187, 'learning_rate': 0.0009297999999999999, 'epoch': 0.45}\n",
      "{'loss': 0.1128, 'learning_rate': 0.0009297, 'epoch': 0.45}\n",
      "{'loss': 0.0869, 'learning_rate': 0.0009296, 'epoch': 0.45}\n",
      "{'loss': 0.0977, 'learning_rate': 0.0009295, 'epoch': 0.45}\n",
      "{'loss': 0.125, 'learning_rate': 0.0009294, 'epoch': 0.45}\n",
      "{'loss': 0.1157, 'learning_rate': 0.0009293, 'epoch': 0.45}\n",
      "{'loss': 0.1118, 'learning_rate': 0.0009292, 'epoch': 0.45}\n",
      "{'loss': 0.1133, 'learning_rate': 0.0009291000000000001, 'epoch': 0.46}\n",
      "{'loss': 0.0938, 'learning_rate': 0.000929, 'epoch': 0.46}\n",
      "{'loss': 0.0879, 'learning_rate': 0.0009289, 'epoch': 0.46}\n",
      "{'loss': 0.1348, 'learning_rate': 0.0009288, 'epoch': 0.46}\n",
      "{'loss': 0.1113, 'learning_rate': 0.0009287, 'epoch': 0.46}\n",
      "{'loss': 0.1279, 'learning_rate': 0.0009286, 'epoch': 0.46}\n",
      "{'loss': 0.1001, 'learning_rate': 0.0009285, 'epoch': 0.46}\n",
      "{'loss': 0.0962, 'learning_rate': 0.0009284, 'epoch': 0.46}\n",
      "{'loss': 0.1074, 'learning_rate': 0.0009283000000000001, 'epoch': 0.46}\n",
      "{'loss': 0.1211, 'learning_rate': 0.0009282, 'epoch': 0.46}\n",
      "{'loss': 0.126, 'learning_rate': 0.0009281000000000001, 'epoch': 0.46}\n",
      "{'loss': 0.1079, 'learning_rate': 0.0009280000000000001, 'epoch': 0.46}\n",
      "{'loss': 0.1016, 'learning_rate': 0.0009279, 'epoch': 0.46}\n",
      "{'loss': 0.1406, 'learning_rate': 0.0009278, 'epoch': 0.46}\n",
      "{'loss': 0.0933, 'learning_rate': 0.0009276999999999999, 'epoch': 0.46}\n",
      "{'loss': 0.1201, 'learning_rate': 0.0009276, 'epoch': 0.46}\n",
      "{'loss': 0.1338, 'learning_rate': 0.0009275, 'epoch': 0.47}\n",
      "{'loss': 0.1133, 'learning_rate': 0.0009274, 'epoch': 0.47}\n",
      "{'loss': 0.1406, 'learning_rate': 0.0009273, 'epoch': 0.47}\n",
      "{'loss': 0.1396, 'learning_rate': 0.0009272000000000001, 'epoch': 0.47}\n",
      "{'loss': 0.1377, 'learning_rate': 0.0009271, 'epoch': 0.47}\n",
      "{'loss': 0.1318, 'learning_rate': 0.0009270000000000001, 'epoch': 0.47}\n",
      "{'loss': 0.106, 'learning_rate': 0.0009268999999999999, 'epoch': 0.47}\n",
      "{'loss': 0.1025, 'learning_rate': 0.0009268, 'epoch': 0.47}\n",
      "{'loss': 0.104, 'learning_rate': 0.0009267, 'epoch': 0.47}\n",
      "{'loss': 0.125, 'learning_rate': 0.0009266, 'epoch': 0.47}\n",
      "{'loss': 0.1006, 'learning_rate': 0.0009265, 'epoch': 0.47}\n",
      "{'loss': 0.1216, 'learning_rate': 0.0009264, 'epoch': 0.47}\n",
      "{'loss': 0.0996, 'learning_rate': 0.0009263, 'epoch': 0.47}\n",
      "{'loss': 0.1357, 'learning_rate': 0.0009262000000000001, 'epoch': 0.47}\n",
      "{'loss': 0.1089, 'learning_rate': 0.0009261, 'epoch': 0.47}\n",
      "{'loss': 0.1245, 'learning_rate': 0.0009260000000000001, 'epoch': 0.47}\n",
      "{'loss': 0.1182, 'learning_rate': 0.0009259, 'epoch': 0.48}\n",
      "{'loss': 0.1064, 'learning_rate': 0.0009258, 'epoch': 0.48}\n",
      "{'loss': 0.1338, 'learning_rate': 0.0009257, 'epoch': 0.48}\n",
      "{'loss': 0.123, 'learning_rate': 0.0009256, 'epoch': 0.48}\n",
      "{'loss': 0.1001, 'learning_rate': 0.0009255, 'epoch': 0.48}\n",
      "{'loss': 0.0801, 'learning_rate': 0.0009254, 'epoch': 0.48}\n",
      "{'loss': 0.0977, 'learning_rate': 0.0009253, 'epoch': 0.48}\n",
      "{'loss': 0.1021, 'learning_rate': 0.0009252, 'epoch': 0.48}\n",
      "{'loss': 0.1494, 'learning_rate': 0.0009251000000000001, 'epoch': 0.48}\n",
      "{'loss': 0.1357, 'learning_rate': 0.000925, 'epoch': 0.48}\n",
      "{'loss': 0.1147, 'learning_rate': 0.0009249000000000001, 'epoch': 0.48}\n",
      "{'loss': 0.1128, 'learning_rate': 0.0009247999999999999, 'epoch': 0.48}\n",
      "{'loss': 0.0981, 'learning_rate': 0.0009247, 'epoch': 0.48}\n",
      "{'loss': 0.1147, 'learning_rate': 0.0009246, 'epoch': 0.48}\n",
      "{'loss': 0.125, 'learning_rate': 0.0009245, 'epoch': 0.48}\n",
      "{'loss': 0.1279, 'learning_rate': 0.0009244, 'epoch': 0.49}\n",
      "{'loss': 0.1187, 'learning_rate': 0.0009243000000000001, 'epoch': 0.49}\n",
      "{'loss': 0.0889, 'learning_rate': 0.0009242, 'epoch': 0.49}\n",
      "{'loss': 0.1426, 'learning_rate': 0.0009241000000000001, 'epoch': 0.49}\n",
      "{'loss': 0.1201, 'learning_rate': 0.000924, 'epoch': 0.49}\n",
      "{'loss': 0.0962, 'learning_rate': 0.0009239000000000001, 'epoch': 0.49}\n",
      "{'loss': 0.1318, 'learning_rate': 0.0009238, 'epoch': 0.49}\n",
      "{'loss': 0.1523, 'learning_rate': 0.0009237, 'epoch': 0.49}\n",
      "{'loss': 0.1484, 'learning_rate': 0.0009236, 'epoch': 0.49}\n",
      "{'loss': 0.1201, 'learning_rate': 0.0009235000000000001, 'epoch': 0.49}\n",
      "{'loss': 0.0996, 'learning_rate': 0.0009234, 'epoch': 0.49}\n",
      "{'loss': 0.0947, 'learning_rate': 0.0009233, 'epoch': 0.49}\n",
      "{'loss': 0.0859, 'learning_rate': 0.0009232, 'epoch': 0.49}\n",
      "{'loss': 0.1245, 'learning_rate': 0.0009231, 'epoch': 0.49}\n",
      "{'loss': 0.1299, 'learning_rate': 0.0009230000000000001, 'epoch': 0.49}\n",
      "{'loss': 0.1348, 'learning_rate': 0.0009229, 'epoch': 0.49}\n",
      "{'loss': 0.084, 'learning_rate': 0.0009228, 'epoch': 0.5}\n",
      "{'loss': 0.1338, 'learning_rate': 0.0009226999999999999, 'epoch': 0.5}\n",
      "{'loss': 0.0864, 'learning_rate': 0.0009226, 'epoch': 0.5}\n",
      "{'loss': 0.1777, 'learning_rate': 0.0009225, 'epoch': 0.5}\n",
      "{'loss': 0.1045, 'learning_rate': 0.0009224, 'epoch': 0.5}\n",
      "{'loss': 0.0952, 'learning_rate': 0.0009223, 'epoch': 0.5}\n",
      "{'loss': 0.1328, 'learning_rate': 0.0009222000000000001, 'epoch': 0.5}\n",
      "{'loss': 0.0913, 'learning_rate': 0.0009221, 'epoch': 0.5}\n",
      "{'loss': 0.1221, 'learning_rate': 0.0009220000000000001, 'epoch': 0.5}\n",
      "{'loss': 0.1016, 'learning_rate': 0.0009219, 'epoch': 0.5}\n",
      "{'loss': 0.1235, 'learning_rate': 0.0009218, 'epoch': 0.5}\n",
      "{'loss': 0.1172, 'learning_rate': 0.0009217, 'epoch': 0.5}\n",
      "{'loss': 0.1924, 'learning_rate': 0.0009216, 'epoch': 0.5}\n",
      "{'loss': 0.1064, 'learning_rate': 0.0009215, 'epoch': 0.5}\n",
      "{'loss': 0.0894, 'learning_rate': 0.0009214000000000001, 'epoch': 0.5}\n",
      "{'loss': 0.1318, 'learning_rate': 0.0009213, 'epoch': 0.51}\n",
      "{'loss': 0.1001, 'learning_rate': 0.0009212000000000001, 'epoch': 0.51}\n",
      "{'loss': 0.1196, 'learning_rate': 0.0009211, 'epoch': 0.51}\n",
      "{'loss': 0.0898, 'learning_rate': 0.000921, 'epoch': 0.51}\n",
      "{'loss': 0.0996, 'learning_rate': 0.0009209000000000001, 'epoch': 0.51}\n",
      "{'loss': 0.1357, 'learning_rate': 0.0009207999999999999, 'epoch': 0.51}\n",
      "{'loss': 0.0938, 'learning_rate': 0.0009207, 'epoch': 0.51}\n",
      "{'loss': 0.124, 'learning_rate': 0.0009206, 'epoch': 0.51}\n",
      "{'loss': 0.1201, 'learning_rate': 0.0009205, 'epoch': 0.51}\n",
      "{'loss': 0.1001, 'learning_rate': 0.0009204, 'epoch': 0.51}\n",
      "{'loss': 0.1289, 'learning_rate': 0.0009203, 'epoch': 0.51}\n",
      "{'loss': 0.1377, 'learning_rate': 0.0009202, 'epoch': 0.51}\n",
      "{'loss': 0.0996, 'learning_rate': 0.0009201000000000001, 'epoch': 0.51}\n",
      "{'loss': 0.1084, 'learning_rate': 0.00092, 'epoch': 0.51}\n",
      "{'loss': 0.1475, 'learning_rate': 0.0009199000000000001, 'epoch': 0.51}\n",
      "{'loss': 0.1226, 'learning_rate': 0.0009198, 'epoch': 0.51}\n",
      "{'loss': 0.1001, 'learning_rate': 0.0009197, 'epoch': 0.52}\n",
      "{'loss': 0.0972, 'learning_rate': 0.0009196, 'epoch': 0.52}\n",
      "{'loss': 0.0767, 'learning_rate': 0.0009195, 'epoch': 0.52}\n",
      "{'loss': 0.1279, 'learning_rate': 0.0009194, 'epoch': 0.52}\n",
      "{'loss': 0.1069, 'learning_rate': 0.0009193000000000001, 'epoch': 0.52}\n",
      "{'loss': 0.1543, 'learning_rate': 0.0009192, 'epoch': 0.52}\n",
      "{'loss': 0.0908, 'learning_rate': 0.0009191000000000001, 'epoch': 0.52}\n",
      "{'loss': 0.105, 'learning_rate': 0.0009190000000000001, 'epoch': 0.52}\n",
      "{'loss': 0.127, 'learning_rate': 0.0009189000000000001, 'epoch': 0.52}\n",
      "{'loss': 0.1299, 'learning_rate': 0.0009188, 'epoch': 0.52}\n",
      "{'loss': 0.1123, 'learning_rate': 0.0009186999999999999, 'epoch': 0.52}\n",
      "{'loss': 0.1099, 'learning_rate': 0.0009186, 'epoch': 0.52}\n",
      "{'loss': 0.0908, 'learning_rate': 0.0009185, 'epoch': 0.52}\n",
      "{'loss': 0.1187, 'learning_rate': 0.0009184, 'epoch': 0.52}\n",
      "{'loss': 0.124, 'learning_rate': 0.0009183, 'epoch': 0.52}\n",
      "{'loss': 0.0913, 'learning_rate': 0.0009182, 'epoch': 0.53}\n",
      "{'loss': 0.0977, 'learning_rate': 0.0009181, 'epoch': 0.53}\n",
      "{'loss': 0.1406, 'learning_rate': 0.0009180000000000001, 'epoch': 0.53}\n",
      "{'loss': 0.1484, 'learning_rate': 0.0009179, 'epoch': 0.53}\n",
      "{'loss': 0.1157, 'learning_rate': 0.0009178, 'epoch': 0.53}\n",
      "{'loss': 0.1152, 'learning_rate': 0.0009177, 'epoch': 0.53}\n",
      "{'loss': 0.0801, 'learning_rate': 0.0009176, 'epoch': 0.53}\n",
      "{'loss': 0.1182, 'learning_rate': 0.0009175, 'epoch': 0.53}\n",
      "{'loss': 0.123, 'learning_rate': 0.0009174, 'epoch': 0.53}\n",
      "{'loss': 0.1299, 'learning_rate': 0.0009173, 'epoch': 0.53}\n",
      "{'loss': 0.1011, 'learning_rate': 0.0009172000000000001, 'epoch': 0.53}\n",
      "{'loss': 0.1309, 'learning_rate': 0.0009171, 'epoch': 0.53}\n",
      "{'loss': 0.1011, 'learning_rate': 0.0009170000000000001, 'epoch': 0.53}\n",
      "{'loss': 0.1201, 'learning_rate': 0.0009169000000000001, 'epoch': 0.53}\n",
      "{'loss': 0.0947, 'learning_rate': 0.0009168, 'epoch': 0.53}\n",
      "{'loss': 0.1318, 'learning_rate': 0.0009167, 'epoch': 0.53}\n",
      "{'loss': 0.1167, 'learning_rate': 0.0009165999999999999, 'epoch': 0.54}\n",
      "{'loss': 0.1445, 'learning_rate': 0.0009165, 'epoch': 0.54}\n",
      "{'loss': 0.1172, 'learning_rate': 0.0009164, 'epoch': 0.54}\n",
      "{'loss': 0.123, 'learning_rate': 0.0009163, 'epoch': 0.54}\n",
      "{'loss': 0.0972, 'learning_rate': 0.0009162, 'epoch': 0.54}\n",
      "{'loss': 0.1035, 'learning_rate': 0.0009161000000000001, 'epoch': 0.54}\n",
      "{'loss': 0.103, 'learning_rate': 0.000916, 'epoch': 0.54}\n",
      "{'loss': 0.1309, 'learning_rate': 0.0009159000000000001, 'epoch': 0.54}\n",
      "{'loss': 0.104, 'learning_rate': 0.0009157999999999999, 'epoch': 0.54}\n",
      "{'loss': 0.0913, 'learning_rate': 0.0009157, 'epoch': 0.54}\n",
      "{'loss': 0.1523, 'learning_rate': 0.0009156, 'epoch': 0.54}\n",
      "{'loss': 0.1128, 'learning_rate': 0.0009155, 'epoch': 0.54}\n",
      "{'loss': 0.0786, 'learning_rate': 0.0009154, 'epoch': 0.54}\n",
      "{'loss': 0.1021, 'learning_rate': 0.0009153, 'epoch': 0.54}\n",
      "{'loss': 0.1211, 'learning_rate': 0.0009152, 'epoch': 0.54}\n",
      "{'loss': 0.0781, 'learning_rate': 0.0009151000000000001, 'epoch': 0.54}\n",
      "{'loss': 0.1016, 'learning_rate': 0.000915, 'epoch': 0.55}\n",
      "{'loss': 0.1128, 'learning_rate': 0.0009149000000000001, 'epoch': 0.55}\n",
      "{'loss': 0.1162, 'learning_rate': 0.0009148, 'epoch': 0.55}\n",
      "{'loss': 0.1074, 'learning_rate': 0.0009147, 'epoch': 0.55}\n",
      "{'loss': 0.1279, 'learning_rate': 0.0009146, 'epoch': 0.55}\n",
      "{'loss': 0.0933, 'learning_rate': 0.0009145, 'epoch': 0.55}\n",
      "{'loss': 0.1387, 'learning_rate': 0.0009144, 'epoch': 0.55}\n",
      "{'loss': 0.083, 'learning_rate': 0.0009143, 'epoch': 0.55}\n",
      "{'loss': 0.1089, 'learning_rate': 0.0009142, 'epoch': 0.55}\n",
      "{'loss': 0.0942, 'learning_rate': 0.0009141, 'epoch': 0.55}\n",
      "{'loss': 0.127, 'learning_rate': 0.0009140000000000001, 'epoch': 0.55}\n",
      "{'loss': 0.1157, 'learning_rate': 0.0009139, 'epoch': 0.55}\n",
      "{'loss': 0.0972, 'learning_rate': 0.0009138, 'epoch': 0.55}\n",
      "{'loss': 0.1211, 'learning_rate': 0.0009136999999999999, 'epoch': 0.55}\n",
      "{'loss': 0.0942, 'learning_rate': 0.0009136, 'epoch': 0.55}\n",
      "{'loss': 0.2246, 'learning_rate': 0.0009135, 'epoch': 0.56}\n",
      "{'loss': 0.0796, 'learning_rate': 0.0009134, 'epoch': 0.56}\n",
      "{'loss': 0.1089, 'learning_rate': 0.0009133, 'epoch': 0.56}\n",
      "{'loss': 0.0894, 'learning_rate': 0.0009132000000000001, 'epoch': 0.56}\n",
      "{'loss': 0.103, 'learning_rate': 0.0009131, 'epoch': 0.56}\n",
      "{'loss': 0.124, 'learning_rate': 0.0009130000000000001, 'epoch': 0.56}\n",
      "{'loss': 0.1094, 'learning_rate': 0.0009129, 'epoch': 0.56}\n",
      "{'loss': 0.1455, 'learning_rate': 0.0009128, 'epoch': 0.56}\n",
      "{'loss': 0.1621, 'learning_rate': 0.0009127, 'epoch': 0.56}\n",
      "{'loss': 0.1631, 'learning_rate': 0.0009126, 'epoch': 0.56}\n",
      "{'loss': 0.1201, 'learning_rate': 0.0009125, 'epoch': 0.56}\n",
      "{'loss': 0.1025, 'learning_rate': 0.0009124000000000001, 'epoch': 0.56}\n",
      "{'loss': 0.0869, 'learning_rate': 0.0009123, 'epoch': 0.56}\n",
      "{'loss': 0.1299, 'learning_rate': 0.0009122000000000001, 'epoch': 0.56}\n",
      "{'loss': 0.1182, 'learning_rate': 0.0009121, 'epoch': 0.56}\n",
      "{'loss': 0.126, 'learning_rate': 0.000912, 'epoch': 0.56}\n",
      "{'loss': 0.1289, 'learning_rate': 0.0009119000000000001, 'epoch': 0.57}\n",
      "{'loss': 0.1445, 'learning_rate': 0.0009118, 'epoch': 0.57}\n",
      "{'loss': 0.1455, 'learning_rate': 0.0009117, 'epoch': 0.57}\n",
      "{'loss': 0.083, 'learning_rate': 0.0009115999999999999, 'epoch': 0.57}\n",
      "{'loss': 0.1328, 'learning_rate': 0.0009115, 'epoch': 0.57}\n",
      "{'loss': 0.0991, 'learning_rate': 0.0009114, 'epoch': 0.57}\n",
      "{'loss': 0.1523, 'learning_rate': 0.0009113, 'epoch': 0.57}\n",
      "{'loss': 0.1152, 'learning_rate': 0.0009112, 'epoch': 0.57}\n",
      "{'loss': 0.0884, 'learning_rate': 0.0009111000000000001, 'epoch': 0.57}\n",
      "{'loss': 0.124, 'learning_rate': 0.000911, 'epoch': 0.57}\n",
      "{'loss': 0.1162, 'learning_rate': 0.0009109000000000001, 'epoch': 0.57}\n",
      "{'loss': 0.1201, 'learning_rate': 0.0009108, 'epoch': 0.57}\n",
      "{'loss': 0.127, 'learning_rate': 0.0009107, 'epoch': 0.57}\n",
      "{'loss': 0.1099, 'learning_rate': 0.0009106, 'epoch': 0.57}\n",
      "{'loss': 0.0903, 'learning_rate': 0.0009105, 'epoch': 0.57}\n",
      "{'loss': 0.0981, 'learning_rate': 0.0009104, 'epoch': 0.58}\n",
      "{'loss': 0.1123, 'learning_rate': 0.0009103000000000001, 'epoch': 0.58}\n",
      "{'loss': 0.1484, 'learning_rate': 0.0009102, 'epoch': 0.58}\n",
      "{'loss': 0.105, 'learning_rate': 0.0009101000000000001, 'epoch': 0.58}\n",
      "{'loss': 0.1348, 'learning_rate': 0.00091, 'epoch': 0.58}\n",
      "{'loss': 0.1069, 'learning_rate': 0.0009099, 'epoch': 0.58}\n",
      "{'loss': 0.0908, 'learning_rate': 0.0009098000000000001, 'epoch': 0.58}\n",
      "{'loss': 0.1196, 'learning_rate': 0.0009096999999999999, 'epoch': 0.58}\n",
      "{'loss': 0.103, 'learning_rate': 0.0009096, 'epoch': 0.58}\n",
      "{'loss': 0.0952, 'learning_rate': 0.0009095, 'epoch': 0.58}\n",
      "{'loss': 0.1348, 'learning_rate': 0.0009094, 'epoch': 0.58}\n",
      "{'loss': 0.1338, 'learning_rate': 0.0009093, 'epoch': 0.58}\n",
      "{'loss': 0.1455, 'learning_rate': 0.0009092, 'epoch': 0.58}\n",
      "{'loss': 0.1118, 'learning_rate': 0.0009091, 'epoch': 0.58}\n",
      "{'loss': 0.1182, 'learning_rate': 0.0009090000000000001, 'epoch': 0.58}\n",
      "{'loss': 0.0903, 'learning_rate': 0.0009089, 'epoch': 0.58}\n",
      "{'loss': 0.1377, 'learning_rate': 0.0009088000000000001, 'epoch': 0.59}\n",
      "{'loss': 0.125, 'learning_rate': 0.0009087, 'epoch': 0.59}\n",
      "{'loss': 0.1406, 'learning_rate': 0.0009086, 'epoch': 0.59}\n",
      "{'loss': 0.1035, 'learning_rate': 0.0009085, 'epoch': 0.59}\n",
      "{'loss': 0.1553, 'learning_rate': 0.0009084, 'epoch': 0.59}\n",
      "{'loss': 0.0903, 'learning_rate': 0.0009083, 'epoch': 0.59}\n",
      "{'loss': 0.1177, 'learning_rate': 0.0009082000000000001, 'epoch': 0.59}\n",
      "{'loss': 0.126, 'learning_rate': 0.0009081, 'epoch': 0.59}\n",
      "{'loss': 0.085, 'learning_rate': 0.0009080000000000001, 'epoch': 0.59}\n",
      "{'loss': 0.0991, 'learning_rate': 0.0009079000000000001, 'epoch': 0.59}\n",
      "{'loss': 0.1455, 'learning_rate': 0.0009078000000000001, 'epoch': 0.59}\n",
      "{'loss': 0.1226, 'learning_rate': 0.0009077, 'epoch': 0.59}\n",
      "{'loss': 0.1104, 'learning_rate': 0.0009075999999999999, 'epoch': 0.59}\n",
      "{'loss': 0.0649, 'learning_rate': 0.0009075, 'epoch': 0.59}\n",
      "{'loss': 0.1143, 'learning_rate': 0.0009074, 'epoch': 0.59}\n",
      "{'loss': 0.1016, 'learning_rate': 0.0009073, 'epoch': 0.59}\n",
      "{'loss': 0.1279, 'learning_rate': 0.0009072, 'epoch': 0.6}\n",
      "{'loss': 0.1235, 'learning_rate': 0.0009071, 'epoch': 0.6}\n",
      "{'loss': 0.1211, 'learning_rate': 0.000907, 'epoch': 0.6}\n",
      "{'loss': 0.0874, 'learning_rate': 0.0009069000000000001, 'epoch': 0.6}\n",
      "{'loss': 0.1367, 'learning_rate': 0.0009068, 'epoch': 0.6}\n",
      "{'loss': 0.0879, 'learning_rate': 0.0009067, 'epoch': 0.6}\n",
      "{'loss': 0.1436, 'learning_rate': 0.0009066, 'epoch': 0.6}\n",
      "{'loss': 0.103, 'learning_rate': 0.0009065, 'epoch': 0.6}\n",
      "{'loss': 0.1094, 'learning_rate': 0.0009064, 'epoch': 0.6}\n",
      "{'loss': 0.1177, 'learning_rate': 0.0009063, 'epoch': 0.6}\n",
      "{'loss': 0.1611, 'learning_rate': 0.0009062, 'epoch': 0.6}\n",
      "{'loss': 0.0977, 'learning_rate': 0.0009061000000000001, 'epoch': 0.6}\n",
      "{'loss': 0.0933, 'learning_rate': 0.000906, 'epoch': 0.6}\n",
      "{'loss': 0.1074, 'learning_rate': 0.0009059000000000001, 'epoch': 0.6}\n",
      "{'loss': 0.1143, 'learning_rate': 0.0009058000000000001, 'epoch': 0.6}\n",
      "{'loss': 0.0942, 'learning_rate': 0.0009057, 'epoch': 0.61}\n",
      "{'loss': 0.104, 'learning_rate': 0.0009056, 'epoch': 0.61}\n",
      "{'loss': 0.1768, 'learning_rate': 0.0009055, 'epoch': 0.61}\n",
      "{'loss': 0.1235, 'learning_rate': 0.0009054, 'epoch': 0.61}\n",
      "{'loss': 0.0981, 'learning_rate': 0.0009053, 'epoch': 0.61}\n",
      "{'loss': 0.1055, 'learning_rate': 0.0009052, 'epoch': 0.61}\n",
      "{'loss': 0.1367, 'learning_rate': 0.0009051, 'epoch': 0.61}\n",
      "{'loss': 0.1035, 'learning_rate': 0.0009050000000000001, 'epoch': 0.61}\n",
      "{'loss': 0.1172, 'learning_rate': 0.0009049, 'epoch': 0.61}\n",
      "{'loss': 0.1099, 'learning_rate': 0.0009048000000000001, 'epoch': 0.61}\n",
      "{'loss': 0.1533, 'learning_rate': 0.0009046999999999999, 'epoch': 0.61}\n",
      "{'loss': 0.1377, 'learning_rate': 0.0009046, 'epoch': 0.61}\n",
      "{'loss': 0.1328, 'learning_rate': 0.0009045, 'epoch': 0.61}\n",
      "{'loss': 0.1206, 'learning_rate': 0.0009044, 'epoch': 0.61}\n",
      "{'loss': 0.1094, 'learning_rate': 0.0009043, 'epoch': 0.61}\n",
      "{'loss': 0.1128, 'learning_rate': 0.0009042, 'epoch': 0.61}\n",
      "{'loss': 0.1221, 'learning_rate': 0.0009041, 'epoch': 0.62}\n",
      "{'loss': 0.1484, 'learning_rate': 0.0009040000000000001, 'epoch': 0.62}\n",
      "{'loss': 0.1138, 'learning_rate': 0.0009039, 'epoch': 0.62}\n",
      "{'loss': 0.0908, 'learning_rate': 0.0009038000000000001, 'epoch': 0.62}\n",
      "{'loss': 0.1152, 'learning_rate': 0.0009037, 'epoch': 0.62}\n",
      "{'loss': 0.1147, 'learning_rate': 0.0009036, 'epoch': 0.62}\n",
      "{'loss': 0.1221, 'learning_rate': 0.0009035, 'epoch': 0.62}\n",
      "{'loss': 0.1836, 'learning_rate': 0.0009034, 'epoch': 0.62}\n",
      "{'loss': 0.1123, 'learning_rate': 0.0009033, 'epoch': 0.62}\n",
      "{'loss': 0.1235, 'learning_rate': 0.0009032, 'epoch': 0.62}\n",
      "{'loss': 0.1123, 'learning_rate': 0.0009031, 'epoch': 0.62}\n",
      "{'loss': 0.1006, 'learning_rate': 0.000903, 'epoch': 0.62}\n",
      "{'loss': 0.0962, 'learning_rate': 0.0009029000000000001, 'epoch': 0.62}\n",
      "{'loss': 0.0889, 'learning_rate': 0.0009028, 'epoch': 0.62}\n",
      "{'loss': 0.1367, 'learning_rate': 0.0009027, 'epoch': 0.62}\n",
      "{'loss': 0.1143, 'learning_rate': 0.0009025999999999999, 'epoch': 0.63}\n",
      "{'loss': 0.1216, 'learning_rate': 0.0009025, 'epoch': 0.63}\n",
      "{'loss': 0.126, 'learning_rate': 0.0009024, 'epoch': 0.63}\n",
      "{'loss': 0.106, 'learning_rate': 0.0009023, 'epoch': 0.63}\n",
      "{'loss': 0.0996, 'learning_rate': 0.0009022, 'epoch': 0.63}\n",
      "{'loss': 0.1416, 'learning_rate': 0.0009021000000000001, 'epoch': 0.63}\n",
      "{'loss': 0.1084, 'learning_rate': 0.000902, 'epoch': 0.63}\n",
      "{'loss': 0.0991, 'learning_rate': 0.0009019000000000001, 'epoch': 0.63}\n",
      "{'loss': 0.1191, 'learning_rate': 0.0009018, 'epoch': 0.63}\n",
      "{'loss': 0.1172, 'learning_rate': 0.0009017, 'epoch': 0.63}\n",
      "{'loss': 0.1138, 'learning_rate': 0.0009016, 'epoch': 0.63}\n",
      "{'loss': 0.0801, 'learning_rate': 0.0009015, 'epoch': 0.63}\n",
      "{'loss': 0.1147, 'learning_rate': 0.0009014, 'epoch': 0.63}\n",
      "{'loss': 0.0928, 'learning_rate': 0.0009013000000000001, 'epoch': 0.63}\n",
      "{'loss': 0.0806, 'learning_rate': 0.0009012, 'epoch': 0.63}\n",
      "{'loss': 0.1162, 'learning_rate': 0.0009011000000000001, 'epoch': 0.63}\n",
      "{'loss': 0.1128, 'learning_rate': 0.000901, 'epoch': 0.64}\n",
      "{'loss': 0.1147, 'learning_rate': 0.0009009, 'epoch': 0.64}\n",
      "{'loss': 0.1758, 'learning_rate': 0.0009008000000000001, 'epoch': 0.64}\n",
      "{'loss': 0.106, 'learning_rate': 0.0009006999999999999, 'epoch': 0.64}\n",
      "{'loss': 0.1807, 'learning_rate': 0.0009006, 'epoch': 0.64}\n",
      "{'loss': 0.1011, 'learning_rate': 0.0009004999999999999, 'epoch': 0.64}\n",
      "{'loss': 0.082, 'learning_rate': 0.0009004, 'epoch': 0.64}\n",
      "{'loss': 0.127, 'learning_rate': 0.0009003, 'epoch': 0.64}\n",
      "{'loss': 0.1201, 'learning_rate': 0.0009002, 'epoch': 0.64}\n",
      "{'loss': 0.1426, 'learning_rate': 0.0009001, 'epoch': 0.64}\n",
      "{'loss': 0.1152, 'learning_rate': 0.0009000000000000001, 'epoch': 0.64}\n",
      "{'loss': 0.1157, 'learning_rate': 0.0008999, 'epoch': 0.64}\n",
      "{'loss': 0.1147, 'learning_rate': 0.0008998000000000001, 'epoch': 0.64}\n",
      "{'loss': 0.0952, 'learning_rate': 0.0008997, 'epoch': 0.64}\n",
      "{'loss': 0.1118, 'learning_rate': 0.0008996, 'epoch': 0.64}\n",
      "{'loss': 0.1445, 'learning_rate': 0.0008995, 'epoch': 0.65}\n",
      "{'loss': 0.1416, 'learning_rate': 0.0008994, 'epoch': 0.65}\n",
      "{'loss': 0.1221, 'learning_rate': 0.0008993, 'epoch': 0.65}\n",
      "{'loss': 0.1201, 'learning_rate': 0.0008992000000000001, 'epoch': 0.65}\n",
      "{'loss': 0.0806, 'learning_rate': 0.0008991, 'epoch': 0.65}\n",
      "{'loss': 0.1045, 'learning_rate': 0.0008990000000000001, 'epoch': 0.65}\n",
      "{'loss': 0.0938, 'learning_rate': 0.0008989, 'epoch': 0.65}\n",
      "{'loss': 0.1079, 'learning_rate': 0.0008988000000000001, 'epoch': 0.65}\n",
      "{'loss': 0.1113, 'learning_rate': 0.0008987000000000001, 'epoch': 0.65}\n",
      "{'loss': 0.2109, 'learning_rate': 0.0008985999999999999, 'epoch': 0.65}\n",
      "{'loss': 0.1426, 'learning_rate': 0.0008985, 'epoch': 0.65}\n",
      "{'loss': 0.1279, 'learning_rate': 0.0008984, 'epoch': 0.65}\n",
      "{'loss': 0.0977, 'learning_rate': 0.0008983, 'epoch': 0.65}\n",
      "{'loss': 0.1108, 'learning_rate': 0.0008982, 'epoch': 0.65}\n",
      "{'loss': 0.1426, 'learning_rate': 0.0008981, 'epoch': 0.65}\n",
      "{'loss': 0.0737, 'learning_rate': 0.000898, 'epoch': 0.65}\n",
      "{'loss': 0.1523, 'learning_rate': 0.0008979000000000001, 'epoch': 0.66}\n",
      "{'loss': 0.1089, 'learning_rate': 0.0008978, 'epoch': 0.66}\n",
      "{'loss': 0.1533, 'learning_rate': 0.0008977000000000001, 'epoch': 0.66}\n",
      "{'loss': 0.1426, 'learning_rate': 0.0008976, 'epoch': 0.66}\n",
      "{'loss': 0.0996, 'learning_rate': 0.0008975, 'epoch': 0.66}\n",
      "{'loss': 0.1206, 'learning_rate': 0.0008974, 'epoch': 0.66}\n",
      "{'loss': 0.1045, 'learning_rate': 0.0008973, 'epoch': 0.66}\n",
      "{'loss': 0.0845, 'learning_rate': 0.0008972, 'epoch': 0.66}\n",
      "{'loss': 0.1226, 'learning_rate': 0.0008971000000000001, 'epoch': 0.66}\n",
      "{'loss': 0.1167, 'learning_rate': 0.000897, 'epoch': 0.66}\n",
      "{'loss': 0.1582, 'learning_rate': 0.0008969000000000001, 'epoch': 0.66}\n",
      "{'loss': 0.1123, 'learning_rate': 0.0008968000000000001, 'epoch': 0.66}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/frog/Code/NLP/NLP_source_code/GenerativeAI/Generative-AI-with-LLMs-main/Week-2/Lab_2_fine_tune_generative_ai_model.ipynb Cell 68\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/GenerativeAI/Generative-AI-with-LLMs-main/Week-2/Lab_2_fine_tune_generative_ai_model.ipynb#Y303sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m peft_trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/GenerativeAI/Generative-AI-with-LLMs-main/Week-2/Lab_2_fine_tune_generative_ai_model.ipynb#Y303sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# peft_model_path=\"./peft-dialogue-summary-checkpoint-local\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/GenerativeAI/Generative-AI-with-LLMs-main/Week-2/Lab_2_fine_tune_generative_ai_model.ipynb#Y303sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m peft_trainer\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39msave_pretrained(output_dir)\n",
      "File \u001b[0;32m~/anaconda3/envs/learning_dl/lib/python3.11/site-packages/transformers/trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1554\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1555\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1556\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1557\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1558\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1559\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1560\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/learning_dl/lib/python3.11/site-packages/accelerate/utils/memory.py:136\u001b[0m, in \u001b[0;36mfind_executable_batch_size.<locals>.decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo executable batch size found, reached zero.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    135\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m     \u001b[39mreturn\u001b[39;00m function(batch_size, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    137\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    138\u001b[0m     \u001b[39mif\u001b[39;00m should_reduce_batch_size(e):\n",
      "File \u001b[0;32m~/anaconda3/envs/learning_dl/lib/python3.11/site-packages/transformers/trainer.py:1895\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1890\u001b[0m         nn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(\n\u001b[1;32m   1891\u001b[0m             amp\u001b[39m.\u001b[39mmaster_params(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer),\n\u001b[1;32m   1892\u001b[0m             args\u001b[39m.\u001b[39mmax_grad_norm,\n\u001b[1;32m   1893\u001b[0m         )\n\u001b[1;32m   1894\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1895\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccelerator\u001b[39m.\u001b[39;49mclip_grad_norm_(\n\u001b[1;32m   1896\u001b[0m             model\u001b[39m.\u001b[39;49mparameters(),\n\u001b[1;32m   1897\u001b[0m             args\u001b[39m.\u001b[39;49mmax_grad_norm,\n\u001b[1;32m   1898\u001b[0m         )\n\u001b[1;32m   1900\u001b[0m \u001b[39m# Optimizer step\u001b[39;00m\n\u001b[1;32m   1901\u001b[0m optimizer_was_run \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/learning_dl/lib/python3.11/site-packages/accelerate/accelerator.py:1926\u001b[0m, in \u001b[0;36mAccelerator.clip_grad_norm_\u001b[0;34m(self, parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m   1924\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munscale_gradients()\n\u001b[0;32m-> 1926\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mclip_grad_norm_(parameters, max_norm, norm_type\u001b[39m=\u001b[39;49mnorm_type)\n",
      "File \u001b[0;32m~/anaconda3/envs/learning_dl/lib/python3.11/site-packages/torch/nn/utils/clip_grad.py:39\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(parameters, torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m     38\u001b[0m     parameters \u001b[39m=\u001b[39m [parameters]\n\u001b[0;32m---> 39\u001b[0m grads \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39;49mgrad \u001b[39mfor\u001b[39;49;00m p \u001b[39min\u001b[39;49;00m parameters \u001b[39mif\u001b[39;49;00m p\u001b[39m.\u001b[39;49mgrad \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m]\n\u001b[1;32m     40\u001b[0m max_norm \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(max_norm)\n\u001b[1;32m     41\u001b[0m norm_type \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(norm_type)\n",
      "File \u001b[0;32m~/anaconda3/envs/learning_dl/lib/python3.11/site-packages/torch/nn/utils/clip_grad.py:39\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(parameters, torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m     38\u001b[0m     parameters \u001b[39m=\u001b[39m [parameters]\n\u001b[0;32m---> 39\u001b[0m grads \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mgrad \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m parameters \u001b[39mif\u001b[39;00m p\u001b[39m.\u001b[39mgrad \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m]\n\u001b[1;32m     40\u001b[0m max_norm \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(max_norm)\n\u001b[1;32m     41\u001b[0m norm_type \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(norm_type)\n",
      "File \u001b[0;32m~/anaconda3/envs/learning_dl/lib/python3.11/site-packages/torch/nn/modules/module.py:2081\u001b[0m, in \u001b[0;36mModule.parameters\u001b[0;34m(self, recurse)\u001b[0m\n\u001b[1;32m   2059\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparameters\u001b[39m(\u001b[39mself\u001b[39m, recurse: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Parameter]:\n\u001b[1;32m   2060\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Returns an iterator over module parameters.\u001b[39;00m\n\u001b[1;32m   2061\u001b[0m \n\u001b[1;32m   2062\u001b[0m \u001b[39m    This is typically passed to an optimizer.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2079\u001b[0m \n\u001b[1;32m   2080\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2081\u001b[0m     \u001b[39mfor\u001b[39;00m name, param \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnamed_parameters(recurse\u001b[39m=\u001b[39mrecurse):\n\u001b[1;32m   2082\u001b[0m         \u001b[39myield\u001b[39;00m param\n",
      "File \u001b[0;32m~/anaconda3/envs/learning_dl/lib/python3.11/site-packages/torch/nn/modules/module.py:2115\u001b[0m, in \u001b[0;36mModule.named_parameters\u001b[0;34m(self, prefix, recurse, remove_duplicate)\u001b[0m\n\u001b[1;32m   2090\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Returns an iterator over module parameters, yielding both the\u001b[39;00m\n\u001b[1;32m   2091\u001b[0m \u001b[39mname of the parameter as well as the parameter itself.\u001b[39;00m\n\u001b[1;32m   2092\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2110\u001b[0m \n\u001b[1;32m   2111\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2112\u001b[0m gen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_named_members(\n\u001b[1;32m   2113\u001b[0m     \u001b[39mlambda\u001b[39;00m module: module\u001b[39m.\u001b[39m_parameters\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   2114\u001b[0m     prefix\u001b[39m=\u001b[39mprefix, recurse\u001b[39m=\u001b[39mrecurse, remove_duplicate\u001b[39m=\u001b[39mremove_duplicate)\n\u001b[0;32m-> 2115\u001b[0m \u001b[39myield from\u001b[39;00m gen\n",
      "File \u001b[0;32m~/anaconda3/envs/learning_dl/lib/python3.11/site-packages/torch/nn/modules/module.py:2050\u001b[0m, in \u001b[0;36mModule._named_members\u001b[0;34m(self, get_members_fn, prefix, recurse, remove_duplicate)\u001b[0m\n\u001b[1;32m   2048\u001b[0m modules \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnamed_modules(prefix\u001b[39m=\u001b[39mprefix, remove_duplicate\u001b[39m=\u001b[39mremove_duplicate) \u001b[39mif\u001b[39;00m recurse \u001b[39melse\u001b[39;00m [(prefix, \u001b[39mself\u001b[39m)]\n\u001b[1;32m   2049\u001b[0m \u001b[39mfor\u001b[39;00m module_prefix, module \u001b[39min\u001b[39;00m modules:\n\u001b[0;32m-> 2050\u001b[0m     members \u001b[39m=\u001b[39m get_members_fn(module)\n\u001b[1;32m   2051\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m members:\n\u001b[1;32m   2052\u001b[0m         \u001b[39mif\u001b[39;00m v \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m v \u001b[39min\u001b[39;00m memo:\n",
      "File \u001b[0;32m~/anaconda3/envs/learning_dl/lib/python3.11/site-packages/torch/nn/modules/module.py:2113\u001b[0m, in \u001b[0;36mModule.named_parameters.<locals>.<lambda>\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m   2084\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnamed_parameters\u001b[39m(\n\u001b[1;32m   2085\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   2086\u001b[0m         prefix: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   2087\u001b[0m         recurse: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   2088\u001b[0m         remove_duplicate: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   2089\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Tuple[\u001b[39mstr\u001b[39m, Parameter]]:\n\u001b[1;32m   2090\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Returns an iterator over module parameters, yielding both the\u001b[39;00m\n\u001b[1;32m   2091\u001b[0m \u001b[39m    name of the parameter as well as the parameter itself.\u001b[39;00m\n\u001b[1;32m   2092\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2110\u001b[0m \n\u001b[1;32m   2111\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2112\u001b[0m     gen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_named_members(\n\u001b[0;32m-> 2113\u001b[0m         \u001b[39mlambda\u001b[39;00m module: module\u001b[39m.\u001b[39m_parameters\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   2114\u001b[0m         prefix\u001b[39m=\u001b[39mprefix, recurse\u001b[39m=\u001b[39mrecurse, remove_duplicate\u001b[39m=\u001b[39mremove_duplicate)\n\u001b[1;32m   2115\u001b[0m     \u001b[39myield from\u001b[39;00m gen\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "peft_trainer.train()\n",
    "\n",
    "# peft_model_path=\"./peft-dialogue-summary-checkpoint-local\"\n",
    "\n",
    "peft_trainer.model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./peft-dialogue-summary-training-1695139204/tokenizer_config.json',\n",
       " './peft-dialogue-summary-training-1695139204/special_tokens_map.json',\n",
       " './peft-dialogue-summary-training-1695139204/tokenizer.json')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_trainer.model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSI1MCIgdmlld0JveD0iMCAwIDgwMCA1MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxkZWZzPgogICAgICAgIDxsaW5lYXJHcmFkaWVudCBpZD0iZmFkZUdyYWRpZW50IiB4MT0iMCIgeDI9IjEiPgogICAgICAgICAgICA8c3RvcCBvZmZzZXQ9IjAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIi8+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMTAwJSIgc3RvcC1jb2xvcj0iI0YwRjBGMCIgc3RvcC1vcGFjaXR5PSIwIi8+CiAgICAgICAgPC9saW5lYXJHcmFkaWVudD4KICAgICAgICA8bWFzayBpZD0iZmFkZU1hc2siPgogICAgICAgICAgICA8cmVjdCB4PSIwIiB5PSIwIiB3aWR0aD0iNzUwIiBoZWlnaHQ9IjUwIiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSI1MCIgZmlsbD0idXJsKCNmYWRlR3JhZGllbnQpIi8+CiAgICAgICAgPC9tYXNrPgogICAgPC9kZWZzPgogICAgPHBhdGggZD0iTTI1LDUwIFEwLDUwIDAsMjUgTDUwLDMgTDk3LDI1IEw3OTcsMjUgTDc5Nyw1MCBMMjUsNTAgWiIgZmlsbD0iI0YwRjBGMCIgc3Ryb2tlPSIjRTBFMEUwIiBzdHJva2Utd2lkdGg9IjEiIG1hc2s9InVybCgjZmFkZU1hc2spIi8+Cjwvc3ZnPgo=\" alt=\"Time alert close\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "That training was performed on a subset of data. To load a fully trained PEFT model, read a checkpoint of a PEFT model from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/adapter_config.json to peft-dialogue-summary-checkpoint-from-s3/adapter_config.json\n",
      "download: s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/special_tokens_map.json to peft-dialogue-summary-checkpoint-from-s3/special_tokens_map.json\n",
      "download: s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/tokenizer_config.json to peft-dialogue-summary-checkpoint-from-s3/tokenizer_config.json\n",
      "download: s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/tokenizer.json to peft-dialogue-summary-checkpoint-from-s3/tokenizer.json\n",
      "download: s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/adapter_model.bin to peft-dialogue-summary-checkpoint-from-s3/adapter_model.bin\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/ ./peft-dialogue-summary-checkpoint-from-s3/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Check that the size of this model is much less than the original LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 14208525 May 15 11:18 ./peft-dialogue-summary-checkpoint-from-s3/adapter_model.bin\n"
     ]
    }
   ],
   "source": [
    "!ls -al ./peft-dialogue-summary-checkpoint-from-s3/adapter_model.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Prepare this model by adding an adapter to the original FLAN-T5 model. You are setting `is_trainable=False` because the plan is only to perform inference with this PEFT model. If you were preparing the model for further training, you would set `is_trainable=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "peft_model_base = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\", torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "\n",
    "# peft_model = PeftModel.from_pretrained(peft_model_base, \n",
    "#                                        './peft-dialogue-summary-checkpoint-local/', \n",
    "#                                        torch_dtype=torch.bfloat16,\n",
    "#                                        is_trainable=False)\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(peft_model_base, \n",
    "                                       output_dir, \n",
    "                                       torch_dtype=torch.bfloat16,\n",
    "                                       is_trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The number of trainable parameters will be `0` due to `is_trainable=False` setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 0\n",
      "all model parameters: 251116800\n",
      "percentage of trainable model parameters: 0.00%\n"
     ]
    }
   ],
   "source": [
    "print(print_number_of_trainable_model_parameters(peft_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 3538944\n",
      "all model parameters: 251116800\n",
      "percentage of trainable model parameters: 1.41%\n"
     ]
    }
   ],
   "source": [
    "print(print_number_of_trainable_model_parameters(peft_trainer.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model = peft_trainer.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.3'></a>\n",
    "### 3.3 - Evaluate the Model Qualitatively (Human Evaluation)\n",
    "\n",
    "Make inferences for the same example as in sections [1.3](#1.3) and [2.3](#2.3), with the original model, fully fine-tuned and PEFT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "ORIGINAL MODEL:\n",
      "#Person1# recommends #Person2# to upgrade #Person2#'s system. #Person2# suggests #Person1# consider adding a painting program to the system, and #Person2# might consider adding a CD-ROM drive. #Person2# thinks #Person2#'s system is outdated. #Person2# thinks it's worth adding a CD-ROM drive.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INSTRUCT MODEL:\n",
      "You might want to upgrade your computer.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL:\n",
      " #Person2# wants to upgrade the system and add a painting program to the software. #Person1# suggests adding a CD-ROM drive and a CD-ROM drive.\n"
     ]
    }
   ],
   "source": [
    "index = 200\n",
    "dialogue = dataset['test'][index]['dialogue']\n",
    "baseline_human_summary = dataset['test'][index]['summary']\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "Summary: \"\"\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
    "original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "instruct_model_outputs = instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
    "instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "peft_model_outputs = peft_model.to(device).generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
    "peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{human_baseline_summary}')\n",
    "print(dash_line)\n",
    "print(f'ORIGINAL MODEL:\\n{original_model_text_output}')\n",
    "print(dash_line)\n",
    "print(f'INSTRUCT MODEL:\\n{instruct_model_text_output}')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL:\\n {peft_model_text_output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.4'></a>\n",
    "### 3.4 - Evaluate the Model Quantitatively (with ROUGE Metric)\n",
    "Perform inferences for the sample of the test dataset (only 10 dialogues and summaries to save time). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human_baseline_summaries</th>\n",
       "      <th>original_model_summaries</th>\n",
       "      <th>instruct_model_summaries</th>\n",
       "      <th>peft_model_summaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ms. Dawson helps #Person1# to write a memo to ...</td>\n",
       "      <td>#Person2# tells #Person1# that instant messagi...</td>\n",
       "      <td>This memo is to be distributed to all employee...</td>\n",
       "      <td>#Person1# wants to give a dictation to all emp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In order to prevent employees from wasting tim...</td>\n",
       "      <td>Ms. Dawson tells M. Dawson that all communicat...</td>\n",
       "      <td>This memo is to be distributed to all employee...</td>\n",
       "      <td>#Person1# tells #Person2# that all office comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ms. Dawson takes a dictation for #Person1# abo...</td>\n",
       "      <td>#Person1# wants to take a memo for Ms. Dawson....</td>\n",
       "      <td>This memo is to be distributed to all employee...</td>\n",
       "      <td>#Person1# asks Ms. Dawson to tell #Person2# ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Person2# arrives late because of traffic jam....</td>\n",
       "      <td>#Person2# is stuck in traffic again. #Person1#...</td>\n",
       "      <td>Taking public transport to work is a good idea.</td>\n",
       "      <td>#Person2# is getting stuck in traffic. #Person...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Person2# decides to follow #Person1#'s sugges...</td>\n",
       "      <td>#Person2# is stuck in traffic. #Person1# think...</td>\n",
       "      <td>Taking public transport to work is a good idea.</td>\n",
       "      <td>#Person1# tells #Person2# that #Person2# got s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#Person2# complains to #Person1# about the tra...</td>\n",
       "      <td>#Person2# is stuck in traffic and is worried a...</td>\n",
       "      <td>Taking public transport to work is a good idea.</td>\n",
       "      <td>#Person2# is stuck in traffic. #Person1# think...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#Person1# tells Kate that Masha and Hero get d...</td>\n",
       "      <td>Kate tells #Person2# that Masha and Hero are g...</td>\n",
       "      <td>Masha and Hero are getting divorced.</td>\n",
       "      <td>#Person1# tells Kate that Masha and Hero are g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#Person1# tells Kate that Masha and Hero are g...</td>\n",
       "      <td>Masha and Hero are getting divorced. Kate is s...</td>\n",
       "      <td>Masha and Hero are getting divorced.</td>\n",
       "      <td>#Person2# tells Kate that Masha and Hero are g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>#Person1# and Kate talk about the divorce betw...</td>\n",
       "      <td>#Person1# tells #Person2# that Masha and Hero ...</td>\n",
       "      <td>Masha and Hero are getting divorced.</td>\n",
       "      <td>Kate and #Person1# are surprised that Masha an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#Person1# and Brian are at the birthday party ...</td>\n",
       "      <td>Brian invites #Person1# to dance with #Person2...</td>\n",
       "      <td>Brian's birthday is coming up.</td>\n",
       "      <td>Brian remembers his birthday and asks #Person1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            human_baseline_summaries  \\\n",
       "0  Ms. Dawson helps #Person1# to write a memo to ...   \n",
       "1  In order to prevent employees from wasting tim...   \n",
       "2  Ms. Dawson takes a dictation for #Person1# abo...   \n",
       "3  #Person2# arrives late because of traffic jam....   \n",
       "4  #Person2# decides to follow #Person1#'s sugges...   \n",
       "5  #Person2# complains to #Person1# about the tra...   \n",
       "6  #Person1# tells Kate that Masha and Hero get d...   \n",
       "7  #Person1# tells Kate that Masha and Hero are g...   \n",
       "8  #Person1# and Kate talk about the divorce betw...   \n",
       "9  #Person1# and Brian are at the birthday party ...   \n",
       "\n",
       "                            original_model_summaries  \\\n",
       "0  #Person2# tells #Person1# that instant messagi...   \n",
       "1  Ms. Dawson tells M. Dawson that all communicat...   \n",
       "2  #Person1# wants to take a memo for Ms. Dawson....   \n",
       "3  #Person2# is stuck in traffic again. #Person1#...   \n",
       "4  #Person2# is stuck in traffic. #Person1# think...   \n",
       "5  #Person2# is stuck in traffic and is worried a...   \n",
       "6  Kate tells #Person2# that Masha and Hero are g...   \n",
       "7  Masha and Hero are getting divorced. Kate is s...   \n",
       "8  #Person1# tells #Person2# that Masha and Hero ...   \n",
       "9  Brian invites #Person1# to dance with #Person2...   \n",
       "\n",
       "                            instruct_model_summaries  \\\n",
       "0  This memo is to be distributed to all employee...   \n",
       "1  This memo is to be distributed to all employee...   \n",
       "2  This memo is to be distributed to all employee...   \n",
       "3    Taking public transport to work is a good idea.   \n",
       "4    Taking public transport to work is a good idea.   \n",
       "5    Taking public transport to work is a good idea.   \n",
       "6               Masha and Hero are getting divorced.   \n",
       "7               Masha and Hero are getting divorced.   \n",
       "8               Masha and Hero are getting divorced.   \n",
       "9                     Brian's birthday is coming up.   \n",
       "\n",
       "                                peft_model_summaries  \n",
       "0  #Person1# wants to give a dictation to all emp...  \n",
       "1  #Person1# tells #Person2# that all office comm...  \n",
       "2  #Person1# asks Ms. Dawson to tell #Person2# ab...  \n",
       "3  #Person2# is getting stuck in traffic. #Person...  \n",
       "4  #Person1# tells #Person2# that #Person2# got s...  \n",
       "5  #Person2# is stuck in traffic. #Person1# think...  \n",
       "6  #Person1# tells Kate that Masha and Hero are g...  \n",
       "7  #Person2# tells Kate that Masha and Hero are g...  \n",
       "8  Kate and #Person1# are surprised that Masha an...  \n",
       "9  Brian remembers his birthday and asks #Person1...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogues = dataset['test'][0:10]['dialogue']\n",
    "human_baseline_summaries = dataset['test'][0:10]['summary']\n",
    "\n",
    "original_model_summaries = []\n",
    "instruct_model_summaries = []\n",
    "peft_model_summaries = []\n",
    "\n",
    "for idx, dialogue in enumerate(dialogues):\n",
    "    prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "Summary: \"\"\"\n",
    "    \n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to('cuda')\n",
    "\n",
    "    human_baseline_text_output = human_baseline_summaries[idx]\n",
    "    \n",
    "    original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    instruct_model_outputs = instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    peft_model_outputs = peft_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    original_model_summaries.append(original_model_text_output)\n",
    "    instruct_model_summaries.append(instruct_model_text_output)\n",
    "    peft_model_summaries.append(peft_model_text_output)\n",
    "\n",
    "zipped_summaries = list(zip(human_baseline_summaries, original_model_summaries, instruct_model_summaries, peft_model_summaries))\n",
    " \n",
    "df = pd.DataFrame(zipped_summaries, columns = ['human_baseline_summaries', 'original_model_summaries', 'instruct_model_summaries', 'peft_model_summaries'])\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Compute ROUGE score for this subset of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL MODEL:\n",
      "{'rouge1': 0.3722904486031801, 'rouge2': 0.11483780833755494, 'rougeL': 0.264589993037062, 'rougeLsum': 0.26665062796456995}\n",
      "INSTRUCT MODEL:\n",
      "{'rouge1': 0.28647748040489973, 'rouge2': 0.13497482028216662, 'rougeL': 0.23619027925479535, 'rougeLsum': 0.23930701616185485}\n",
      "PEFT MODEL:\n",
      "{'rouge1': 0.3836320336809933, 'rouge2': 0.13163962399580614, 'rougeL': 0.2892582353047469, 'rougeLsum': 0.2923788573727374}\n"
     ]
    }
   ],
   "source": [
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "original_model_results = rouge.compute(\n",
    "    predictions=original_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "instruct_model_results = rouge.compute(\n",
    "    predictions=instruct_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(instruct_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "peft_model_results = rouge.compute(\n",
    "    predictions=peft_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(peft_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "print('ORIGINAL MODEL:')\n",
    "print(original_model_results)\n",
    "print('INSTRUCT MODEL:')\n",
    "print(instruct_model_results)\n",
    "print('PEFT MODEL:')\n",
    "print(peft_model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice, that PEFT model results are not too bad, while the training process was much easier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You already computed ROUGE score on the full dataset, after loading the results from the `data/dialogue-summary-training-results.csv` file. Load the values for the PEFT model now and check its performance compared to other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL MODEL:\n",
      "{'rouge1': 0.2334158581572823, 'rouge2': 0.07603964187010573, 'rougeL': 0.20145520923859048, 'rougeLsum': 0.20145899339006135}\n",
      "INSTRUCT MODEL:\n",
      "{'rouge1': 0.42161291557556113, 'rouge2': 0.18035380596301792, 'rougeL': 0.3384439349963909, 'rougeLsum': 0.33835653595561666}\n",
      "PEFT MODEL:\n",
      "{'rouge1': 0.40810631575616746, 'rouge2': 0.1633255794568712, 'rougeL': 0.32507074586565354, 'rougeLsum': 0.3248950182867091}\n"
     ]
    }
   ],
   "source": [
    "human_baseline_summaries = results['human_baseline_summaries'].values\n",
    "original_model_summaries = results['original_model_summaries'].values\n",
    "instruct_model_summaries = results['instruct_model_summaries'].values\n",
    "peft_model_summaries     = results['peft_model_summaries'].values\n",
    "\n",
    "original_model_results = rouge.compute(\n",
    "    predictions=original_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "instruct_model_results = rouge.compute(\n",
    "    predictions=instruct_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(instruct_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "peft_model_results = rouge.compute(\n",
    "    predictions=peft_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(peft_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "print('ORIGINAL MODEL:')\n",
    "print(original_model_results)\n",
    "print('INSTRUCT MODEL:')\n",
    "print(instruct_model_results)\n",
    "print('PEFT MODEL:')\n",
    "print(peft_model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show less of an improvement over full fine-tuning, but the benefits of PEFT typically outweigh the slightly-lower performance metrics.\n",
    "\n",
    "Calculate the improvement of PEFT over the original model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute percentage improvement of PEFT MODEL over HUMAN BASELINE\n",
      "rouge1: 17.47%\n",
      "rouge2: 8.73%\n",
      "rougeL: 12.36%\n",
      "rougeLsum: 12.34%\n"
     ]
    }
   ],
   "source": [
    "print(\"Absolute percentage improvement of PEFT MODEL over HUMAN BASELINE\")\n",
    "\n",
    "improvement = (np.array(list(peft_model_results.values())) - np.array(list(original_model_results.values())))\n",
    "for key, value in zip(peft_model_results.keys(), improvement):\n",
    "    print(f'{key}: {value*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate the improvement of PEFT over a full fine-tuned model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute percentage improvement of PEFT MODEL over INSTRUCT MODEL\n",
      "rouge1: -1.35%\n",
      "rouge2: -1.70%\n",
      "rougeL: -1.34%\n",
      "rougeLsum: -1.35%\n"
     ]
    }
   ],
   "source": [
    "print(\"Absolute percentage improvement of PEFT MODEL over INSTRUCT MODEL\")\n",
    "\n",
    "improvement = (np.array(list(peft_model_results.values())) - np.array(list(instruct_model_results.values())))\n",
    "for key, value in zip(peft_model_results.keys(), improvement):\n",
    "    print(f'{key}: {value*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you see a small percentage decrease in the ROUGE metrics vs. full fine-tuned. However, the training requires much less computing and memory resources (often just a single GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "colab": {
   "name": "Fine-tune a language model",
   "provenance": []
  },
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "learning_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
