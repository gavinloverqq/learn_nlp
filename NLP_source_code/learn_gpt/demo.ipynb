{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 语言模型是什么？\n",
    "\n",
    "* Tom was watching TV in his room. Mary came into the room. Mary said hi to ??\n",
    "\n",
    "## RNN 与 Transformer\n",
    "- 用时间序列解决sec to sec 问题, 求b4的时候要考虑到a1 - a3\n",
    "- 求b4的时候，要前面几个中间层的weights都要求出来，因此无法并行\n",
    "- attention 机制就是解决无法并行的问题\n",
    "\n",
    "![Alt text](image.png)\n",
    "\n",
    "\n",
    "- > 李宏毅视频 <https://www.youtube.com/watch?v=ugWDIIOHtPA>  以及PPT <http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.html>\n",
    "- > andrej 视频 <https://www.youtube.com/watch?v=kCc8FmEb1nY&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=7&t=2526s>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer\n",
    "![Alt text](image-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single head attention\n",
    "![Alt text](image-2.png)\n",
    "\n",
    "![Alt text](image-6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multihead Attention\n",
    "![Alt text](image-4.png)\n",
    "\n",
    "![Alt text](image-7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# position encoding\n",
    "\n",
    "![Alt text](image-8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# layer normalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT\n",
    "## PreTtrain\n",
    "- Transformer\n",
    "## Fine tune and RLHF\n",
    "![Alt text](image-5.png)\n",
    "\n",
    "- > https://openai.com/research/instruction-following\n",
    "- > https://zhuanlan.zhihu.com/p/590311003"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.401665 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/frog/anaconda3/envs/learning_dl/lib/python3.11/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py\", line 945, in trace_dispatch\n",
      "    self.do_wait_suspend(thread, frame, event, arg)\n",
      "  File \"/home/frog/anaconda3/envs/learning_dl/lib/python3.11/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py\", line 164, in do_wait_suspend\n",
      "    self._args[0].do_wait_suspend(*args, **kwargs)\n",
      "  File \"/home/frog/anaconda3/envs/learning_dl/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 1976, in do_wait_suspend\n",
      "    keep_suspended = self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/frog/anaconda3/envs/learning_dl/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 2011, in _do_wait_suspend\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=193'>194</a>\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39miter\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_iters):\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=194'>195</a>\u001b[0m \n\u001b[1;32m    <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=195'>196</a>\u001b[0m     \u001b[39m# every once in a while evaluate the loss on train and val sets\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=196'>197</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39miter\u001b[39m \u001b[39m%\u001b[39m eval_interval \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39miter\u001b[39m \u001b[39m==\u001b[39m max_iters \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=197'>198</a>\u001b[0m         losses \u001b[39m=\u001b[39m estimate_loss()\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=198'>199</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstep \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39miter\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: train loss \u001b[39m\u001b[39m{\u001b[39;00mlosses[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, val loss \u001b[39m\u001b[39m{\u001b[39;00mlosses[\u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=200'>201</a>\u001b[0m     \u001b[39m# sample a batch of data\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/learning_dl/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb Cell 9\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(eval_iters):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     X, Y \u001b[39m=\u001b[39m get_batch(split)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     logits, loss \u001b[39m=\u001b[39m model(X, Y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     losses[k] \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m out[split] \u001b[39m=\u001b[39m losses\u001b[39m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/anaconda3/envs/learning_dl/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=152'>153</a>\u001b[0m pos_emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embedding_table(torch\u001b[39m.\u001b[39marange(T, device\u001b[39m=\u001b[39mdevice)) \u001b[39m# (T,C)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=153'>154</a>\u001b[0m x \u001b[39m=\u001b[39m tok_emb \u001b[39m+\u001b[39m pos_emb \u001b[39m# (B,T,C)\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=154'>155</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblocks(x) \u001b[39m# (B,T,C)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=155'>156</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_f(x) \u001b[39m# (B,T,C)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=156'>157</a>\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlm_head(x) \u001b[39m# (B,T,vocab_size)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/learning_dl/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/learning_dl/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/learning_dl/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=130'>131</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=131'>132</a>\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msa(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mln1(x))\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=132'>133</a>\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mffwd(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln2(x))\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=133'>134</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/learning_dl/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m     out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([h(x) \u001b[39mfor\u001b[39;49;00m h \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheads], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproj(out))\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "\u001b[1;32m/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m     out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([h(x) \u001b[39mfor\u001b[39;00m h \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheads], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproj(out))\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/envs/learning_dl/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb Cell 9\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue(x) \u001b[39m# (B,T,C)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m out \u001b[39m=\u001b[39m wei \u001b[39m@\u001b[39m v \u001b[39m# (B, T, T) @ (B, T, C) -> (B, T, C)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "\u001b[1;32m/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb Cell 9\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue(x) \u001b[39m# (B,T,C)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m out \u001b[39m=\u001b[39m wei \u001b[39m@\u001b[39m v \u001b[39m# (B, T, T) @ (B, T, C) -> (B, T, C)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/frog/Code/NLP/NLP_source_code/learn_gpt/demo.ipynb#X11sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/envs/learning_dl/lib/python3.11/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:945\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[39m# if thread has a suspend flag, we suspend with a busy wait\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[39mif\u001b[39;00m info\u001b[39m.\u001b[39mpydev_state \u001b[39m==\u001b[39m STATE_SUSPEND:\n\u001b[0;32m--> 945\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_wait_suspend(thread, frame, event, arg)\n\u001b[1;32m    946\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrace_dispatch\n\u001b[1;32m    947\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/learning_dl/lib/python3.11/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:164\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_wait_suspend\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 164\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_args[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mdo_wait_suspend(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/learning_dl/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:1976\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   1973\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   1975\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001b[0;32m-> 1976\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[1;32m   1978\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1980\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   1981\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/learning_dl/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2011\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_mpl_hook()\n\u001b[1;32m   2010\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2011\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.01\u001b[39m)\n\u001b[1;32m   2013\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[1;32m   2015\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 64 # how many independent sequences will we process in parallel?\n",
    "block_size = 256 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 516\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2\n",
    "# ------------\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "# super simple bigram model\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) # vocab_size个词，用从n_embd 维向量表示 Embedding的输入形状N×W，N是batch size，W是序列的长度，输出的形状是N×W×embedding_dim。\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SLY:\n",
      "Part, good-morrow; gentlemen!\n",
      "\n",
      "JULIET:\n",
      "O sack, shut!\n",
      "Most and hum good holds to lether growe to shrunk.\n",
      "\n",
      "FLORIZEL:\n",
      "My good mother, whom, it was your father commend,\n",
      "On up to his talk of him.\n",
      "\n",
      "CAMILLO:\n",
      "Why, is alliance?\n",
      "O my glory\n",
      "I come, good friend, and conclude 's held;' promised,\n",
      "To grudge me with him own and bodies would,\n",
      "I have firmly over-quench at tongue the world.\n",
      "\n",
      "FLORIZEL:\n",
      "O POMPEY:\n",
      "Womenes so that the rebels should object\n",
      "To help accuse it in your arms' gage;\n",
      "Justice finds it the pray: for the office,\n",
      "Wheneither you make us some new with you\n",
      "Of our of success with herself.\n",
      "\n",
      "LORTENSON:\n",
      "My lord, the noble husband hast.\n",
      "\n",
      "PAULINA:\n",
      "I have wounded.\n",
      "\n",
      "LEONTES:\n",
      "Why, breathe how that account!\n",
      "Though a brazen sight instruction,\n",
      "How far glash is there! Is this the morning hock,\n",
      "Sometime puts the hheavy singing strutless tongue\n",
      "That but beyond that parts the strength on.\n",
      "I should draw her where out at kind\n",
      "That would I blaze out? But thou trailly it will\n",
      "Ere thy bone in life, to make am death together,\n",
      "On earth, and it still then how prefixes.\n",
      "\n",
      "ISABELLA:\n",
      "O, make an ill answer night,\n",
      "Or else in the morning thunds of their walls.\n",
      "King Henceford and Clarence is his fortune:\n",
      "Your brother is a paece did embrate your head\n",
      "From this land another beneve to the gate,\n",
      "The young princess for your bed. So, tratling\n",
      "Ascend al the every first flesh horses!\n",
      "\n",
      "CLAUDIO:\n",
      "But now, fair myself to our dear blood?\n",
      "Be in this morning's poor worthin and twenty;\n",
      "For never take proplexing the streems of pen;\n",
      "Whither they wees breathe hurs in the sky.\n",
      "Father, fair fair glorious hand I banish my foot.\n",
      "Now broad of just lords before his womb,\n",
      "That my brother Edward whose iscarle wought\n",
      "With ourself now with hath much become the splot.\n",
      "What shall we pronounce in your heading bless\n",
      "Because I could speak with sighs. Take your children\n",
      "Into the marber's soul, and to dry your grave.\n",
      "\n",
      "KING EDWARD IV:\n",
      "So, Clifford, farewell, offorencators:\n",
      "Clarence, how dost thou buy another spirit.\n",
      "Come on fooly E\n"
     ]
    }
   ],
   "source": [
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
